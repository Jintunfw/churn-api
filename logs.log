2025-12-01 16:05:55,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:05:55,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:05:55,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:05:55,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:06:14,260:INFO:PyCaret ClassificationExperiment
2025-12-01 16:06:14,260:INFO:Logging name: clf-default-name
2025-12-01 16:06:14,260:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 16:06:14,260:INFO:version 3.3.2
2025-12-01 16:06:14,260:INFO:Initializing setup()
2025-12-01 16:06:14,260:INFO:self.USI: dbab
2025-12-01 16:06:14,260:INFO:self._variable_keys: {'n_jobs_param', 'is_multiclass', 'fix_imbalance', 'X', 'gpu_param', 'data', 'gpu_n_jobs_param', 'log_plots_param', 'exp_name_log', 'html_param', 'idx', '_available_plots', '_ml_usecase', 'seed', 'y_train', 'y', 'y_test', 'target_param', 'USI', 'memory', 'pipeline', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'X_train', 'fold_generator', 'X_test', 'logging_param'}
2025-12-01 16:06:14,260:INFO:Checking environment
2025-12-01 16:06:14,260:INFO:python_version: 3.11.14
2025-12-01 16:06:14,260:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-01 16:06:14,260:INFO:machine: arm64
2025-12-01 16:06:14,260:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:06:14,260:INFO:Memory: svmem(total=8589934592, available=1619574784, percent=81.1, used=3277766656, free=70565888, active=1558528000, inactive=1530216448, wired=1719238656)
2025-12-01 16:06:14,260:INFO:Physical Core: 8
2025-12-01 16:06:14,260:INFO:Logical Core: 8
2025-12-01 16:06:14,260:INFO:Checking libraries
2025-12-01 16:06:14,260:INFO:System:
2025-12-01 16:06:14,260:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-01 16:06:14,260:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-01 16:06:14,260:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:06:14,260:INFO:PyCaret required dependencies:
2025-12-01 16:06:14,261:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:27,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:10:27,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:10:27,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:10:27,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 16:10:37,401:INFO:PyCaret ClassificationExperiment
2025-12-01 16:10:37,401:INFO:Logging name: clf-default-name
2025-12-01 16:10:37,401:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 16:10:37,401:INFO:version 3.3.2
2025-12-01 16:10:37,401:INFO:Initializing setup()
2025-12-01 16:10:37,401:INFO:self.USI: 4e8d
2025-12-01 16:10:37,402:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-01 16:10:37,402:INFO:Checking environment
2025-12-01 16:10:37,402:INFO:python_version: 3.11.14
2025-12-01 16:10:37,402:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-01 16:10:37,402:INFO:machine: arm64
2025-12-01 16:10:37,402:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:10:37,402:INFO:Memory: svmem(total=8589934592, available=1666498560, percent=80.6, used=3114401792, free=66289664, active=1613627392, inactive=1585053696, wired=1500774400)
2025-12-01 16:10:37,402:INFO:Physical Core: 8
2025-12-01 16:10:37,402:INFO:Logical Core: 8
2025-12-01 16:10:37,402:INFO:Checking libraries
2025-12-01 16:10:37,402:INFO:System:
2025-12-01 16:10:37,402:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-01 16:10:37,402:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-01 16:10:37,402:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:10:37,402:INFO:PyCaret required dependencies:
2025-12-01 16:10:37,403:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:37,796:INFO:                 pip: 25.3
2025-12-01 16:10:37,796:INFO:          setuptools: 80.9.0
2025-12-01 16:10:37,796:INFO:             pycaret: 3.3.2
2025-12-01 16:10:37,796:INFO:             IPython: 9.7.0
2025-12-01 16:10:37,796:INFO:          ipywidgets: 8.1.8
2025-12-01 16:10:37,796:INFO:                tqdm: 4.67.1
2025-12-01 16:10:37,796:INFO:               numpy: 1.26.4
2025-12-01 16:10:37,796:INFO:              pandas: 2.1.4
2025-12-01 16:10:37,796:INFO:              jinja2: 3.1.6
2025-12-01 16:10:37,797:INFO:               scipy: 1.11.4
2025-12-01 16:10:37,797:INFO:              joblib: 1.3.2
2025-12-01 16:10:37,797:INFO:             sklearn: 1.4.2
2025-12-01 16:10:37,797:INFO:                pyod: 2.0.5
2025-12-01 16:10:37,797:INFO:            imblearn: 0.14.0
2025-12-01 16:10:37,797:INFO:   category_encoders: 2.7.0
2025-12-01 16:10:37,797:INFO:            lightgbm: 4.6.0
2025-12-01 16:10:37,797:INFO:               numba: 0.62.1
2025-12-01 16:10:37,797:INFO:            requests: 2.32.5
2025-12-01 16:10:37,797:INFO:          matplotlib: 3.7.5
2025-12-01 16:10:37,797:INFO:          scikitplot: 0.3.7
2025-12-01 16:10:37,797:INFO:         yellowbrick: 1.5
2025-12-01 16:10:37,797:INFO:              plotly: 6.5.0
2025-12-01 16:10:37,797:INFO:    plotly-resampler: Not installed
2025-12-01 16:10:37,797:INFO:             kaleido: 1.2.0
2025-12-01 16:10:37,797:INFO:           schemdraw: 0.15
2025-12-01 16:10:37,797:INFO:         statsmodels: 0.14.5
2025-12-01 16:10:37,797:INFO:              sktime: 0.26.0
2025-12-01 16:10:37,797:INFO:               tbats: 1.1.3
2025-12-01 16:10:37,797:INFO:            pmdarima: 2.0.4
2025-12-01 16:10:37,797:INFO:              psutil: 7.1.3
2025-12-01 16:10:37,797:INFO:          markupsafe: 3.0.3
2025-12-01 16:10:37,797:INFO:             pickle5: Not installed
2025-12-01 16:10:37,797:INFO:         cloudpickle: 3.1.2
2025-12-01 16:10:37,797:INFO:         deprecation: 2.1.0
2025-12-01 16:10:37,797:INFO:              xxhash: 3.6.0
2025-12-01 16:10:37,797:INFO:           wurlitzer: 3.1.1
2025-12-01 16:10:37,797:INFO:PyCaret optional dependencies:
2025-12-01 16:10:37,803:INFO:                shap: Not installed
2025-12-01 16:10:37,803:INFO:           interpret: Not installed
2025-12-01 16:10:37,803:INFO:                umap: Not installed
2025-12-01 16:10:37,803:INFO:     ydata_profiling: Not installed
2025-12-01 16:10:37,803:INFO:  explainerdashboard: Not installed
2025-12-01 16:10:37,803:INFO:             autoviz: Not installed
2025-12-01 16:10:37,803:INFO:           fairlearn: Not installed
2025-12-01 16:10:37,803:INFO:          deepchecks: Not installed
2025-12-01 16:10:37,803:INFO:             xgboost: Not installed
2025-12-01 16:10:37,803:INFO:            catboost: Not installed
2025-12-01 16:10:37,803:INFO:              kmodes: Not installed
2025-12-01 16:10:37,803:INFO:             mlxtend: Not installed
2025-12-01 16:10:37,803:INFO:       statsforecast: Not installed
2025-12-01 16:10:37,803:INFO:        tune_sklearn: Not installed
2025-12-01 16:10:37,803:INFO:                 ray: Not installed
2025-12-01 16:10:37,803:INFO:            hyperopt: Not installed
2025-12-01 16:10:37,803:INFO:              optuna: Not installed
2025-12-01 16:10:37,803:INFO:               skopt: Not installed
2025-12-01 16:10:37,803:INFO:              mlflow: Not installed
2025-12-01 16:10:37,803:INFO:              gradio: Not installed
2025-12-01 16:10:37,803:INFO:             fastapi: Not installed
2025-12-01 16:10:37,803:INFO:             uvicorn: Not installed
2025-12-01 16:10:37,803:INFO:              m2cgen: Not installed
2025-12-01 16:10:37,803:INFO:           evidently: Not installed
2025-12-01 16:10:37,803:INFO:               fugue: Not installed
2025-12-01 16:10:37,803:INFO:           streamlit: Not installed
2025-12-01 16:10:37,803:INFO:             prophet: Not installed
2025-12-01 16:10:37,803:INFO:None
2025-12-01 16:10:37,803:INFO:Set up data.
2025-12-01 16:10:37,809:INFO:Set up folding strategy.
2025-12-01 16:10:37,809:INFO:Set up train/test split.
2025-12-01 16:10:37,818:INFO:Set up index.
2025-12-01 16:10:37,819:INFO:Assigning column types.
2025-12-01 16:10:37,823:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 16:10:37,840:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,881:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 16:10:37,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:10:37,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,935:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 16:10:37,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:37,992:INFO:Preparing preprocessing pipeline...
2025-12-01 16:10:37,996:INFO:Set up simple imputation.
2025-12-01 16:10:37,996:INFO:Set up imbalanced handling.
2025-12-01 16:10:37,996:INFO:Set up column name cleaning.
2025-12-01 16:10:38,223:INFO:Finished creating preprocessing pipeline.
2025-12-01 16:10:38,226:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['gender', 'age', 'under_30',
                                             'senior_citizen', 'partner',
                                             'dependents',
                                             'number_of_dependents', 'married',
                                             'paperless_billing',
                                             'monthly_ charges',
                                             'avg_monthly_long_distance_charges',
                                             'total_charges'...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-01 16:10:38,226:INFO:Creating final display dataframe.
2025-12-01 16:10:38,387:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 44)
4        Transformed data shape        (9687, 44)
5   Transformed train set shape        (8278, 44)
6    Transformed test set shape        (1409, 44)
7              Numeric features                32
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              4e8d
2025-12-01 16:10:38,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:38,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:38,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:38,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:10:38,454:INFO:setup() successfully completed in 1.06s...............
2025-12-01 16:10:38,455:INFO:Initializing compare_models()
2025-12-01 16:10:38,455:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-01 16:10:38,455:INFO:Checking exceptions
2025-12-01 16:10:38,461:INFO:Preparing display monitor
2025-12-01 16:10:38,920:INFO:Initializing Logistic Regression
2025-12-01 16:10:38,920:INFO:Total runtime is 2.3166338602701823e-06 minutes
2025-12-01 16:10:38,921:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:38,922:INFO:Initializing create_model()
2025-12-01 16:10:38,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:38,922:INFO:Checking exceptions
2025-12-01 16:10:38,922:INFO:Importing libraries
2025-12-01 16:10:38,922:INFO:Copying training dataset
2025-12-01 16:10:38,930:INFO:Defining folds
2025-12-01 16:10:38,930:INFO:Declaring metric variables
2025-12-01 16:10:38,931:INFO:Importing untrained model
2025-12-01 16:10:38,933:INFO:Logistic Regression Imported successfully
2025-12-01 16:10:38,936:INFO:Starting cross validation
2025-12-01 16:10:38,937:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:42,086:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:42,109:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:42,134:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:42,140:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:42,147:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:42,565:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:42,582:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:42,588:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:42,596:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:42,930:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:42,946:INFO:Calculating mean and std
2025-12-01 16:10:42,949:INFO:Creating metrics dataframe
2025-12-01 16:10:42,960:INFO:Uploading results into container
2025-12-01 16:10:42,960:INFO:Uploading model into container now
2025-12-01 16:10:42,961:INFO:_master_model_container: 1
2025-12-01 16:10:42,961:INFO:_display_container: 2
2025-12-01 16:10:42,962:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:10:42,962:INFO:create_model() successfully completed......................................
2025-12-01 16:10:43,071:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:43,071:INFO:Creating metrics dataframe
2025-12-01 16:10:43,075:INFO:Initializing K Neighbors Classifier
2025-12-01 16:10:43,075:INFO:Total runtime is 0.06924854914347331 minutes
2025-12-01 16:10:43,076:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:43,076:INFO:Initializing create_model()
2025-12-01 16:10:43,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:43,076:INFO:Checking exceptions
2025-12-01 16:10:43,077:INFO:Importing libraries
2025-12-01 16:10:43,077:INFO:Copying training dataset
2025-12-01 16:10:43,084:INFO:Defining folds
2025-12-01 16:10:43,084:INFO:Declaring metric variables
2025-12-01 16:10:43,085:INFO:Importing untrained model
2025-12-01 16:10:43,086:INFO:K Neighbors Classifier Imported successfully
2025-12-01 16:10:43,089:INFO:Starting cross validation
2025-12-01 16:10:43,090:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:44,633:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:44,633:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:44,633:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:10:44,841:INFO:Calculating mean and std
2025-12-01 16:10:44,849:INFO:Creating metrics dataframe
2025-12-01 16:10:44,865:INFO:Uploading results into container
2025-12-01 16:10:44,866:INFO:Uploading model into container now
2025-12-01 16:10:44,868:INFO:_master_model_container: 2
2025-12-01 16:10:44,868:INFO:_display_container: 2
2025-12-01 16:10:44,868:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 16:10:44,868:INFO:create_model() successfully completed......................................
2025-12-01 16:10:44,968:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:44,968:INFO:Creating metrics dataframe
2025-12-01 16:10:44,971:INFO:Initializing Naive Bayes
2025-12-01 16:10:44,971:INFO:Total runtime is 0.10085751612981161 minutes
2025-12-01 16:10:44,973:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:44,973:INFO:Initializing create_model()
2025-12-01 16:10:44,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:44,973:INFO:Checking exceptions
2025-12-01 16:10:44,973:INFO:Importing libraries
2025-12-01 16:10:44,973:INFO:Copying training dataset
2025-12-01 16:10:44,981:INFO:Defining folds
2025-12-01 16:10:44,981:INFO:Declaring metric variables
2025-12-01 16:10:44,982:INFO:Importing untrained model
2025-12-01 16:10:44,983:INFO:Naive Bayes Imported successfully
2025-12-01 16:10:44,988:INFO:Starting cross validation
2025-12-01 16:10:44,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:45,138:INFO:Calculating mean and std
2025-12-01 16:10:45,138:INFO:Creating metrics dataframe
2025-12-01 16:10:45,139:INFO:Uploading results into container
2025-12-01 16:10:45,139:INFO:Uploading model into container now
2025-12-01 16:10:45,139:INFO:_master_model_container: 3
2025-12-01 16:10:45,139:INFO:_display_container: 2
2025-12-01 16:10:45,140:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 16:10:45,140:INFO:create_model() successfully completed......................................
2025-12-01 16:10:45,192:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:45,192:INFO:Creating metrics dataframe
2025-12-01 16:10:45,195:INFO:Initializing Decision Tree Classifier
2025-12-01 16:10:45,195:INFO:Total runtime is 0.10458631515502931 minutes
2025-12-01 16:10:45,197:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:45,197:INFO:Initializing create_model()
2025-12-01 16:10:45,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:45,197:INFO:Checking exceptions
2025-12-01 16:10:45,197:INFO:Importing libraries
2025-12-01 16:10:45,197:INFO:Copying training dataset
2025-12-01 16:10:45,203:INFO:Defining folds
2025-12-01 16:10:45,203:INFO:Declaring metric variables
2025-12-01 16:10:45,205:INFO:Importing untrained model
2025-12-01 16:10:45,206:INFO:Decision Tree Classifier Imported successfully
2025-12-01 16:10:45,208:INFO:Starting cross validation
2025-12-01 16:10:45,208:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:45,398:INFO:Calculating mean and std
2025-12-01 16:10:45,399:INFO:Creating metrics dataframe
2025-12-01 16:10:45,400:INFO:Uploading results into container
2025-12-01 16:10:45,400:INFO:Uploading model into container now
2025-12-01 16:10:45,400:INFO:_master_model_container: 4
2025-12-01 16:10:45,400:INFO:_display_container: 2
2025-12-01 16:10:45,401:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-12-01 16:10:45,401:INFO:create_model() successfully completed......................................
2025-12-01 16:10:45,453:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:45,453:INFO:Creating metrics dataframe
2025-12-01 16:10:45,456:INFO:Initializing SVM - Linear Kernel
2025-12-01 16:10:45,456:INFO:Total runtime is 0.10894033114115398 minutes
2025-12-01 16:10:45,458:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:45,459:INFO:Initializing create_model()
2025-12-01 16:10:45,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:45,459:INFO:Checking exceptions
2025-12-01 16:10:45,459:INFO:Importing libraries
2025-12-01 16:10:45,459:INFO:Copying training dataset
2025-12-01 16:10:45,465:INFO:Defining folds
2025-12-01 16:10:45,465:INFO:Declaring metric variables
2025-12-01 16:10:45,466:INFO:Importing untrained model
2025-12-01 16:10:45,467:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 16:10:45,469:INFO:Starting cross validation
2025-12-01 16:10:45,470:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:45,701:INFO:Calculating mean and std
2025-12-01 16:10:45,701:INFO:Creating metrics dataframe
2025-12-01 16:10:45,704:INFO:Uploading results into container
2025-12-01 16:10:45,704:INFO:Uploading model into container now
2025-12-01 16:10:45,704:INFO:_master_model_container: 5
2025-12-01 16:10:45,705:INFO:_display_container: 2
2025-12-01 16:10:45,706:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 16:10:45,706:INFO:create_model() successfully completed......................................
2025-12-01 16:10:45,766:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:45,766:INFO:Creating metrics dataframe
2025-12-01 16:10:45,770:INFO:Initializing Ridge Classifier
2025-12-01 16:10:45,770:INFO:Total runtime is 0.11416711409886679 minutes
2025-12-01 16:10:45,772:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:45,772:INFO:Initializing create_model()
2025-12-01 16:10:45,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:45,772:INFO:Checking exceptions
2025-12-01 16:10:45,772:INFO:Importing libraries
2025-12-01 16:10:45,772:INFO:Copying training dataset
2025-12-01 16:10:45,779:INFO:Defining folds
2025-12-01 16:10:45,779:INFO:Declaring metric variables
2025-12-01 16:10:45,780:INFO:Importing untrained model
2025-12-01 16:10:45,781:INFO:Ridge Classifier Imported successfully
2025-12-01 16:10:45,784:INFO:Starting cross validation
2025-12-01 16:10:45,785:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:45,953:INFO:Calculating mean and std
2025-12-01 16:10:45,953:INFO:Creating metrics dataframe
2025-12-01 16:10:45,954:INFO:Uploading results into container
2025-12-01 16:10:45,954:INFO:Uploading model into container now
2025-12-01 16:10:45,954:INFO:_master_model_container: 6
2025-12-01 16:10:45,954:INFO:_display_container: 2
2025-12-01 16:10:45,954:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 16:10:45,954:INFO:create_model() successfully completed......................................
2025-12-01 16:10:46,092:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:46,093:INFO:Creating metrics dataframe
2025-12-01 16:10:46,106:INFO:Initializing Random Forest Classifier
2025-12-01 16:10:46,106:INFO:Total runtime is 0.11976736783981325 minutes
2025-12-01 16:10:46,107:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:46,108:INFO:Initializing create_model()
2025-12-01 16:10:46,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:46,108:INFO:Checking exceptions
2025-12-01 16:10:46,108:INFO:Importing libraries
2025-12-01 16:10:46,108:INFO:Copying training dataset
2025-12-01 16:10:46,117:INFO:Defining folds
2025-12-01 16:10:46,117:INFO:Declaring metric variables
2025-12-01 16:10:46,118:INFO:Importing untrained model
2025-12-01 16:10:46,119:INFO:Random Forest Classifier Imported successfully
2025-12-01 16:10:46,122:INFO:Starting cross validation
2025-12-01 16:10:46,124:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:47,051:INFO:Calculating mean and std
2025-12-01 16:10:47,055:INFO:Creating metrics dataframe
2025-12-01 16:10:47,064:INFO:Uploading results into container
2025-12-01 16:10:47,065:INFO:Uploading model into container now
2025-12-01 16:10:47,066:INFO:_master_model_container: 7
2025-12-01 16:10:47,066:INFO:_display_container: 2
2025-12-01 16:10:47,066:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-01 16:10:47,067:INFO:create_model() successfully completed......................................
2025-12-01 16:10:47,171:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:47,171:INFO:Creating metrics dataframe
2025-12-01 16:10:47,175:INFO:Initializing Quadratic Discriminant Analysis
2025-12-01 16:10:47,175:INFO:Total runtime is 0.13757853110631307 minutes
2025-12-01 16:10:47,176:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:47,176:INFO:Initializing create_model()
2025-12-01 16:10:47,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:47,176:INFO:Checking exceptions
2025-12-01 16:10:47,176:INFO:Importing libraries
2025-12-01 16:10:47,176:INFO:Copying training dataset
2025-12-01 16:10:47,183:INFO:Defining folds
2025-12-01 16:10:47,183:INFO:Declaring metric variables
2025-12-01 16:10:47,185:INFO:Importing untrained model
2025-12-01 16:10:47,186:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 16:10:47,188:INFO:Starting cross validation
2025-12-01 16:10:47,191:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:47,277:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:10:47,290:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:10:47,294:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:10:47,298:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:10:47,298:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:10:47,321:INFO:Calculating mean and std
2025-12-01 16:10:47,321:INFO:Creating metrics dataframe
2025-12-01 16:10:47,322:INFO:Uploading results into container
2025-12-01 16:10:47,322:INFO:Uploading model into container now
2025-12-01 16:10:47,322:INFO:_master_model_container: 8
2025-12-01 16:10:47,322:INFO:_display_container: 2
2025-12-01 16:10:47,323:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 16:10:47,323:INFO:create_model() successfully completed......................................
2025-12-01 16:10:47,369:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:47,369:INFO:Creating metrics dataframe
2025-12-01 16:10:47,372:INFO:Initializing Ada Boost Classifier
2025-12-01 16:10:47,373:INFO:Total runtime is 0.1408782482147217 minutes
2025-12-01 16:10:47,374:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:47,374:INFO:Initializing create_model()
2025-12-01 16:10:47,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:47,374:INFO:Checking exceptions
2025-12-01 16:10:47,374:INFO:Importing libraries
2025-12-01 16:10:47,374:INFO:Copying training dataset
2025-12-01 16:10:47,381:INFO:Defining folds
2025-12-01 16:10:47,381:INFO:Declaring metric variables
2025-12-01 16:10:47,382:INFO:Importing untrained model
2025-12-01 16:10:47,383:INFO:Ada Boost Classifier Imported successfully
2025-12-01 16:10:47,385:INFO:Starting cross validation
2025-12-01 16:10:47,386:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:47,447:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:10:47,447:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:10:47,453:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:10:47,459:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:10:47,461:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:10:47,966:INFO:Calculating mean and std
2025-12-01 16:10:47,967:INFO:Creating metrics dataframe
2025-12-01 16:10:47,967:INFO:Uploading results into container
2025-12-01 16:10:47,967:INFO:Uploading model into container now
2025-12-01 16:10:47,968:INFO:_master_model_container: 9
2025-12-01 16:10:47,968:INFO:_display_container: 2
2025-12-01 16:10:47,968:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-01 16:10:47,968:INFO:create_model() successfully completed......................................
2025-12-01 16:10:48,014:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:48,014:INFO:Creating metrics dataframe
2025-12-01 16:10:48,018:INFO:Initializing Gradient Boosting Classifier
2025-12-01 16:10:48,018:INFO:Total runtime is 0.15163021485010786 minutes
2025-12-01 16:10:48,019:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:48,019:INFO:Initializing create_model()
2025-12-01 16:10:48,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:48,019:INFO:Checking exceptions
2025-12-01 16:10:48,019:INFO:Importing libraries
2025-12-01 16:10:48,019:INFO:Copying training dataset
2025-12-01 16:10:48,025:INFO:Defining folds
2025-12-01 16:10:48,025:INFO:Declaring metric variables
2025-12-01 16:10:48,026:INFO:Importing untrained model
2025-12-01 16:10:48,027:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 16:10:48,029:INFO:Starting cross validation
2025-12-01 16:10:48,030:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:50,514:INFO:Calculating mean and std
2025-12-01 16:10:50,515:INFO:Creating metrics dataframe
2025-12-01 16:10:50,518:INFO:Uploading results into container
2025-12-01 16:10:50,519:INFO:Uploading model into container now
2025-12-01 16:10:50,519:INFO:_master_model_container: 10
2025-12-01 16:10:50,520:INFO:_display_container: 2
2025-12-01 16:10:50,520:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 16:10:50,520:INFO:create_model() successfully completed......................................
2025-12-01 16:10:50,603:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:50,604:INFO:Creating metrics dataframe
2025-12-01 16:10:50,607:INFO:Initializing Linear Discriminant Analysis
2025-12-01 16:10:50,607:INFO:Total runtime is 0.19478896458943687 minutes
2025-12-01 16:10:50,609:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:50,609:INFO:Initializing create_model()
2025-12-01 16:10:50,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:50,609:INFO:Checking exceptions
2025-12-01 16:10:50,609:INFO:Importing libraries
2025-12-01 16:10:50,609:INFO:Copying training dataset
2025-12-01 16:10:50,615:INFO:Defining folds
2025-12-01 16:10:50,615:INFO:Declaring metric variables
2025-12-01 16:10:50,616:INFO:Importing untrained model
2025-12-01 16:10:50,618:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 16:10:50,620:INFO:Starting cross validation
2025-12-01 16:10:50,621:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:50,787:INFO:Calculating mean and std
2025-12-01 16:10:50,788:INFO:Creating metrics dataframe
2025-12-01 16:10:50,789:INFO:Uploading results into container
2025-12-01 16:10:50,789:INFO:Uploading model into container now
2025-12-01 16:10:50,790:INFO:_master_model_container: 11
2025-12-01 16:10:50,790:INFO:_display_container: 2
2025-12-01 16:10:50,790:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 16:10:50,790:INFO:create_model() successfully completed......................................
2025-12-01 16:10:50,833:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:50,833:INFO:Creating metrics dataframe
2025-12-01 16:10:50,837:INFO:Initializing Extra Trees Classifier
2025-12-01 16:10:50,837:INFO:Total runtime is 0.19861558278401695 minutes
2025-12-01 16:10:50,839:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:50,839:INFO:Initializing create_model()
2025-12-01 16:10:50,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:50,839:INFO:Checking exceptions
2025-12-01 16:10:50,839:INFO:Importing libraries
2025-12-01 16:10:50,839:INFO:Copying training dataset
2025-12-01 16:10:50,846:INFO:Defining folds
2025-12-01 16:10:50,846:INFO:Declaring metric variables
2025-12-01 16:10:50,847:INFO:Importing untrained model
2025-12-01 16:10:50,848:INFO:Extra Trees Classifier Imported successfully
2025-12-01 16:10:50,850:INFO:Starting cross validation
2025-12-01 16:10:50,851:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:51,449:INFO:Calculating mean and std
2025-12-01 16:10:51,450:INFO:Creating metrics dataframe
2025-12-01 16:10:51,451:INFO:Uploading results into container
2025-12-01 16:10:51,452:INFO:Uploading model into container now
2025-12-01 16:10:51,452:INFO:_master_model_container: 12
2025-12-01 16:10:51,452:INFO:_display_container: 2
2025-12-01 16:10:51,452:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-12-01 16:10:51,452:INFO:create_model() successfully completed......................................
2025-12-01 16:10:51,503:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:51,503:INFO:Creating metrics dataframe
2025-12-01 16:10:51,506:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 16:10:51,507:INFO:Total runtime is 0.2097769856452942 minutes
2025-12-01 16:10:51,508:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:51,508:INFO:Initializing create_model()
2025-12-01 16:10:51,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:51,508:INFO:Checking exceptions
2025-12-01 16:10:51,508:INFO:Importing libraries
2025-12-01 16:10:51,508:INFO:Copying training dataset
2025-12-01 16:10:51,514:INFO:Defining folds
2025-12-01 16:10:51,514:INFO:Declaring metric variables
2025-12-01 16:10:51,515:INFO:Importing untrained model
2025-12-01 16:10:51,516:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 16:10:51,518:INFO:Starting cross validation
2025-12-01 16:10:51,519:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:53,272:INFO:Calculating mean and std
2025-12-01 16:10:53,274:INFO:Creating metrics dataframe
2025-12-01 16:10:53,276:INFO:Uploading results into container
2025-12-01 16:10:53,276:INFO:Uploading model into container now
2025-12-01 16:10:53,277:INFO:_master_model_container: 13
2025-12-01 16:10:53,277:INFO:_display_container: 2
2025-12-01 16:10:53,277:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 16:10:53,277:INFO:create_model() successfully completed......................................
2025-12-01 16:10:53,354:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:53,354:INFO:Creating metrics dataframe
2025-12-01 16:10:53,358:INFO:Initializing Dummy Classifier
2025-12-01 16:10:53,358:INFO:Total runtime is 0.24064028263092044 minutes
2025-12-01 16:10:53,360:INFO:SubProcess create_model() called ==================================
2025-12-01 16:10:53,360:INFO:Initializing create_model()
2025-12-01 16:10:53,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9ae9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:53,360:INFO:Checking exceptions
2025-12-01 16:10:53,360:INFO:Importing libraries
2025-12-01 16:10:53,360:INFO:Copying training dataset
2025-12-01 16:10:53,367:INFO:Defining folds
2025-12-01 16:10:53,367:INFO:Declaring metric variables
2025-12-01 16:10:53,368:INFO:Importing untrained model
2025-12-01 16:10:53,369:INFO:Dummy Classifier Imported successfully
2025-12-01 16:10:53,371:INFO:Starting cross validation
2025-12-01 16:10:53,373:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:10:53,453:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:10:53,457:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:10:53,457:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:10:53,462:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:10:53,470:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:10:53,482:INFO:Calculating mean and std
2025-12-01 16:10:53,482:INFO:Creating metrics dataframe
2025-12-01 16:10:53,483:INFO:Uploading results into container
2025-12-01 16:10:53,483:INFO:Uploading model into container now
2025-12-01 16:10:53,483:INFO:_master_model_container: 14
2025-12-01 16:10:53,484:INFO:_display_container: 2
2025-12-01 16:10:53,484:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 16:10:53,484:INFO:create_model() successfully completed......................................
2025-12-01 16:10:53,529:INFO:SubProcess create_model() end ==================================
2025-12-01 16:10:53,529:INFO:Creating metrics dataframe
2025-12-01 16:10:53,535:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-01 16:10:53,538:INFO:Initializing create_model()
2025-12-01 16:10:53,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x12fb95250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:10:53,538:INFO:Checking exceptions
2025-12-01 16:10:53,539:INFO:Importing libraries
2025-12-01 16:10:53,539:INFO:Copying training dataset
2025-12-01 16:10:53,545:INFO:Defining folds
2025-12-01 16:10:53,545:INFO:Declaring metric variables
2025-12-01 16:10:53,545:INFO:Importing untrained model
2025-12-01 16:10:53,545:INFO:Declaring custom model
2025-12-01 16:10:53,545:INFO:Logistic Regression Imported successfully
2025-12-01 16:10:53,546:INFO:Cross validation set to False
2025-12-01 16:10:53,546:INFO:Fitting Model
2025-12-01 16:10:54,705:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:10:54,706:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:10:54,707:INFO:create_model() successfully completed......................................
2025-12-01 16:10:54,784:INFO:_master_model_container: 14
2025-12-01 16:10:54,784:INFO:_display_container: 2
2025-12-01 16:10:54,784:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:10:54,784:INFO:compare_models() successfully completed......................................
2025-12-01 16:11:32,286:INFO:PyCaret ClassificationExperiment
2025-12-01 16:11:32,287:INFO:Logging name: clf-default-name
2025-12-01 16:11:32,287:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 16:11:32,287:INFO:version 3.3.2
2025-12-01 16:11:32,287:INFO:Initializing setup()
2025-12-01 16:11:32,287:INFO:self.USI: 1e15
2025-12-01 16:11:32,287:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-01 16:11:32,287:INFO:Checking environment
2025-12-01 16:11:32,287:INFO:python_version: 3.11.14
2025-12-01 16:11:32,287:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-01 16:11:32,287:INFO:machine: arm64
2025-12-01 16:11:32,287:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:11:32,288:INFO:Memory: svmem(total=8589934592, available=1338834944, percent=84.4, used=2800271360, free=57589760, active=1298251776, inactive=1268203520, wired=1502019584)
2025-12-01 16:11:32,288:INFO:Physical Core: 8
2025-12-01 16:11:32,288:INFO:Logical Core: 8
2025-12-01 16:11:32,288:INFO:Checking libraries
2025-12-01 16:11:32,288:INFO:System:
2025-12-01 16:11:32,288:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-01 16:11:32,288:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-01 16:11:32,288:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:11:32,288:INFO:PyCaret required dependencies:
2025-12-01 16:11:32,289:INFO:                 pip: 25.3
2025-12-01 16:11:32,289:INFO:          setuptools: 80.9.0
2025-12-01 16:11:32,289:INFO:             pycaret: 3.3.2
2025-12-01 16:11:32,289:INFO:             IPython: 9.7.0
2025-12-01 16:11:32,289:INFO:          ipywidgets: 8.1.8
2025-12-01 16:11:32,289:INFO:                tqdm: 4.67.1
2025-12-01 16:11:32,289:INFO:               numpy: 1.26.4
2025-12-01 16:11:32,289:INFO:              pandas: 2.1.4
2025-12-01 16:11:32,289:INFO:              jinja2: 3.1.6
2025-12-01 16:11:32,289:INFO:               scipy: 1.11.4
2025-12-01 16:11:32,289:INFO:              joblib: 1.3.2
2025-12-01 16:11:32,289:INFO:             sklearn: 1.4.2
2025-12-01 16:11:32,289:INFO:                pyod: 2.0.5
2025-12-01 16:11:32,289:INFO:            imblearn: 0.14.0
2025-12-01 16:11:32,289:INFO:   category_encoders: 2.7.0
2025-12-01 16:11:32,289:INFO:            lightgbm: 4.6.0
2025-12-01 16:11:32,289:INFO:               numba: 0.62.1
2025-12-01 16:11:32,289:INFO:            requests: 2.32.5
2025-12-01 16:11:32,289:INFO:          matplotlib: 3.7.5
2025-12-01 16:11:32,289:INFO:          scikitplot: 0.3.7
2025-12-01 16:11:32,289:INFO:         yellowbrick: 1.5
2025-12-01 16:11:32,289:INFO:              plotly: 6.5.0
2025-12-01 16:11:32,289:INFO:    plotly-resampler: Not installed
2025-12-01 16:11:32,289:INFO:             kaleido: 1.2.0
2025-12-01 16:11:32,289:INFO:           schemdraw: 0.15
2025-12-01 16:11:32,289:INFO:         statsmodels: 0.14.5
2025-12-01 16:11:32,289:INFO:              sktime: 0.26.0
2025-12-01 16:11:32,289:INFO:               tbats: 1.1.3
2025-12-01 16:11:32,289:INFO:            pmdarima: 2.0.4
2025-12-01 16:11:32,289:INFO:              psutil: 7.1.3
2025-12-01 16:11:32,289:INFO:          markupsafe: 3.0.3
2025-12-01 16:11:32,289:INFO:             pickle5: Not installed
2025-12-01 16:11:32,289:INFO:         cloudpickle: 3.1.2
2025-12-01 16:11:32,289:INFO:         deprecation: 2.1.0
2025-12-01 16:11:32,289:INFO:              xxhash: 3.6.0
2025-12-01 16:11:32,289:INFO:           wurlitzer: 3.1.1
2025-12-01 16:11:32,289:INFO:PyCaret optional dependencies:
2025-12-01 16:11:32,290:INFO:                shap: Not installed
2025-12-01 16:11:32,290:INFO:           interpret: Not installed
2025-12-01 16:11:32,290:INFO:                umap: Not installed
2025-12-01 16:11:32,290:INFO:     ydata_profiling: Not installed
2025-12-01 16:11:32,290:INFO:  explainerdashboard: Not installed
2025-12-01 16:11:32,290:INFO:             autoviz: Not installed
2025-12-01 16:11:32,290:INFO:           fairlearn: Not installed
2025-12-01 16:11:32,290:INFO:          deepchecks: Not installed
2025-12-01 16:11:32,290:INFO:             xgboost: Not installed
2025-12-01 16:11:32,290:INFO:            catboost: Not installed
2025-12-01 16:11:32,290:INFO:              kmodes: Not installed
2025-12-01 16:11:32,290:INFO:             mlxtend: Not installed
2025-12-01 16:11:32,290:INFO:       statsforecast: Not installed
2025-12-01 16:11:32,290:INFO:        tune_sklearn: Not installed
2025-12-01 16:11:32,290:INFO:                 ray: Not installed
2025-12-01 16:11:32,290:INFO:            hyperopt: Not installed
2025-12-01 16:11:32,290:INFO:              optuna: Not installed
2025-12-01 16:11:32,290:INFO:               skopt: Not installed
2025-12-01 16:11:32,290:INFO:              mlflow: Not installed
2025-12-01 16:11:32,290:INFO:              gradio: Not installed
2025-12-01 16:11:32,290:INFO:             fastapi: Not installed
2025-12-01 16:11:32,290:INFO:             uvicorn: Not installed
2025-12-01 16:11:32,290:INFO:              m2cgen: Not installed
2025-12-01 16:11:32,290:INFO:           evidently: Not installed
2025-12-01 16:11:32,290:INFO:               fugue: Not installed
2025-12-01 16:11:32,290:INFO:           streamlit: Not installed
2025-12-01 16:11:32,290:INFO:             prophet: Not installed
2025-12-01 16:11:32,290:INFO:None
2025-12-01 16:11:32,290:INFO:Set up data.
2025-12-01 16:11:32,313:INFO:Set up folding strategy.
2025-12-01 16:11:32,313:INFO:Set up train/test split.
2025-12-01 16:11:32,323:INFO:Set up index.
2025-12-01 16:11:32,323:INFO:Assigning column types.
2025-12-01 16:11:32,329:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 16:11:32,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,388:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 16:11:32,406:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:11:32,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,445:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 16:11:32,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,502:INFO:Preparing preprocessing pipeline...
2025-12-01 16:11:32,504:INFO:Set up simple imputation.
2025-12-01 16:11:32,505:INFO:Set up column name cleaning.
2025-12-01 16:11:32,525:INFO:Finished creating preprocessing pipeline.
2025-12-01 16:11:32,527:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['gender', 'age', 'under_30',
                                             'senior_citizen', 'partner',
                                             'dependents',
                                             'number_of_dependents', 'married',
                                             'paperless_billing',
                                             'monthly_ charges',
                                             'avg_monthly_long_distance_charges',
                                             'total_charges'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-01 16:11:32,527:INFO:Creating final display dataframe.
2025-12-01 16:11:32,593:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 44)
4        Transformed data shape        (7043, 44)
5   Transformed train set shape        (5634, 44)
6    Transformed test set shape        (1409, 44)
7              Numeric features                32
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1e15
2025-12-01 16:11:32,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:11:32,655:INFO:setup() successfully completed in 0.38s...............
2025-12-01 16:11:32,657:INFO:Initializing compare_models()
2025-12-01 16:11:32,657:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-01 16:11:32,657:INFO:Checking exceptions
2025-12-01 16:11:32,661:INFO:Preparing display monitor
2025-12-01 16:11:32,671:INFO:Initializing Logistic Regression
2025-12-01 16:11:32,671:INFO:Total runtime is 3.9299329121907554e-06 minutes
2025-12-01 16:11:32,678:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:32,679:INFO:Initializing create_model()
2025-12-01 16:11:32,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:32,679:INFO:Checking exceptions
2025-12-01 16:11:32,679:INFO:Importing libraries
2025-12-01 16:11:32,679:INFO:Copying training dataset
2025-12-01 16:11:32,689:INFO:Defining folds
2025-12-01 16:11:32,689:INFO:Declaring metric variables
2025-12-01 16:11:32,691:INFO:Importing untrained model
2025-12-01 16:11:32,693:INFO:Logistic Regression Imported successfully
2025-12-01 16:11:32,697:INFO:Starting cross validation
2025-12-01 16:11:32,697:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:33,071:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:11:33,102:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:11:33,103:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:11:33,110:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:11:33,168:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:11:33,180:INFO:Calculating mean and std
2025-12-01 16:11:33,180:INFO:Creating metrics dataframe
2025-12-01 16:11:33,181:INFO:Uploading results into container
2025-12-01 16:11:33,181:INFO:Uploading model into container now
2025-12-01 16:11:33,181:INFO:_master_model_container: 1
2025-12-01 16:11:33,181:INFO:_display_container: 2
2025-12-01 16:11:33,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:11:33,181:INFO:create_model() successfully completed......................................
2025-12-01 16:11:33,253:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:33,253:INFO:Creating metrics dataframe
2025-12-01 16:11:33,256:INFO:Initializing K Neighbors Classifier
2025-12-01 16:11:33,256:INFO:Total runtime is 0.009750032424926757 minutes
2025-12-01 16:11:33,257:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:33,257:INFO:Initializing create_model()
2025-12-01 16:11:33,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:33,257:INFO:Checking exceptions
2025-12-01 16:11:33,257:INFO:Importing libraries
2025-12-01 16:11:33,257:INFO:Copying training dataset
2025-12-01 16:11:33,264:INFO:Defining folds
2025-12-01 16:11:33,264:INFO:Declaring metric variables
2025-12-01 16:11:33,265:INFO:Importing untrained model
2025-12-01 16:11:33,266:INFO:K Neighbors Classifier Imported successfully
2025-12-01 16:11:33,268:INFO:Starting cross validation
2025-12-01 16:11:33,268:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:33,426:INFO:Calculating mean and std
2025-12-01 16:11:33,426:INFO:Creating metrics dataframe
2025-12-01 16:11:33,427:INFO:Uploading results into container
2025-12-01 16:11:33,427:INFO:Uploading model into container now
2025-12-01 16:11:33,427:INFO:_master_model_container: 2
2025-12-01 16:11:33,427:INFO:_display_container: 2
2025-12-01 16:11:33,427:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 16:11:33,427:INFO:create_model() successfully completed......................................
2025-12-01 16:11:33,473:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:33,473:INFO:Creating metrics dataframe
2025-12-01 16:11:33,476:INFO:Initializing Naive Bayes
2025-12-01 16:11:33,476:INFO:Total runtime is 0.013411947091420491 minutes
2025-12-01 16:11:33,477:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:33,477:INFO:Initializing create_model()
2025-12-01 16:11:33,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:33,477:INFO:Checking exceptions
2025-12-01 16:11:33,477:INFO:Importing libraries
2025-12-01 16:11:33,478:INFO:Copying training dataset
2025-12-01 16:11:33,483:INFO:Defining folds
2025-12-01 16:11:33,484:INFO:Declaring metric variables
2025-12-01 16:11:33,484:INFO:Importing untrained model
2025-12-01 16:11:33,485:INFO:Naive Bayes Imported successfully
2025-12-01 16:11:33,488:INFO:Starting cross validation
2025-12-01 16:11:33,488:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:33,627:INFO:Calculating mean and std
2025-12-01 16:11:33,627:INFO:Creating metrics dataframe
2025-12-01 16:11:33,627:INFO:Uploading results into container
2025-12-01 16:11:33,628:INFO:Uploading model into container now
2025-12-01 16:11:33,628:INFO:_master_model_container: 3
2025-12-01 16:11:33,628:INFO:_display_container: 2
2025-12-01 16:11:33,628:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 16:11:33,628:INFO:create_model() successfully completed......................................
2025-12-01 16:11:33,676:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:33,676:INFO:Creating metrics dataframe
2025-12-01 16:11:33,678:INFO:Initializing Decision Tree Classifier
2025-12-01 16:11:33,678:INFO:Total runtime is 0.016788450876871745 minutes
2025-12-01 16:11:33,680:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:33,680:INFO:Initializing create_model()
2025-12-01 16:11:33,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:33,680:INFO:Checking exceptions
2025-12-01 16:11:33,680:INFO:Importing libraries
2025-12-01 16:11:33,680:INFO:Copying training dataset
2025-12-01 16:11:33,686:INFO:Defining folds
2025-12-01 16:11:33,687:INFO:Declaring metric variables
2025-12-01 16:11:33,688:INFO:Importing untrained model
2025-12-01 16:11:33,689:INFO:Decision Tree Classifier Imported successfully
2025-12-01 16:11:33,694:INFO:Starting cross validation
2025-12-01 16:11:33,695:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:33,805:INFO:Calculating mean and std
2025-12-01 16:11:33,806:INFO:Creating metrics dataframe
2025-12-01 16:11:33,806:INFO:Uploading results into container
2025-12-01 16:11:33,806:INFO:Uploading model into container now
2025-12-01 16:11:33,807:INFO:_master_model_container: 4
2025-12-01 16:11:33,807:INFO:_display_container: 2
2025-12-01 16:11:33,807:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-12-01 16:11:33,807:INFO:create_model() successfully completed......................................
2025-12-01 16:11:33,853:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:33,853:INFO:Creating metrics dataframe
2025-12-01 16:11:33,856:INFO:Initializing SVM - Linear Kernel
2025-12-01 16:11:33,856:INFO:Total runtime is 0.019750499725341798 minutes
2025-12-01 16:11:33,857:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:33,858:INFO:Initializing create_model()
2025-12-01 16:11:33,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:33,858:INFO:Checking exceptions
2025-12-01 16:11:33,858:INFO:Importing libraries
2025-12-01 16:11:33,858:INFO:Copying training dataset
2025-12-01 16:11:33,864:INFO:Defining folds
2025-12-01 16:11:33,864:INFO:Declaring metric variables
2025-12-01 16:11:33,864:INFO:Importing untrained model
2025-12-01 16:11:33,865:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 16:11:33,868:INFO:Starting cross validation
2025-12-01 16:11:33,868:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:33,965:INFO:Calculating mean and std
2025-12-01 16:11:33,966:INFO:Creating metrics dataframe
2025-12-01 16:11:33,966:INFO:Uploading results into container
2025-12-01 16:11:33,967:INFO:Uploading model into container now
2025-12-01 16:11:33,967:INFO:_master_model_container: 5
2025-12-01 16:11:33,967:INFO:_display_container: 2
2025-12-01 16:11:33,967:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 16:11:33,967:INFO:create_model() successfully completed......................................
2025-12-01 16:11:34,016:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:34,016:INFO:Creating metrics dataframe
2025-12-01 16:11:34,019:INFO:Initializing Ridge Classifier
2025-12-01 16:11:34,019:INFO:Total runtime is 0.022461565335591634 minutes
2025-12-01 16:11:34,020:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:34,020:INFO:Initializing create_model()
2025-12-01 16:11:34,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:34,020:INFO:Checking exceptions
2025-12-01 16:11:34,021:INFO:Importing libraries
2025-12-01 16:11:34,021:INFO:Copying training dataset
2025-12-01 16:11:34,027:INFO:Defining folds
2025-12-01 16:11:34,027:INFO:Declaring metric variables
2025-12-01 16:11:34,028:INFO:Importing untrained model
2025-12-01 16:11:34,029:INFO:Ridge Classifier Imported successfully
2025-12-01 16:11:34,031:INFO:Starting cross validation
2025-12-01 16:11:34,031:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:34,098:INFO:Calculating mean and std
2025-12-01 16:11:34,098:INFO:Creating metrics dataframe
2025-12-01 16:11:34,099:INFO:Uploading results into container
2025-12-01 16:11:34,099:INFO:Uploading model into container now
2025-12-01 16:11:34,101:INFO:_master_model_container: 6
2025-12-01 16:11:34,101:INFO:_display_container: 2
2025-12-01 16:11:34,101:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 16:11:34,101:INFO:create_model() successfully completed......................................
2025-12-01 16:11:34,150:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:34,150:INFO:Creating metrics dataframe
2025-12-01 16:11:34,154:INFO:Initializing Random Forest Classifier
2025-12-01 16:11:34,154:INFO:Total runtime is 0.024714748064676918 minutes
2025-12-01 16:11:34,156:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:34,157:INFO:Initializing create_model()
2025-12-01 16:11:34,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:34,157:INFO:Checking exceptions
2025-12-01 16:11:34,157:INFO:Importing libraries
2025-12-01 16:11:34,157:INFO:Copying training dataset
2025-12-01 16:11:34,164:INFO:Defining folds
2025-12-01 16:11:34,164:INFO:Declaring metric variables
2025-12-01 16:11:34,165:INFO:Importing untrained model
2025-12-01 16:11:34,166:INFO:Random Forest Classifier Imported successfully
2025-12-01 16:11:34,169:INFO:Starting cross validation
2025-12-01 16:11:34,170:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:34,616:INFO:Calculating mean and std
2025-12-01 16:11:34,616:INFO:Creating metrics dataframe
2025-12-01 16:11:34,617:INFO:Uploading results into container
2025-12-01 16:11:34,617:INFO:Uploading model into container now
2025-12-01 16:11:34,617:INFO:_master_model_container: 7
2025-12-01 16:11:34,617:INFO:_display_container: 2
2025-12-01 16:11:34,618:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-01 16:11:34,618:INFO:create_model() successfully completed......................................
2025-12-01 16:11:34,661:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:34,661:INFO:Creating metrics dataframe
2025-12-01 16:11:34,664:INFO:Initializing Quadratic Discriminant Analysis
2025-12-01 16:11:34,664:INFO:Total runtime is 0.033224232991536456 minutes
2025-12-01 16:11:34,666:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:34,666:INFO:Initializing create_model()
2025-12-01 16:11:34,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:34,666:INFO:Checking exceptions
2025-12-01 16:11:34,666:INFO:Importing libraries
2025-12-01 16:11:34,666:INFO:Copying training dataset
2025-12-01 16:11:34,672:INFO:Defining folds
2025-12-01 16:11:34,672:INFO:Declaring metric variables
2025-12-01 16:11:34,673:INFO:Importing untrained model
2025-12-01 16:11:34,674:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 16:11:34,676:INFO:Starting cross validation
2025-12-01 16:11:34,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:34,703:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:11:34,712:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:11:34,717:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:11:34,724:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:11:34,733:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:11:34,754:INFO:Calculating mean and std
2025-12-01 16:11:34,754:INFO:Creating metrics dataframe
2025-12-01 16:11:34,755:INFO:Uploading results into container
2025-12-01 16:11:34,755:INFO:Uploading model into container now
2025-12-01 16:11:34,756:INFO:_master_model_container: 8
2025-12-01 16:11:34,756:INFO:_display_container: 2
2025-12-01 16:11:34,756:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 16:11:34,756:INFO:create_model() successfully completed......................................
2025-12-01 16:11:34,798:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:34,798:INFO:Creating metrics dataframe
2025-12-01 16:11:34,801:INFO:Initializing Ada Boost Classifier
2025-12-01 16:11:34,801:INFO:Total runtime is 0.03550736904144287 minutes
2025-12-01 16:11:34,803:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:34,803:INFO:Initializing create_model()
2025-12-01 16:11:34,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:34,803:INFO:Checking exceptions
2025-12-01 16:11:34,803:INFO:Importing libraries
2025-12-01 16:11:34,803:INFO:Copying training dataset
2025-12-01 16:11:34,809:INFO:Defining folds
2025-12-01 16:11:34,809:INFO:Declaring metric variables
2025-12-01 16:11:34,810:INFO:Importing untrained model
2025-12-01 16:11:34,811:INFO:Ada Boost Classifier Imported successfully
2025-12-01 16:11:34,814:INFO:Starting cross validation
2025-12-01 16:11:34,814:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:34,829:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:11:34,836:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:11:34,838:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:11:34,839:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:11:34,849:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:11:35,131:INFO:Calculating mean and std
2025-12-01 16:11:35,131:INFO:Creating metrics dataframe
2025-12-01 16:11:35,132:INFO:Uploading results into container
2025-12-01 16:11:35,132:INFO:Uploading model into container now
2025-12-01 16:11:35,132:INFO:_master_model_container: 9
2025-12-01 16:11:35,132:INFO:_display_container: 2
2025-12-01 16:11:35,133:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-01 16:11:35,133:INFO:create_model() successfully completed......................................
2025-12-01 16:11:35,176:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:35,176:INFO:Creating metrics dataframe
2025-12-01 16:11:35,179:INFO:Initializing Gradient Boosting Classifier
2025-12-01 16:11:35,179:INFO:Total runtime is 0.041798432668050126 minutes
2025-12-01 16:11:35,180:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:35,180:INFO:Initializing create_model()
2025-12-01 16:11:35,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:35,181:INFO:Checking exceptions
2025-12-01 16:11:35,181:INFO:Importing libraries
2025-12-01 16:11:35,181:INFO:Copying training dataset
2025-12-01 16:11:35,186:INFO:Defining folds
2025-12-01 16:11:35,186:INFO:Declaring metric variables
2025-12-01 16:11:35,187:INFO:Importing untrained model
2025-12-01 16:11:35,188:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 16:11:35,191:INFO:Starting cross validation
2025-12-01 16:11:35,191:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:36,369:INFO:Calculating mean and std
2025-12-01 16:11:36,370:INFO:Creating metrics dataframe
2025-12-01 16:11:36,370:INFO:Uploading results into container
2025-12-01 16:11:36,371:INFO:Uploading model into container now
2025-12-01 16:11:36,371:INFO:_master_model_container: 10
2025-12-01 16:11:36,371:INFO:_display_container: 2
2025-12-01 16:11:36,371:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 16:11:36,371:INFO:create_model() successfully completed......................................
2025-12-01 16:11:36,413:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:36,413:INFO:Creating metrics dataframe
2025-12-01 16:11:36,416:INFO:Initializing Linear Discriminant Analysis
2025-12-01 16:11:36,417:INFO:Total runtime is 0.06242514848709106 minutes
2025-12-01 16:11:36,418:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:36,418:INFO:Initializing create_model()
2025-12-01 16:11:36,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:36,418:INFO:Checking exceptions
2025-12-01 16:11:36,418:INFO:Importing libraries
2025-12-01 16:11:36,418:INFO:Copying training dataset
2025-12-01 16:11:36,424:INFO:Defining folds
2025-12-01 16:11:36,424:INFO:Declaring metric variables
2025-12-01 16:11:36,425:INFO:Importing untrained model
2025-12-01 16:11:36,426:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 16:11:36,428:INFO:Starting cross validation
2025-12-01 16:11:36,429:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:36,499:INFO:Calculating mean and std
2025-12-01 16:11:36,499:INFO:Creating metrics dataframe
2025-12-01 16:11:36,500:INFO:Uploading results into container
2025-12-01 16:11:36,500:INFO:Uploading model into container now
2025-12-01 16:11:36,500:INFO:_master_model_container: 11
2025-12-01 16:11:36,501:INFO:_display_container: 2
2025-12-01 16:11:36,501:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 16:11:36,501:INFO:create_model() successfully completed......................................
2025-12-01 16:11:36,543:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:36,543:INFO:Creating metrics dataframe
2025-12-01 16:11:36,547:INFO:Initializing Extra Trees Classifier
2025-12-01 16:11:36,547:INFO:Total runtime is 0.06459410190582275 minutes
2025-12-01 16:11:36,548:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:36,548:INFO:Initializing create_model()
2025-12-01 16:11:36,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:36,548:INFO:Checking exceptions
2025-12-01 16:11:36,548:INFO:Importing libraries
2025-12-01 16:11:36,548:INFO:Copying training dataset
2025-12-01 16:11:36,554:INFO:Defining folds
2025-12-01 16:11:36,554:INFO:Declaring metric variables
2025-12-01 16:11:36,555:INFO:Importing untrained model
2025-12-01 16:11:36,556:INFO:Extra Trees Classifier Imported successfully
2025-12-01 16:11:36,558:INFO:Starting cross validation
2025-12-01 16:11:36,558:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:36,977:INFO:Calculating mean and std
2025-12-01 16:11:36,978:INFO:Creating metrics dataframe
2025-12-01 16:11:36,980:INFO:Uploading results into container
2025-12-01 16:11:36,980:INFO:Uploading model into container now
2025-12-01 16:11:36,981:INFO:_master_model_container: 12
2025-12-01 16:11:36,981:INFO:_display_container: 2
2025-12-01 16:11:36,981:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-12-01 16:11:36,981:INFO:create_model() successfully completed......................................
2025-12-01 16:11:37,091:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:37,091:INFO:Creating metrics dataframe
2025-12-01 16:11:37,096:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 16:11:37,096:INFO:Total runtime is 0.07375715176264444 minutes
2025-12-01 16:11:37,101:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:37,101:INFO:Initializing create_model()
2025-12-01 16:11:37,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:37,101:INFO:Checking exceptions
2025-12-01 16:11:37,101:INFO:Importing libraries
2025-12-01 16:11:37,101:INFO:Copying training dataset
2025-12-01 16:11:37,108:INFO:Defining folds
2025-12-01 16:11:37,108:INFO:Declaring metric variables
2025-12-01 16:11:37,110:INFO:Importing untrained model
2025-12-01 16:11:37,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 16:11:37,117:INFO:Starting cross validation
2025-12-01 16:11:37,118:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:38,803:INFO:Calculating mean and std
2025-12-01 16:11:38,804:INFO:Creating metrics dataframe
2025-12-01 16:11:38,806:INFO:Uploading results into container
2025-12-01 16:11:38,806:INFO:Uploading model into container now
2025-12-01 16:11:38,809:INFO:_master_model_container: 13
2025-12-01 16:11:38,809:INFO:_display_container: 2
2025-12-01 16:11:38,810:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 16:11:38,810:INFO:create_model() successfully completed......................................
2025-12-01 16:11:38,893:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:38,893:INFO:Creating metrics dataframe
2025-12-01 16:11:38,897:INFO:Initializing Dummy Classifier
2025-12-01 16:11:38,897:INFO:Total runtime is 0.10376478433609007 minutes
2025-12-01 16:11:38,898:INFO:SubProcess create_model() called ==================================
2025-12-01 16:11:38,898:INFO:Initializing create_model()
2025-12-01 16:11:38,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c97bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:38,898:INFO:Checking exceptions
2025-12-01 16:11:38,898:INFO:Importing libraries
2025-12-01 16:11:38,898:INFO:Copying training dataset
2025-12-01 16:11:38,905:INFO:Defining folds
2025-12-01 16:11:38,905:INFO:Declaring metric variables
2025-12-01 16:11:38,907:INFO:Importing untrained model
2025-12-01 16:11:38,908:INFO:Dummy Classifier Imported successfully
2025-12-01 16:11:38,910:INFO:Starting cross validation
2025-12-01 16:11:38,910:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:11:38,965:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:11:38,968:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:11:38,973:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:11:38,974:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:11:38,977:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:11:38,984:INFO:Calculating mean and std
2025-12-01 16:11:38,985:INFO:Creating metrics dataframe
2025-12-01 16:11:38,985:INFO:Uploading results into container
2025-12-01 16:11:38,985:INFO:Uploading model into container now
2025-12-01 16:11:38,985:INFO:_master_model_container: 14
2025-12-01 16:11:38,985:INFO:_display_container: 2
2025-12-01 16:11:38,986:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 16:11:38,986:INFO:create_model() successfully completed......................................
2025-12-01 16:11:39,026:INFO:SubProcess create_model() end ==================================
2025-12-01 16:11:39,026:INFO:Creating metrics dataframe
2025-12-01 16:11:39,030:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-01 16:11:39,033:INFO:Initializing create_model()
2025-12-01 16:11:39,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x16c9f6650>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:11:39,033:INFO:Checking exceptions
2025-12-01 16:11:39,034:INFO:Importing libraries
2025-12-01 16:11:39,034:INFO:Copying training dataset
2025-12-01 16:11:39,040:INFO:Defining folds
2025-12-01 16:11:39,040:INFO:Declaring metric variables
2025-12-01 16:11:39,040:INFO:Importing untrained model
2025-12-01 16:11:39,041:INFO:Declaring custom model
2025-12-01 16:11:39,041:INFO:Naive Bayes Imported successfully
2025-12-01 16:11:39,041:INFO:Cross validation set to False
2025-12-01 16:11:39,041:INFO:Fitting Model
2025-12-01 16:11:39,053:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 16:11:39,053:INFO:create_model() successfully completed......................................
2025-12-01 16:11:39,105:INFO:_master_model_container: 14
2025-12-01 16:11:39,105:INFO:_display_container: 2
2025-12-01 16:11:39,105:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 16:11:39,105:INFO:compare_models() successfully completed......................................
2025-12-01 16:19:02,501:INFO:PyCaret ClassificationExperiment
2025-12-01 16:19:02,502:INFO:Logging name: clf-default-name
2025-12-01 16:19:02,502:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 16:19:02,502:INFO:version 3.3.2
2025-12-01 16:19:02,502:INFO:Initializing setup()
2025-12-01 16:19:02,502:INFO:self.USI: 58f5
2025-12-01 16:19:02,502:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-01 16:19:02,502:INFO:Checking environment
2025-12-01 16:19:02,502:INFO:python_version: 3.11.14
2025-12-01 16:19:02,502:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-01 16:19:02,502:INFO:machine: arm64
2025-12-01 16:19:02,502:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:19:02,504:INFO:Memory: svmem(total=8589934592, available=1908719616, percent=77.8, used=3366600704, free=65355776, active=1857028096, inactive=1842855936, wired=1509572608)
2025-12-01 16:19:02,504:INFO:Physical Core: 8
2025-12-01 16:19:02,504:INFO:Logical Core: 8
2025-12-01 16:19:02,504:INFO:Checking libraries
2025-12-01 16:19:02,504:INFO:System:
2025-12-01 16:19:02,504:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-01 16:19:02,504:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-01 16:19:02,504:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-01 16:19:02,504:INFO:PyCaret required dependencies:
2025-12-01 16:19:02,504:INFO:                 pip: 25.3
2025-12-01 16:19:02,505:INFO:          setuptools: 80.9.0
2025-12-01 16:19:02,505:INFO:             pycaret: 3.3.2
2025-12-01 16:19:02,505:INFO:             IPython: 9.7.0
2025-12-01 16:19:02,505:INFO:          ipywidgets: 8.1.8
2025-12-01 16:19:02,505:INFO:                tqdm: 4.67.1
2025-12-01 16:19:02,505:INFO:               numpy: 1.26.4
2025-12-01 16:19:02,505:INFO:              pandas: 2.1.4
2025-12-01 16:19:02,505:INFO:              jinja2: 3.1.6
2025-12-01 16:19:02,505:INFO:               scipy: 1.11.4
2025-12-01 16:19:02,505:INFO:              joblib: 1.3.2
2025-12-01 16:19:02,505:INFO:             sklearn: 1.4.2
2025-12-01 16:19:02,505:INFO:                pyod: 2.0.5
2025-12-01 16:19:02,505:INFO:            imblearn: 0.14.0
2025-12-01 16:19:02,505:INFO:   category_encoders: 2.7.0
2025-12-01 16:19:02,505:INFO:            lightgbm: 4.6.0
2025-12-01 16:19:02,505:INFO:               numba: 0.62.1
2025-12-01 16:19:02,505:INFO:            requests: 2.32.5
2025-12-01 16:19:02,505:INFO:          matplotlib: 3.7.5
2025-12-01 16:19:02,505:INFO:          scikitplot: 0.3.7
2025-12-01 16:19:02,505:INFO:         yellowbrick: 1.5
2025-12-01 16:19:02,505:INFO:              plotly: 6.5.0
2025-12-01 16:19:02,505:INFO:    plotly-resampler: Not installed
2025-12-01 16:19:02,505:INFO:             kaleido: 1.2.0
2025-12-01 16:19:02,505:INFO:           schemdraw: 0.15
2025-12-01 16:19:02,505:INFO:         statsmodels: 0.14.5
2025-12-01 16:19:02,505:INFO:              sktime: 0.26.0
2025-12-01 16:19:02,505:INFO:               tbats: 1.1.3
2025-12-01 16:19:02,505:INFO:            pmdarima: 2.0.4
2025-12-01 16:19:02,505:INFO:              psutil: 7.1.3
2025-12-01 16:19:02,505:INFO:          markupsafe: 3.0.3
2025-12-01 16:19:02,505:INFO:             pickle5: Not installed
2025-12-01 16:19:02,505:INFO:         cloudpickle: 3.1.2
2025-12-01 16:19:02,505:INFO:         deprecation: 2.1.0
2025-12-01 16:19:02,505:INFO:              xxhash: 3.6.0
2025-12-01 16:19:02,505:INFO:           wurlitzer: 3.1.1
2025-12-01 16:19:02,505:INFO:PyCaret optional dependencies:
2025-12-01 16:19:02,505:INFO:                shap: Not installed
2025-12-01 16:19:02,505:INFO:           interpret: Not installed
2025-12-01 16:19:02,505:INFO:                umap: Not installed
2025-12-01 16:19:02,505:INFO:     ydata_profiling: Not installed
2025-12-01 16:19:02,505:INFO:  explainerdashboard: Not installed
2025-12-01 16:19:02,505:INFO:             autoviz: Not installed
2025-12-01 16:19:02,505:INFO:           fairlearn: Not installed
2025-12-01 16:19:02,505:INFO:          deepchecks: Not installed
2025-12-01 16:19:02,505:INFO:             xgboost: Not installed
2025-12-01 16:19:02,505:INFO:            catboost: Not installed
2025-12-01 16:19:02,505:INFO:              kmodes: Not installed
2025-12-01 16:19:02,505:INFO:             mlxtend: Not installed
2025-12-01 16:19:02,505:INFO:       statsforecast: Not installed
2025-12-01 16:19:02,505:INFO:        tune_sklearn: Not installed
2025-12-01 16:19:02,505:INFO:                 ray: Not installed
2025-12-01 16:19:02,505:INFO:            hyperopt: Not installed
2025-12-01 16:19:02,505:INFO:              optuna: Not installed
2025-12-01 16:19:02,505:INFO:               skopt: Not installed
2025-12-01 16:19:02,505:INFO:              mlflow: Not installed
2025-12-01 16:19:02,505:INFO:              gradio: Not installed
2025-12-01 16:19:02,505:INFO:             fastapi: Not installed
2025-12-01 16:19:02,505:INFO:             uvicorn: Not installed
2025-12-01 16:19:02,505:INFO:              m2cgen: Not installed
2025-12-01 16:19:02,505:INFO:           evidently: Not installed
2025-12-01 16:19:02,505:INFO:               fugue: Not installed
2025-12-01 16:19:02,505:INFO:           streamlit: Not installed
2025-12-01 16:19:02,505:INFO:             prophet: Not installed
2025-12-01 16:19:02,505:INFO:None
2025-12-01 16:19:02,505:INFO:Set up data.
2025-12-01 16:19:02,570:INFO:Set up folding strategy.
2025-12-01 16:19:02,571:INFO:Set up train/test split.
2025-12-01 16:19:02,584:INFO:Set up index.
2025-12-01 16:19:02,584:INFO:Assigning column types.
2025-12-01 16:19:02,589:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 16:19:02,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,607:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,645:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 16:19:02,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,690:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 16:19:02,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,701:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 16:19:02,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,755:INFO:Preparing preprocessing pipeline...
2025-12-01 16:19:02,757:INFO:Set up simple imputation.
2025-12-01 16:19:02,757:INFO:Set up imbalanced handling.
2025-12-01 16:19:02,757:INFO:Set up column name cleaning.
2025-12-01 16:19:02,787:INFO:Finished creating preprocessing pipeline.
2025-12-01 16:19:02,789:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['gender', 'age', 'under_30',
                                             'senior_citizen', 'partner',
                                             'dependents',
                                             'number_of_dependents', 'married',
                                             'paperless_billing',
                                             'monthly_ charges',
                                             'avg_monthly_long_distance_charges',
                                             'total_charges'...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-01 16:19:02,789:INFO:Creating final display dataframe.
2025-12-01 16:19:02,859:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 44)
4        Transformed data shape        (9687, 44)
5   Transformed train set shape        (8278, 44)
6    Transformed test set shape        (1409, 44)
7              Numeric features                32
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              58f5
2025-12-01 16:19:02,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 16:19:02,921:INFO:setup() successfully completed in 0.43s...............
2025-12-01 16:19:02,923:INFO:Initializing compare_models()
2025-12-01 16:19:02,923:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-01 16:19:02,923:INFO:Checking exceptions
2025-12-01 16:19:02,926:INFO:Preparing display monitor
2025-12-01 16:19:02,936:INFO:Initializing Logistic Regression
2025-12-01 16:19:02,936:INFO:Total runtime is 1.3192494710286458e-06 minutes
2025-12-01 16:19:02,937:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:02,937:INFO:Initializing create_model()
2025-12-01 16:19:02,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:02,937:INFO:Checking exceptions
2025-12-01 16:19:02,937:INFO:Importing libraries
2025-12-01 16:19:02,937:INFO:Copying training dataset
2025-12-01 16:19:02,950:INFO:Defining folds
2025-12-01 16:19:02,950:INFO:Declaring metric variables
2025-12-01 16:19:02,951:INFO:Importing untrained model
2025-12-01 16:19:02,952:INFO:Logistic Regression Imported successfully
2025-12-01 16:19:02,954:INFO:Starting cross validation
2025-12-01 16:19:02,955:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:06,246:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:06,246:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:06,246:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:06,246:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:06,246:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:06,732:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:06,743:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:06,746:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:06,748:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:06,753:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:06,785:INFO:Calculating mean and std
2025-12-01 16:19:06,792:INFO:Creating metrics dataframe
2025-12-01 16:19:06,799:INFO:Uploading results into container
2025-12-01 16:19:06,801:INFO:Uploading model into container now
2025-12-01 16:19:06,802:INFO:_master_model_container: 1
2025-12-01 16:19:06,802:INFO:_display_container: 2
2025-12-01 16:19:06,810:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:19:06,810:INFO:create_model() successfully completed......................................
2025-12-01 16:19:07,362:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:07,362:INFO:Creating metrics dataframe
2025-12-01 16:19:07,366:INFO:Initializing K Neighbors Classifier
2025-12-01 16:19:07,366:INFO:Total runtime is 0.07384620110193889 minutes
2025-12-01 16:19:07,368:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:07,368:INFO:Initializing create_model()
2025-12-01 16:19:07,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:07,368:INFO:Checking exceptions
2025-12-01 16:19:07,368:INFO:Importing libraries
2025-12-01 16:19:07,368:INFO:Copying training dataset
2025-12-01 16:19:07,376:INFO:Defining folds
2025-12-01 16:19:07,376:INFO:Declaring metric variables
2025-12-01 16:19:07,377:INFO:Importing untrained model
2025-12-01 16:19:07,379:INFO:K Neighbors Classifier Imported successfully
2025-12-01 16:19:07,381:INFO:Starting cross validation
2025-12-01 16:19:07,381:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:08,605:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:08,609:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:08,765:INFO:Calculating mean and std
2025-12-01 16:19:08,772:INFO:Creating metrics dataframe
2025-12-01 16:19:08,781:INFO:Uploading results into container
2025-12-01 16:19:08,781:INFO:Uploading model into container now
2025-12-01 16:19:08,782:INFO:_master_model_container: 2
2025-12-01 16:19:08,782:INFO:_display_container: 2
2025-12-01 16:19:08,783:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 16:19:08,783:INFO:create_model() successfully completed......................................
2025-12-01 16:19:08,923:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:08,923:INFO:Creating metrics dataframe
2025-12-01 16:19:08,926:INFO:Initializing Naive Bayes
2025-12-01 16:19:08,926:INFO:Total runtime is 0.09983437061309815 minutes
2025-12-01 16:19:08,927:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:08,928:INFO:Initializing create_model()
2025-12-01 16:19:08,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:08,928:INFO:Checking exceptions
2025-12-01 16:19:08,928:INFO:Importing libraries
2025-12-01 16:19:08,928:INFO:Copying training dataset
2025-12-01 16:19:08,935:INFO:Defining folds
2025-12-01 16:19:08,935:INFO:Declaring metric variables
2025-12-01 16:19:08,936:INFO:Importing untrained model
2025-12-01 16:19:08,939:INFO:Naive Bayes Imported successfully
2025-12-01 16:19:08,943:INFO:Starting cross validation
2025-12-01 16:19:08,943:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:10,235:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 16:19:10,322:INFO:Calculating mean and std
2025-12-01 16:19:10,324:INFO:Creating metrics dataframe
2025-12-01 16:19:10,329:INFO:Uploading results into container
2025-12-01 16:19:10,330:INFO:Uploading model into container now
2025-12-01 16:19:10,334:INFO:_master_model_container: 3
2025-12-01 16:19:10,335:INFO:_display_container: 2
2025-12-01 16:19:10,339:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 16:19:10,339:INFO:create_model() successfully completed......................................
2025-12-01 16:19:10,469:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:10,469:INFO:Creating metrics dataframe
2025-12-01 16:19:10,473:INFO:Initializing Decision Tree Classifier
2025-12-01 16:19:10,473:INFO:Total runtime is 0.12561553716659546 minutes
2025-12-01 16:19:10,474:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:10,474:INFO:Initializing create_model()
2025-12-01 16:19:10,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:10,474:INFO:Checking exceptions
2025-12-01 16:19:10,474:INFO:Importing libraries
2025-12-01 16:19:10,474:INFO:Copying training dataset
2025-12-01 16:19:10,481:INFO:Defining folds
2025-12-01 16:19:10,481:INFO:Declaring metric variables
2025-12-01 16:19:10,482:INFO:Importing untrained model
2025-12-01 16:19:10,484:INFO:Decision Tree Classifier Imported successfully
2025-12-01 16:19:10,487:INFO:Starting cross validation
2025-12-01 16:19:10,489:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:10,785:INFO:Calculating mean and std
2025-12-01 16:19:10,786:INFO:Creating metrics dataframe
2025-12-01 16:19:10,787:INFO:Uploading results into container
2025-12-01 16:19:10,787:INFO:Uploading model into container now
2025-12-01 16:19:10,787:INFO:_master_model_container: 4
2025-12-01 16:19:10,788:INFO:_display_container: 2
2025-12-01 16:19:10,789:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-12-01 16:19:10,789:INFO:create_model() successfully completed......................................
2025-12-01 16:19:10,848:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:10,848:INFO:Creating metrics dataframe
2025-12-01 16:19:10,851:INFO:Initializing SVM - Linear Kernel
2025-12-01 16:19:10,851:INFO:Total runtime is 0.1319161534309387 minutes
2025-12-01 16:19:10,852:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:10,852:INFO:Initializing create_model()
2025-12-01 16:19:10,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:10,852:INFO:Checking exceptions
2025-12-01 16:19:10,853:INFO:Importing libraries
2025-12-01 16:19:10,853:INFO:Copying training dataset
2025-12-01 16:19:10,858:INFO:Defining folds
2025-12-01 16:19:10,858:INFO:Declaring metric variables
2025-12-01 16:19:10,859:INFO:Importing untrained model
2025-12-01 16:19:10,861:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 16:19:10,863:INFO:Starting cross validation
2025-12-01 16:19:10,863:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:11,045:INFO:Calculating mean and std
2025-12-01 16:19:11,046:INFO:Creating metrics dataframe
2025-12-01 16:19:11,048:INFO:Uploading results into container
2025-12-01 16:19:11,048:INFO:Uploading model into container now
2025-12-01 16:19:11,049:INFO:_master_model_container: 5
2025-12-01 16:19:11,049:INFO:_display_container: 2
2025-12-01 16:19:11,049:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 16:19:11,049:INFO:create_model() successfully completed......................................
2025-12-01 16:19:11,107:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:11,107:INFO:Creating metrics dataframe
2025-12-01 16:19:11,110:INFO:Initializing Ridge Classifier
2025-12-01 16:19:11,110:INFO:Total runtime is 0.13624050219853717 minutes
2025-12-01 16:19:11,111:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:11,111:INFO:Initializing create_model()
2025-12-01 16:19:11,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:11,112:INFO:Checking exceptions
2025-12-01 16:19:11,112:INFO:Importing libraries
2025-12-01 16:19:11,112:INFO:Copying training dataset
2025-12-01 16:19:11,118:INFO:Defining folds
2025-12-01 16:19:11,118:INFO:Declaring metric variables
2025-12-01 16:19:11,119:INFO:Importing untrained model
2025-12-01 16:19:11,120:INFO:Ridge Classifier Imported successfully
2025-12-01 16:19:11,122:INFO:Starting cross validation
2025-12-01 16:19:11,122:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:11,253:INFO:Calculating mean and std
2025-12-01 16:19:11,254:INFO:Creating metrics dataframe
2025-12-01 16:19:11,255:INFO:Uploading results into container
2025-12-01 16:19:11,255:INFO:Uploading model into container now
2025-12-01 16:19:11,255:INFO:_master_model_container: 6
2025-12-01 16:19:11,255:INFO:_display_container: 2
2025-12-01 16:19:11,255:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 16:19:11,255:INFO:create_model() successfully completed......................................
2025-12-01 16:19:11,377:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:11,377:INFO:Creating metrics dataframe
2025-12-01 16:19:11,380:INFO:Initializing Random Forest Classifier
2025-12-01 16:19:11,381:INFO:Total runtime is 0.14074726899464923 minutes
2025-12-01 16:19:11,382:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:11,382:INFO:Initializing create_model()
2025-12-01 16:19:11,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:11,382:INFO:Checking exceptions
2025-12-01 16:19:11,382:INFO:Importing libraries
2025-12-01 16:19:11,383:INFO:Copying training dataset
2025-12-01 16:19:11,389:INFO:Defining folds
2025-12-01 16:19:11,389:INFO:Declaring metric variables
2025-12-01 16:19:11,391:INFO:Importing untrained model
2025-12-01 16:19:11,392:INFO:Random Forest Classifier Imported successfully
2025-12-01 16:19:11,394:INFO:Starting cross validation
2025-12-01 16:19:11,395:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:12,226:INFO:Calculating mean and std
2025-12-01 16:19:12,228:INFO:Creating metrics dataframe
2025-12-01 16:19:12,229:INFO:Uploading results into container
2025-12-01 16:19:12,230:INFO:Uploading model into container now
2025-12-01 16:19:12,230:INFO:_master_model_container: 7
2025-12-01 16:19:12,230:INFO:_display_container: 2
2025-12-01 16:19:12,230:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-01 16:19:12,230:INFO:create_model() successfully completed......................................
2025-12-01 16:19:12,299:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:12,299:INFO:Creating metrics dataframe
2025-12-01 16:19:12,302:INFO:Initializing Quadratic Discriminant Analysis
2025-12-01 16:19:12,302:INFO:Total runtime is 0.15610206921895342 minutes
2025-12-01 16:19:12,303:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:12,304:INFO:Initializing create_model()
2025-12-01 16:19:12,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:12,304:INFO:Checking exceptions
2025-12-01 16:19:12,304:INFO:Importing libraries
2025-12-01 16:19:12,304:INFO:Copying training dataset
2025-12-01 16:19:12,310:INFO:Defining folds
2025-12-01 16:19:12,310:INFO:Declaring metric variables
2025-12-01 16:19:12,311:INFO:Importing untrained model
2025-12-01 16:19:12,312:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 16:19:12,314:INFO:Starting cross validation
2025-12-01 16:19:12,314:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:12,401:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:19:12,408:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:19:12,421:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:19:12,428:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:19:12,433:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 16:19:12,462:INFO:Calculating mean and std
2025-12-01 16:19:12,463:INFO:Creating metrics dataframe
2025-12-01 16:19:12,464:INFO:Uploading results into container
2025-12-01 16:19:12,464:INFO:Uploading model into container now
2025-12-01 16:19:12,464:INFO:_master_model_container: 8
2025-12-01 16:19:12,464:INFO:_display_container: 2
2025-12-01 16:19:12,464:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 16:19:12,464:INFO:create_model() successfully completed......................................
2025-12-01 16:19:12,589:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:12,589:INFO:Creating metrics dataframe
2025-12-01 16:19:12,593:INFO:Initializing Ada Boost Classifier
2025-12-01 16:19:12,593:INFO:Total runtime is 0.16095005273818966 minutes
2025-12-01 16:19:12,594:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:12,594:INFO:Initializing create_model()
2025-12-01 16:19:12,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:12,595:INFO:Checking exceptions
2025-12-01 16:19:12,595:INFO:Importing libraries
2025-12-01 16:19:12,595:INFO:Copying training dataset
2025-12-01 16:19:12,602:INFO:Defining folds
2025-12-01 16:19:12,602:INFO:Declaring metric variables
2025-12-01 16:19:12,604:INFO:Importing untrained model
2025-12-01 16:19:12,606:INFO:Ada Boost Classifier Imported successfully
2025-12-01 16:19:12,609:INFO:Starting cross validation
2025-12-01 16:19:12,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:12,681:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:19:12,682:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:19:12,683:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:19:12,700:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:19:12,721:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-01 16:19:13,211:INFO:Calculating mean and std
2025-12-01 16:19:13,211:INFO:Creating metrics dataframe
2025-12-01 16:19:13,212:INFO:Uploading results into container
2025-12-01 16:19:13,212:INFO:Uploading model into container now
2025-12-01 16:19:13,212:INFO:_master_model_container: 9
2025-12-01 16:19:13,213:INFO:_display_container: 2
2025-12-01 16:19:13,213:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-01 16:19:13,213:INFO:create_model() successfully completed......................................
2025-12-01 16:19:13,271:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:13,271:INFO:Creating metrics dataframe
2025-12-01 16:19:13,274:INFO:Initializing Gradient Boosting Classifier
2025-12-01 16:19:13,274:INFO:Total runtime is 0.17230747143427527 minutes
2025-12-01 16:19:13,275:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:13,276:INFO:Initializing create_model()
2025-12-01 16:19:13,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:13,276:INFO:Checking exceptions
2025-12-01 16:19:13,276:INFO:Importing libraries
2025-12-01 16:19:13,276:INFO:Copying training dataset
2025-12-01 16:19:13,282:INFO:Defining folds
2025-12-01 16:19:13,282:INFO:Declaring metric variables
2025-12-01 16:19:13,283:INFO:Importing untrained model
2025-12-01 16:19:13,284:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 16:19:13,287:INFO:Starting cross validation
2025-12-01 16:19:13,287:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:15,539:INFO:Calculating mean and std
2025-12-01 16:19:15,542:INFO:Creating metrics dataframe
2025-12-01 16:19:15,545:INFO:Uploading results into container
2025-12-01 16:19:15,545:INFO:Uploading model into container now
2025-12-01 16:19:15,546:INFO:_master_model_container: 10
2025-12-01 16:19:15,546:INFO:_display_container: 2
2025-12-01 16:19:15,546:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 16:19:15,547:INFO:create_model() successfully completed......................................
2025-12-01 16:19:15,645:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:15,645:INFO:Creating metrics dataframe
2025-12-01 16:19:15,648:INFO:Initializing Linear Discriminant Analysis
2025-12-01 16:19:15,648:INFO:Total runtime is 0.21187856594721471 minutes
2025-12-01 16:19:15,650:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:15,650:INFO:Initializing create_model()
2025-12-01 16:19:15,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:15,650:INFO:Checking exceptions
2025-12-01 16:19:15,650:INFO:Importing libraries
2025-12-01 16:19:15,650:INFO:Copying training dataset
2025-12-01 16:19:15,656:INFO:Defining folds
2025-12-01 16:19:15,656:INFO:Declaring metric variables
2025-12-01 16:19:15,658:INFO:Importing untrained model
2025-12-01 16:19:15,660:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 16:19:15,662:INFO:Starting cross validation
2025-12-01 16:19:15,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:15,795:INFO:Calculating mean and std
2025-12-01 16:19:15,796:INFO:Creating metrics dataframe
2025-12-01 16:19:15,796:INFO:Uploading results into container
2025-12-01 16:19:15,797:INFO:Uploading model into container now
2025-12-01 16:19:15,797:INFO:_master_model_container: 11
2025-12-01 16:19:15,797:INFO:_display_container: 2
2025-12-01 16:19:15,797:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 16:19:15,797:INFO:create_model() successfully completed......................................
2025-12-01 16:19:15,856:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:15,856:INFO:Creating metrics dataframe
2025-12-01 16:19:15,859:INFO:Initializing Extra Trees Classifier
2025-12-01 16:19:15,859:INFO:Total runtime is 0.215389867623647 minutes
2025-12-01 16:19:15,860:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:15,861:INFO:Initializing create_model()
2025-12-01 16:19:15,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:15,861:INFO:Checking exceptions
2025-12-01 16:19:15,861:INFO:Importing libraries
2025-12-01 16:19:15,861:INFO:Copying training dataset
2025-12-01 16:19:15,867:INFO:Defining folds
2025-12-01 16:19:15,867:INFO:Declaring metric variables
2025-12-01 16:19:15,868:INFO:Importing untrained model
2025-12-01 16:19:15,869:INFO:Extra Trees Classifier Imported successfully
2025-12-01 16:19:15,871:INFO:Starting cross validation
2025-12-01 16:19:15,872:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:16,392:INFO:Calculating mean and std
2025-12-01 16:19:16,393:INFO:Creating metrics dataframe
2025-12-01 16:19:16,394:INFO:Uploading results into container
2025-12-01 16:19:16,394:INFO:Uploading model into container now
2025-12-01 16:19:16,394:INFO:_master_model_container: 12
2025-12-01 16:19:16,394:INFO:_display_container: 2
2025-12-01 16:19:16,395:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-12-01 16:19:16,395:INFO:create_model() successfully completed......................................
2025-12-01 16:19:16,462:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:16,463:INFO:Creating metrics dataframe
2025-12-01 16:19:16,466:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 16:19:16,466:INFO:Total runtime is 0.2255070845286051 minutes
2025-12-01 16:19:16,468:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:16,468:INFO:Initializing create_model()
2025-12-01 16:19:16,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:16,469:INFO:Checking exceptions
2025-12-01 16:19:16,469:INFO:Importing libraries
2025-12-01 16:19:16,469:INFO:Copying training dataset
2025-12-01 16:19:16,477:INFO:Defining folds
2025-12-01 16:19:16,477:INFO:Declaring metric variables
2025-12-01 16:19:16,478:INFO:Importing untrained model
2025-12-01 16:19:16,480:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 16:19:16,482:INFO:Starting cross validation
2025-12-01 16:19:16,483:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:17,968:INFO:Calculating mean and std
2025-12-01 16:19:17,968:INFO:Creating metrics dataframe
2025-12-01 16:19:17,970:INFO:Uploading results into container
2025-12-01 16:19:17,970:INFO:Uploading model into container now
2025-12-01 16:19:17,971:INFO:_master_model_container: 13
2025-12-01 16:19:17,971:INFO:_display_container: 2
2025-12-01 16:19:17,971:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 16:19:17,971:INFO:create_model() successfully completed......................................
2025-12-01 16:19:18,161:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:18,161:INFO:Creating metrics dataframe
2025-12-01 16:19:18,166:INFO:Initializing Dummy Classifier
2025-12-01 16:19:18,166:INFO:Total runtime is 0.25384020010630287 minutes
2025-12-01 16:19:18,167:INFO:SubProcess create_model() called ==================================
2025-12-01 16:19:18,168:INFO:Initializing create_model()
2025-12-01 16:19:18,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16c9f6650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:18,168:INFO:Checking exceptions
2025-12-01 16:19:18,168:INFO:Importing libraries
2025-12-01 16:19:18,168:INFO:Copying training dataset
2025-12-01 16:19:18,177:INFO:Defining folds
2025-12-01 16:19:18,177:INFO:Declaring metric variables
2025-12-01 16:19:18,178:INFO:Importing untrained model
2025-12-01 16:19:18,181:INFO:Dummy Classifier Imported successfully
2025-12-01 16:19:18,184:INFO:Starting cross validation
2025-12-01 16:19:18,184:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 16:19:18,284:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:19:18,311:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:19:18,322:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:19:18,329:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:19:18,335:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-01 16:19:18,339:INFO:Calculating mean and std
2025-12-01 16:19:18,340:INFO:Creating metrics dataframe
2025-12-01 16:19:18,342:INFO:Uploading results into container
2025-12-01 16:19:18,343:INFO:Uploading model into container now
2025-12-01 16:19:18,343:INFO:_master_model_container: 14
2025-12-01 16:19:18,343:INFO:_display_container: 2
2025-12-01 16:19:18,343:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 16:19:18,343:INFO:create_model() successfully completed......................................
2025-12-01 16:19:18,417:INFO:SubProcess create_model() end ==================================
2025-12-01 16:19:18,417:INFO:Creating metrics dataframe
2025-12-01 16:19:18,421:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-01 16:19:18,425:INFO:Initializing create_model()
2025-12-01 16:19:18,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-01 16:19:18,425:INFO:Checking exceptions
2025-12-01 16:19:18,426:INFO:Importing libraries
2025-12-01 16:19:18,426:INFO:Copying training dataset
2025-12-01 16:19:18,433:INFO:Defining folds
2025-12-01 16:19:18,433:INFO:Declaring metric variables
2025-12-01 16:19:18,433:INFO:Importing untrained model
2025-12-01 16:19:18,433:INFO:Declaring custom model
2025-12-01 16:19:18,433:INFO:Logistic Regression Imported successfully
2025-12-01 16:19:18,433:INFO:Cross validation set to False
2025-12-01 16:19:18,433:INFO:Fitting Model
2025-12-01 16:19:19,542:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-01 16:19:19,543:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:19:19,543:INFO:create_model() successfully completed......................................
2025-12-01 16:19:19,810:INFO:_master_model_container: 14
2025-12-01 16:19:19,811:INFO:_display_container: 2
2025-12-01 16:19:19,811:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 16:19:19,811:INFO:compare_models() successfully completed......................................
2025-12-03 14:12:59,266:INFO:Initializing compare_models()
2025-12-03 14:12:59,269:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:12:59,269:INFO:Checking exceptions
2025-12-03 14:12:59,441:INFO:Preparing display monitor
2025-12-03 14:12:59,608:INFO:Initializing Logistic Regression
2025-12-03 14:12:59,609:INFO:Total runtime is 1.1416276295979818e-05 minutes
2025-12-03 14:12:59,610:INFO:SubProcess create_model() called ==================================
2025-12-03 14:12:59,617:INFO:Initializing create_model()
2025-12-03 14:12:59,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16a4a6c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:12:59,617:INFO:Checking exceptions
2025-12-03 14:12:59,617:INFO:Importing libraries
2025-12-03 14:12:59,617:INFO:Copying training dataset
2025-12-03 14:12:59,629:INFO:Defining folds
2025-12-03 14:12:59,629:INFO:Declaring metric variables
2025-12-03 14:12:59,631:INFO:Importing untrained model
2025-12-03 14:12:59,638:INFO:Logistic Regression Imported successfully
2025-12-03 14:12:59,641:INFO:Starting cross validation
2025-12-03 14:12:59,673:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:13:03,816:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:03,816:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:03,816:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:03,816:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:03,816:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:04,299:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:04,310:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:04,318:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:04,342:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:04,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:04,387:INFO:Calculating mean and std
2025-12-03 14:13:04,398:INFO:Creating metrics dataframe
2025-12-03 14:13:04,416:INFO:Uploading results into container
2025-12-03 14:13:04,418:INFO:Uploading model into container now
2025-12-03 14:13:04,422:INFO:_master_model_container: 15
2025-12-03 14:13:04,422:INFO:_display_container: 3
2025-12-03 14:13:04,424:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:13:04,424:INFO:create_model() successfully completed......................................
2025-12-03 14:13:05,336:INFO:SubProcess create_model() end ==================================
2025-12-03 14:13:05,336:INFO:Creating metrics dataframe
2025-12-03 14:13:05,345:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:13:05,345:INFO:Total runtime is 0.09561986525853476 minutes
2025-12-03 14:13:05,346:INFO:SubProcess create_model() called ==================================
2025-12-03 14:13:05,346:INFO:Initializing create_model()
2025-12-03 14:13:05,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16a4a6c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:13:05,346:INFO:Checking exceptions
2025-12-03 14:13:05,347:INFO:Importing libraries
2025-12-03 14:13:05,347:INFO:Copying training dataset
2025-12-03 14:13:05,372:INFO:Defining folds
2025-12-03 14:13:05,372:INFO:Declaring metric variables
2025-12-03 14:13:05,376:INFO:Importing untrained model
2025-12-03 14:13:05,378:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:13:05,381:INFO:Starting cross validation
2025-12-03 14:13:05,382:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:13:05,517:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:13:05,521:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:13:05,534:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:13:06,782:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:06,783:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:06,866:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:13:06,866:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:13:06,892:INFO:Calculating mean and std
2025-12-03 14:13:06,897:INFO:Creating metrics dataframe
2025-12-03 14:13:06,903:INFO:Uploading results into container
2025-12-03 14:13:06,904:INFO:Uploading model into container now
2025-12-03 14:13:06,905:INFO:_master_model_container: 16
2025-12-03 14:13:06,905:INFO:_display_container: 3
2025-12-03 14:13:06,906:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:13:06,906:INFO:create_model() successfully completed......................................
2025-12-03 14:13:07,184:INFO:SubProcess create_model() end ==================================
2025-12-03 14:13:07,185:INFO:Creating metrics dataframe
2025-12-03 14:13:07,187:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:13:07,187:INFO:Total runtime is 0.1263322154680888 minutes
2025-12-03 14:13:07,189:INFO:SubProcess create_model() called ==================================
2025-12-03 14:13:07,190:INFO:Initializing create_model()
2025-12-03 14:13:07,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16a4a6c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:13:07,190:INFO:Checking exceptions
2025-12-03 14:13:07,190:INFO:Importing libraries
2025-12-03 14:13:07,190:INFO:Copying training dataset
2025-12-03 14:13:07,196:INFO:Defining folds
2025-12-03 14:13:07,197:INFO:Declaring metric variables
2025-12-03 14:13:07,198:INFO:Importing untrained model
2025-12-03 14:13:07,199:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:13:07,202:INFO:Starting cross validation
2025-12-03 14:13:07,203:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:13:08,948:INFO:Calculating mean and std
2025-12-03 14:13:08,951:INFO:Creating metrics dataframe
2025-12-03 14:13:08,964:INFO:Uploading results into container
2025-12-03 14:13:08,965:INFO:Uploading model into container now
2025-12-03 14:13:08,966:INFO:_master_model_container: 17
2025-12-03 14:13:08,966:INFO:_display_container: 3
2025-12-03 14:13:08,968:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:13:08,968:INFO:create_model() successfully completed......................................
2025-12-03 14:13:09,084:INFO:SubProcess create_model() end ==================================
2025-12-03 14:13:09,084:INFO:Creating metrics dataframe
2025-12-03 14:13:09,087:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:13:09,091:INFO:Initializing create_model()
2025-12-03 14:13:09,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x320f41890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:13:09,091:INFO:Checking exceptions
2025-12-03 14:13:09,092:INFO:Importing libraries
2025-12-03 14:13:09,092:INFO:Copying training dataset
2025-12-03 14:13:09,099:INFO:Defining folds
2025-12-03 14:13:09,099:INFO:Declaring metric variables
2025-12-03 14:13:09,099:INFO:Importing untrained model
2025-12-03 14:13:09,099:INFO:Declaring custom model
2025-12-03 14:13:09,099:INFO:Logistic Regression Imported successfully
2025-12-03 14:13:09,099:INFO:Cross validation set to False
2025-12-03 14:13:09,099:INFO:Fitting Model
2025-12-03 14:13:10,428:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:13:10,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:13:10,429:INFO:create_model() successfully completed......................................
2025-12-03 14:13:10,560:INFO:_master_model_container: 17
2025-12-03 14:13:10,560:INFO:_display_container: 3
2025-12-03 14:13:10,560:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:13:10,560:INFO:compare_models() successfully completed......................................
2025-12-03 14:20:38,992:INFO:PyCaret ClassificationExperiment
2025-12-03 14:20:38,992:INFO:Logging name: clf-default-name
2025-12-03 14:20:38,992:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 14:20:38,992:INFO:version 3.3.2
2025-12-03 14:20:38,992:INFO:Initializing setup()
2025-12-03 14:20:38,992:INFO:self.USI: 5e61
2025-12-03 14:20:38,992:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 14:20:38,992:INFO:Checking environment
2025-12-03 14:20:38,992:INFO:python_version: 3.11.14
2025-12-03 14:20:38,992:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 14:20:38,992:INFO:machine: arm64
2025-12-03 14:20:38,992:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:20:38,994:INFO:Memory: svmem(total=8589934592, available=1395998720, percent=83.7, used=2994241536, free=60456960, active=1348599808, inactive=1334116352, wired=1645641728)
2025-12-03 14:20:38,994:INFO:Physical Core: 8
2025-12-03 14:20:38,994:INFO:Logical Core: 8
2025-12-03 14:20:38,994:INFO:Checking libraries
2025-12-03 14:20:38,994:INFO:System:
2025-12-03 14:20:38,994:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 14:20:38,994:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 14:20:38,994:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:20:38,994:INFO:PyCaret required dependencies:
2025-12-03 14:20:38,994:INFO:                 pip: 25.3
2025-12-03 14:20:38,994:INFO:          setuptools: 80.9.0
2025-12-03 14:20:38,994:INFO:             pycaret: 3.3.2
2025-12-03 14:20:38,994:INFO:             IPython: 9.7.0
2025-12-03 14:20:38,994:INFO:          ipywidgets: 8.1.8
2025-12-03 14:20:38,994:INFO:                tqdm: 4.67.1
2025-12-03 14:20:38,994:INFO:               numpy: 1.26.4
2025-12-03 14:20:38,994:INFO:              pandas: 2.1.4
2025-12-03 14:20:38,994:INFO:              jinja2: 3.1.6
2025-12-03 14:20:38,994:INFO:               scipy: 1.11.4
2025-12-03 14:20:38,994:INFO:              joblib: 1.3.2
2025-12-03 14:20:38,994:INFO:             sklearn: 1.4.2
2025-12-03 14:20:38,994:INFO:                pyod: 2.0.5
2025-12-03 14:20:38,994:INFO:            imblearn: 0.14.0
2025-12-03 14:20:38,994:INFO:   category_encoders: 2.7.0
2025-12-03 14:20:38,994:INFO:            lightgbm: 4.6.0
2025-12-03 14:20:38,994:INFO:               numba: 0.62.1
2025-12-03 14:20:38,994:INFO:            requests: 2.32.5
2025-12-03 14:20:38,994:INFO:          matplotlib: 3.7.5
2025-12-03 14:20:38,994:INFO:          scikitplot: 0.3.7
2025-12-03 14:20:38,994:INFO:         yellowbrick: 1.5
2025-12-03 14:20:38,994:INFO:              plotly: 6.5.0
2025-12-03 14:20:38,994:INFO:    plotly-resampler: Not installed
2025-12-03 14:20:38,994:INFO:             kaleido: 1.2.0
2025-12-03 14:20:38,994:INFO:           schemdraw: 0.15
2025-12-03 14:20:38,994:INFO:         statsmodels: 0.14.5
2025-12-03 14:20:38,994:INFO:              sktime: 0.26.0
2025-12-03 14:20:38,995:INFO:               tbats: 1.1.3
2025-12-03 14:20:38,995:INFO:            pmdarima: 2.0.4
2025-12-03 14:20:38,995:INFO:              psutil: 7.1.3
2025-12-03 14:20:38,995:INFO:          markupsafe: 3.0.3
2025-12-03 14:20:38,995:INFO:             pickle5: Not installed
2025-12-03 14:20:38,995:INFO:         cloudpickle: 3.1.2
2025-12-03 14:20:38,995:INFO:         deprecation: 2.1.0
2025-12-03 14:20:38,995:INFO:              xxhash: 3.6.0
2025-12-03 14:20:38,995:INFO:           wurlitzer: 3.1.1
2025-12-03 14:20:38,995:INFO:PyCaret optional dependencies:
2025-12-03 14:20:38,995:INFO:                shap: Not installed
2025-12-03 14:20:38,995:INFO:           interpret: Not installed
2025-12-03 14:20:38,995:INFO:                umap: Not installed
2025-12-03 14:20:38,995:INFO:     ydata_profiling: Not installed
2025-12-03 14:20:38,995:INFO:  explainerdashboard: Not installed
2025-12-03 14:20:38,995:INFO:             autoviz: Not installed
2025-12-03 14:20:38,995:INFO:           fairlearn: Not installed
2025-12-03 14:20:38,995:INFO:          deepchecks: Not installed
2025-12-03 14:20:38,995:INFO:             xgboost: Not installed
2025-12-03 14:20:38,995:INFO:            catboost: Not installed
2025-12-03 14:20:38,995:INFO:              kmodes: Not installed
2025-12-03 14:20:38,995:INFO:             mlxtend: Not installed
2025-12-03 14:20:38,995:INFO:       statsforecast: Not installed
2025-12-03 14:20:38,995:INFO:        tune_sklearn: Not installed
2025-12-03 14:20:38,995:INFO:                 ray: Not installed
2025-12-03 14:20:38,995:INFO:            hyperopt: Not installed
2025-12-03 14:20:38,995:INFO:              optuna: Not installed
2025-12-03 14:20:38,995:INFO:               skopt: Not installed
2025-12-03 14:20:38,995:INFO:              mlflow: Not installed
2025-12-03 14:20:38,995:INFO:              gradio: Not installed
2025-12-03 14:20:38,995:INFO:             fastapi: Not installed
2025-12-03 14:20:38,995:INFO:             uvicorn: Not installed
2025-12-03 14:20:38,995:INFO:              m2cgen: Not installed
2025-12-03 14:20:38,995:INFO:           evidently: Not installed
2025-12-03 14:20:38,995:INFO:               fugue: Not installed
2025-12-03 14:20:38,995:INFO:           streamlit: Not installed
2025-12-03 14:20:38,995:INFO:             prophet: Not installed
2025-12-03 14:20:38,995:INFO:None
2025-12-03 14:20:38,995:INFO:Set up data.
2025-12-03 14:20:39,031:INFO:Set up folding strategy.
2025-12-03 14:20:39,031:INFO:Set up train/test split.
2025-12-03 14:20:39,045:INFO:Set up index.
2025-12-03 14:20:39,045:INFO:Assigning column types.
2025-12-03 14:20:39,050:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 14:20:39,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,072:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,102:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,113:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 14:20:39,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:20:39,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,172:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 14:20:39,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,231:INFO:Preparing preprocessing pipeline...
2025-12-03 14:20:39,234:INFO:Set up simple imputation.
2025-12-03 14:20:39,234:INFO:Set up imbalanced handling.
2025-12-03 14:20:39,237:INFO:Set up column name cleaning.
2025-12-03 14:20:39,308:INFO:Finished creating preprocessing pipeline.
2025-12-03 14:20:39,311:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['gender', 'age', 'under_30',
                                             'senior_citizen', 'partner',
                                             'dependents',
                                             'number_of_dependents', 'married',
                                             'paperless_billing',
                                             'monthly_ charges',
                                             'avg_monthly_long_distance_charges',
                                             'total_charges'...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 14:20:39,311:INFO:Creating final display dataframe.
2025-12-03 14:20:39,429:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 45)
4        Transformed data shape        (9687, 45)
5   Transformed train set shape        (8278, 45)
6    Transformed test set shape        (1409, 45)
7              Numeric features                33
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              5e61
2025-12-03 14:20:39,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:20:39,498:INFO:setup() successfully completed in 0.52s...............
2025-12-03 14:20:39,508:INFO:Initializing compare_models()
2025-12-03 14:20:39,508:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:20:39,508:INFO:Checking exceptions
2025-12-03 14:20:39,515:INFO:Preparing display monitor
2025-12-03 14:20:39,529:INFO:Initializing Logistic Regression
2025-12-03 14:20:39,529:INFO:Total runtime is 1.633167266845703e-06 minutes
2025-12-03 14:20:39,530:INFO:SubProcess create_model() called ==================================
2025-12-03 14:20:39,530:INFO:Initializing create_model()
2025-12-03 14:20:39,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32759cf50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:20:39,530:INFO:Checking exceptions
2025-12-03 14:20:39,530:INFO:Importing libraries
2025-12-03 14:20:39,530:INFO:Copying training dataset
2025-12-03 14:20:39,543:INFO:Defining folds
2025-12-03 14:20:39,543:INFO:Declaring metric variables
2025-12-03 14:20:39,546:INFO:Importing untrained model
2025-12-03 14:20:39,547:INFO:Logistic Regression Imported successfully
2025-12-03 14:20:39,551:INFO:Starting cross validation
2025-12-03 14:20:39,551:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:20:43,114:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:43,114:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:43,114:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:43,114:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:43,115:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:43,574:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:43,588:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:43,601:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:43,611:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:43,619:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:43,650:INFO:Calculating mean and std
2025-12-03 14:20:43,661:INFO:Creating metrics dataframe
2025-12-03 14:20:43,669:INFO:Uploading results into container
2025-12-03 14:20:43,672:INFO:Uploading model into container now
2025-12-03 14:20:43,676:INFO:_master_model_container: 1
2025-12-03 14:20:43,677:INFO:_display_container: 2
2025-12-03 14:20:43,678:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:20:43,678:INFO:create_model() successfully completed......................................
2025-12-03 14:20:43,969:INFO:SubProcess create_model() end ==================================
2025-12-03 14:20:43,969:INFO:Creating metrics dataframe
2025-12-03 14:20:43,971:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:20:43,971:INFO:Total runtime is 0.07404763301213582 minutes
2025-12-03 14:20:43,973:INFO:SubProcess create_model() called ==================================
2025-12-03 14:20:43,973:INFO:Initializing create_model()
2025-12-03 14:20:43,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32759cf50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:20:43,973:INFO:Checking exceptions
2025-12-03 14:20:43,973:INFO:Importing libraries
2025-12-03 14:20:43,973:INFO:Copying training dataset
2025-12-03 14:20:43,982:INFO:Defining folds
2025-12-03 14:20:43,982:INFO:Declaring metric variables
2025-12-03 14:20:43,983:INFO:Importing untrained model
2025-12-03 14:20:43,985:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:20:43,990:INFO:Starting cross validation
2025-12-03 14:20:43,991:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:20:44,103:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:20:44,104:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:20:44,115:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:20:45,240:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:45,269:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:45,329:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:20:45,356:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:20:45,377:INFO:Calculating mean and std
2025-12-03 14:20:45,380:INFO:Creating metrics dataframe
2025-12-03 14:20:45,384:INFO:Uploading results into container
2025-12-03 14:20:45,384:INFO:Uploading model into container now
2025-12-03 14:20:45,385:INFO:_master_model_container: 2
2025-12-03 14:20:45,385:INFO:_display_container: 2
2025-12-03 14:20:45,386:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:20:45,386:INFO:create_model() successfully completed......................................
2025-12-03 14:20:45,539:INFO:SubProcess create_model() end ==================================
2025-12-03 14:20:45,539:INFO:Creating metrics dataframe
2025-12-03 14:20:45,541:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:20:45,542:INFO:Total runtime is 0.10021704832712809 minutes
2025-12-03 14:20:45,543:INFO:SubProcess create_model() called ==================================
2025-12-03 14:20:45,543:INFO:Initializing create_model()
2025-12-03 14:20:45,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32759cf50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:20:45,543:INFO:Checking exceptions
2025-12-03 14:20:45,543:INFO:Importing libraries
2025-12-03 14:20:45,543:INFO:Copying training dataset
2025-12-03 14:20:45,550:INFO:Defining folds
2025-12-03 14:20:45,550:INFO:Declaring metric variables
2025-12-03 14:20:45,552:INFO:Importing untrained model
2025-12-03 14:20:45,553:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:20:45,555:INFO:Starting cross validation
2025-12-03 14:20:45,556:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:20:47,393:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:20:47,947:INFO:Calculating mean and std
2025-12-03 14:20:47,953:INFO:Creating metrics dataframe
2025-12-03 14:20:47,961:INFO:Uploading results into container
2025-12-03 14:20:47,962:INFO:Uploading model into container now
2025-12-03 14:20:47,963:INFO:_master_model_container: 3
2025-12-03 14:20:47,963:INFO:_display_container: 2
2025-12-03 14:20:47,964:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:20:47,964:INFO:create_model() successfully completed......................................
2025-12-03 14:20:48,132:INFO:SubProcess create_model() end ==================================
2025-12-03 14:20:48,133:INFO:Creating metrics dataframe
2025-12-03 14:20:48,136:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:20:48,139:INFO:Initializing create_model()
2025-12-03 14:20:48,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e200050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:20:48,139:INFO:Checking exceptions
2025-12-03 14:20:48,141:INFO:Importing libraries
2025-12-03 14:20:48,141:INFO:Copying training dataset
2025-12-03 14:20:48,149:INFO:Defining folds
2025-12-03 14:20:48,149:INFO:Declaring metric variables
2025-12-03 14:20:48,149:INFO:Importing untrained model
2025-12-03 14:20:48,149:INFO:Declaring custom model
2025-12-03 14:20:48,149:INFO:Logistic Regression Imported successfully
2025-12-03 14:20:48,150:INFO:Cross validation set to False
2025-12-03 14:20:48,150:INFO:Fitting Model
2025-12-03 14:20:49,627:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 14:20:49,629:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:20:49,629:INFO:create_model() successfully completed......................................
2025-12-03 14:20:49,880:INFO:_master_model_container: 3
2025-12-03 14:20:49,880:INFO:_display_container: 2
2025-12-03 14:20:49,881:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:20:49,881:INFO:compare_models() successfully completed......................................
2025-12-03 14:24:11,825:INFO:PyCaret ClassificationExperiment
2025-12-03 14:24:11,826:INFO:Logging name: clf-default-name
2025-12-03 14:24:11,826:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 14:24:11,826:INFO:version 3.3.2
2025-12-03 14:24:11,826:INFO:Initializing setup()
2025-12-03 14:24:11,826:INFO:self.USI: 163c
2025-12-03 14:24:11,826:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 14:24:11,826:INFO:Checking environment
2025-12-03 14:24:11,826:INFO:python_version: 3.11.14
2025-12-03 14:24:11,826:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 14:24:11,826:INFO:machine: arm64
2025-12-03 14:24:11,826:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:24:11,829:INFO:Memory: svmem(total=8589934592, available=1341636608, percent=84.4, used=2945417216, free=59539456, active=1299939328, inactive=1278132224, wired=1645477888)
2025-12-03 14:24:11,829:INFO:Physical Core: 8
2025-12-03 14:24:11,829:INFO:Logical Core: 8
2025-12-03 14:24:11,829:INFO:Checking libraries
2025-12-03 14:24:11,829:INFO:System:
2025-12-03 14:24:11,829:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 14:24:11,829:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 14:24:11,829:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:24:11,829:INFO:PyCaret required dependencies:
2025-12-03 14:24:11,830:INFO:                 pip: 25.3
2025-12-03 14:24:11,830:INFO:          setuptools: 80.9.0
2025-12-03 14:24:11,830:INFO:             pycaret: 3.3.2
2025-12-03 14:24:11,830:INFO:             IPython: 9.7.0
2025-12-03 14:24:11,830:INFO:          ipywidgets: 8.1.8
2025-12-03 14:24:11,830:INFO:                tqdm: 4.67.1
2025-12-03 14:24:11,830:INFO:               numpy: 1.26.4
2025-12-03 14:24:11,830:INFO:              pandas: 2.1.4
2025-12-03 14:24:11,830:INFO:              jinja2: 3.1.6
2025-12-03 14:24:11,830:INFO:               scipy: 1.11.4
2025-12-03 14:24:11,830:INFO:              joblib: 1.3.2
2025-12-03 14:24:11,830:INFO:             sklearn: 1.4.2
2025-12-03 14:24:11,830:INFO:                pyod: 2.0.5
2025-12-03 14:24:11,830:INFO:            imblearn: 0.14.0
2025-12-03 14:24:11,830:INFO:   category_encoders: 2.7.0
2025-12-03 14:24:11,830:INFO:            lightgbm: 4.6.0
2025-12-03 14:24:11,830:INFO:               numba: 0.62.1
2025-12-03 14:24:11,830:INFO:            requests: 2.32.5
2025-12-03 14:24:11,830:INFO:          matplotlib: 3.7.5
2025-12-03 14:24:11,830:INFO:          scikitplot: 0.3.7
2025-12-03 14:24:11,830:INFO:         yellowbrick: 1.5
2025-12-03 14:24:11,830:INFO:              plotly: 6.5.0
2025-12-03 14:24:11,830:INFO:    plotly-resampler: Not installed
2025-12-03 14:24:11,830:INFO:             kaleido: 1.2.0
2025-12-03 14:24:11,830:INFO:           schemdraw: 0.15
2025-12-03 14:24:11,830:INFO:         statsmodels: 0.14.5
2025-12-03 14:24:11,830:INFO:              sktime: 0.26.0
2025-12-03 14:24:11,830:INFO:               tbats: 1.1.3
2025-12-03 14:24:11,830:INFO:            pmdarima: 2.0.4
2025-12-03 14:24:11,830:INFO:              psutil: 7.1.3
2025-12-03 14:24:11,830:INFO:          markupsafe: 3.0.3
2025-12-03 14:24:11,830:INFO:             pickle5: Not installed
2025-12-03 14:24:11,830:INFO:         cloudpickle: 3.1.2
2025-12-03 14:24:11,830:INFO:         deprecation: 2.1.0
2025-12-03 14:24:11,830:INFO:              xxhash: 3.6.0
2025-12-03 14:24:11,830:INFO:           wurlitzer: 3.1.1
2025-12-03 14:24:11,830:INFO:PyCaret optional dependencies:
2025-12-03 14:24:11,831:INFO:                shap: Not installed
2025-12-03 14:24:11,831:INFO:           interpret: Not installed
2025-12-03 14:24:11,831:INFO:                umap: Not installed
2025-12-03 14:24:11,831:INFO:     ydata_profiling: Not installed
2025-12-03 14:24:11,831:INFO:  explainerdashboard: Not installed
2025-12-03 14:24:11,831:INFO:             autoviz: Not installed
2025-12-03 14:24:11,831:INFO:           fairlearn: Not installed
2025-12-03 14:24:11,831:INFO:          deepchecks: Not installed
2025-12-03 14:24:11,831:INFO:             xgboost: Not installed
2025-12-03 14:24:11,831:INFO:            catboost: Not installed
2025-12-03 14:24:11,831:INFO:              kmodes: Not installed
2025-12-03 14:24:11,831:INFO:             mlxtend: Not installed
2025-12-03 14:24:11,831:INFO:       statsforecast: Not installed
2025-12-03 14:24:11,831:INFO:        tune_sklearn: Not installed
2025-12-03 14:24:11,831:INFO:                 ray: Not installed
2025-12-03 14:24:11,831:INFO:            hyperopt: Not installed
2025-12-03 14:24:11,831:INFO:              optuna: Not installed
2025-12-03 14:24:11,831:INFO:               skopt: Not installed
2025-12-03 14:24:11,831:INFO:              mlflow: Not installed
2025-12-03 14:24:11,831:INFO:              gradio: Not installed
2025-12-03 14:24:11,832:INFO:             fastapi: Not installed
2025-12-03 14:24:11,832:INFO:             uvicorn: Not installed
2025-12-03 14:24:11,832:INFO:              m2cgen: Not installed
2025-12-03 14:24:11,832:INFO:           evidently: Not installed
2025-12-03 14:24:11,832:INFO:               fugue: Not installed
2025-12-03 14:24:11,832:INFO:           streamlit: Not installed
2025-12-03 14:24:11,832:INFO:             prophet: Not installed
2025-12-03 14:24:11,832:INFO:None
2025-12-03 14:24:11,832:INFO:Set up data.
2025-12-03 14:24:11,855:INFO:Set up folding strategy.
2025-12-03 14:24:11,855:INFO:Set up train/test split.
2025-12-03 14:24:11,872:INFO:Set up index.
2025-12-03 14:24:11,872:INFO:Assigning column types.
2025-12-03 14:24:11,875:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 14:24:11,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,940:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 14:24:11,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:24:11,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:11,996:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 14:24:12,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,054:INFO:Preparing preprocessing pipeline...
2025-12-03 14:24:12,056:INFO:Set up simple imputation.
2025-12-03 14:24:12,056:INFO:Set up imbalanced handling.
2025-12-03 14:24:12,056:INFO:Set up column name cleaning.
2025-12-03 14:24:12,098:INFO:Finished creating preprocessing pipeline.
2025-12-03 14:24:12,100:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              ke...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 14:24:12,100:INFO:Creating final display dataframe.
2025-12-03 14:24:12,162:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 10)
4        Transformed data shape        (9687, 10)
5   Transformed train set shape        (8278, 10)
6    Transformed test set shape        (1409, 10)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              163c
2025-12-03 14:24:12,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:24:12,236:INFO:setup() successfully completed in 0.42s...............
2025-12-03 14:24:12,240:INFO:Initializing compare_models()
2025-12-03 14:24:12,240:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:24:12,240:INFO:Checking exceptions
2025-12-03 14:24:12,243:INFO:Preparing display monitor
2025-12-03 14:24:12,257:INFO:Initializing Logistic Regression
2025-12-03 14:24:12,258:INFO:Total runtime is 3.2822291056315106e-06 minutes
2025-12-03 14:24:12,259:INFO:SubProcess create_model() called ==================================
2025-12-03 14:24:12,259:INFO:Initializing create_model()
2025-12-03 14:24:12,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e15b8d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:24:12,259:INFO:Checking exceptions
2025-12-03 14:24:12,259:INFO:Importing libraries
2025-12-03 14:24:12,259:INFO:Copying training dataset
2025-12-03 14:24:12,300:INFO:Defining folds
2025-12-03 14:24:12,300:INFO:Declaring metric variables
2025-12-03 14:24:12,307:INFO:Importing untrained model
2025-12-03 14:24:12,319:INFO:Logistic Regression Imported successfully
2025-12-03 14:24:12,327:INFO:Starting cross validation
2025-12-03 14:24:12,329:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:24:12,664:INFO:Calculating mean and std
2025-12-03 14:24:12,664:INFO:Creating metrics dataframe
2025-12-03 14:24:12,665:INFO:Uploading results into container
2025-12-03 14:24:12,665:INFO:Uploading model into container now
2025-12-03 14:24:12,665:INFO:_master_model_container: 1
2025-12-03 14:24:12,665:INFO:_display_container: 2
2025-12-03 14:24:12,665:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:24:12,665:INFO:create_model() successfully completed......................................
2025-12-03 14:24:13,010:INFO:SubProcess create_model() end ==================================
2025-12-03 14:24:13,010:INFO:Creating metrics dataframe
2025-12-03 14:24:13,012:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:24:13,012:INFO:Total runtime is 0.012586085001627605 minutes
2025-12-03 14:24:13,014:INFO:SubProcess create_model() called ==================================
2025-12-03 14:24:13,014:INFO:Initializing create_model()
2025-12-03 14:24:13,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e15b8d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:24:13,014:INFO:Checking exceptions
2025-12-03 14:24:13,014:INFO:Importing libraries
2025-12-03 14:24:13,014:INFO:Copying training dataset
2025-12-03 14:24:13,016:INFO:Defining folds
2025-12-03 14:24:13,016:INFO:Declaring metric variables
2025-12-03 14:24:13,017:INFO:Importing untrained model
2025-12-03 14:24:13,018:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:24:13,020:INFO:Starting cross validation
2025-12-03 14:24:13,021:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:24:13,168:INFO:Calculating mean and std
2025-12-03 14:24:13,168:INFO:Creating metrics dataframe
2025-12-03 14:24:13,169:INFO:Uploading results into container
2025-12-03 14:24:13,169:INFO:Uploading model into container now
2025-12-03 14:24:13,169:INFO:_master_model_container: 2
2025-12-03 14:24:13,169:INFO:_display_container: 2
2025-12-03 14:24:13,169:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:24:13,169:INFO:create_model() successfully completed......................................
2025-12-03 14:24:13,246:INFO:SubProcess create_model() end ==================================
2025-12-03 14:24:13,246:INFO:Creating metrics dataframe
2025-12-03 14:24:13,249:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:24:13,249:INFO:Total runtime is 0.016524000962575277 minutes
2025-12-03 14:24:13,250:INFO:SubProcess create_model() called ==================================
2025-12-03 14:24:13,250:INFO:Initializing create_model()
2025-12-03 14:24:13,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e15b8d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:24:13,251:INFO:Checking exceptions
2025-12-03 14:24:13,251:INFO:Importing libraries
2025-12-03 14:24:13,251:INFO:Copying training dataset
2025-12-03 14:24:13,253:INFO:Defining folds
2025-12-03 14:24:13,253:INFO:Declaring metric variables
2025-12-03 14:24:13,254:INFO:Importing untrained model
2025-12-03 14:24:13,256:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:24:13,258:INFO:Starting cross validation
2025-12-03 14:24:13,259:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:24:14,995:INFO:Calculating mean and std
2025-12-03 14:24:14,997:INFO:Creating metrics dataframe
2025-12-03 14:24:15,001:INFO:Uploading results into container
2025-12-03 14:24:15,002:INFO:Uploading model into container now
2025-12-03 14:24:15,003:INFO:_master_model_container: 3
2025-12-03 14:24:15,004:INFO:_display_container: 2
2025-12-03 14:24:15,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:24:15,005:INFO:create_model() successfully completed......................................
2025-12-03 14:24:15,145:INFO:SubProcess create_model() end ==================================
2025-12-03 14:24:15,145:INFO:Creating metrics dataframe
2025-12-03 14:24:15,148:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:24:15,152:INFO:Initializing create_model()
2025-12-03 14:24:15,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31ddca810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:24:15,152:INFO:Checking exceptions
2025-12-03 14:24:15,153:INFO:Importing libraries
2025-12-03 14:24:15,153:INFO:Copying training dataset
2025-12-03 14:24:15,155:INFO:Defining folds
2025-12-03 14:24:15,155:INFO:Declaring metric variables
2025-12-03 14:24:15,155:INFO:Importing untrained model
2025-12-03 14:24:15,155:INFO:Declaring custom model
2025-12-03 14:24:15,156:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:24:15,156:INFO:Cross validation set to False
2025-12-03 14:24:15,156:INFO:Fitting Model
2025-12-03 14:24:15,407:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 14:24:15,408:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:24:15,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-12-03 14:24:15,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:24:15,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:24:15,409:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:24:15,409:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:24:15,409:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:24:15,775:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:24:15,775:INFO:create_model() successfully completed......................................
2025-12-03 14:24:15,856:INFO:_master_model_container: 3
2025-12-03 14:24:15,856:INFO:_display_container: 2
2025-12-03 14:24:15,856:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:24:15,856:INFO:compare_models() successfully completed......................................
2025-12-03 14:30:45,041:INFO:PyCaret ClassificationExperiment
2025-12-03 14:30:45,042:INFO:Logging name: clf-default-name
2025-12-03 14:30:45,042:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 14:30:45,042:INFO:version 3.3.2
2025-12-03 14:30:45,042:INFO:Initializing setup()
2025-12-03 14:30:45,042:INFO:self.USI: e80b
2025-12-03 14:30:45,042:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 14:30:45,043:INFO:Checking environment
2025-12-03 14:30:45,043:INFO:python_version: 3.11.14
2025-12-03 14:30:45,043:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 14:30:45,043:INFO:machine: arm64
2025-12-03 14:30:45,043:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:30:45,045:INFO:Memory: svmem(total=8589934592, available=1387495424, percent=83.8, used=2947334144, free=63488000, active=1346011136, inactive=1297842176, wired=1601323008)
2025-12-03 14:30:45,045:INFO:Physical Core: 8
2025-12-03 14:30:45,045:INFO:Logical Core: 8
2025-12-03 14:30:45,045:INFO:Checking libraries
2025-12-03 14:30:45,045:INFO:System:
2025-12-03 14:30:45,045:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 14:30:45,045:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 14:30:45,045:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:30:45,045:INFO:PyCaret required dependencies:
2025-12-03 14:30:45,046:INFO:                 pip: 25.3
2025-12-03 14:30:45,046:INFO:          setuptools: 80.9.0
2025-12-03 14:30:45,046:INFO:             pycaret: 3.3.2
2025-12-03 14:30:45,046:INFO:             IPython: 9.7.0
2025-12-03 14:30:45,046:INFO:          ipywidgets: 8.1.8
2025-12-03 14:30:45,046:INFO:                tqdm: 4.67.1
2025-12-03 14:30:45,046:INFO:               numpy: 1.26.4
2025-12-03 14:30:45,046:INFO:              pandas: 2.1.4
2025-12-03 14:30:45,046:INFO:              jinja2: 3.1.6
2025-12-03 14:30:45,046:INFO:               scipy: 1.11.4
2025-12-03 14:30:45,046:INFO:              joblib: 1.3.2
2025-12-03 14:30:45,046:INFO:             sklearn: 1.4.2
2025-12-03 14:30:45,046:INFO:                pyod: 2.0.5
2025-12-03 14:30:45,046:INFO:            imblearn: 0.14.0
2025-12-03 14:30:45,046:INFO:   category_encoders: 2.7.0
2025-12-03 14:30:45,046:INFO:            lightgbm: 4.6.0
2025-12-03 14:30:45,046:INFO:               numba: 0.62.1
2025-12-03 14:30:45,046:INFO:            requests: 2.32.5
2025-12-03 14:30:45,046:INFO:          matplotlib: 3.7.5
2025-12-03 14:30:45,046:INFO:          scikitplot: 0.3.7
2025-12-03 14:30:45,046:INFO:         yellowbrick: 1.5
2025-12-03 14:30:45,046:INFO:              plotly: 6.5.0
2025-12-03 14:30:45,046:INFO:    plotly-resampler: Not installed
2025-12-03 14:30:45,046:INFO:             kaleido: 1.2.0
2025-12-03 14:30:45,046:INFO:           schemdraw: 0.15
2025-12-03 14:30:45,046:INFO:         statsmodels: 0.14.5
2025-12-03 14:30:45,046:INFO:              sktime: 0.26.0
2025-12-03 14:30:45,046:INFO:               tbats: 1.1.3
2025-12-03 14:30:45,046:INFO:            pmdarima: 2.0.4
2025-12-03 14:30:45,046:INFO:              psutil: 7.1.3
2025-12-03 14:30:45,047:INFO:          markupsafe: 3.0.3
2025-12-03 14:30:45,047:INFO:             pickle5: Not installed
2025-12-03 14:30:45,047:INFO:         cloudpickle: 3.1.2
2025-12-03 14:30:45,047:INFO:         deprecation: 2.1.0
2025-12-03 14:30:45,047:INFO:              xxhash: 3.6.0
2025-12-03 14:30:45,047:INFO:           wurlitzer: 3.1.1
2025-12-03 14:30:45,047:INFO:PyCaret optional dependencies:
2025-12-03 14:30:45,047:INFO:                shap: Not installed
2025-12-03 14:30:45,047:INFO:           interpret: Not installed
2025-12-03 14:30:45,047:INFO:                umap: Not installed
2025-12-03 14:30:45,047:INFO:     ydata_profiling: Not installed
2025-12-03 14:30:45,047:INFO:  explainerdashboard: Not installed
2025-12-03 14:30:45,047:INFO:             autoviz: Not installed
2025-12-03 14:30:45,047:INFO:           fairlearn: Not installed
2025-12-03 14:30:45,047:INFO:          deepchecks: Not installed
2025-12-03 14:30:45,047:INFO:             xgboost: Not installed
2025-12-03 14:30:45,047:INFO:            catboost: Not installed
2025-12-03 14:30:45,047:INFO:              kmodes: Not installed
2025-12-03 14:30:45,047:INFO:             mlxtend: Not installed
2025-12-03 14:30:45,047:INFO:       statsforecast: Not installed
2025-12-03 14:30:45,047:INFO:        tune_sklearn: Not installed
2025-12-03 14:30:45,047:INFO:                 ray: Not installed
2025-12-03 14:30:45,047:INFO:            hyperopt: Not installed
2025-12-03 14:30:45,047:INFO:              optuna: Not installed
2025-12-03 14:30:45,047:INFO:               skopt: Not installed
2025-12-03 14:30:45,047:INFO:              mlflow: Not installed
2025-12-03 14:30:45,047:INFO:              gradio: Not installed
2025-12-03 14:30:45,047:INFO:             fastapi: Not installed
2025-12-03 14:30:45,047:INFO:             uvicorn: Not installed
2025-12-03 14:30:45,047:INFO:              m2cgen: Not installed
2025-12-03 14:30:45,047:INFO:           evidently: Not installed
2025-12-03 14:30:45,047:INFO:               fugue: Not installed
2025-12-03 14:30:45,047:INFO:           streamlit: Not installed
2025-12-03 14:30:45,047:INFO:             prophet: Not installed
2025-12-03 14:30:45,047:INFO:None
2025-12-03 14:30:45,047:INFO:Set up data.
2025-12-03 14:30:45,076:INFO:Set up folding strategy.
2025-12-03 14:30:45,077:INFO:Set up train/test split.
2025-12-03 14:30:45,095:INFO:Set up index.
2025-12-03 14:30:45,095:INFO:Assigning column types.
2025-12-03 14:30:45,099:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 14:30:45,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,121:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,165:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 14:30:45,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:30:45,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,225:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 14:30:45,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,293:INFO:Preparing preprocessing pipeline...
2025-12-03 14:30:45,296:INFO:Set up simple imputation.
2025-12-03 14:30:45,296:INFO:Set up imbalanced handling.
2025-12-03 14:30:45,296:INFO:Set up column name cleaning.
2025-12-03 14:30:45,357:INFO:Finished creating preprocessing pipeline.
2025-12-03 14:30:45,359:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'partner',
                                             'married', 'streaming_movies',
                                             'online_security'],
                                    transformer=Simpl...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 14:30:45,359:INFO:Creating final display dataframe.
2025-12-03 14:30:45,440:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 15)
4        Transformed data shape        (9687, 15)
5   Transformed train set shape        (8278, 15)
6    Transformed test set shape        (1409, 15)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e80b
2025-12-03 14:30:45,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:30:45,510:INFO:setup() successfully completed in 0.48s...............
2025-12-03 14:30:45,511:INFO:Initializing compare_models()
2025-12-03 14:30:45,511:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:30:45,511:INFO:Checking exceptions
2025-12-03 14:30:45,514:INFO:Preparing display monitor
2025-12-03 14:30:45,529:INFO:Initializing Logistic Regression
2025-12-03 14:30:45,529:INFO:Total runtime is 1.4861424763997396e-06 minutes
2025-12-03 14:30:45,530:INFO:SubProcess create_model() called ==================================
2025-12-03 14:30:45,530:INFO:Initializing create_model()
2025-12-03 14:30:45,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db7bc90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:30:45,530:INFO:Checking exceptions
2025-12-03 14:30:45,531:INFO:Importing libraries
2025-12-03 14:30:45,531:INFO:Copying training dataset
2025-12-03 14:30:45,536:INFO:Defining folds
2025-12-03 14:30:45,536:INFO:Declaring metric variables
2025-12-03 14:30:45,539:INFO:Importing untrained model
2025-12-03 14:30:45,541:INFO:Logistic Regression Imported successfully
2025-12-03 14:30:45,545:INFO:Starting cross validation
2025-12-03 14:30:45,547:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:30:49,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:49,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:49,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:49,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:49,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:49,731:INFO:Calculating mean and std
2025-12-03 14:30:49,741:INFO:Creating metrics dataframe
2025-12-03 14:30:49,765:INFO:Uploading results into container
2025-12-03 14:30:49,768:INFO:Uploading model into container now
2025-12-03 14:30:49,771:INFO:_master_model_container: 1
2025-12-03 14:30:49,771:INFO:_display_container: 2
2025-12-03 14:30:49,781:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:30:49,781:INFO:create_model() successfully completed......................................
2025-12-03 14:30:50,845:INFO:SubProcess create_model() end ==================================
2025-12-03 14:30:50,845:INFO:Creating metrics dataframe
2025-12-03 14:30:50,848:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:30:50,848:INFO:Total runtime is 0.0886480172475179 minutes
2025-12-03 14:30:50,849:INFO:SubProcess create_model() called ==================================
2025-12-03 14:30:50,849:INFO:Initializing create_model()
2025-12-03 14:30:50,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db7bc90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:30:50,849:INFO:Checking exceptions
2025-12-03 14:30:50,850:INFO:Importing libraries
2025-12-03 14:30:50,850:INFO:Copying training dataset
2025-12-03 14:30:50,859:INFO:Defining folds
2025-12-03 14:30:50,859:INFO:Declaring metric variables
2025-12-03 14:30:50,860:INFO:Importing untrained model
2025-12-03 14:30:50,862:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:30:50,866:INFO:Starting cross validation
2025-12-03 14:30:50,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:30:50,949:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:30:50,963:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:30:50,978:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:30:52,351:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:52,358:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:52,452:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:30:52,459:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:30:52,496:INFO:Calculating mean and std
2025-12-03 14:30:52,500:INFO:Creating metrics dataframe
2025-12-03 14:30:52,508:INFO:Uploading results into container
2025-12-03 14:30:52,509:INFO:Uploading model into container now
2025-12-03 14:30:52,511:INFO:_master_model_container: 2
2025-12-03 14:30:52,511:INFO:_display_container: 2
2025-12-03 14:30:52,513:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:30:52,513:INFO:create_model() successfully completed......................................
2025-12-03 14:30:52,796:INFO:SubProcess create_model() end ==================================
2025-12-03 14:30:52,796:INFO:Creating metrics dataframe
2025-12-03 14:30:52,800:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:30:52,800:INFO:Total runtime is 0.12118603785832724 minutes
2025-12-03 14:30:52,804:INFO:SubProcess create_model() called ==================================
2025-12-03 14:30:52,805:INFO:Initializing create_model()
2025-12-03 14:30:52,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db7bc90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:30:52,805:INFO:Checking exceptions
2025-12-03 14:30:52,806:INFO:Importing libraries
2025-12-03 14:30:52,806:INFO:Copying training dataset
2025-12-03 14:30:52,817:INFO:Defining folds
2025-12-03 14:30:52,817:INFO:Declaring metric variables
2025-12-03 14:30:52,819:INFO:Importing untrained model
2025-12-03 14:30:52,823:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:30:52,833:INFO:Starting cross validation
2025-12-03 14:30:52,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:30:56,454:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:30:58,456:INFO:Calculating mean and std
2025-12-03 14:30:58,463:INFO:Creating metrics dataframe
2025-12-03 14:30:58,475:INFO:Uploading results into container
2025-12-03 14:30:58,476:INFO:Uploading model into container now
2025-12-03 14:30:58,476:INFO:_master_model_container: 3
2025-12-03 14:30:58,476:INFO:_display_container: 2
2025-12-03 14:30:58,479:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:30:58,479:INFO:create_model() successfully completed......................................
2025-12-03 14:30:58,659:INFO:SubProcess create_model() end ==================================
2025-12-03 14:30:58,659:INFO:Creating metrics dataframe
2025-12-03 14:30:58,662:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:30:58,664:INFO:Initializing create_model()
2025-12-03 14:30:58,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31d8a5a50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:30:58,664:INFO:Checking exceptions
2025-12-03 14:30:58,665:INFO:Importing libraries
2025-12-03 14:30:58,666:INFO:Copying training dataset
2025-12-03 14:30:58,671:INFO:Defining folds
2025-12-03 14:30:58,671:INFO:Declaring metric variables
2025-12-03 14:30:58,671:INFO:Importing untrained model
2025-12-03 14:30:58,671:INFO:Declaring custom model
2025-12-03 14:30:58,671:INFO:Logistic Regression Imported successfully
2025-12-03 14:30:58,672:INFO:Cross validation set to False
2025-12-03 14:30:58,672:INFO:Fitting Model
2025-12-03 14:30:58,733:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:30:58,734:INFO:create_model() successfully completed......................................
2025-12-03 14:30:58,860:INFO:_master_model_container: 3
2025-12-03 14:30:58,861:INFO:_display_container: 2
2025-12-03 14:30:58,861:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:30:58,861:INFO:compare_models() successfully completed......................................
2025-12-03 14:32:27,726:INFO:PyCaret ClassificationExperiment
2025-12-03 14:32:27,726:INFO:Logging name: clf-default-name
2025-12-03 14:32:27,726:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 14:32:27,726:INFO:version 3.3.2
2025-12-03 14:32:27,726:INFO:Initializing setup()
2025-12-03 14:32:27,726:INFO:self.USI: 6107
2025-12-03 14:32:27,726:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 14:32:27,726:INFO:Checking environment
2025-12-03 14:32:27,727:INFO:python_version: 3.11.14
2025-12-03 14:32:27,727:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 14:32:27,727:INFO:machine: arm64
2025-12-03 14:32:27,727:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:32:27,728:INFO:Memory: svmem(total=8589934592, available=1391869952, percent=83.8, used=2963013632, free=57999360, active=1345224704, inactive=1258799104, wired=1617788928)
2025-12-03 14:32:27,728:INFO:Physical Core: 8
2025-12-03 14:32:27,728:INFO:Logical Core: 8
2025-12-03 14:32:27,728:INFO:Checking libraries
2025-12-03 14:32:27,728:INFO:System:
2025-12-03 14:32:27,728:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 14:32:27,728:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 14:32:27,728:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:32:27,728:INFO:PyCaret required dependencies:
2025-12-03 14:32:27,729:INFO:                 pip: 25.3
2025-12-03 14:32:27,729:INFO:          setuptools: 80.9.0
2025-12-03 14:32:27,729:INFO:             pycaret: 3.3.2
2025-12-03 14:32:27,729:INFO:             IPython: 9.7.0
2025-12-03 14:32:27,729:INFO:          ipywidgets: 8.1.8
2025-12-03 14:32:27,729:INFO:                tqdm: 4.67.1
2025-12-03 14:32:27,729:INFO:               numpy: 1.26.4
2025-12-03 14:32:27,729:INFO:              pandas: 2.1.4
2025-12-03 14:32:27,729:INFO:              jinja2: 3.1.6
2025-12-03 14:32:27,729:INFO:               scipy: 1.11.4
2025-12-03 14:32:27,729:INFO:              joblib: 1.3.2
2025-12-03 14:32:27,729:INFO:             sklearn: 1.4.2
2025-12-03 14:32:27,729:INFO:                pyod: 2.0.5
2025-12-03 14:32:27,729:INFO:            imblearn: 0.14.0
2025-12-03 14:32:27,729:INFO:   category_encoders: 2.7.0
2025-12-03 14:32:27,729:INFO:            lightgbm: 4.6.0
2025-12-03 14:32:27,729:INFO:               numba: 0.62.1
2025-12-03 14:32:27,729:INFO:            requests: 2.32.5
2025-12-03 14:32:27,729:INFO:          matplotlib: 3.7.5
2025-12-03 14:32:27,729:INFO:          scikitplot: 0.3.7
2025-12-03 14:32:27,729:INFO:         yellowbrick: 1.5
2025-12-03 14:32:27,729:INFO:              plotly: 6.5.0
2025-12-03 14:32:27,729:INFO:    plotly-resampler: Not installed
2025-12-03 14:32:27,729:INFO:             kaleido: 1.2.0
2025-12-03 14:32:27,729:INFO:           schemdraw: 0.15
2025-12-03 14:32:27,729:INFO:         statsmodels: 0.14.5
2025-12-03 14:32:27,729:INFO:              sktime: 0.26.0
2025-12-03 14:32:27,729:INFO:               tbats: 1.1.3
2025-12-03 14:32:27,729:INFO:            pmdarima: 2.0.4
2025-12-03 14:32:27,729:INFO:              psutil: 7.1.3
2025-12-03 14:32:27,729:INFO:          markupsafe: 3.0.3
2025-12-03 14:32:27,729:INFO:             pickle5: Not installed
2025-12-03 14:32:27,729:INFO:         cloudpickle: 3.1.2
2025-12-03 14:32:27,729:INFO:         deprecation: 2.1.0
2025-12-03 14:32:27,729:INFO:              xxhash: 3.6.0
2025-12-03 14:32:27,730:INFO:           wurlitzer: 3.1.1
2025-12-03 14:32:27,730:INFO:PyCaret optional dependencies:
2025-12-03 14:32:27,730:INFO:                shap: Not installed
2025-12-03 14:32:27,730:INFO:           interpret: Not installed
2025-12-03 14:32:27,730:INFO:                umap: Not installed
2025-12-03 14:32:27,730:INFO:     ydata_profiling: Not installed
2025-12-03 14:32:27,730:INFO:  explainerdashboard: Not installed
2025-12-03 14:32:27,730:INFO:             autoviz: Not installed
2025-12-03 14:32:27,730:INFO:           fairlearn: Not installed
2025-12-03 14:32:27,730:INFO:          deepchecks: Not installed
2025-12-03 14:32:27,730:INFO:             xgboost: Not installed
2025-12-03 14:32:27,730:INFO:            catboost: Not installed
2025-12-03 14:32:27,730:INFO:              kmodes: Not installed
2025-12-03 14:32:27,730:INFO:             mlxtend: Not installed
2025-12-03 14:32:27,730:INFO:       statsforecast: Not installed
2025-12-03 14:32:27,730:INFO:        tune_sklearn: Not installed
2025-12-03 14:32:27,730:INFO:                 ray: Not installed
2025-12-03 14:32:27,730:INFO:            hyperopt: Not installed
2025-12-03 14:32:27,730:INFO:              optuna: Not installed
2025-12-03 14:32:27,730:INFO:               skopt: Not installed
2025-12-03 14:32:27,730:INFO:              mlflow: Not installed
2025-12-03 14:32:27,730:INFO:              gradio: Not installed
2025-12-03 14:32:27,730:INFO:             fastapi: Not installed
2025-12-03 14:32:27,730:INFO:             uvicorn: Not installed
2025-12-03 14:32:27,730:INFO:              m2cgen: Not installed
2025-12-03 14:32:27,730:INFO:           evidently: Not installed
2025-12-03 14:32:27,730:INFO:               fugue: Not installed
2025-12-03 14:32:27,730:INFO:           streamlit: Not installed
2025-12-03 14:32:27,730:INFO:             prophet: Not installed
2025-12-03 14:32:27,730:INFO:None
2025-12-03 14:32:27,730:INFO:Set up data.
2025-12-03 14:32:27,767:INFO:Set up folding strategy.
2025-12-03 14:32:27,767:INFO:Set up train/test split.
2025-12-03 14:32:27,779:INFO:Set up index.
2025-12-03 14:32:27,780:INFO:Assigning column types.
2025-12-03 14:32:27,783:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 14:32:27,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,846:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 14:32:27,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,893:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:27,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,904:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 14:32:27,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:27,965:INFO:Preparing preprocessing pipeline...
2025-12-03 14:32:27,966:INFO:Set up simple imputation.
2025-12-03 14:32:27,966:INFO:Set up imbalanced handling.
2025-12-03 14:32:27,967:INFO:Set up column name cleaning.
2025-12-03 14:32:28,008:INFO:Finished creating preprocessing pipeline.
2025-12-03 14:32:28,010:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'partner',
                                             'married', 'streaming_movies',
                                             'online_security'],
                                    transformer=Simpl...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 14:32:28,010:INFO:Creating final display dataframe.
2025-12-03 14:32:28,092:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 15)
4        Transformed data shape        (9687, 15)
5   Transformed train set shape        (8278, 15)
6    Transformed test set shape        (1409, 15)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6107
2025-12-03 14:32:28,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:28,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:28,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:28,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:28,162:INFO:setup() successfully completed in 0.45s...............
2025-12-03 14:32:28,162:INFO:Initializing compare_models()
2025-12-03 14:32:28,162:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:32:28,162:INFO:Checking exceptions
2025-12-03 14:32:28,164:INFO:Preparing display monitor
2025-12-03 14:32:28,173:INFO:Initializing Logistic Regression
2025-12-03 14:32:28,174:INFO:Total runtime is 1.4503796895345051e-06 minutes
2025-12-03 14:32:28,174:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:28,175:INFO:Initializing create_model()
2025-12-03 14:32:28,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327e27910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:28,175:INFO:Checking exceptions
2025-12-03 14:32:28,175:INFO:Importing libraries
2025-12-03 14:32:28,175:INFO:Copying training dataset
2025-12-03 14:32:28,181:INFO:Defining folds
2025-12-03 14:32:28,181:INFO:Declaring metric variables
2025-12-03 14:32:28,182:INFO:Importing untrained model
2025-12-03 14:32:28,183:INFO:Logistic Regression Imported successfully
2025-12-03 14:32:28,185:INFO:Starting cross validation
2025-12-03 14:32:28,186:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:28,463:INFO:Calculating mean and std
2025-12-03 14:32:28,464:INFO:Creating metrics dataframe
2025-12-03 14:32:28,465:INFO:Uploading results into container
2025-12-03 14:32:28,465:INFO:Uploading model into container now
2025-12-03 14:32:28,465:INFO:_master_model_container: 1
2025-12-03 14:32:28,465:INFO:_display_container: 2
2025-12-03 14:32:28,466:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:32:28,466:INFO:create_model() successfully completed......................................
2025-12-03 14:32:28,691:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:28,691:INFO:Creating metrics dataframe
2025-12-03 14:32:28,694:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:32:28,694:INFO:Total runtime is 0.008677001794179282 minutes
2025-12-03 14:32:28,695:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:28,695:INFO:Initializing create_model()
2025-12-03 14:32:28,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327e27910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:28,695:INFO:Checking exceptions
2025-12-03 14:32:28,695:INFO:Importing libraries
2025-12-03 14:32:28,696:INFO:Copying training dataset
2025-12-03 14:32:28,699:INFO:Defining folds
2025-12-03 14:32:28,699:INFO:Declaring metric variables
2025-12-03 14:32:28,700:INFO:Importing untrained model
2025-12-03 14:32:28,701:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:32:28,704:INFO:Starting cross validation
2025-12-03 14:32:28,705:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:28,792:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:32:28,808:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:32:28,813:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:32:28,841:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:32:28,841:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 14:32:28,860:INFO:Calculating mean and std
2025-12-03 14:32:28,861:INFO:Creating metrics dataframe
2025-12-03 14:32:28,861:INFO:Uploading results into container
2025-12-03 14:32:28,861:INFO:Uploading model into container now
2025-12-03 14:32:28,862:INFO:_master_model_container: 2
2025-12-03 14:32:28,862:INFO:_display_container: 2
2025-12-03 14:32:28,862:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:32:28,862:INFO:create_model() successfully completed......................................
2025-12-03 14:32:28,948:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:28,948:INFO:Creating metrics dataframe
2025-12-03 14:32:28,951:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:32:28,951:INFO:Total runtime is 0.012955586115519207 minutes
2025-12-03 14:32:28,952:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:28,952:INFO:Initializing create_model()
2025-12-03 14:32:28,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327e27910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:28,952:INFO:Checking exceptions
2025-12-03 14:32:28,952:INFO:Importing libraries
2025-12-03 14:32:28,952:INFO:Copying training dataset
2025-12-03 14:32:28,956:INFO:Defining folds
2025-12-03 14:32:28,956:INFO:Declaring metric variables
2025-12-03 14:32:28,957:INFO:Importing untrained model
2025-12-03 14:32:28,958:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:32:28,960:INFO:Starting cross validation
2025-12-03 14:32:28,961:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:30,610:INFO:Calculating mean and std
2025-12-03 14:32:30,615:INFO:Creating metrics dataframe
2025-12-03 14:32:30,618:INFO:Uploading results into container
2025-12-03 14:32:30,620:INFO:Uploading model into container now
2025-12-03 14:32:30,621:INFO:_master_model_container: 3
2025-12-03 14:32:30,621:INFO:_display_container: 2
2025-12-03 14:32:30,622:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:32:30,622:INFO:create_model() successfully completed......................................
2025-12-03 14:32:30,796:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:30,797:INFO:Creating metrics dataframe
2025-12-03 14:32:30,800:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:32:30,804:INFO:Initializing create_model()
2025-12-03 14:32:30,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c4bed50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:30,804:INFO:Checking exceptions
2025-12-03 14:32:30,805:INFO:Importing libraries
2025-12-03 14:32:30,805:INFO:Copying training dataset
2025-12-03 14:32:30,811:INFO:Defining folds
2025-12-03 14:32:30,811:INFO:Declaring metric variables
2025-12-03 14:32:30,811:INFO:Importing untrained model
2025-12-03 14:32:30,811:INFO:Declaring custom model
2025-12-03 14:32:30,811:INFO:Logistic Regression Imported successfully
2025-12-03 14:32:30,811:INFO:Cross validation set to False
2025-12-03 14:32:30,811:INFO:Fitting Model
2025-12-03 14:32:30,919:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:32:30,919:INFO:create_model() successfully completed......................................
2025-12-03 14:32:31,115:INFO:_master_model_container: 3
2025-12-03 14:32:31,115:INFO:_display_container: 2
2025-12-03 14:32:31,116:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:32:31,116:INFO:compare_models() successfully completed......................................
2025-12-03 14:32:55,032:INFO:PyCaret ClassificationExperiment
2025-12-03 14:32:55,032:INFO:Logging name: clf-default-name
2025-12-03 14:32:55,032:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 14:32:55,032:INFO:version 3.3.2
2025-12-03 14:32:55,032:INFO:Initializing setup()
2025-12-03 14:32:55,032:INFO:self.USI: 5a89
2025-12-03 14:32:55,032:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 14:32:55,032:INFO:Checking environment
2025-12-03 14:32:55,032:INFO:python_version: 3.11.14
2025-12-03 14:32:55,032:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 14:32:55,032:INFO:machine: arm64
2025-12-03 14:32:55,032:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:32:55,032:INFO:Memory: svmem(total=8589934592, available=1324384256, percent=84.6, used=2944745472, free=67584000, active=1269727232, inactive=1216184320, wired=1675018240)
2025-12-03 14:32:55,032:INFO:Physical Core: 8
2025-12-03 14:32:55,032:INFO:Logical Core: 8
2025-12-03 14:32:55,032:INFO:Checking libraries
2025-12-03 14:32:55,032:INFO:System:
2025-12-03 14:32:55,032:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 14:32:55,032:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 14:32:55,032:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 14:32:55,032:INFO:PyCaret required dependencies:
2025-12-03 14:32:55,033:INFO:                 pip: 25.3
2025-12-03 14:32:55,033:INFO:          setuptools: 80.9.0
2025-12-03 14:32:55,033:INFO:             pycaret: 3.3.2
2025-12-03 14:32:55,033:INFO:             IPython: 9.7.0
2025-12-03 14:32:55,033:INFO:          ipywidgets: 8.1.8
2025-12-03 14:32:55,033:INFO:                tqdm: 4.67.1
2025-12-03 14:32:55,034:INFO:               numpy: 1.26.4
2025-12-03 14:32:55,034:INFO:              pandas: 2.1.4
2025-12-03 14:32:55,035:INFO:              jinja2: 3.1.6
2025-12-03 14:32:55,035:INFO:               scipy: 1.11.4
2025-12-03 14:32:55,035:INFO:              joblib: 1.3.2
2025-12-03 14:32:55,035:INFO:             sklearn: 1.4.2
2025-12-03 14:32:55,035:INFO:                pyod: 2.0.5
2025-12-03 14:32:55,035:INFO:            imblearn: 0.14.0
2025-12-03 14:32:55,035:INFO:   category_encoders: 2.7.0
2025-12-03 14:32:55,035:INFO:            lightgbm: 4.6.0
2025-12-03 14:32:55,035:INFO:               numba: 0.62.1
2025-12-03 14:32:55,035:INFO:            requests: 2.32.5
2025-12-03 14:32:55,035:INFO:          matplotlib: 3.7.5
2025-12-03 14:32:55,035:INFO:          scikitplot: 0.3.7
2025-12-03 14:32:55,035:INFO:         yellowbrick: 1.5
2025-12-03 14:32:55,035:INFO:              plotly: 6.5.0
2025-12-03 14:32:55,035:INFO:    plotly-resampler: Not installed
2025-12-03 14:32:55,035:INFO:             kaleido: 1.2.0
2025-12-03 14:32:55,035:INFO:           schemdraw: 0.15
2025-12-03 14:32:55,035:INFO:         statsmodels: 0.14.5
2025-12-03 14:32:55,035:INFO:              sktime: 0.26.0
2025-12-03 14:32:55,035:INFO:               tbats: 1.1.3
2025-12-03 14:32:55,035:INFO:            pmdarima: 2.0.4
2025-12-03 14:32:55,035:INFO:              psutil: 7.1.3
2025-12-03 14:32:55,035:INFO:          markupsafe: 3.0.3
2025-12-03 14:32:55,035:INFO:             pickle5: Not installed
2025-12-03 14:32:55,035:INFO:         cloudpickle: 3.1.2
2025-12-03 14:32:55,035:INFO:         deprecation: 2.1.0
2025-12-03 14:32:55,035:INFO:              xxhash: 3.6.0
2025-12-03 14:32:55,035:INFO:           wurlitzer: 3.1.1
2025-12-03 14:32:55,035:INFO:PyCaret optional dependencies:
2025-12-03 14:32:55,035:INFO:                shap: Not installed
2025-12-03 14:32:55,035:INFO:           interpret: Not installed
2025-12-03 14:32:55,035:INFO:                umap: Not installed
2025-12-03 14:32:55,035:INFO:     ydata_profiling: Not installed
2025-12-03 14:32:55,035:INFO:  explainerdashboard: Not installed
2025-12-03 14:32:55,035:INFO:             autoviz: Not installed
2025-12-03 14:32:55,035:INFO:           fairlearn: Not installed
2025-12-03 14:32:55,035:INFO:          deepchecks: Not installed
2025-12-03 14:32:55,035:INFO:             xgboost: Not installed
2025-12-03 14:32:55,035:INFO:            catboost: Not installed
2025-12-03 14:32:55,035:INFO:              kmodes: Not installed
2025-12-03 14:32:55,035:INFO:             mlxtend: Not installed
2025-12-03 14:32:55,035:INFO:       statsforecast: Not installed
2025-12-03 14:32:55,035:INFO:        tune_sklearn: Not installed
2025-12-03 14:32:55,035:INFO:                 ray: Not installed
2025-12-03 14:32:55,035:INFO:            hyperopt: Not installed
2025-12-03 14:32:55,035:INFO:              optuna: Not installed
2025-12-03 14:32:55,035:INFO:               skopt: Not installed
2025-12-03 14:32:55,035:INFO:              mlflow: Not installed
2025-12-03 14:32:55,035:INFO:              gradio: Not installed
2025-12-03 14:32:55,035:INFO:             fastapi: Not installed
2025-12-03 14:32:55,035:INFO:             uvicorn: Not installed
2025-12-03 14:32:55,035:INFO:              m2cgen: Not installed
2025-12-03 14:32:55,035:INFO:           evidently: Not installed
2025-12-03 14:32:55,035:INFO:               fugue: Not installed
2025-12-03 14:32:55,035:INFO:           streamlit: Not installed
2025-12-03 14:32:55,035:INFO:             prophet: Not installed
2025-12-03 14:32:55,035:INFO:None
2025-12-03 14:32:55,035:INFO:Set up data.
2025-12-03 14:32:55,049:INFO:Set up folding strategy.
2025-12-03 14:32:55,049:INFO:Set up train/test split.
2025-12-03 14:32:55,053:INFO:Set up index.
2025-12-03 14:32:55,053:INFO:Assigning column types.
2025-12-03 14:32:55,055:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 14:32:55,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,074:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,105:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 14:32:55,133:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 14:32:55,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,171:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 14:32:55,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,229:INFO:Preparing preprocessing pipeline...
2025-12-03 14:32:55,230:INFO:Set up simple imputation.
2025-12-03 14:32:55,230:INFO:Set up imbalanced handling.
2025-12-03 14:32:55,230:INFO:Set up column name cleaning.
2025-12-03 14:32:55,261:INFO:Finished creating preprocessing pipeline.
2025-12-03 14:32:55,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              ke...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 14:32:55,263:INFO:Creating final display dataframe.
2025-12-03 14:32:55,323:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 10)
4        Transformed data shape        (9687, 10)
5   Transformed train set shape        (8278, 10)
6    Transformed test set shape        (1409, 10)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              5a89
2025-12-03 14:32:55,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 14:32:55,388:INFO:setup() successfully completed in 0.37s...............
2025-12-03 14:32:55,389:INFO:Initializing compare_models()
2025-12-03 14:32:55,389:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 14:32:55,389:INFO:Checking exceptions
2025-12-03 14:32:55,391:INFO:Preparing display monitor
2025-12-03 14:32:55,400:INFO:Initializing Logistic Regression
2025-12-03 14:32:55,400:INFO:Total runtime is 1.4861424763997396e-06 minutes
2025-12-03 14:32:55,401:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:55,401:INFO:Initializing create_model()
2025-12-03 14:32:55,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db78450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:55,401:INFO:Checking exceptions
2025-12-03 14:32:55,401:INFO:Importing libraries
2025-12-03 14:32:55,401:INFO:Copying training dataset
2025-12-03 14:32:55,405:INFO:Defining folds
2025-12-03 14:32:55,405:INFO:Declaring metric variables
2025-12-03 14:32:55,407:INFO:Importing untrained model
2025-12-03 14:32:55,408:INFO:Logistic Regression Imported successfully
2025-12-03 14:32:55,412:INFO:Starting cross validation
2025-12-03 14:32:55,413:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:55,541:INFO:Calculating mean and std
2025-12-03 14:32:55,541:INFO:Creating metrics dataframe
2025-12-03 14:32:55,542:INFO:Uploading results into container
2025-12-03 14:32:55,542:INFO:Uploading model into container now
2025-12-03 14:32:55,542:INFO:_master_model_container: 1
2025-12-03 14:32:55,542:INFO:_display_container: 2
2025-12-03 14:32:55,542:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 14:32:55,542:INFO:create_model() successfully completed......................................
2025-12-03 14:32:55,678:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:55,678:INFO:Creating metrics dataframe
2025-12-03 14:32:55,680:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 14:32:55,680:INFO:Total runtime is 0.0046735366185506185 minutes
2025-12-03 14:32:55,681:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:55,682:INFO:Initializing create_model()
2025-12-03 14:32:55,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db78450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:55,682:INFO:Checking exceptions
2025-12-03 14:32:55,682:INFO:Importing libraries
2025-12-03 14:32:55,682:INFO:Copying training dataset
2025-12-03 14:32:55,684:INFO:Defining folds
2025-12-03 14:32:55,684:INFO:Declaring metric variables
2025-12-03 14:32:55,685:INFO:Importing untrained model
2025-12-03 14:32:55,686:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 14:32:55,688:INFO:Starting cross validation
2025-12-03 14:32:55,688:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:55,764:INFO:Calculating mean and std
2025-12-03 14:32:55,764:INFO:Creating metrics dataframe
2025-12-03 14:32:55,764:INFO:Uploading results into container
2025-12-03 14:32:55,765:INFO:Uploading model into container now
2025-12-03 14:32:55,765:INFO:_master_model_container: 2
2025-12-03 14:32:55,765:INFO:_display_container: 2
2025-12-03 14:32:55,765:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 14:32:55,765:INFO:create_model() successfully completed......................................
2025-12-03 14:32:55,839:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:55,839:INFO:Creating metrics dataframe
2025-12-03 14:32:55,841:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 14:32:55,841:INFO:Total runtime is 0.007360601425170898 minutes
2025-12-03 14:32:55,843:INFO:SubProcess create_model() called ==================================
2025-12-03 14:32:55,843:INFO:Initializing create_model()
2025-12-03 14:32:55,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db78450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:55,843:INFO:Checking exceptions
2025-12-03 14:32:55,843:INFO:Importing libraries
2025-12-03 14:32:55,843:INFO:Copying training dataset
2025-12-03 14:32:55,845:INFO:Defining folds
2025-12-03 14:32:55,845:INFO:Declaring metric variables
2025-12-03 14:32:55,846:INFO:Importing untrained model
2025-12-03 14:32:55,847:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:32:55,849:INFO:Starting cross validation
2025-12-03 14:32:55,850:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:32:57,225:INFO:Calculating mean and std
2025-12-03 14:32:57,228:INFO:Creating metrics dataframe
2025-12-03 14:32:57,232:INFO:Uploading results into container
2025-12-03 14:32:57,232:INFO:Uploading model into container now
2025-12-03 14:32:57,236:INFO:_master_model_container: 3
2025-12-03 14:32:57,236:INFO:_display_container: 2
2025-12-03 14:32:57,237:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:32:57,237:INFO:create_model() successfully completed......................................
2025-12-03 14:32:57,388:INFO:SubProcess create_model() end ==================================
2025-12-03 14:32:57,388:INFO:Creating metrics dataframe
2025-12-03 14:32:57,391:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 14:32:57,395:INFO:Initializing create_model()
2025-12-03 14:32:57,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:32:57,396:INFO:Checking exceptions
2025-12-03 14:32:57,396:INFO:Importing libraries
2025-12-03 14:32:57,397:INFO:Copying training dataset
2025-12-03 14:32:57,399:INFO:Defining folds
2025-12-03 14:32:57,399:INFO:Declaring metric variables
2025-12-03 14:32:57,399:INFO:Importing untrained model
2025-12-03 14:32:57,399:INFO:Declaring custom model
2025-12-03 14:32:57,399:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:32:57,400:INFO:Cross validation set to False
2025-12-03 14:32:57,400:INFO:Fitting Model
2025-12-03 14:32:57,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 14:32:57,423:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:32:57,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-12-03 14:32:57,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:32:57,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:32:57,424:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:32:57,424:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:32:57,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:32:57,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:32:57,799:INFO:create_model() successfully completed......................................
2025-12-03 14:32:57,880:INFO:_master_model_container: 3
2025-12-03 14:32:57,880:INFO:_display_container: 2
2025-12-03 14:32:57,880:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:32:57,880:INFO:compare_models() successfully completed......................................
2025-12-03 14:37:33,544:INFO:Initializing create_model()
2025-12-03 14:37:33,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:37:33,546:INFO:Checking exceptions
2025-12-03 14:37:33,637:INFO:Importing libraries
2025-12-03 14:37:33,642:INFO:Copying training dataset
2025-12-03 14:37:33,664:INFO:Defining folds
2025-12-03 14:37:33,665:INFO:Declaring metric variables
2025-12-03 14:37:33,668:INFO:Importing untrained model
2025-12-03 14:37:33,673:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:37:33,678:INFO:Starting cross validation
2025-12-03 14:37:33,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:37:35,330:INFO:Calculating mean and std
2025-12-03 14:37:35,332:INFO:Creating metrics dataframe
2025-12-03 14:37:35,336:INFO:Finalizing model
2025-12-03 14:37:35,392:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 14:37:35,392:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:37:35,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.
2025-12-03 14:37:35,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:37:35,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:37:35,393:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:37:35,393:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:37:35,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:37:35,893:INFO:Uploading results into container
2025-12-03 14:37:35,893:INFO:Uploading model into container now
2025-12-03 14:37:35,903:INFO:_master_model_container: 4
2025-12-03 14:37:35,903:INFO:_display_container: 3
2025-12-03 14:37:35,904:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:37:35,904:INFO:create_model() successfully completed......................................
2025-12-03 14:37:36,355:INFO:Initializing tune_model()
2025-12-03 14:37:36,356:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-03 14:37:36,356:INFO:Checking exceptions
2025-12-03 14:37:36,362:INFO:Copying training dataset
2025-12-03 14:37:36,370:INFO:Checking base model
2025-12-03 14:37:36,370:INFO:Base model : Light Gradient Boosting Machine
2025-12-03 14:37:36,371:INFO:Declaring metric variables
2025-12-03 14:37:36,372:INFO:Defining Hyperparameters
2025-12-03 14:37:36,467:INFO:Tuning with n_jobs=-1
2025-12-03 14:37:36,467:INFO:Initializing RandomizedSearchCV
2025-12-03 14:38:13,931:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.01, 'actual_estimator__num_leaves': 100, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 1.0}
2025-12-03 14:38:13,935:INFO:Hyperparameter search completed
2025-12-03 14:38:13,935:INFO:SubProcess create_model() called ==================================
2025-12-03 14:38:13,938:INFO:Initializing create_model()
2025-12-03 14:38:13,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de51ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.01, 'num_leaves': 100, 'n_estimators': 20, 'min_split_gain': 0.6, 'min_child_samples': 61, 'learning_rate': 0.01, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 1.0})
2025-12-03 14:38:13,938:INFO:Checking exceptions
2025-12-03 14:38:13,938:INFO:Importing libraries
2025-12-03 14:38:13,938:INFO:Copying training dataset
2025-12-03 14:38:13,944:INFO:Defining folds
2025-12-03 14:38:13,944:INFO:Declaring metric variables
2025-12-03 14:38:13,947:INFO:Importing untrained model
2025-12-03 14:38:13,947:INFO:Declaring custom model
2025-12-03 14:38:13,951:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:38:13,953:INFO:Starting cross validation
2025-12-03 14:38:13,955:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:38:14,152:INFO:Calculating mean and std
2025-12-03 14:38:14,152:INFO:Creating metrics dataframe
2025-12-03 14:38:14,157:INFO:Finalizing model
2025-12-03 14:38:14,182:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:14,182:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:14,182:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:14,184:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 14:38:14,184:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:14,184:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:14,184:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:14,184:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:38:14,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.
2025-12-03 14:38:14,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:38:14,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:38:14,186:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:38:14,186:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:38:14,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:38:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:38:14,219:INFO:Uploading results into container
2025-12-03 14:38:14,219:INFO:Uploading model into container now
2025-12-03 14:38:14,221:INFO:_master_model_container: 5
2025-12-03 14:38:14,221:INFO:_display_container: 4
2025-12-03 14:38:14,221:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:38:14,221:INFO:create_model() successfully completed......................................
2025-12-03 14:38:14,436:INFO:SubProcess create_model() end ==================================
2025-12-03 14:38:14,436:INFO:choose_better activated
2025-12-03 14:38:14,437:INFO:SubProcess create_model() called ==================================
2025-12-03 14:38:14,437:INFO:Initializing create_model()
2025-12-03 14:38:14,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 14:38:14,437:INFO:Checking exceptions
2025-12-03 14:38:14,438:INFO:Importing libraries
2025-12-03 14:38:14,438:INFO:Copying training dataset
2025-12-03 14:38:14,441:INFO:Defining folds
2025-12-03 14:38:14,441:INFO:Declaring metric variables
2025-12-03 14:38:14,441:INFO:Importing untrained model
2025-12-03 14:38:14,441:INFO:Declaring custom model
2025-12-03 14:38:14,441:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 14:38:14,441:INFO:Starting cross validation
2025-12-03 14:38:14,441:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 14:38:16,164:INFO:Calculating mean and std
2025-12-03 14:38:16,164:INFO:Creating metrics dataframe
2025-12-03 14:38:16,172:INFO:Finalizing model
2025-12-03 14:38:16,252:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 14:38:16,253:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:38:16,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.
2025-12-03 14:38:16,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:38:16,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:38:16,258:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:38:16,258:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:38:16,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:38:16,796:INFO:Uploading results into container
2025-12-03 14:38:16,797:INFO:Uploading model into container now
2025-12-03 14:38:16,797:INFO:_master_model_container: 6
2025-12-03 14:38:16,797:INFO:_display_container: 5
2025-12-03 14:38:16,797:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:38:16,797:INFO:create_model() successfully completed......................................
2025-12-03 14:38:16,975:INFO:SubProcess create_model() end ==================================
2025-12-03 14:38:16,976:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8816
2025-12-03 14:38:16,976:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8936
2025-12-03 14:38:16,976:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-03 14:38:16,976:INFO:choose_better completed
2025-12-03 14:38:16,982:INFO:_master_model_container: 6
2025-12-03 14:38:16,982:INFO:_display_container: 4
2025-12-03 14:38:16,983:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 14:38:16,983:INFO:tune_model() successfully completed......................................
2025-12-03 14:38:28,202:INFO:Initializing evaluate_model()
2025-12-03 14:38:28,203:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-12-03 14:38:28,222:INFO:Initializing plot_model()
2025-12-03 14:38:28,222:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:38:28,222:INFO:Checking exceptions
2025-12-03 14:38:28,226:INFO:Preloading libraries
2025-12-03 14:38:28,229:INFO:Copying training dataset
2025-12-03 14:38:28,229:INFO:Plot type: pipeline
2025-12-03 14:38:29,497:INFO:Visual Rendered Successfully
2025-12-03 14:38:29,651:INFO:plot_model() successfully completed......................................
2025-12-03 14:38:29,652:INFO:Initializing plot_model()
2025-12-03 14:38:29,652:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-03 14:38:29,652:INFO:Checking exceptions
2025-12-03 14:38:29,656:INFO:Preloading libraries
2025-12-03 14:38:29,659:INFO:Copying training dataset
2025-12-03 14:38:29,659:INFO:Plot type: confusion_matrix
2025-12-03 14:38:29,729:INFO:Fitting Model
2025-12-03 14:38:29,729:INFO:Scoring test/hold-out set
2025-12-03 14:38:29,730:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:29,730:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:29,730:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:29,731:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:29,731:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:29,731:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:29,768:INFO:Visual Rendered Successfully
2025-12-03 14:38:29,863:INFO:plot_model() successfully completed......................................
2025-12-03 14:38:29,863:INFO:Initializing plot_model()
2025-12-03 14:38:29,863:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-03 14:38:29,863:INFO:Checking exceptions
2025-12-03 14:38:29,865:INFO:Preloading libraries
2025-12-03 14:38:29,866:INFO:Copying training dataset
2025-12-03 14:38:29,866:INFO:Plot type: pr
2025-12-03 14:38:29,933:INFO:Fitting Model
2025-12-03 14:38:29,933:INFO:Scoring test/hold-out set
2025-12-03 14:38:29,934:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:29,934:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:29,934:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:29,935:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:38:29,935:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:38:29,935:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:38:29,990:INFO:Visual Rendered Successfully
2025-12-03 14:38:30,070:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:11,857:INFO:Initializing plot_model()
2025-12-03 14:39:11,858:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:11,858:INFO:Checking exceptions
2025-12-03 14:39:11,866:INFO:Preloading libraries
2025-12-03 14:39:11,868:INFO:Copying training dataset
2025-12-03 14:39:11,868:INFO:Plot type: confusion_matrix
2025-12-03 14:39:11,939:INFO:Fitting Model
2025-12-03 14:39:11,939:INFO:Scoring test/hold-out set
2025-12-03 14:39:11,940:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:11,940:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:11,940:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:11,941:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:11,941:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:11,941:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:11,977:INFO:Visual Rendered Successfully
2025-12-03 14:39:12,140:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:14,611:INFO:Initializing plot_model()
2025-12-03 14:39:14,611:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:14,611:INFO:Checking exceptions
2025-12-03 14:39:14,617:INFO:Preloading libraries
2025-12-03 14:39:14,619:INFO:Copying training dataset
2025-12-03 14:39:14,619:INFO:Plot type: parameter
2025-12-03 14:39:14,622:INFO:Visual Rendered Successfully
2025-12-03 14:39:14,714:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:18,814:INFO:Initializing plot_model()
2025-12-03 14:39:18,815:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:18,815:INFO:Checking exceptions
2025-12-03 14:39:18,821:INFO:Preloading libraries
2025-12-03 14:39:18,825:INFO:Copying training dataset
2025-12-03 14:39:18,825:INFO:Plot type: pipeline
2025-12-03 14:39:18,892:INFO:Visual Rendered Successfully
2025-12-03 14:39:19,145:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:22,505:INFO:Initializing plot_model()
2025-12-03 14:39:22,505:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:22,505:INFO:Checking exceptions
2025-12-03 14:39:22,509:INFO:Preloading libraries
2025-12-03 14:39:22,510:INFO:Copying training dataset
2025-12-03 14:39:22,510:INFO:Plot type: ks
2025-12-03 14:39:22,510:INFO:Generating predictions / predict_proba on X_test
2025-12-03 14:39:22,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:22,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:22,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:22,624:INFO:Visual Rendered Successfully
2025-12-03 14:39:22,717:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:26,463:INFO:Initializing plot_model()
2025-12-03 14:39:26,463:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:26,463:INFO:Checking exceptions
2025-12-03 14:39:30,209:INFO:Initializing plot_model()
2025-12-03 14:39:30,210:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:30,210:INFO:Checking exceptions
2025-12-03 14:39:30,214:INFO:Preloading libraries
2025-12-03 14:39:30,216:INFO:Copying training dataset
2025-12-03 14:39:30,216:INFO:Plot type: gain
2025-12-03 14:39:30,217:INFO:Generating predictions / predict_proba on X_test
2025-12-03 14:39:30,251:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:30,251:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:30,251:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:30,311:INFO:Visual Rendered Successfully
2025-12-03 14:39:30,480:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:33,227:INFO:Initializing plot_model()
2025-12-03 14:39:33,228:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=manifold, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:33,228:INFO:Checking exceptions
2025-12-03 14:39:33,240:INFO:Preloading libraries
2025-12-03 14:39:33,242:INFO:Copying training dataset
2025-12-03 14:39:33,242:INFO:Plot type: manifold
2025-12-03 14:39:33,336:INFO:Fitting & Transforming Model
2025-12-03 14:39:44,992:INFO:Visual Rendered Successfully
2025-12-03 14:39:45,244:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:45,251:INFO:Initializing plot_model()
2025-12-03 14:39:45,251:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:45,251:INFO:Checking exceptions
2025-12-03 14:39:45,253:INFO:Preloading libraries
2025-12-03 14:39:45,254:INFO:Copying training dataset
2025-12-03 14:39:45,254:INFO:Plot type: feature
2025-12-03 14:39:45,255:WARNING:No coef_ found. Trying feature_importances_
2025-12-03 14:39:45,335:INFO:Visual Rendered Successfully
2025-12-03 14:39:45,431:INFO:plot_model() successfully completed......................................
2025-12-03 14:39:50,529:INFO:Initializing plot_model()
2025-12-03 14:39:50,529:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e0a9490>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 14:39:50,530:INFO:Checking exceptions
2025-12-03 14:39:50,535:INFO:Preloading libraries
2025-12-03 14:39:50,536:INFO:Copying training dataset
2025-12-03 14:39:50,536:INFO:Plot type: rfe
2025-12-03 14:39:50,608:INFO:Fitting Model
2025-12-03 14:39:50,622:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,623:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,624:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,624:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,624:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,624:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-12-03 14:39:50,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,625:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:50,626:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:50,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,650:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,650:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,650:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,652:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,652:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,652:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-12-03 14:39:50,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,653:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:50,653:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:50,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,680:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,680:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,680:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,681:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,681:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,681:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,681:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-12-03 14:39:50,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,682:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:50,682:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:50,682:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,715:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,715:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,715:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,716:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,716:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,716:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,716:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-12-03 14:39:50,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,717:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:50,717:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:50,717:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,746:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,746:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,746:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,747:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,747:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,747:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-12-03 14:39:50,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,747:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 14:39:50,748:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:50,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,779:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,779:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,779:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,780:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,780:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,780:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,780:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-12-03 14:39:50,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,780:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 14:39:50,781:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:50,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,805:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,805:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,805:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,806:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,806:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,806:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,806:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.
2025-12-03 14:39:50,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,807:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:50,807:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:50,807:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,830:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,830:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,830:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,831:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,831:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,831:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,831:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2025-12-03 14:39:50,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,831:INFO:[LightGBM] [Info] Total Bins 34
2025-12-03 14:39:50,832:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:50,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,843:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,843:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2025-12-03 14:39:50,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,843:INFO:[LightGBM] [Info] Total Bins 19
2025-12-03 14:39:50,843:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 14:39:50,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,857:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,857:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,858:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,859:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,859:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,859:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,860:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,861:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,861:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,861:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.
2025-12-03 14:39:50,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,862:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:50,862:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:50,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,895:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,895:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,895:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,896:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,896:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,896:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,896:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-12-03 14:39:50,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,897:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:50,897:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:50,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,929:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,929:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,930:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,930:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,930:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,930:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-12-03 14:39:50,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:50,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:50,931:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:50,931:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:50,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,966:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,966:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,966:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,966:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,967:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,967:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,967:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,967:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-12-03 14:39:50,967:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,967:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:50,967:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:50,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:50,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:50,997:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,997:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,997:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,998:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:50,998:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:50,998:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:50,998:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:50,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-12-03 14:39:50,999:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:50,999:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 14:39:50,999:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:50,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,029:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,029:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,030:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-12-03 14:39:51,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,031:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 14:39:51,031:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:51,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,054:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,054:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,054:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,055:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,055:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,055:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,055:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.
2025-12-03 14:39:51,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,055:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:51,055:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:51,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,080:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,080:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,080:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,081:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,081:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,081:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,081:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2025-12-03 14:39:51,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,081:INFO:[LightGBM] [Info] Total Bins 33
2025-12-03 14:39:51,081:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:51,082:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,094:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,094:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.
2025-12-03 14:39:51,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,094:INFO:[LightGBM] [Info] Total Bins 19
2025-12-03 14:39:51,095:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 14:39:51,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,110:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,110:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,110:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,112:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,113:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,113:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,113:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,113:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,114:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,114:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-12-03 14:39:51,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,115:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:51,115:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:51,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,146:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,146:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,146:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,147:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,147:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,148:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2025-12-03 14:39:51,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,149:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:51,149:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:51,149:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,179:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,179:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,179:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,180:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,180:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,180:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,180:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,181:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-12-03 14:39:51,181:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,181:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,181:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:51,181:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:51,181:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,214:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,214:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,214:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,215:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,215:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,215:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-12-03 14:39:51,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,216:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:51,216:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:51,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,244:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,244:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,244:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,245:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,245:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,245:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,245:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-12-03 14:39:51,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,246:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:51,246:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:51,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,278:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,278:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,278:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,279:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,279:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,279:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,279:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-12-03 14:39:51,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,280:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:51,280:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:51,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,305:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,305:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,305:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,306:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,306:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,306:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,306:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-12-03 14:39:51,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,307:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 14:39:51,307:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:51,307:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,330:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,330:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,330:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,331:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,331:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,331:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,331:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,331:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-12-03 14:39:51,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,331:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 14:39:51,331:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:51,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,340:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,340:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,340:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,341:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,341:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,341:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,341:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-12-03 14:39:51,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,341:INFO:[LightGBM] [Info] Total Bins 17
2025-12-03 14:39:51,341:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 14:39:51,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,353:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,353:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,353:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,355:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,355:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,355:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,356:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,356:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,356:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-12-03 14:39:51,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,356:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:51,357:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:51,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,357:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,388:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,388:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,388:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,389:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,389:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,389:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,389:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-12-03 14:39:51,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,390:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:51,390:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:51,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,390:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,422:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,422:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,423:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,423:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,423:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,423:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-12-03 14:39:51,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,424:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:51,424:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:51,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,424:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,457:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,457:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,457:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,458:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,458:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,458:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,458:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,459:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-12-03 14:39:51,459:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,459:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:51,459:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:51,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,459:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,487:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,487:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,487:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,488:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,488:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,488:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,489:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-12-03 14:39:51,489:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,489:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:51,489:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:51,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,489:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,521:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,521:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,521:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,522:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,522:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,522:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,523:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2025-12-03 14:39:51,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,523:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:51,523:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:51,523:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,523:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,547:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,547:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,548:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,548:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,548:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,548:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.
2025-12-03 14:39:51,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,549:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 14:39:51,549:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:51,549:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,549:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,571:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,571:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,571:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,572:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,572:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,572:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2025-12-03 14:39:51,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] Total Bins 27
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,572:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,582:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,582:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:51,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.
2025-12-03 14:39:51,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,583:INFO:[LightGBM] [Info] Total Bins 17
2025-12-03 14:39:51,583:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 1
2025-12-03 14:39:51,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:51,583:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:51,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,595:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,595:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,595:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,597:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,597:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,598:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,598:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,598:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,598:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.
2025-12-03 14:39:51,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,599:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:51,599:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:51,599:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,600:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,632:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,632:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,632:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,633:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,633:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,633:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,633:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-12-03 14:39:51,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,634:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:51,634:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:51,634:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,634:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,665:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,665:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,665:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,666:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,666:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,666:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,666:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-12-03 14:39:51,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,667:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:51,667:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:51,667:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,667:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,698:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,698:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,698:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,699:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,699:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,699:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,699:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-12-03 14:39:51,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,700:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:51,700:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:51,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,700:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,728:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,728:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,728:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,729:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,729:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,729:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,730:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2025-12-03 14:39:51,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,730:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:51,730:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:51,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,730:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,761:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,761:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,761:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,762:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,762:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,762:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,762:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-12-03 14:39:51,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,763:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:51,763:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:51,763:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,763:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,786:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,786:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,787:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,787:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,787:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,787:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-12-03 14:39:51,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,787:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:51,787:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:51,788:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,788:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,811:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,811:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,811:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,812:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,812:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,812:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.
2025-12-03 14:39:51,812:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,812:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,824:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-12-03 14:39:51,824:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] Total Bins 16
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 1
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:51,824:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:51,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,839:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,839:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,839:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,841:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,841:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,841:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,842:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,842:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,842:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2025-12-03 14:39:51,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,843:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:51,843:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:51,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,876:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,876:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,876:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,877:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,877:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,877:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.
2025-12-03 14:39:51,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,878:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:51,878:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:51,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,908:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,908:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,908:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,909:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,909:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,909:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,909:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-12-03 14:39:51,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:51,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:51,910:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:51,910:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:51,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,942:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,942:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,942:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,943:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,943:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,943:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,943:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,944:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2025-12-03 14:39:51,944:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,944:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:51,944:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:51,944:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,971:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,971:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,971:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,972:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:51,972:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:51,972:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:51,972:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:51,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-12-03 14:39:51,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:51,973:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 14:39:51,973:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:51,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:51,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:51,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,004:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,004:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,004:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,005:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,005:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,005:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,005:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-12-03 14:39:52,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,006:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 14:39:52,006:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:52,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,031:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,031:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,031:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,031:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2025-12-03 14:39:52,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,032:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:52,032:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:52,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,056:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,056:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,056:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,057:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,057:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,057:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,057:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2025-12-03 14:39:52,057:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,057:INFO:[LightGBM] [Info] Total Bins 34
2025-12-03 14:39:52,057:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:52,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,068:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,068:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,068:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,070:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,070:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,071:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,071:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,071:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,071:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
2025-12-03 14:39:52,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,072:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:52,072:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:52,072:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,104:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,104:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,104:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,105:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,105:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,105:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,105:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
2025-12-03 14:39:52,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,106:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:52,106:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:52,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,137:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,137:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,138:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,138:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,138:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,138:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-12-03 14:39:52,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,139:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:52,139:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:52,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,173:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,173:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,173:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,174:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,174:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,174:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,174:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-12-03 14:39:52,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,175:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:52,175:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:52,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,203:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,204:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-12-03 14:39:52,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,204:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 14:39:52,204:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:52,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,235:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,235:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,236:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,236:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,236:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,236:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-12-03 14:39:52,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,237:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 14:39:52,237:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:52,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,259:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,259:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,259:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,260:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,260:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,260:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,260:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-12-03 14:39:52,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,261:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:52,261:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:52,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,286:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,286:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2025-12-03 14:39:52,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,287:INFO:[LightGBM] [Info] Total Bins 33
2025-12-03 14:39:52,287:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:52,287:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,298:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,298:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,298:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,301:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,301:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,301:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,302:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,302:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,302:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,302:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-12-03 14:39:52,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,303:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:52,303:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:52,303:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,360:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,360:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,361:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,361:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,361:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,362:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001767 seconds.
2025-12-03 14:39:52,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,364:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:52,364:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:52,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,405:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,405:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,406:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,406:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,406:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,406:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-12-03 14:39:52,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,408:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:52,408:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:52,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,444:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,444:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,445:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,445:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,445:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2025-12-03 14:39:52,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,446:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:52,446:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:52,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,481:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,481:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,481:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,482:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,482:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,482:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,482:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-12-03 14:39:52,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,482:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:52,482:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:52,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,526:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,526:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,526:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,527:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,527:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,527:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,527:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2025-12-03 14:39:52,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,528:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:52,528:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:52,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,554:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,554:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,554:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,555:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,555:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,555:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,555:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2025-12-03 14:39:52,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,555:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,556:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 14:39:52,556:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:52,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,580:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,580:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:52,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2025-12-03 14:39:52,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,581:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 14:39:52,581:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 14:39:52,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,589:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,589:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,589:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,591:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,591:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,591:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,592:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,592:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,592:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-12-03 14:39:52,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,593:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:52,593:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:52,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,593:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,626:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,626:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,626:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,627:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,627:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,627:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,627:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-12-03 14:39:52,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,628:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:52,628:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:52,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,628:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,657:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,657:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,657:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,658:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,658:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,658:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.
2025-12-03 14:39:52,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,659:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,659:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:52,659:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:52,659:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,659:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,694:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,694:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,694:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,694:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,694:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-12-03 14:39:52,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,695:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:52,695:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:52,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,695:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,721:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,722:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,722:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,722:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,722:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2025-12-03 14:39:52,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,723:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:52,723:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:52,723:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,723:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,755:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,755:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,755:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,755:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,755:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,756:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,756:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-12-03 14:39:52,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,756:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:52,756:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:52,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,757:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,781:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,781:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,781:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,782:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,782:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,782:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,782:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,783:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-12-03 14:39:52,783:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,783:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,783:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 14:39:52,783:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:52,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,783:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,807:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,807:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:52,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2025-12-03 14:39:52,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,808:INFO:[LightGBM] [Info] Total Bins 27
2025-12-03 14:39:52,808:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 14:39:52,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:52,808:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:52,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,819:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,819:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,819:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,821:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,821:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,821:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,822:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,822:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,822:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,822:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2025-12-03 14:39:52,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,823:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:52,823:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:52,823:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,823:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,855:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,855:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,855:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,855:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,856:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,856:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,856:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2025-12-03 14:39:52,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,856:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:52,856:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:52,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,857:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,886:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,886:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,887:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,887:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,887:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,887:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-12-03 14:39:52,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,888:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:52,888:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:52,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,888:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,922:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,922:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,922:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,923:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,923:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,923:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,923:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-12-03 14:39:52,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,924:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:52,924:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:52,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,924:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,950:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,950:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,950:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,951:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,951:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,951:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-12-03 14:39:52,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:52,952:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:52,952:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:52,952:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,952:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,983:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,983:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,983:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,984:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:52,984:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:52,984:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:52,984:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:52,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-12-03 14:39:52,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:52,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:52,985:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:52,985:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:52,985:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:52,985:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:52,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,008:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,008:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,008:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,009:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,009:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,009:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,009:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:53,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.
2025-12-03 14:39:53,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,009:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:53,009:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:53,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:53,010:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:53,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,033:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,033:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:53,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2025-12-03 14:39:53,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,034:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 14:39:53,034:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 14:39:53,034:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:53,034:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:53,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,046:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,046:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,046:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,048:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,048:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,048:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,049:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,049:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,049:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,049:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
2025-12-03 14:39:53,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,050:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:53,050:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:53,050:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,081:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,081:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,081:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,082:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,082:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,082:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,082:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-12-03 14:39:53,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,083:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:53,083:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:53,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,114:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,115:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,115:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,115:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-12-03 14:39:53,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,116:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:53,116:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:53,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,147:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,147:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,148:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,148:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,148:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,148:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-12-03 14:39:53,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,148:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:53,149:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:53,149:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,176:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,176:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,177:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,177:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,177:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,177:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2025-12-03 14:39:53,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,178:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 14:39:53,178:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:53,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,209:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,210:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.
2025-12-03 14:39:53,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,210:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 14:39:53,210:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:53,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,235:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,235:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,236:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,236:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,236:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,236:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2025-12-03 14:39:53,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,237:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:53,237:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:53,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,260:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,260:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,260:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,262:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,262:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,262:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,263:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,263:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,263:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,263:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
2025-12-03 14:39:53,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,264:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:53,264:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:53,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,296:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,296:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,296:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,297:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,297:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,297:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,297:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-12-03 14:39:53,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,298:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:53,298:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:53,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,327:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,327:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,327:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,328:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,328:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,328:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,328:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-12-03 14:39:53,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,329:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:53,329:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:53,329:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,362:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,362:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,362:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,363:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,363:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,363:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,363:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-12-03 14:39:53,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,364:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:53,364:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:53,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,392:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,392:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,392:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,393:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,393:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,393:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,393:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-12-03 14:39:53,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,394:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 14:39:53,394:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:53,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,424:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,424:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,424:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,425:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,425:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,425:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-12-03 14:39:53,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,426:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 14:39:53,426:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:53,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,448:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,448:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,448:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,449:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,449:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,449:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,449:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-12-03 14:39:53,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,450:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:53,450:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:53,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,474:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,474:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,474:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,476:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,476:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,477:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,477:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,478:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.
2025-12-03 14:39:53,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,479:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:53,479:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:53,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,511:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,511:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,512:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,512:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,512:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,512:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-12-03 14:39:53,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,513:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:53,513:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:53,513:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,544:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-12-03 14:39:53,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,544:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:53,544:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:53,545:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,578:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,578:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,579:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,579:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,579:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-12-03 14:39:53,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,580:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:53,580:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:53,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,608:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,608:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,608:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,609:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,609:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,609:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,609:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2025-12-03 14:39:53,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,610:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:53,610:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:53,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,641:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,641:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,641:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,642:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,642:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,642:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,642:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-12-03 14:39:53,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,643:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:53,643:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:53,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,668:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,668:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,669:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,669:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,669:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,669:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:53,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-12-03 14:39:53,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,670:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 14:39:53,670:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 14:39:53,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:53,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,692:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,692:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,692:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,694:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,695:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,695:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,695:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,695:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.
2025-12-03 14:39:53,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,696:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,696:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:53,696:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:53,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,696:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,729:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,730:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,730:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,730:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,730:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,731:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,731:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-12-03 14:39:53,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,732:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:53,732:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:53,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,732:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,766:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,766:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,766:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,767:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,767:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,767:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,767:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.
2025-12-03 14:39:53,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,768:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:53,768:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:53,768:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,768:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,802:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,802:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,803:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,803:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,803:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-12-03 14:39:53,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,804:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:53,804:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:53,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,804:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,833:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,833:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,833:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,834:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,834:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,834:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,834:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2025-12-03 14:39:53,835:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,835:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:53,835:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:53,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,835:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,867:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,867:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,867:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,868:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,868:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,868:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.
2025-12-03 14:39:53,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,869:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:53,869:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:53,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,869:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,896:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,896:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,896:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,897:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,897:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,897:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:53,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-12-03 14:39:53,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,898:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 14:39:53,898:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:53,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:53,898:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,921:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,921:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,921:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,924:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,924:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,925:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,925:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,925:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,925:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:53,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.
2025-12-03 14:39:53,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,926:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:53,926:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:53,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:53,926:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:53,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,958:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,958:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,958:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,959:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,959:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,959:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,960:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:53,960:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-12-03 14:39:53,960:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:53,960:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:53,961:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:53,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:53,961:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,992:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,992:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,992:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,993:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:53,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:53,993:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:53,993:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:53,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-12-03 14:39:53,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:53,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:53,994:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:53,994:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:53,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:53,994:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,028:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,028:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,029:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,029:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,029:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-12-03 14:39:54,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,030:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:54,030:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:54,030:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,030:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,058:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2025-12-03 14:39:54,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,059:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,090:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,090:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,090:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,091:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,091:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,091:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,091:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-12-03 14:39:54,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,092:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:54,092:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:54,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,092:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,114:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,115:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,115:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,115:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-12-03 14:39:54,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,116:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:54,116:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 14:39:54,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,116:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,137:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,137:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,141:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,141:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,142:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,142:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,142:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,142:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-12-03 14:39:54,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,143:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:54,143:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:54,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,176:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,176:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,177:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,177:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,177:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,177:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-12-03 14:39:54,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,178:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:54,178:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:54,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,208:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,208:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,209:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,209:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,209:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.
2025-12-03 14:39:54,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,210:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:54,210:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:54,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,240:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,240:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,240:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,241:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,241:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,241:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,241:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,242:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-12-03 14:39:54,242:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,242:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:54,242:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:54,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,269:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,269:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,269:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,270:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,270:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,270:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,270:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2025-12-03 14:39:54,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,271:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 14:39:54,271:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:54,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,301:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,301:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,301:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,302:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,302:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,302:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,302:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-12-03 14:39:54,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,303:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 14:39:54,303:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:54,303:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,328:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,328:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,328:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,330:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,330:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,330:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,331:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,331:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,331:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,331:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-12-03 14:39:54,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,332:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:54,332:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:54,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,365:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,365:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,365:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,366:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,366:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,366:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,366:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.
2025-12-03 14:39:54,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,367:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:54,367:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:54,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,400:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,400:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,400:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,401:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,401:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,401:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,401:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-12-03 14:39:54,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,402:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:54,402:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:54,402:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,436:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,436:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,437:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,437:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,437:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,437:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-12-03 14:39:54,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,438:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:54,438:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:54,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,465:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,465:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,465:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,466:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,466:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,466:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,466:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-12-03 14:39:54,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,467:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 14:39:54,467:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:54,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,498:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,498:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,498:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,499:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,499:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,499:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,499:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-12-03 14:39:54,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,500:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 14:39:54,500:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:54,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,522:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,522:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,524:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,524:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,524:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,525:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,525:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,525:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-12-03 14:39:54,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,526:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:54,526:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:54,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,559:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,559:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,559:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,560:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,560:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,560:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,560:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,561:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-12-03 14:39:54,561:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,561:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:54,561:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:54,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,591:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,591:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,591:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,592:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,592:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,592:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-12-03 14:39:54,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,593:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:54,593:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:54,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,627:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,627:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,627:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,628:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,628:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,628:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2025-12-03 14:39:54,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,629:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:54,629:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:54,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,657:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,657:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,657:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,658:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,658:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,659:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,659:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-12-03 14:39:54,659:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,659:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:54,659:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:54,659:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,692:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,692:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,692:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,693:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,693:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:54,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.
2025-12-03 14:39:54,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,694:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 14:39:54,694:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 14:39:54,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,730:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,730:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,730:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,733:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,733:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,733:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,735:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,736:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,736:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,736:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000963 seconds.
2025-12-03 14:39:54,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,738:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:54,738:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:54,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,738:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,777:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,778:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,778:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,779:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,779:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,779:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,779:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2025-12-03 14:39:54,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,780:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:54,780:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:54,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,780:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,812:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,812:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,812:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,813:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,813:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,813:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,813:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-12-03 14:39:54,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,814:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:54,814:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:54,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,814:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,850:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,850:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,851:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,851:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,851:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,851:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2025-12-03 14:39:54,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,852:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:54,852:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:54,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,852:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,882:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,882:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,883:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,883:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,883:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-12-03 14:39:54,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,883:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:54,884:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:54,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,884:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,918:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,918:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,918:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,919:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,920:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,920:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:54,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-12-03 14:39:54,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,921:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:54,921:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:54,921:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:54,921:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,952:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,952:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,952:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,955:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,955:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,955:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,956:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,956:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,956:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,956:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.
2025-12-03 14:39:54,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:54,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:54,957:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:54,957:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:54,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,957:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,992:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,992:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,992:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,993:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:54,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:54,993:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:54,993:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:54,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-12-03 14:39:54,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:54,994:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:54,994:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:54,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:54,994:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,027:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,027:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,027:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,028:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,028:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,028:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000377 seconds.
2025-12-03 14:39:55,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,029:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:55,029:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:55,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,029:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,063:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,063:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,064:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,064:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,064:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-12-03 14:39:55,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,065:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:55,065:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:55,065:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,065:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,094:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2025-12-03 14:39:55,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,095:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,127:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,127:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,127:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,128:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,128:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,128:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,128:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-12-03 14:39:55,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,129:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 14:39:55,129:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 14:39:55,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,129:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,152:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,152:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,152:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,154:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,154:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,154:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,155:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,155:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,155:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,155:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2025-12-03 14:39:55,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,157:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:55,157:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:55,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,190:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,191:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,191:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,192:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,192:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,192:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,192:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,193:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.
2025-12-03 14:39:55,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,193:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,193:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:55,193:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:55,194:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,224:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,224:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,224:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,225:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,225:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,225:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,225:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,226:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-12-03 14:39:55,226:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,226:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,226:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:55,226:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:55,226:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,257:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,257:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,257:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,258:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,259:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,259:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-12-03 14:39:55,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,259:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:55,260:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:55,260:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,286:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,286:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,286:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,287:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,287:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,287:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,287:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2025-12-03 14:39:55,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,288:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 14:39:55,288:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:55,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,318:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,318:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,318:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,320:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,320:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,320:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,321:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,321:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,321:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,322:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-12-03 14:39:55,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,323:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:55,323:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:55,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,357:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,358:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,358:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,358:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,358:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-12-03 14:39:55,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,359:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:55,359:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:55,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,391:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,391:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,391:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,392:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,392:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,392:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,392:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-12-03 14:39:55,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,393:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:55,393:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:55,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,426:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,426:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,426:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,427:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,427:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,427:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,427:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-12-03 14:39:55,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,428:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:55,428:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:55,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,456:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,456:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,456:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,457:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,457:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,457:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,457:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-12-03 14:39:55,457:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,457:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 14:39:55,457:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:55,457:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,487:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,487:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,487:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,489:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,489:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,489:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,490:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,490:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,490:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,490:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.
2025-12-03 14:39:55,491:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,491:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:55,491:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:55,491:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,524:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,524:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,524:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,525:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,525:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,525:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-12-03 14:39:55,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,526:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:55,526:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:55,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,556:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,556:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,556:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,557:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,557:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,557:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,557:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-12-03 14:39:55,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,558:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:55,558:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:55,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,592:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,593:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-12-03 14:39:55,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,593:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:55,593:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:55,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,622:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,623:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:55,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-12-03 14:39:55,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,623:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 14:39:55,623:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 14:39:55,623:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:55,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,656:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,656:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,656:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,659:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,659:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,659:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,660:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,660:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,660:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,660:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:55,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-12-03 14:39:55,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,661:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:55,661:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:55,661:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:55,661:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:55,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,695:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,695:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,695:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,696:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,696:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,696:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:55,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2025-12-03 14:39:55,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,697:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:55,697:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:55,697:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:55,697:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:55,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,728:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,728:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,728:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,729:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,729:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,729:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:55,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.
2025-12-03 14:39:55,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,730:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:55,730:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:55,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:55,730:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:55,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,764:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,764:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,764:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,765:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,765:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,765:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,765:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:55,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-12-03 14:39:55,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,766:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:55,766:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:55,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:55,766:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:55,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,795:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,795:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,795:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,796:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,796:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,796:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,796:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:55,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-12-03 14:39:55,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,797:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:55,797:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:55,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:55,797:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:55,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,829:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,829:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,829:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,831:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,831:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,832:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,832:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,832:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,832:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-12-03 14:39:55,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,834:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:55,834:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:55,834:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,834:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,867:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,867:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,867:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,868:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,868:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,868:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,869:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.
2025-12-03 14:39:55,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,869:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:55,869:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:55,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,869:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,902:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,902:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,902:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,903:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,903:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,903:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,903:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-12-03 14:39:55,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:55,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:55,904:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:55,904:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:55,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,904:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,938:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,938:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,938:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,939:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,939:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,939:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,940:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2025-12-03 14:39:55,940:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,940:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:55,940:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:55,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,940:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,968:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,968:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,968:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,969:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:55,969:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:55,969:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:55,969:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:55,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-12-03 14:39:55,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:55,970:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 14:39:55,970:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 14:39:55,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:55,970:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:55,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:55,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,004:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,004:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,004:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,007:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,007:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,007:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,008:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,008:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,008:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,008:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.
2025-12-03 14:39:56,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,009:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:56,009:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,043:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,043:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,043:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,044:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,044:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,044:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.
2025-12-03 14:39:56,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,045:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:56,045:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,074:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,074:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,076:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,076:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,076:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,076:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-12-03 14:39:56,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,077:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:56,077:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,110:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,110:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,110:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,111:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,111:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,111:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,111:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,112:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-12-03 14:39:56,112:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,112:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:56,112:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:56,112:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,139:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,139:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,139:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,141:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,141:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,142:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,142:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,142:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,142:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-12-03 14:39:56,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,143:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:56,143:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,176:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,176:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,178:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,178:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,178:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,178:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2025-12-03 14:39:56,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,179:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:56,179:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,179:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,212:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,212:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,213:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,213:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,213:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-12-03 14:39:56,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,214:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:56,214:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,252:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,252:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,252:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,253:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,253:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,253:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
2025-12-03 14:39:56,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,254:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:56,254:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:56,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,279:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,279:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,279:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,281:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,281:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,282:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,282:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,282:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,282:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-12-03 14:39:56,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,283:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:56,283:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,314:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,314:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,314:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,315:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,315:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,315:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,315:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-12-03 14:39:56,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,316:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:56,316:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,347:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,347:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,347:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,348:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,348:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,348:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,348:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-12-03 14:39:56,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,349:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:56,349:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,383:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,383:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,383:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,384:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,384:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,384:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,384:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-12-03 14:39:56,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,385:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 14:39:56,385:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 14:39:56,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,413:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,413:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,413:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,415:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,415:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,415:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,416:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,416:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,416:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,416:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:56,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-12-03 14:39:56,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,417:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:56,418:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:56,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:56,418:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,450:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,450:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,450:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,451:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,451:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,451:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:56,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-12-03 14:39:56,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,453:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:56,453:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:56,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:56,453:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:56,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,485:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,485:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,486:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,486:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,486:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
2025-12-03 14:39:56,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:56,486:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,515:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,515:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,515:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,516:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,516:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,516:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,516:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:56,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-12-03 14:39:56,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,517:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:56,517:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:56,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:56,517:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:56,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,545:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,545:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,545:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,547:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,547:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,548:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,548:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,548:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,548:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:56,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-12-03 14:39:56,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,549:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:56,549:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:56,549:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:56,549:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,582:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,582:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,582:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,583:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,583:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,583:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:56,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2025-12-03 14:39:56,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,584:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:56,584:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:56,585:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:56,585:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,616:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,616:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,617:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:56,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-12-03 14:39:56,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,618:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:56,618:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:56,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:56,618:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,652:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,652:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,653:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,653:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,653:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,653:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:56,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-12-03 14:39:56,654:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,654:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 14:39:56,654:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 14:39:56,654:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:56,654:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,683:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,683:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,683:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,686:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,686:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,687:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,687:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,687:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,687:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-12-03 14:39:56,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,688:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:56,688:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,688:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,719:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,719:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,720:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,720:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,720:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000414 seconds.
2025-12-03 14:39:56,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,721:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:56,721:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,721:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,752:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,752:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,752:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,753:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,753:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,753:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,753:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.
2025-12-03 14:39:56,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,754:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:56,754:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,754:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,786:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,786:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,788:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,788:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,788:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,789:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,789:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,789:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,790:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-12-03 14:39:56,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,791:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,791:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:56,791:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,823:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,823:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,823:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,824:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,824:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,824:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2025-12-03 14:39:56,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,825:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:56,825:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,825:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,856:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,856:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,856:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,857:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,857:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,857:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,857:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2025-12-03 14:39:56,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,858:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:56,858:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,892:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,892:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,894:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,894:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,894:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,895:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,895:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,895:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,895:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-12-03 14:39:56,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,896:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:56,896:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:56,896:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,926:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,926:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,926:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,927:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,927:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,928:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
2025-12-03 14:39:56,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:56,929:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:56,929:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:56,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,959:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,960:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:56,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.
2025-12-03 14:39:56,960:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,960:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,960:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 14:39:56,961:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 14:39:56,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:56,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:56,993:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,993:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,995:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,995:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,995:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,996:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:56,996:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:56,996:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:56,996:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:56,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.
2025-12-03 14:39:56,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:56,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:56,997:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:56,997:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:56,997:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:56,997:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:56,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,031:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,031:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,031:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,031:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:57,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-12-03 14:39:57,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,032:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:57,032:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:57,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:57,032:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:57,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,063:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,063:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,064:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,064:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,064:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:57,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-12-03 14:39:57,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,065:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:57,065:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:57,065:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:57,065:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,098:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,098:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,098:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,099:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,099:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,099:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,100:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,100:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,100:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,100:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.
2025-12-03 14:39:57,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,102:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:57,102:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:57,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,102:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,134:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,134:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,134:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,135:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,135:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,136:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-12-03 14:39:57,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,136:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:57,136:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:57,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,137:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,168:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,168:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,168:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,169:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,169:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,169:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,169:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-12-03 14:39:57,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,170:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 14:39:57,170:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 14:39:57,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,170:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,203:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,203:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,206:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,206:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,206:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,207:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,207:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,207:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,208:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.
2025-12-03 14:39:57,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,209:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:57,209:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,209:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,242:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,242:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,242:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,243:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,243:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,243:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,243:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.
2025-12-03 14:39:57,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,244:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:57,244:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:57,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,273:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,273:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,275:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,276:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,276:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,277:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,277:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,277:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,277:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-12-03 14:39:57,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,278:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:57,278:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,311:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,311:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,311:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,312:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,312:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,312:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,312:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
2025-12-03 14:39:57,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,313:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 14:39:57,313:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:57,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,345:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,345:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,345:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,347:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,347:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,347:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,348:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,349:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,349:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,349:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.
2025-12-03 14:39:57,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,350:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:57,350:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,381:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,381:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,381:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,382:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,382:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,382:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,382:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-12-03 14:39:57,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,383:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 14:39:57,383:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 14:39:57,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,414:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,414:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,414:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,417:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,417:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,417:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,418:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,418:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,418:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,418:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:57,419:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-12-03 14:39:57,419:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,419:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,419:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:57,419:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:57,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:57,419:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:57,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,452:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,452:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,452:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,453:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,453:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,453:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,453:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:57,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-12-03 14:39:57,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,454:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:57,454:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:57,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:57,455:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,485:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,485:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,487:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,487:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,487:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,488:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,488:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,488:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.
2025-12-03 14:39:57,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,489:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:57,489:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:57,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,489:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,522:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,522:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,524:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,524:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,524:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,524:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-12-03 14:39:57,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 14:39:57,525:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 14:39:57,525:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 14:39:57,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,526:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,555:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,555:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,555:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,559:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,559:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,559:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,560:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,560:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,560:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,560:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2025-12-03 14:39:57,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,561:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:57,561:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,594:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,594:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,594:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,596:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,596:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,597:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,597:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,597:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.
2025-12-03 14:39:57,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,598:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 14:39:57,598:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,599:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,631:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,631:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,631:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,633:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,633:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,633:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,634:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,634:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,634:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,634:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 14:39:57,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.
2025-12-03 14:39:57,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,635:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 14:39:57,635:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 14:39:57,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,666:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,666:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,666:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,668:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,668:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,669:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,670:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,670:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,670:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 14:39:57,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.
2025-12-03 14:39:57,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,671:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:57,671:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:57,671:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 14:39:57,671:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 14:39:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,703:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,703:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,703:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,705:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,705:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,705:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,706:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,706:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,706:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,706:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 14:39:57,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.
2025-12-03 14:39:57,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,707:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 14:39:57,707:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 14:39:57,707:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 14:39:57,707:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 14:39:57,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,739:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,739:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,739:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,741:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,741:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,741:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,743:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 14:39:57,743:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 14:39:57,743:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 14:39:57,743:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 14:39:57,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.
2025-12-03 14:39:57,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 14:39:57,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 14:39:57,744:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 14:39:57,744:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 14:39:57,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 14:39:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 14:39:57,945:INFO:Visual Rendered Successfully
2025-12-03 14:39:58,131:INFO:plot_model() successfully completed......................................
2025-12-03 15:44:59,970:INFO:PyCaret ClassificationExperiment
2025-12-03 15:44:59,970:INFO:Logging name: clf-default-name
2025-12-03 15:44:59,972:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 15:44:59,972:INFO:version 3.3.2
2025-12-03 15:44:59,972:INFO:Initializing setup()
2025-12-03 15:44:59,972:INFO:self.USI: 2dc4
2025-12-03 15:44:59,972:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 15:44:59,974:INFO:Checking environment
2025-12-03 15:44:59,975:INFO:python_version: 3.11.14
2025-12-03 15:44:59,975:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 15:44:59,977:INFO:machine: arm64
2025-12-03 15:44:59,977:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 15:44:59,979:INFO:Memory: svmem(total=8589934592, available=1297563648, percent=84.9, used=2897887232, free=67207168, active=1248247808, inactive=1205501952, wired=1649639424)
2025-12-03 15:44:59,979:INFO:Physical Core: 8
2025-12-03 15:44:59,979:INFO:Logical Core: 8
2025-12-03 15:44:59,980:INFO:Checking libraries
2025-12-03 15:44:59,981:INFO:System:
2025-12-03 15:44:59,981:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 15:44:59,981:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 15:44:59,981:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 15:44:59,981:INFO:PyCaret required dependencies:
2025-12-03 15:44:59,987:INFO:                 pip: 25.3
2025-12-03 15:44:59,987:INFO:          setuptools: 80.9.0
2025-12-03 15:44:59,987:INFO:             pycaret: 3.3.2
2025-12-03 15:44:59,987:INFO:             IPython: 9.7.0
2025-12-03 15:44:59,987:INFO:          ipywidgets: 8.1.8
2025-12-03 15:44:59,987:INFO:                tqdm: 4.67.1
2025-12-03 15:44:59,987:INFO:               numpy: 1.26.4
2025-12-03 15:44:59,987:INFO:              pandas: 2.1.4
2025-12-03 15:44:59,987:INFO:              jinja2: 3.1.6
2025-12-03 15:44:59,987:INFO:               scipy: 1.11.4
2025-12-03 15:44:59,987:INFO:              joblib: 1.3.2
2025-12-03 15:44:59,987:INFO:             sklearn: 1.4.2
2025-12-03 15:44:59,987:INFO:                pyod: 2.0.5
2025-12-03 15:44:59,987:INFO:            imblearn: 0.14.0
2025-12-03 15:44:59,987:INFO:   category_encoders: 2.7.0
2025-12-03 15:44:59,987:INFO:            lightgbm: 4.6.0
2025-12-03 15:44:59,987:INFO:               numba: 0.62.1
2025-12-03 15:44:59,987:INFO:            requests: 2.32.5
2025-12-03 15:44:59,987:INFO:          matplotlib: 3.7.5
2025-12-03 15:44:59,987:INFO:          scikitplot: 0.3.7
2025-12-03 15:44:59,987:INFO:         yellowbrick: 1.5
2025-12-03 15:44:59,987:INFO:              plotly: 6.5.0
2025-12-03 15:44:59,987:INFO:    plotly-resampler: Not installed
2025-12-03 15:44:59,987:INFO:             kaleido: 1.2.0
2025-12-03 15:44:59,987:INFO:           schemdraw: 0.15
2025-12-03 15:44:59,987:INFO:         statsmodels: 0.14.5
2025-12-03 15:44:59,987:INFO:              sktime: 0.26.0
2025-12-03 15:44:59,987:INFO:               tbats: 1.1.3
2025-12-03 15:44:59,987:INFO:            pmdarima: 2.0.4
2025-12-03 15:44:59,987:INFO:              psutil: 7.1.3
2025-12-03 15:44:59,987:INFO:          markupsafe: 3.0.3
2025-12-03 15:44:59,987:INFO:             pickle5: Not installed
2025-12-03 15:44:59,987:INFO:         cloudpickle: 3.1.2
2025-12-03 15:44:59,987:INFO:         deprecation: 2.1.0
2025-12-03 15:44:59,987:INFO:              xxhash: 3.6.0
2025-12-03 15:44:59,987:INFO:           wurlitzer: 3.1.1
2025-12-03 15:44:59,987:INFO:PyCaret optional dependencies:
2025-12-03 15:44:59,987:INFO:                shap: Not installed
2025-12-03 15:44:59,987:INFO:           interpret: Not installed
2025-12-03 15:44:59,987:INFO:                umap: Not installed
2025-12-03 15:44:59,987:INFO:     ydata_profiling: Not installed
2025-12-03 15:44:59,987:INFO:  explainerdashboard: Not installed
2025-12-03 15:44:59,987:INFO:             autoviz: Not installed
2025-12-03 15:44:59,987:INFO:           fairlearn: Not installed
2025-12-03 15:44:59,987:INFO:          deepchecks: Not installed
2025-12-03 15:44:59,987:INFO:             xgboost: Not installed
2025-12-03 15:44:59,987:INFO:            catboost: Not installed
2025-12-03 15:44:59,987:INFO:              kmodes: Not installed
2025-12-03 15:44:59,987:INFO:             mlxtend: Not installed
2025-12-03 15:44:59,987:INFO:       statsforecast: Not installed
2025-12-03 15:44:59,987:INFO:        tune_sklearn: Not installed
2025-12-03 15:44:59,987:INFO:                 ray: Not installed
2025-12-03 15:44:59,987:INFO:            hyperopt: Not installed
2025-12-03 15:44:59,987:INFO:              optuna: Not installed
2025-12-03 15:44:59,987:INFO:               skopt: Not installed
2025-12-03 15:44:59,987:INFO:              mlflow: Not installed
2025-12-03 15:44:59,987:INFO:              gradio: Not installed
2025-12-03 15:44:59,987:INFO:             fastapi: Not installed
2025-12-03 15:44:59,987:INFO:             uvicorn: Not installed
2025-12-03 15:44:59,987:INFO:              m2cgen: Not installed
2025-12-03 15:44:59,987:INFO:           evidently: Not installed
2025-12-03 15:44:59,987:INFO:               fugue: Not installed
2025-12-03 15:44:59,987:INFO:           streamlit: Not installed
2025-12-03 15:44:59,987:INFO:             prophet: Not installed
2025-12-03 15:44:59,987:INFO:None
2025-12-03 15:44:59,988:INFO:Set up data.
2025-12-03 15:45:00,333:INFO:Set up folding strategy.
2025-12-03 15:45:00,336:INFO:Set up train/test split.
2025-12-03 15:45:00,411:INFO:Set up index.
2025-12-03 15:45:00,412:INFO:Assigning column types.
2025-12-03 15:45:00,425:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 15:45:00,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,584:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 15:45:00,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,647:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:45:00,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,659:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 15:45:00,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:00,734:INFO:Preparing preprocessing pipeline...
2025-12-03 15:45:00,737:INFO:Set up simple imputation.
2025-12-03 15:45:00,739:INFO:Set up imbalanced handling.
2025-12-03 15:45:00,745:INFO:Set up column name cleaning.
2025-12-03 15:45:00,823:INFO:Finished creating preprocessing pipeline.
2025-12-03 15:45:00,830:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['gender', 'age', 'under_30',
                                             'senior_citizen', 'partner',
                                             'dependents',
                                             'number_of_dependents', 'married',
                                             'paperless_billing',
                                             'monthly_ charges',
                                             'avg_monthly_long_distance_charges',
                                             'total_charges'...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 15:45:00,830:INFO:Creating final display dataframe.
2025-12-03 15:45:00,945:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 44)
4        Transformed data shape        (9687, 44)
5   Transformed train set shape        (8278, 44)
6    Transformed test set shape        (1409, 44)
7              Numeric features                32
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              2dc4
2025-12-03 15:45:01,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:01,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:01,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:01,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:45:01,143:INFO:setup() successfully completed in 1.25s...............
2025-12-03 15:45:01,143:INFO:Initializing compare_models()
2025-12-03 15:45:01,143:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 15:45:01,143:INFO:Checking exceptions
2025-12-03 15:45:01,148:INFO:Preparing display monitor
2025-12-03 15:45:01,178:INFO:Initializing Logistic Regression
2025-12-03 15:45:01,178:INFO:Total runtime is 1.903374989827474e-06 minutes
2025-12-03 15:45:01,180:INFO:SubProcess create_model() called ==================================
2025-12-03 15:45:01,180:INFO:Initializing create_model()
2025-12-03 15:45:01,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31d9b4290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:45:01,180:INFO:Checking exceptions
2025-12-03 15:45:01,180:INFO:Importing libraries
2025-12-03 15:45:01,180:INFO:Copying training dataset
2025-12-03 15:45:01,188:INFO:Defining folds
2025-12-03 15:45:01,188:INFO:Declaring metric variables
2025-12-03 15:45:01,190:INFO:Importing untrained model
2025-12-03 15:45:01,191:INFO:Logistic Regression Imported successfully
2025-12-03 15:45:01,193:INFO:Starting cross validation
2025-12-03 15:45:01,194:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:45:04,955:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:04,955:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:04,955:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:04,955:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:04,955:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:05,434:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:05,443:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:05,445:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:05,446:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:05,466:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:05,495:INFO:Calculating mean and std
2025-12-03 15:45:05,502:INFO:Creating metrics dataframe
2025-12-03 15:45:05,512:INFO:Uploading results into container
2025-12-03 15:45:05,516:INFO:Uploading model into container now
2025-12-03 15:45:05,520:INFO:_master_model_container: 1
2025-12-03 15:45:05,520:INFO:_display_container: 2
2025-12-03 15:45:05,522:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 15:45:05,525:INFO:create_model() successfully completed......................................
2025-12-03 15:45:06,417:INFO:SubProcess create_model() end ==================================
2025-12-03 15:45:06,418:INFO:Creating metrics dataframe
2025-12-03 15:45:06,422:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 15:45:06,422:INFO:Total runtime is 0.08739540179570517 minutes
2025-12-03 15:45:06,423:INFO:SubProcess create_model() called ==================================
2025-12-03 15:45:06,423:INFO:Initializing create_model()
2025-12-03 15:45:06,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31d9b4290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:45:06,423:INFO:Checking exceptions
2025-12-03 15:45:06,423:INFO:Importing libraries
2025-12-03 15:45:06,423:INFO:Copying training dataset
2025-12-03 15:45:06,431:INFO:Defining folds
2025-12-03 15:45:06,431:INFO:Declaring metric variables
2025-12-03 15:45:06,432:INFO:Importing untrained model
2025-12-03 15:45:06,434:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 15:45:06,436:INFO:Starting cross validation
2025-12-03 15:45:06,436:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:45:06,548:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 15:45:06,567:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 15:45:06,582:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 15:45:07,754:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:07,771:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:07,844:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 15:45:07,865:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-03 15:45:07,892:INFO:Calculating mean and std
2025-12-03 15:45:07,895:INFO:Creating metrics dataframe
2025-12-03 15:45:07,908:INFO:Uploading results into container
2025-12-03 15:45:07,908:INFO:Uploading model into container now
2025-12-03 15:45:07,909:INFO:_master_model_container: 2
2025-12-03 15:45:07,909:INFO:_display_container: 2
2025-12-03 15:45:07,910:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 15:45:07,910:INFO:create_model() successfully completed......................................
2025-12-03 15:45:08,081:INFO:SubProcess create_model() end ==================================
2025-12-03 15:45:08,081:INFO:Creating metrics dataframe
2025-12-03 15:45:08,084:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 15:45:08,084:INFO:Total runtime is 0.11510099967320761 minutes
2025-12-03 15:45:08,086:INFO:SubProcess create_model() called ==================================
2025-12-03 15:45:08,086:INFO:Initializing create_model()
2025-12-03 15:45:08,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31d9b4290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:45:08,086:INFO:Checking exceptions
2025-12-03 15:45:08,086:INFO:Importing libraries
2025-12-03 15:45:08,087:INFO:Copying training dataset
2025-12-03 15:45:08,097:INFO:Defining folds
2025-12-03 15:45:08,097:INFO:Declaring metric variables
2025-12-03 15:45:08,099:INFO:Importing untrained model
2025-12-03 15:45:08,100:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:45:08,108:INFO:Starting cross validation
2025-12-03 15:45:08,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:45:10,161:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 15:45:11,011:INFO:Calculating mean and std
2025-12-03 15:45:11,015:INFO:Creating metrics dataframe
2025-12-03 15:45:11,024:INFO:Uploading results into container
2025-12-03 15:45:11,024:INFO:Uploading model into container now
2025-12-03 15:45:11,025:INFO:_master_model_container: 3
2025-12-03 15:45:11,025:INFO:_display_container: 2
2025-12-03 15:45:11,026:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:45:11,026:INFO:create_model() successfully completed......................................
2025-12-03 15:45:11,308:INFO:SubProcess create_model() end ==================================
2025-12-03 15:45:11,309:INFO:Creating metrics dataframe
2025-12-03 15:45:11,312:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 15:45:11,317:INFO:Initializing create_model()
2025-12-03 15:45:11,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:45:11,317:INFO:Checking exceptions
2025-12-03 15:45:11,320:INFO:Importing libraries
2025-12-03 15:45:11,320:INFO:Copying training dataset
2025-12-03 15:45:11,561:INFO:Defining folds
2025-12-03 15:45:11,893:INFO:Declaring metric variables
2025-12-03 15:45:11,894:INFO:Importing untrained model
2025-12-03 15:45:11,895:INFO:Declaring custom model
2025-12-03 15:45:11,897:INFO:Logistic Regression Imported successfully
2025-12-03 15:45:12,061:INFO:Cross validation set to False
2025-12-03 15:45:12,064:INFO:Fitting Model
2025-12-03 15:45:13,693:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-12-03 15:45:13,699:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 15:45:13,699:INFO:create_model() successfully completed......................................
2025-12-03 15:45:13,926:INFO:_master_model_container: 3
2025-12-03 15:45:13,926:INFO:_display_container: 2
2025-12-03 15:45:13,926:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 15:45:13,927:INFO:compare_models() successfully completed......................................
2025-12-03 15:45:27,208:INFO:Initializing create_model()
2025-12-03 15:45:27,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:45:27,209:INFO:Checking exceptions
2025-12-03 15:45:27,305:INFO:Importing libraries
2025-12-03 15:45:27,305:INFO:Copying training dataset
2025-12-03 15:45:27,320:INFO:Defining folds
2025-12-03 15:45:27,320:INFO:Declaring metric variables
2025-12-03 15:45:27,322:INFO:Importing untrained model
2025-12-03 15:45:27,328:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:45:27,332:INFO:Starting cross validation
2025-12-03 15:45:27,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:45:29,025:INFO:Calculating mean and std
2025-12-03 15:45:29,026:INFO:Creating metrics dataframe
2025-12-03 15:45:29,029:INFO:Finalizing model
2025-12-03 15:45:29,081:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:45:29,082:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:45:29,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.
2025-12-03 15:45:29,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:45:29,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:45:29,086:INFO:[LightGBM] [Info] Total Bins 7958
2025-12-03 15:45:29,087:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 43
2025-12-03 15:45:29,087:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:45:29,567:INFO:Uploading results into container
2025-12-03 15:45:29,568:INFO:Uploading model into container now
2025-12-03 15:45:29,574:INFO:_master_model_container: 4
2025-12-03 15:45:29,574:INFO:_display_container: 3
2025-12-03 15:45:29,574:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:45:29,575:INFO:create_model() successfully completed......................................
2025-12-03 15:45:29,749:INFO:Initializing tune_model()
2025-12-03 15:45:29,749:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-03 15:45:29,749:INFO:Checking exceptions
2025-12-03 15:45:29,757:INFO:Copying training dataset
2025-12-03 15:45:29,764:INFO:Checking base model
2025-12-03 15:45:29,764:INFO:Base model : Light Gradient Boosting Machine
2025-12-03 15:45:29,765:INFO:Declaring metric variables
2025-12-03 15:45:29,766:INFO:Defining Hyperparameters
2025-12-03 15:45:29,872:INFO:Tuning with n_jobs=-1
2025-12-03 15:45:29,873:INFO:Initializing RandomizedSearchCV
2025-12-03 15:47:03,967:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 4, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.6}
2025-12-03 15:47:03,979:INFO:Hyperparameter search completed
2025-12-03 15:47:03,981:INFO:SubProcess create_model() called ==================================
2025-12-03 15:47:03,984:INFO:Initializing create_model()
2025-12-03 15:47:03,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319f3bcd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 3, 'num_leaves': 4, 'n_estimators': 20, 'min_split_gain': 0.4, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.6})
2025-12-03 15:47:03,984:INFO:Checking exceptions
2025-12-03 15:47:03,984:INFO:Importing libraries
2025-12-03 15:47:03,985:INFO:Copying training dataset
2025-12-03 15:47:04,003:INFO:Defining folds
2025-12-03 15:47:04,003:INFO:Declaring metric variables
2025-12-03 15:47:04,007:INFO:Importing untrained model
2025-12-03 15:47:04,007:INFO:Declaring custom model
2025-12-03 15:47:04,015:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:47:04,017:INFO:Starting cross validation
2025-12-03 15:47:04,019:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:47:04,213:INFO:Calculating mean and std
2025-12-03 15:47:04,214:INFO:Creating metrics dataframe
2025-12-03 15:47:04,218:INFO:Finalizing model
2025-12-03 15:47:04,257:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-03 15:47:04,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-12-03 15:47:04,258:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-03 15:47:04,267:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:47:04,268:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-03 15:47:04,268:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-12-03 15:47:04,268:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-03 15:47:04,268:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:47:04,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003423 seconds.
2025-12-03 15:47:04,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:47:04,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:47:04,276:INFO:[LightGBM] [Info] Total Bins 7958
2025-12-03 15:47:04,276:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 43
2025-12-03 15:47:04,276:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:47:04,307:INFO:Uploading results into container
2025-12-03 15:47:04,308:INFO:Uploading model into container now
2025-12-03 15:47:04,309:INFO:_master_model_container: 5
2025-12-03 15:47:04,309:INFO:_display_container: 4
2025-12-03 15:47:04,310:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=20, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:47:04,310:INFO:create_model() successfully completed......................................
2025-12-03 15:47:04,607:INFO:SubProcess create_model() end ==================================
2025-12-03 15:47:04,607:INFO:choose_better activated
2025-12-03 15:47:04,609:INFO:SubProcess create_model() called ==================================
2025-12-03 15:47:04,609:INFO:Initializing create_model()
2025-12-03 15:47:04,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326ecded0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:47:04,609:INFO:Checking exceptions
2025-12-03 15:47:04,610:INFO:Importing libraries
2025-12-03 15:47:04,610:INFO:Copying training dataset
2025-12-03 15:47:04,619:INFO:Defining folds
2025-12-03 15:47:04,619:INFO:Declaring metric variables
2025-12-03 15:47:04,619:INFO:Importing untrained model
2025-12-03 15:47:04,619:INFO:Declaring custom model
2025-12-03 15:47:04,619:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:47:04,619:INFO:Starting cross validation
2025-12-03 15:47:04,620:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:47:06,423:INFO:Calculating mean and std
2025-12-03 15:47:06,423:INFO:Creating metrics dataframe
2025-12-03 15:47:06,426:INFO:Finalizing model
2025-12-03 15:47:06,475:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:47:06,475:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:47:06,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.
2025-12-03 15:47:06,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:47:06,479:INFO:[LightGBM] [Info] Total Bins 7958
2025-12-03 15:47:06,479:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 43
2025-12-03 15:47:06,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:47:07,041:INFO:Uploading results into container
2025-12-03 15:47:07,042:INFO:Uploading model into container now
2025-12-03 15:47:07,042:INFO:_master_model_container: 6
2025-12-03 15:47:07,042:INFO:_display_container: 5
2025-12-03 15:47:07,043:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:47:07,043:INFO:create_model() successfully completed......................................
2025-12-03 15:47:07,240:INFO:SubProcess create_model() end ==================================
2025-12-03 15:47:07,241:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.6702
2025-12-03 15:47:07,241:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=20, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7264
2025-12-03 15:47:07,241:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=20, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-03 15:47:07,241:INFO:choose_better completed
2025-12-03 15:47:07,249:INFO:_master_model_container: 6
2025-12-03 15:47:07,249:INFO:_display_container: 4
2025-12-03 15:47:07,249:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=20, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=0.05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:47:07,249:INFO:tune_model() successfully completed......................................
2025-12-03 15:48:52,212:INFO:PyCaret ClassificationExperiment
2025-12-03 15:48:52,212:INFO:Logging name: clf-default-name
2025-12-03 15:48:52,212:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 15:48:52,212:INFO:version 3.3.2
2025-12-03 15:48:52,212:INFO:Initializing setup()
2025-12-03 15:48:52,212:INFO:self.USI: 373b
2025-12-03 15:48:52,212:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-03 15:48:52,212:INFO:Checking environment
2025-12-03 15:48:52,212:INFO:python_version: 3.11.14
2025-12-03 15:48:52,212:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-03 15:48:52,212:INFO:machine: arm64
2025-12-03 15:48:52,212:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-03 15:48:52,214:INFO:Memory: svmem(total=8589934592, available=1345699840, percent=84.3, used=2907439104, free=58523648, active=1302577152, inactive=1246904320, wired=1604861952)
2025-12-03 15:48:52,214:INFO:Physical Core: 8
2025-12-03 15:48:52,214:INFO:Logical Core: 8
2025-12-03 15:48:52,214:INFO:Checking libraries
2025-12-03 15:48:52,214:INFO:System:
2025-12-03 15:48:52,214:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-03 15:48:52,214:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-03 15:48:52,214:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-03 15:48:52,214:INFO:PyCaret required dependencies:
2025-12-03 15:48:52,214:INFO:                 pip: 25.3
2025-12-03 15:48:52,214:INFO:          setuptools: 80.9.0
2025-12-03 15:48:52,214:INFO:             pycaret: 3.3.2
2025-12-03 15:48:52,214:INFO:             IPython: 9.7.0
2025-12-03 15:48:52,214:INFO:          ipywidgets: 8.1.8
2025-12-03 15:48:52,214:INFO:                tqdm: 4.67.1
2025-12-03 15:48:52,214:INFO:               numpy: 1.26.4
2025-12-03 15:48:52,214:INFO:              pandas: 2.1.4
2025-12-03 15:48:52,214:INFO:              jinja2: 3.1.6
2025-12-03 15:48:52,214:INFO:               scipy: 1.11.4
2025-12-03 15:48:52,214:INFO:              joblib: 1.3.2
2025-12-03 15:48:52,214:INFO:             sklearn: 1.4.2
2025-12-03 15:48:52,214:INFO:                pyod: 2.0.5
2025-12-03 15:48:52,214:INFO:            imblearn: 0.14.0
2025-12-03 15:48:52,214:INFO:   category_encoders: 2.7.0
2025-12-03 15:48:52,214:INFO:            lightgbm: 4.6.0
2025-12-03 15:48:52,214:INFO:               numba: 0.62.1
2025-12-03 15:48:52,214:INFO:            requests: 2.32.5
2025-12-03 15:48:52,214:INFO:          matplotlib: 3.7.5
2025-12-03 15:48:52,214:INFO:          scikitplot: 0.3.7
2025-12-03 15:48:52,214:INFO:         yellowbrick: 1.5
2025-12-03 15:48:52,214:INFO:              plotly: 6.5.0
2025-12-03 15:48:52,214:INFO:    plotly-resampler: Not installed
2025-12-03 15:48:52,214:INFO:             kaleido: 1.2.0
2025-12-03 15:48:52,214:INFO:           schemdraw: 0.15
2025-12-03 15:48:52,214:INFO:         statsmodels: 0.14.5
2025-12-03 15:48:52,215:INFO:              sktime: 0.26.0
2025-12-03 15:48:52,215:INFO:               tbats: 1.1.3
2025-12-03 15:48:52,215:INFO:            pmdarima: 2.0.4
2025-12-03 15:48:52,215:INFO:              psutil: 7.1.3
2025-12-03 15:48:52,215:INFO:          markupsafe: 3.0.3
2025-12-03 15:48:52,215:INFO:             pickle5: Not installed
2025-12-03 15:48:52,215:INFO:         cloudpickle: 3.1.2
2025-12-03 15:48:52,215:INFO:         deprecation: 2.1.0
2025-12-03 15:48:52,215:INFO:              xxhash: 3.6.0
2025-12-03 15:48:52,215:INFO:           wurlitzer: 3.1.1
2025-12-03 15:48:52,215:INFO:PyCaret optional dependencies:
2025-12-03 15:48:52,215:INFO:                shap: Not installed
2025-12-03 15:48:52,215:INFO:           interpret: Not installed
2025-12-03 15:48:52,215:INFO:                umap: Not installed
2025-12-03 15:48:52,215:INFO:     ydata_profiling: Not installed
2025-12-03 15:48:52,215:INFO:  explainerdashboard: Not installed
2025-12-03 15:48:52,215:INFO:             autoviz: Not installed
2025-12-03 15:48:52,215:INFO:           fairlearn: Not installed
2025-12-03 15:48:52,215:INFO:          deepchecks: Not installed
2025-12-03 15:48:52,215:INFO:             xgboost: Not installed
2025-12-03 15:48:52,215:INFO:            catboost: Not installed
2025-12-03 15:48:52,215:INFO:              kmodes: Not installed
2025-12-03 15:48:52,215:INFO:             mlxtend: Not installed
2025-12-03 15:48:52,215:INFO:       statsforecast: Not installed
2025-12-03 15:48:52,215:INFO:        tune_sklearn: Not installed
2025-12-03 15:48:52,215:INFO:                 ray: Not installed
2025-12-03 15:48:52,215:INFO:            hyperopt: Not installed
2025-12-03 15:48:52,215:INFO:              optuna: Not installed
2025-12-03 15:48:52,215:INFO:               skopt: Not installed
2025-12-03 15:48:52,215:INFO:              mlflow: Not installed
2025-12-03 15:48:52,215:INFO:              gradio: Not installed
2025-12-03 15:48:52,215:INFO:             fastapi: Not installed
2025-12-03 15:48:52,215:INFO:             uvicorn: Not installed
2025-12-03 15:48:52,215:INFO:              m2cgen: Not installed
2025-12-03 15:48:52,215:INFO:           evidently: Not installed
2025-12-03 15:48:52,215:INFO:               fugue: Not installed
2025-12-03 15:48:52,215:INFO:           streamlit: Not installed
2025-12-03 15:48:52,215:INFO:             prophet: Not installed
2025-12-03 15:48:52,215:INFO:None
2025-12-03 15:48:52,215:INFO:Set up data.
2025-12-03 15:48:52,248:INFO:Set up folding strategy.
2025-12-03 15:48:52,249:INFO:Set up train/test split.
2025-12-03 15:48:52,260:INFO:Set up index.
2025-12-03 15:48:52,261:INFO:Assigning column types.
2025-12-03 15:48:52,263:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 15:48:52,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,285:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,335:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 15:48:52,380:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,428:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 15:48:52,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,441:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 15:48:52,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,507:INFO:Preparing preprocessing pipeline...
2025-12-03 15:48:52,510:INFO:Set up simple imputation.
2025-12-03 15:48:52,510:INFO:Set up imbalanced handling.
2025-12-03 15:48:52,510:INFO:Set up column name cleaning.
2025-12-03 15:48:52,551:INFO:Finished creating preprocessing pipeline.
2025-12-03 15:48:52,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              ke...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-03 15:48:52,553:INFO:Creating final display dataframe.
2025-12-03 15:48:52,626:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 10)
4        Transformed data shape        (9687, 10)
5   Transformed train set shape        (8278, 10)
6    Transformed test set shape        (1409, 10)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              373b
2025-12-03 15:48:52,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-03 15:48:52,793:INFO:setup() successfully completed in 0.59s...............
2025-12-03 15:48:52,800:INFO:Initializing compare_models()
2025-12-03 15:48:52,800:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-03 15:48:52,800:INFO:Checking exceptions
2025-12-03 15:48:52,802:INFO:Preparing display monitor
2025-12-03 15:48:52,813:INFO:Initializing Logistic Regression
2025-12-03 15:48:52,813:INFO:Total runtime is 1.5695889790852864e-06 minutes
2025-12-03 15:48:52,814:INFO:SubProcess create_model() called ==================================
2025-12-03 15:48:52,814:INFO:Initializing create_model()
2025-12-03 15:48:52,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e32d750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:48:52,814:INFO:Checking exceptions
2025-12-03 15:48:52,814:INFO:Importing libraries
2025-12-03 15:48:52,814:INFO:Copying training dataset
2025-12-03 15:48:52,818:INFO:Defining folds
2025-12-03 15:48:52,818:INFO:Declaring metric variables
2025-12-03 15:48:52,820:INFO:Importing untrained model
2025-12-03 15:48:52,822:INFO:Logistic Regression Imported successfully
2025-12-03 15:48:52,825:INFO:Starting cross validation
2025-12-03 15:48:52,827:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:48:52,996:INFO:Calculating mean and std
2025-12-03 15:48:52,996:INFO:Creating metrics dataframe
2025-12-03 15:48:52,998:INFO:Uploading results into container
2025-12-03 15:48:52,998:INFO:Uploading model into container now
2025-12-03 15:48:52,998:INFO:_master_model_container: 1
2025-12-03 15:48:52,998:INFO:_display_container: 2
2025-12-03 15:48:52,998:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 15:48:52,998:INFO:create_model() successfully completed......................................
2025-12-03 15:48:53,430:INFO:SubProcess create_model() end ==================================
2025-12-03 15:48:53,430:INFO:Creating metrics dataframe
2025-12-03 15:48:53,433:INFO:Initializing Quadratic Discriminant Analysis
2025-12-03 15:48:53,433:INFO:Total runtime is 0.010332687695821127 minutes
2025-12-03 15:48:53,434:INFO:SubProcess create_model() called ==================================
2025-12-03 15:48:53,434:INFO:Initializing create_model()
2025-12-03 15:48:53,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e32d750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:48:53,434:INFO:Checking exceptions
2025-12-03 15:48:53,434:INFO:Importing libraries
2025-12-03 15:48:53,434:INFO:Copying training dataset
2025-12-03 15:48:53,437:INFO:Defining folds
2025-12-03 15:48:53,437:INFO:Declaring metric variables
2025-12-03 15:48:53,438:INFO:Importing untrained model
2025-12-03 15:48:53,439:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-03 15:48:53,442:INFO:Starting cross validation
2025-12-03 15:48:53,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:48:53,565:INFO:Calculating mean and std
2025-12-03 15:48:53,565:INFO:Creating metrics dataframe
2025-12-03 15:48:53,566:INFO:Uploading results into container
2025-12-03 15:48:53,567:INFO:Uploading model into container now
2025-12-03 15:48:53,567:INFO:_master_model_container: 2
2025-12-03 15:48:53,567:INFO:_display_container: 2
2025-12-03 15:48:53,567:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-03 15:48:53,567:INFO:create_model() successfully completed......................................
2025-12-03 15:48:53,669:INFO:SubProcess create_model() end ==================================
2025-12-03 15:48:53,669:INFO:Creating metrics dataframe
2025-12-03 15:48:53,673:INFO:Initializing Light Gradient Boosting Machine
2025-12-03 15:48:53,673:INFO:Total runtime is 0.014337738355000814 minutes
2025-12-03 15:48:53,674:INFO:SubProcess create_model() called ==================================
2025-12-03 15:48:53,674:INFO:Initializing create_model()
2025-12-03 15:48:53,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e32d750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:48:53,674:INFO:Checking exceptions
2025-12-03 15:48:53,675:INFO:Importing libraries
2025-12-03 15:48:53,675:INFO:Copying training dataset
2025-12-03 15:48:53,678:INFO:Defining folds
2025-12-03 15:48:53,678:INFO:Declaring metric variables
2025-12-03 15:48:53,679:INFO:Importing untrained model
2025-12-03 15:48:53,680:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:48:53,682:INFO:Starting cross validation
2025-12-03 15:48:53,683:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:48:55,114:INFO:Calculating mean and std
2025-12-03 15:48:55,115:INFO:Creating metrics dataframe
2025-12-03 15:48:55,116:INFO:Uploading results into container
2025-12-03 15:48:55,116:INFO:Uploading model into container now
2025-12-03 15:48:55,117:INFO:_master_model_container: 3
2025-12-03 15:48:55,117:INFO:_display_container: 2
2025-12-03 15:48:55,117:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:48:55,118:INFO:create_model() successfully completed......................................
2025-12-03 15:48:55,316:INFO:SubProcess create_model() end ==================================
2025-12-03 15:48:55,316:INFO:Creating metrics dataframe
2025-12-03 15:48:55,319:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-03 15:48:55,325:INFO:Initializing create_model()
2025-12-03 15:48:55,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:48:55,325:INFO:Checking exceptions
2025-12-03 15:48:55,327:INFO:Importing libraries
2025-12-03 15:48:55,327:INFO:Copying training dataset
2025-12-03 15:48:55,329:INFO:Defining folds
2025-12-03 15:48:55,329:INFO:Declaring metric variables
2025-12-03 15:48:55,329:INFO:Importing untrained model
2025-12-03 15:48:55,329:INFO:Declaring custom model
2025-12-03 15:48:55,330:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:48:55,330:INFO:Cross validation set to False
2025-12-03 15:48:55,330:INFO:Fitting Model
2025-12-03 15:48:55,361:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:48:55,361:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:48:55,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002395 seconds.
2025-12-03 15:48:55,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:48:55,364:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:48:55,365:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 15:48:55,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:48:55,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:48:55,958:INFO:create_model() successfully completed......................................
2025-12-03 15:48:56,157:INFO:_master_model_container: 3
2025-12-03 15:48:56,157:INFO:_display_container: 2
2025-12-03 15:48:56,158:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:48:56,158:INFO:compare_models() successfully completed......................................
2025-12-03 15:49:02,728:INFO:Initializing create_model()
2025-12-03 15:49:02,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:49:02,728:INFO:Checking exceptions
2025-12-03 15:49:02,749:INFO:Importing libraries
2025-12-03 15:49:02,749:INFO:Copying training dataset
2025-12-03 15:49:02,761:INFO:Defining folds
2025-12-03 15:49:02,761:INFO:Declaring metric variables
2025-12-03 15:49:02,762:INFO:Importing untrained model
2025-12-03 15:49:02,764:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:49:02,766:INFO:Starting cross validation
2025-12-03 15:49:02,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:49:04,244:INFO:Calculating mean and std
2025-12-03 15:49:04,246:INFO:Creating metrics dataframe
2025-12-03 15:49:04,249:INFO:Finalizing model
2025-12-03 15:49:04,270:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:49:04,270:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:49:04,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000706 seconds.
2025-12-03 15:49:04,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:49:04,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:49:04,271:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:49:04,271:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 15:49:04,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:49:04,634:INFO:Uploading results into container
2025-12-03 15:49:04,635:INFO:Uploading model into container now
2025-12-03 15:49:04,640:INFO:_master_model_container: 4
2025-12-03 15:49:04,640:INFO:_display_container: 3
2025-12-03 15:49:04,640:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:49:04,640:INFO:create_model() successfully completed......................................
2025-12-03 15:49:04,816:INFO:Initializing tune_model()
2025-12-03 15:49:04,816:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-03 15:49:04,816:INFO:Checking exceptions
2025-12-03 15:49:04,824:INFO:Copying training dataset
2025-12-03 15:49:04,827:INFO:Checking base model
2025-12-03 15:49:04,827:INFO:Base model : Light Gradient Boosting Machine
2025-12-03 15:49:04,829:INFO:Declaring metric variables
2025-12-03 15:49:04,830:INFO:Defining Hyperparameters
2025-12-03 15:49:05,008:INFO:Tuning with n_jobs=-1
2025-12-03 15:49:05,009:INFO:Initializing RandomizedSearchCV
2025-12-03 15:49:46,755:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.01, 'actual_estimator__num_leaves': 100, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 1.0}
2025-12-03 15:49:46,767:INFO:Hyperparameter search completed
2025-12-03 15:49:46,769:INFO:SubProcess create_model() called ==================================
2025-12-03 15:49:46,773:INFO:Initializing create_model()
2025-12-03 15:49:46,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de50ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.01, 'num_leaves': 100, 'n_estimators': 20, 'min_split_gain': 0.6, 'min_child_samples': 61, 'learning_rate': 0.01, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 1.0})
2025-12-03 15:49:46,773:INFO:Checking exceptions
2025-12-03 15:49:46,774:INFO:Importing libraries
2025-12-03 15:49:46,775:INFO:Copying training dataset
2025-12-03 15:49:46,783:INFO:Defining folds
2025-12-03 15:49:46,783:INFO:Declaring metric variables
2025-12-03 15:49:46,790:INFO:Importing untrained model
2025-12-03 15:49:46,790:INFO:Declaring custom model
2025-12-03 15:49:46,798:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:49:46,801:INFO:Starting cross validation
2025-12-03 15:49:46,802:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:49:46,993:INFO:Calculating mean and std
2025-12-03 15:49:46,994:INFO:Creating metrics dataframe
2025-12-03 15:49:46,997:INFO:Finalizing model
2025-12-03 15:49:47,028:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:49:47,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:49:47,028:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:49:47,030:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:49:47,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:49:47,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:49:47,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:49:47,030:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:49:47,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-12-03 15:49:47,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:49:47,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:49:47,032:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:49:47,032:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 15:49:47,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:49:47,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:49:47,062:INFO:Uploading results into container
2025-12-03 15:49:47,062:INFO:Uploading model into container now
2025-12-03 15:49:47,065:INFO:_master_model_container: 5
2025-12-03 15:49:47,065:INFO:_display_container: 4
2025-12-03 15:49:47,065:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:49:47,065:INFO:create_model() successfully completed......................................
2025-12-03 15:49:47,407:INFO:SubProcess create_model() end ==================================
2025-12-03 15:49:47,407:INFO:choose_better activated
2025-12-03 15:49:47,408:INFO:SubProcess create_model() called ==================================
2025-12-03 15:49:47,408:INFO:Initializing create_model()
2025-12-03 15:49:47,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 15:49:47,409:INFO:Checking exceptions
2025-12-03 15:49:47,409:INFO:Importing libraries
2025-12-03 15:49:47,410:INFO:Copying training dataset
2025-12-03 15:49:47,412:INFO:Defining folds
2025-12-03 15:49:47,412:INFO:Declaring metric variables
2025-12-03 15:49:47,412:INFO:Importing untrained model
2025-12-03 15:49:47,412:INFO:Declaring custom model
2025-12-03 15:49:47,412:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-03 15:49:47,412:INFO:Starting cross validation
2025-12-03 15:49:47,413:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-03 15:49:48,813:INFO:Calculating mean and std
2025-12-03 15:49:48,813:INFO:Creating metrics dataframe
2025-12-03 15:49:48,814:INFO:Finalizing model
2025-12-03 15:49:48,835:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:49:48,835:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:49:48,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-12-03 15:49:48,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:49:48,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:49:48,836:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:49:48,836:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 15:49:48,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:49:49,185:INFO:Uploading results into container
2025-12-03 15:49:49,186:INFO:Uploading model into container now
2025-12-03 15:49:49,186:INFO:_master_model_container: 6
2025-12-03 15:49:49,186:INFO:_display_container: 5
2025-12-03 15:49:49,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:49:49,186:INFO:create_model() successfully completed......................................
2025-12-03 15:49:49,291:INFO:SubProcess create_model() end ==================================
2025-12-03 15:49:49,292:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8816
2025-12-03 15:49:49,292:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8936
2025-12-03 15:49:49,292:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-03 15:49:49,292:INFO:choose_better completed
2025-12-03 15:49:49,300:INFO:_master_model_container: 6
2025-12-03 15:49:49,300:INFO:_display_container: 4
2025-12-03 15:49:49,300:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-03 15:49:49,300:INFO:tune_model() successfully completed......................................
2025-12-03 15:50:25,431:INFO:Initializing evaluate_model()
2025-12-03 15:50:25,433:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-12-03 15:50:25,463:INFO:Initializing plot_model()
2025-12-03 15:50:25,464:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:25,464:INFO:Checking exceptions
2025-12-03 15:50:25,468:INFO:Preloading libraries
2025-12-03 15:50:25,475:INFO:Copying training dataset
2025-12-03 15:50:25,475:INFO:Plot type: pipeline
2025-12-03 15:50:25,553:INFO:Visual Rendered Successfully
2025-12-03 15:50:25,766:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:25,768:INFO:Initializing plot_model()
2025-12-03 15:50:25,768:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-03 15:50:25,768:INFO:Checking exceptions
2025-12-03 15:50:25,772:INFO:Preloading libraries
2025-12-03 15:50:25,774:INFO:Copying training dataset
2025-12-03 15:50:25,774:INFO:Plot type: confusion_matrix
2025-12-03 15:50:25,868:INFO:Fitting Model
2025-12-03 15:50:25,869:INFO:Scoring test/hold-out set
2025-12-03 15:50:25,871:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:25,871:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:25,871:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:25,873:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:25,873:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:25,873:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:25,908:INFO:Visual Rendered Successfully
2025-12-03 15:50:25,997:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:25,998:INFO:Initializing plot_model()
2025-12-03 15:50:25,998:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-03 15:50:25,998:INFO:Checking exceptions
2025-12-03 15:50:26,000:INFO:Preloading libraries
2025-12-03 15:50:26,000:INFO:Copying training dataset
2025-12-03 15:50:26,001:INFO:Plot type: pr
2025-12-03 15:50:26,062:INFO:Fitting Model
2025-12-03 15:50:26,063:INFO:Scoring test/hold-out set
2025-12-03 15:50:26,063:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:26,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:26,063:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:26,064:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:26,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:26,064:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:26,117:INFO:Visual Rendered Successfully
2025-12-03 15:50:26,204:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:29,983:INFO:Initializing plot_model()
2025-12-03 15:50:29,983:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:29,984:INFO:Checking exceptions
2025-12-03 15:50:29,989:INFO:Preloading libraries
2025-12-03 15:50:29,991:INFO:Copying training dataset
2025-12-03 15:50:29,991:INFO:Plot type: parameter
2025-12-03 15:50:29,995:INFO:Visual Rendered Successfully
2025-12-03 15:50:30,184:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:34,825:INFO:Initializing plot_model()
2025-12-03 15:50:34,826:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:34,826:INFO:Checking exceptions
2025-12-03 15:50:34,829:INFO:Preloading libraries
2025-12-03 15:50:34,830:INFO:Copying training dataset
2025-12-03 15:50:34,830:INFO:Plot type: auc
2025-12-03 15:50:34,904:INFO:Fitting Model
2025-12-03 15:50:34,904:INFO:Scoring test/hold-out set
2025-12-03 15:50:34,905:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:34,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:34,905:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:34,906:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:34,906:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:34,906:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:34,966:INFO:Visual Rendered Successfully
2025-12-03 15:50:35,071:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:40,051:INFO:Initializing plot_model()
2025-12-03 15:50:40,051:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:40,051:INFO:Checking exceptions
2025-12-03 15:50:40,063:INFO:Preloading libraries
2025-12-03 15:50:40,065:INFO:Copying training dataset
2025-12-03 15:50:40,065:INFO:Plot type: confusion_matrix
2025-12-03 15:50:40,134:INFO:Fitting Model
2025-12-03 15:50:40,134:INFO:Scoring test/hold-out set
2025-12-03 15:50:40,135:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:40,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:40,135:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:40,137:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:40,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:40,137:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:40,176:INFO:Visual Rendered Successfully
2025-12-03 15:50:40,428:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:45,098:INFO:Initializing plot_model()
2025-12-03 15:50:45,099:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:45,099:INFO:Checking exceptions
2025-12-03 15:50:45,111:INFO:Preloading libraries
2025-12-03 15:50:45,116:INFO:Copying training dataset
2025-12-03 15:50:45,116:INFO:Plot type: threshold
2025-12-03 15:50:45,186:INFO:Fitting Model
2025-12-03 15:50:45,189:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,189:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,189:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,193:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,193:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,193:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,193:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,193:INFO:[LightGBM] [Info] Number of positive: 3718, number of negative: 3732
2025-12-03 15:50:45,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.
2025-12-03 15:50:45,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,197:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,197:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499060 -> initscore=-0.003758
2025-12-03 15:50:45,198:INFO:[LightGBM] [Info] Start training from score -0.003758
2025-12-03 15:50:45,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,226:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,226:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,226:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,229:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,229:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,230:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,230:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,230:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,230:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,230:INFO:[LightGBM] [Info] Number of positive: 3741, number of negative: 3709
2025-12-03 15:50:45,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-12-03 15:50:45,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,231:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,231:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502148 -> initscore=0.008591
2025-12-03 15:50:45,231:INFO:[LightGBM] [Info] Start training from score 0.008591
2025-12-03 15:50:45,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,262:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,262:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,262:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,264:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,265:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,265:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,266:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,266:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,266:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,266:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,266:INFO:[LightGBM] [Info] Number of positive: 3746, number of negative: 3704
2025-12-03 15:50:45,267:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.
2025-12-03 15:50:45,267:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,267:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,267:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502819 -> initscore=0.011275
2025-12-03 15:50:45,267:INFO:[LightGBM] [Info] Start training from score 0.011275
2025-12-03 15:50:45,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,297:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,297:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,297:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,300:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,300:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,300:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,301:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,301:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,301:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,301:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,301:INFO:[LightGBM] [Info] Number of positive: 3710, number of negative: 3740
2025-12-03 15:50:45,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-12-03 15:50:45,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,302:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,302:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,302:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497987 -> initscore=-0.008054
2025-12-03 15:50:45,302:INFO:[LightGBM] [Info] Start training from score -0.008054
2025-12-03 15:50:45,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,333:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,333:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,333:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,335:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,335:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,335:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,336:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,336:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,336:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,336:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,336:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:45,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-12-03 15:50:45,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,337:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,337:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:45,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,368:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,368:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,368:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,370:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,370:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,370:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,372:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,372:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,372:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,372:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,372:INFO:[LightGBM] [Info] Number of positive: 3728, number of negative: 3722
2025-12-03 15:50:45,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2025-12-03 15:50:45,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,373:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,373:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,373:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500403 -> initscore=0.001611
2025-12-03 15:50:45,373:INFO:[LightGBM] [Info] Start training from score 0.001611
2025-12-03 15:50:45,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,397:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,397:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,397:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,400:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,400:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,400:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,401:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,401:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,401:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,401:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,401:INFO:[LightGBM] [Info] Number of positive: 3714, number of negative: 3736
2025-12-03 15:50:45,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-12-03 15:50:45,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,402:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:50:45,402:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,402:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498523 -> initscore=-0.005906
2025-12-03 15:50:45,402:INFO:[LightGBM] [Info] Start training from score -0.005906
2025-12-03 15:50:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,434:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,434:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,434:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,436:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,436:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,438:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,438:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,438:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,438:INFO:[LightGBM] [Info] Number of positive: 3719, number of negative: 3731
2025-12-03 15:50:45,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-12-03 15:50:45,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,439:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:45,439:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499195 -> initscore=-0.003221
2025-12-03 15:50:45,439:INFO:[LightGBM] [Info] Start training from score -0.003221
2025-12-03 15:50:45,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,470:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,470:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,473:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,473:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,473:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,474:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,474:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,474:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,474:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,474:INFO:[LightGBM] [Info] Number of positive: 3723, number of negative: 3727
2025-12-03 15:50:45,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.
2025-12-03 15:50:45,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,475:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:45,475:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499732 -> initscore=-0.001074
2025-12-03 15:50:45,475:INFO:[LightGBM] [Info] Start training from score -0.001074
2025-12-03 15:50:45,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,507:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,508:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,510:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,510:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,512:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,512:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,512:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,512:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,512:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-03 15:50:45,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2025-12-03 15:50:45,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,513:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:45,513:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,513:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-03 15:50:45,513:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-03 15:50:45,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,545:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,545:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,545:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,548:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,548:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,548:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,549:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,549:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,549:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,549:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,549:INFO:[LightGBM] [Info] Number of positive: 3706, number of negative: 3744
2025-12-03 15:50:45,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2025-12-03 15:50:45,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,550:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,550:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497450 -> initscore=-0.010201
2025-12-03 15:50:45,550:INFO:[LightGBM] [Info] Start training from score -0.010201
2025-12-03 15:50:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,581:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,581:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,581:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,583:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,583:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,584:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,585:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,585:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,585:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,585:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-03 15:50:45,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-12-03 15:50:45,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,586:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,586:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,586:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-03 15:50:45,586:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-03 15:50:45,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,619:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,620:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,620:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,621:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,621:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,621:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,621:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,621:INFO:[LightGBM] [Info] Number of positive: 3730, number of negative: 3720
2025-12-03 15:50:45,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-12-03 15:50:45,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,622:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:45,622:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,622:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500671 -> initscore=0.002685
2025-12-03 15:50:45,622:INFO:[LightGBM] [Info] Start training from score 0.002685
2025-12-03 15:50:45,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,650:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,650:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,650:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,652:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,652:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,653:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,653:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,653:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,653:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,653:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:45,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2025-12-03 15:50:45,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,654:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,655:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:45,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,688:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,688:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,690:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,690:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,690:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,691:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,691:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,691:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,691:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,691:INFO:[LightGBM] [Info] Number of positive: 3712, number of negative: 3738
2025-12-03 15:50:45,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.
2025-12-03 15:50:45,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,693:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,693:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,693:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498255 -> initscore=-0.006980
2025-12-03 15:50:45,693:INFO:[LightGBM] [Info] Start training from score -0.006980
2025-12-03 15:50:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,725:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,725:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,725:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,727:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,727:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,729:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,729:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,729:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:45,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
2025-12-03 15:50:45,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,730:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:45,730:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:45,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,762:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,762:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,762:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,764:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,764:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,764:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,765:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,765:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,765:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,765:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,765:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-03 15:50:45,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2025-12-03 15:50:45,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,766:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:45,766:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-03 15:50:45,767:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-03 15:50:45,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,800:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,800:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,800:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,802:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,802:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,803:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,803:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,803:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,803:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-03 15:50:45,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.
2025-12-03 15:50:45,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,804:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:45,804:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-03 15:50:45,805:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-03 15:50:45,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,836:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,836:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,836:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,838:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,838:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,838:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,839:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,839:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,839:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,839:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,839:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-03 15:50:45,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-12-03 15:50:45,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,840:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:45,840:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-03 15:50:45,840:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-03 15:50:45,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,874:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,874:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,874:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,876:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,876:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,876:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,877:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,877:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,877:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,877:INFO:[LightGBM] [Info] Number of positive: 3749, number of negative: 3701
2025-12-03 15:50:45,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.
2025-12-03 15:50:45,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,878:INFO:[LightGBM] [Info] Total Bins 69
2025-12-03 15:50:45,878:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503221 -> initscore=0.012886
2025-12-03 15:50:45,878:INFO:[LightGBM] [Info] Start training from score 0.012886
2025-12-03 15:50:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,911:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,911:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,911:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,914:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,914:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,915:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,915:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,915:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,915:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,915:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-03 15:50:45,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.
2025-12-03 15:50:45,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,916:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,916:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-03 15:50:45,916:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-03 15:50:45,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,949:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,949:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,949:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,951:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,951:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,952:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,952:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,952:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,952:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,952:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:45,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.
2025-12-03 15:50:45,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,953:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:45,953:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:45,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,985:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,985:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,988:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,988:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,988:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,989:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:45,989:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:45,989:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:45,989:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:45,989:INFO:[LightGBM] [Info] Number of positive: 3746, number of negative: 3704
2025-12-03 15:50:45,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.
2025-12-03 15:50:45,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:45,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:45,990:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:45,990:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:45,990:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502819 -> initscore=0.011275
2025-12-03 15:50:45,990:INFO:[LightGBM] [Info] Start training from score 0.011275
2025-12-03 15:50:45,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:45,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,022:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,022:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,022:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,024:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,024:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,024:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,025:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,025:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,025:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,025:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,026:INFO:[LightGBM] [Info] Number of positive: 3727, number of negative: 3723
2025-12-03 15:50:46,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.
2025-12-03 15:50:46,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,027:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,027:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500268 -> initscore=0.001074
2025-12-03 15:50:46,027:INFO:[LightGBM] [Info] Start training from score 0.001074
2025-12-03 15:50:46,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,059:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,059:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,061:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,061:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,061:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,062:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,063:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,063:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,063:INFO:[LightGBM] [Info] Number of positive: 3733, number of negative: 3717
2025-12-03 15:50:46,064:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.
2025-12-03 15:50:46,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,064:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:46,064:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501074 -> initscore=0.004295
2025-12-03 15:50:46,064:INFO:[LightGBM] [Info] Start training from score 0.004295
2025-12-03 15:50:46,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,095:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,095:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,095:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,097:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,097:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,097:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,098:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,099:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,099:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,099:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,099:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:46,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.
2025-12-03 15:50:46,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,100:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,100:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:46,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,133:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,133:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,133:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,135:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,135:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,136:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,136:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,136:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,136:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,136:INFO:[LightGBM] [Info] Number of positive: 3727, number of negative: 3723
2025-12-03 15:50:46,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-12-03 15:50:46,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,137:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,137:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500268 -> initscore=0.001074
2025-12-03 15:50:46,137:INFO:[LightGBM] [Info] Start training from score 0.001074
2025-12-03 15:50:46,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,168:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,168:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,168:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,171:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,171:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,171:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,172:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,172:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,172:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,172:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,172:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-03 15:50:46,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-12-03 15:50:46,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,173:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,173:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-03 15:50:46,173:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-03 15:50:46,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,206:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,206:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,206:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,208:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,208:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,209:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,209:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,209:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,209:INFO:[LightGBM] [Info] Number of positive: 3694, number of negative: 3756
2025-12-03 15:50:46,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-12-03 15:50:46,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,210:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,210:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495839 -> initscore=-0.016645
2025-12-03 15:50:46,211:INFO:[LightGBM] [Info] Start training from score -0.016645
2025-12-03 15:50:46,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,244:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,244:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,244:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,246:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,246:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,246:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,247:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,247:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,247:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,247:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,247:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-03 15:50:46,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.
2025-12-03 15:50:46,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,249:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,249:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-03 15:50:46,249:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-03 15:50:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,281:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,281:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,283:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,283:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,284:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,285:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,285:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,285:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,285:INFO:[LightGBM] [Info] Number of positive: 3738, number of negative: 3712
2025-12-03 15:50:46,286:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-12-03 15:50:46,286:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,286:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,286:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,286:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501745 -> initscore=0.006980
2025-12-03 15:50:46,286:INFO:[LightGBM] [Info] Start training from score 0.006980
2025-12-03 15:50:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,318:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,318:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,318:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,320:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,320:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,320:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,321:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,321:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,321:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,321:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,321:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-03 15:50:46,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.
2025-12-03 15:50:46,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,322:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,322:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:50:46,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,353:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,353:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,353:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,355:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,355:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,355:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,356:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,356:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,356:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,357:INFO:[LightGBM] [Info] Number of positive: 3763, number of negative: 3687
2025-12-03 15:50:46,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.
2025-12-03 15:50:46,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,358:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:46,358:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505101 -> initscore=0.020403
2025-12-03 15:50:46,358:INFO:[LightGBM] [Info] Start training from score 0.020403
2025-12-03 15:50:46,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,388:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,388:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,388:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,390:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,390:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,390:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,391:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,392:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,392:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,392:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,392:INFO:[LightGBM] [Info] Number of positive: 3720, number of negative: 3730
2025-12-03 15:50:46,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.
2025-12-03 15:50:46,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,393:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:46,393:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499329 -> initscore=-0.002685
2025-12-03 15:50:46,393:INFO:[LightGBM] [Info] Start training from score -0.002685
2025-12-03 15:50:46,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,428:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,428:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,428:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,430:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,430:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,430:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,431:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,431:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,431:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,431:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,431:INFO:[LightGBM] [Info] Number of positive: 3782, number of negative: 3668
2025-12-03 15:50:46,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-12-03 15:50:46,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,432:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:50:46,432:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030606
2025-12-03 15:50:46,432:INFO:[LightGBM] [Info] Start training from score 0.030606
2025-12-03 15:50:46,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,466:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,466:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,466:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,468:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,468:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,468:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,469:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,470:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,470:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,470:INFO:[LightGBM] [Info] Number of positive: 3723, number of negative: 3727
2025-12-03 15:50:46,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-12-03 15:50:46,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,471:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,471:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499732 -> initscore=-0.001074
2025-12-03 15:50:46,471:INFO:[LightGBM] [Info] Start training from score -0.001074
2025-12-03 15:50:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,503:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,504:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,504:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,506:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,506:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,506:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,507:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,507:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,507:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,507:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,507:INFO:[LightGBM] [Info] Number of positive: 3721, number of negative: 3729
2025-12-03 15:50:46,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.
2025-12-03 15:50:46,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,508:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,508:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499463 -> initscore=-0.002148
2025-12-03 15:50:46,508:INFO:[LightGBM] [Info] Start training from score -0.002148
2025-12-03 15:50:46,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,541:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,541:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,541:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,544:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,545:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,545:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,545:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,545:INFO:[LightGBM] [Info] Number of positive: 3731, number of negative: 3719
2025-12-03 15:50:46,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.
2025-12-03 15:50:46,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,546:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:46,546:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500805 -> initscore=0.003221
2025-12-03 15:50:46,546:INFO:[LightGBM] [Info] Start training from score 0.003221
2025-12-03 15:50:46,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,579:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,580:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,582:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,582:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,582:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,583:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,583:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,583:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,583:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-03 15:50:46,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.
2025-12-03 15:50:46,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,584:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,584:INFO:[LightGBM] [Info] Total Bins 69
2025-12-03 15:50:46,584:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-03 15:50:46,584:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-03 15:50:46,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,619:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,619:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,619:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,620:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,620:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,620:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,620:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,620:INFO:[LightGBM] [Info] Number of positive: 3704, number of negative: 3746
2025-12-03 15:50:46,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.
2025-12-03 15:50:46,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,621:INFO:[LightGBM] [Info] Total Bins 69
2025-12-03 15:50:46,621:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497181 -> initscore=-0.011275
2025-12-03 15:50:46,621:INFO:[LightGBM] [Info] Start training from score -0.011275
2025-12-03 15:50:46,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,654:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,654:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,654:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,656:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,656:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,656:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,657:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,657:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,657:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,658:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,658:INFO:[LightGBM] [Info] Number of positive: 3740, number of negative: 3710
2025-12-03 15:50:46,658:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-12-03 15:50:46,658:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,658:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,659:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:46,659:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,659:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502013 -> initscore=0.008054
2025-12-03 15:50:46,659:INFO:[LightGBM] [Info] Start training from score 0.008054
2025-12-03 15:50:46,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,690:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,690:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,690:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,692:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,692:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,692:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,693:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,693:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,693:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,693:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-03 15:50:46,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-12-03 15:50:46,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,695:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,695:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-03 15:50:46,695:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-03 15:50:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,727:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,727:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,729:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,729:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,730:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,730:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,730:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,730:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,730:INFO:[LightGBM] [Info] Number of positive: 3734, number of negative: 3716
2025-12-03 15:50:46,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.
2025-12-03 15:50:46,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,731:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,731:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501208 -> initscore=0.004832
2025-12-03 15:50:46,731:INFO:[LightGBM] [Info] Start training from score 0.004832
2025-12-03 15:50:46,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,764:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,764:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,764:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,766:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,766:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,766:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,767:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,767:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,767:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,767:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,767:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-03 15:50:46,768:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-12-03 15:50:46,768:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,768:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,769:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-03 15:50:46,769:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-03 15:50:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,801:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,801:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,803:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,803:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,804:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,804:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,804:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,804:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,804:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-03 15:50:46,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.
2025-12-03 15:50:46,805:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,805:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,805:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,806:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,806:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-03 15:50:46,806:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-03 15:50:46,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,839:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,839:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,839:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,841:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,841:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,841:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,842:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,842:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,842:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,842:INFO:[LightGBM] [Info] Number of positive: 3750, number of negative: 3700
2025-12-03 15:50:46,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-12-03 15:50:46,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,843:INFO:[LightGBM] [Info] Total Bins 70
2025-12-03 15:50:46,843:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423
2025-12-03 15:50:46,844:INFO:[LightGBM] [Info] Start training from score 0.013423
2025-12-03 15:50:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,877:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,877:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,879:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,879:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,879:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,880:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,880:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,880:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,880:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,881:INFO:[LightGBM] [Info] Number of positive: 3731, number of negative: 3719
2025-12-03 15:50:46,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-12-03 15:50:46,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,882:INFO:[LightGBM] [Info] Total Bins 73
2025-12-03 15:50:46,882:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,882:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500805 -> initscore=0.003221
2025-12-03 15:50:46,882:INFO:[LightGBM] [Info] Start training from score 0.003221
2025-12-03 15:50:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,917:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,917:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,917:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,919:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,919:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,920:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,920:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,920:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,920:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,920:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-03 15:50:46,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-12-03 15:50:46,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,921:INFO:[LightGBM] [Info] Total Bins 71
2025-12-03 15:50:46,921:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,921:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-03 15:50:46,921:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-03 15:50:46,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,952:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,952:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,952:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,954:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,954:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,954:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,955:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,955:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,955:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,955:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,955:INFO:[LightGBM] [Info] Number of positive: 3713, number of negative: 3737
2025-12-03 15:50:46,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-12-03 15:50:46,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,956:INFO:[LightGBM] [Info] Total Bins 69
2025-12-03 15:50:46,956:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,956:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498389 -> initscore=-0.006443
2025-12-03 15:50:46,957:INFO:[LightGBM] [Info] Start training from score -0.006443
2025-12-03 15:50:46,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,985:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,985:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,987:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,987:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,987:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,989:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-03 15:50:46,989:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:46,989:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:46,989:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:46,989:INFO:[LightGBM] [Info] Number of positive: 3739, number of negative: 3711
2025-12-03 15:50:46,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2025-12-03 15:50:46,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:50:46,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:50:46,990:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:50:46,990:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 9
2025-12-03 15:50:46,990:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501879 -> initscore=0.007517
2025-12-03 15:50:46,990:INFO:[LightGBM] [Info] Start training from score 0.007517
2025-12-03 15:50:46,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:46,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:50:47,017:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:47,017:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:47,017:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:47,039:INFO:Scoring test/hold-out set
2025-12-03 15:50:47,040:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:47,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:47,040:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:47,147:INFO:Visual Rendered Successfully
2025-12-03 15:50:47,437:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:47,447:INFO:Initializing plot_model()
2025-12-03 15:50:47,447:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:47,447:INFO:Checking exceptions
2025-12-03 15:50:47,449:INFO:Preloading libraries
2025-12-03 15:50:47,450:INFO:Copying training dataset
2025-12-03 15:50:47,450:INFO:Plot type: pr
2025-12-03 15:50:47,507:INFO:Fitting Model
2025-12-03 15:50:47,507:INFO:Scoring test/hold-out set
2025-12-03 15:50:47,508:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:47,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:47,508:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:47,509:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:47,509:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:47,509:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:47,559:INFO:Visual Rendered Successfully
2025-12-03 15:50:47,651:INFO:plot_model() successfully completed......................................
2025-12-03 15:50:54,261:INFO:Initializing plot_model()
2025-12-03 15:50:54,261:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:50:54,262:INFO:Checking exceptions
2025-12-03 15:50:54,266:INFO:Preloading libraries
2025-12-03 15:50:54,268:INFO:Copying training dataset
2025-12-03 15:50:54,268:INFO:Plot type: error
2025-12-03 15:50:54,337:INFO:Fitting Model
2025-12-03 15:50:54,337:INFO:Scoring test/hold-out set
2025-12-03 15:50:54,338:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:54,338:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:54,338:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:54,339:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:50:54,339:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:50:54,339:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:50:54,401:INFO:Visual Rendered Successfully
2025-12-03 15:50:54,595:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:12,947:INFO:Initializing plot_model()
2025-12-03 15:51:12,948:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:12,948:INFO:Checking exceptions
2025-12-03 15:51:12,957:INFO:Preloading libraries
2025-12-03 15:51:12,958:INFO:Copying training dataset
2025-12-03 15:51:12,958:INFO:Plot type: class_report
2025-12-03 15:51:13,027:INFO:Fitting Model
2025-12-03 15:51:13,027:INFO:Scoring test/hold-out set
2025-12-03 15:51:13,028:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:13,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:13,028:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:13,029:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:13,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:13,029:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:13,102:INFO:Visual Rendered Successfully
2025-12-03 15:51:13,273:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:14,125:INFO:Initializing plot_model()
2025-12-03 15:51:14,125:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:14,125:INFO:Checking exceptions
2025-12-03 15:51:14,128:INFO:Preloading libraries
2025-12-03 15:51:14,130:INFO:Copying training dataset
2025-12-03 15:51:14,131:INFO:Plot type: rfe
2025-12-03 15:51:14,283:INFO:Fitting Model
2025-12-03 15:51:14,290:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,290:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,290:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,291:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,291:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,291:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.
2025-12-03 15:51:14,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,292:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:14,292:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:14,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,325:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,325:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,325:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,326:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,326:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,326:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,326:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-12-03 15:51:14,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,327:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:14,327:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:14,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,356:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,356:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,357:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,357:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-12-03 15:51:14,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,359:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:14,359:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:14,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,395:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,395:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,395:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,398:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,398:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,398:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,398:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.
2025-12-03 15:51:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,399:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:14,399:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:14,399:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,428:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,428:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,428:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,429:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,429:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,429:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,429:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-12-03 15:51:14,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,430:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 15:51:14,430:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:14,430:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,463:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,463:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,463:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,464:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,464:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,464:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,464:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.
2025-12-03 15:51:14,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,465:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 15:51:14,465:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:14,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,492:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,492:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,492:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,493:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,493:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,493:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,493:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-12-03 15:51:14,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,494:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:14,494:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:14,494:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,518:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,518:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,518:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,519:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,519:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,519:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
2025-12-03 15:51:14,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,519:INFO:[LightGBM] [Info] Total Bins 34
2025-12-03 15:51:14,519:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:14,519:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,532:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,532:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2025-12-03 15:51:14,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,533:INFO:[LightGBM] [Info] Total Bins 19
2025-12-03 15:51:14,533:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 15:51:14,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,548:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,548:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,548:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,550:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,550:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,550:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,551:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,551:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,551:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,551:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-12-03 15:51:14,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,552:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:14,552:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:14,552:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,584:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,584:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,584:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,585:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,585:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,585:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,586:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-12-03 15:51:14,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,586:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:14,587:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:14,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,619:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,619:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,619:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,619:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.
2025-12-03 15:51:14,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,620:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:14,620:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:14,620:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,654:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,654:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,654:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,655:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,655:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,655:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,655:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-12-03 15:51:14,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,656:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:14,656:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:14,657:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,686:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,687:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2025-12-03 15:51:14,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,687:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 15:51:14,687:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:14,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,718:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,718:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,718:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,719:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,719:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,719:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-12-03 15:51:14,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,720:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 15:51:14,720:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:14,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,743:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,743:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-12-03 15:51:14,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,744:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:14,744:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:14,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,769:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,769:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,769:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,770:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,770:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,770:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,770:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2025-12-03 15:51:14,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,770:INFO:[LightGBM] [Info] Total Bins 33
2025-12-03 15:51:14,770:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:14,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,782:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,782:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,782:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,783:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,783:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,783:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,783:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-12-03 15:51:14,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,783:INFO:[LightGBM] [Info] Total Bins 19
2025-12-03 15:51:14,783:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 15:51:14,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,799:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,799:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,801:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,801:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,802:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,802:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,802:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-12-03 15:51:14,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,803:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:14,803:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:14,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,837:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,837:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,837:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,838:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,838:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,838:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,838:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-12-03 15:51:14,839:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,839:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:14,839:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:14,839:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,869:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,869:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,870:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,870:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,870:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,870:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-12-03 15:51:14,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,871:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:14,871:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:14,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,904:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,904:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,904:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,905:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,905:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,905:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2025-12-03 15:51:14,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,906:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:14,906:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:14,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,933:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,933:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,933:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,934:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,934:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,934:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,934:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,935:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-12-03 15:51:14,935:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:14,935:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:14,935:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:14,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,966:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,966:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,966:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,967:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,967:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,967:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,967:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-12-03 15:51:14,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,968:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:14,968:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:14,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,992:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,992:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,992:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,993:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:14,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:14,993:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:14,993:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:14,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2025-12-03 15:51:14,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:14,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:14,994:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 15:51:14,994:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:14,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:14,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:14,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,017:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,017:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,017:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,018:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,018:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,018:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,018:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2025-12-03 15:51:15,018:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,018:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 15:51:15,018:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:15,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,030:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,031:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,031:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2025-12-03 15:51:15,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,031:INFO:[LightGBM] [Info] Total Bins 17
2025-12-03 15:51:15,031:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 1
2025-12-03 15:51:15,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,045:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,045:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,045:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,046:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,047:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,047:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,047:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,048:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,048:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,048:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-12-03 15:51:15,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,049:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:15,049:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:15,049:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,049:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,081:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,081:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,081:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,082:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,082:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,082:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,082:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-12-03 15:51:15,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,083:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:15,083:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:15,083:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,083:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,113:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,113:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,113:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,114:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,114:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-12-03 15:51:15,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,115:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:15,115:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:15,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,115:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,148:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,148:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,149:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,149:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,149:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,149:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,149:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.
2025-12-03 15:51:15,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,150:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:15,150:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:15,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,150:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,180:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,180:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,180:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,181:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,181:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,181:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,181:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2025-12-03 15:51:15,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,182:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:15,182:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:15,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,182:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,213:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,213:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,214:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,214:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,214:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,214:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-12-03 15:51:15,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,215:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:15,215:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:15,215:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,215:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,239:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,239:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2025-12-03 15:51:15,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,240:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 15:51:15,240:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:15,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,240:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,264:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,264:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2025-12-03 15:51:15,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,265:INFO:[LightGBM] [Info] Total Bins 27
2025-12-03 15:51:15,265:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 15:51:15,265:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,265:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,276:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,276:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,276:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,277:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,277:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,277:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2025-12-03 15:51:15,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] Total Bins 17
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 1
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:15,277:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:15,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,291:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,291:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,293:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,293:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,293:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,294:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,294:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,294:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-12-03 15:51:15,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,295:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:15,295:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:15,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,295:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,325:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,325:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,325:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,326:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,326:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,326:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,326:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2025-12-03 15:51:15,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,327:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:15,327:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:15,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,327:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,356:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,356:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,357:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,357:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-12-03 15:51:15,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,358:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:15,358:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:15,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,359:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,390:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,390:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,390:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,391:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,391:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,391:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,391:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-12-03 15:51:15,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,392:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:15,392:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:15,392:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,392:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,420:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,420:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,420:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,421:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,421:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,421:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-12-03 15:51:15,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,421:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:15,421:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:15,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,422:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,452:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,452:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,452:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,453:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,453:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,453:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,453:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2025-12-03 15:51:15,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,454:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:15,454:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:15,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,454:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,477:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,477:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.
2025-12-03 15:51:15,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,478:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:15,478:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:15,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,478:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,501:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,501:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,501:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,502:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,502:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2025-12-03 15:51:15,502:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,502:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,514:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,514:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:15,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-12-03 15:51:15,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,515:INFO:[LightGBM] [Info] Total Bins 16
2025-12-03 15:51:15,515:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 1
2025-12-03 15:51:15,515:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:15,515:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:15,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,529:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,529:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,529:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,531:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,531:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,531:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,532:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,532:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,533:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2025-12-03 15:51:15,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,534:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:15,534:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:15,534:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,566:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,566:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,566:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,567:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,567:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,567:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,567:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2025-12-03 15:51:15,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,568:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:15,568:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:15,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,599:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,599:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,599:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,600:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,600:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,600:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,600:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.
2025-12-03 15:51:15,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,601:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:15,601:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:15,601:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,633:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,633:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,633:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,634:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,634:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,634:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,634:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,635:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2025-12-03 15:51:15,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,635:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:15,635:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:15,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,662:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,662:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,662:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,663:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,663:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,663:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2025-12-03 15:51:15,664:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,664:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 15:51:15,664:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:15,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,695:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,695:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,695:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,696:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,696:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,696:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2025-12-03 15:51:15,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,697:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 15:51:15,697:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:15,697:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,721:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,721:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,722:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,722:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,722:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.
2025-12-03 15:51:15,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,723:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:15,723:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:15,723:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,746:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,747:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,747:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,747:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,747:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2025-12-03 15:51:15,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,748:INFO:[LightGBM] [Info] Total Bins 34
2025-12-03 15:51:15,748:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:15,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,758:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,758:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,758:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,760:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,760:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,761:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,761:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,761:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,761:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.
2025-12-03 15:51:15,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,762:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:15,762:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:15,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,794:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,794:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,795:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,795:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,795:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,795:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2025-12-03 15:51:15,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,796:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:15,796:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:15,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,827:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,827:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,827:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,828:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,828:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,828:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,828:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-12-03 15:51:15,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,829:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:15,829:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:15,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,863:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,864:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2025-12-03 15:51:15,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,864:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:15,864:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:15,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,892:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,892:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,893:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,893:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,893:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,893:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2025-12-03 15:51:15,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,894:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 15:51:15,894:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:15,894:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,924:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,924:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,925:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,925:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,925:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,925:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.
2025-12-03 15:51:15,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,926:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 15:51:15,926:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:15,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,947:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,947:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,947:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,948:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,948:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,948:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,948:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.
2025-12-03 15:51:15,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,948:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:15,948:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:15,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,971:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,971:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,971:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,972:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,972:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,972:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,972:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2025-12-03 15:51:15,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:15,972:INFO:[LightGBM] [Info] Total Bins 33
2025-12-03 15:51:15,972:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:15,972:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,984:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,984:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,984:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,985:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,985:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,986:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:15,986:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:15,986:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:15,986:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:15,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.
2025-12-03 15:51:15,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:15,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:15,987:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:15,987:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:15,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:15,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:15,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,019:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,019:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,019:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,020:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,020:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,020:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,020:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-12-03 15:51:16,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,021:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:16,021:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:16,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,051:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,051:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,051:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,052:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,052:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,052:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,052:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-12-03 15:51:16,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,053:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:16,053:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:16,053:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,086:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,086:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,087:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,087:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,087:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,087:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2025-12-03 15:51:16,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,088:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:16,088:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:16,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,115:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,115:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,116:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,116:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,116:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,116:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2025-12-03 15:51:16,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,117:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:16,117:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:16,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,148:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,148:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,148:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,149:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,149:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,149:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,149:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-12-03 15:51:16,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,150:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:16,150:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:16,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,175:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,175:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
2025-12-03 15:51:16,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,176:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 15:51:16,176:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:16,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,201:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,201:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,201:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,202:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,202:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,202:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,202:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2025-12-03 15:51:16,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,202:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 15:51:16,203:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 2
2025-12-03 15:51:16,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,213:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,213:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,215:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,215:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,216:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,216:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,216:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,216:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2025-12-03 15:51:16,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,217:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:16,217:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:16,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,217:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,249:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,249:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,249:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,250:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,250:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,250:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,250:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.
2025-12-03 15:51:16,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,251:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:16,251:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:16,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,251:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,281:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,281:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,282:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,282:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,282:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,282:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.
2025-12-03 15:51:16,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,283:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:16,283:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:16,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,283:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,316:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,316:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,316:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,317:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,317:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2025-12-03 15:51:16,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,317:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:16,317:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:16,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,318:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,344:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,344:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,344:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,345:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,345:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,345:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,345:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2025-12-03 15:51:16,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,346:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:16,346:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:16,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,346:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,375:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,375:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,375:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,376:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,376:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,376:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.
2025-12-03 15:51:16,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,376:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,402:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,402:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,402:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,403:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,403:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.
2025-12-03 15:51:16,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,403:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,423:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,423:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,423:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,424:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,424:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,424:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2025-12-03 15:51:16,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] Total Bins 27
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:16,424:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:16,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,435:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,435:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,435:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,437:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,437:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,438:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,438:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,438:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-12-03 15:51:16,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,439:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:16,439:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:16,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,439:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,471:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,471:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,471:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,472:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,472:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,472:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,472:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.
2025-12-03 15:51:16,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,473:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:16,473:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:16,473:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,473:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,501:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,501:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,501:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,502:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,502:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,502:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-12-03 15:51:16,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,503:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:16,503:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:16,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,503:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,534:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,534:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,534:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,535:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,535:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,535:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,535:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-12-03 15:51:16,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,536:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:16,536:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:16,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,536:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,564:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,564:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,564:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,565:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,565:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,565:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,565:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2025-12-03 15:51:16,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,566:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:16,566:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:16,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,566:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,596:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,596:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,597:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,597:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,597:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.
2025-12-03 15:51:16,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,598:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:16,598:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:16,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,598:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,617:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,617:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,618:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,618:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,618:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.
2025-12-03 15:51:16,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,618:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,639:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,639:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,639:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,640:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2025-12-03 15:51:16,640:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] Total Bins 28
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 2
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:16,640:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:16,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,651:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,651:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,651:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,653:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,653:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,653:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,654:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,654:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,654:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,654:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.
2025-12-03 15:51:16,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,655:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:16,655:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:16,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,687:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,687:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,687:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,688:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,688:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,688:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,689:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
2025-12-03 15:51:16,689:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,689:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:16,689:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:16,689:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,720:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,720:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,721:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,721:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,721:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-12-03 15:51:16,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,722:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:16,722:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:16,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,754:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,754:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,754:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,755:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,755:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,755:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,755:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2025-12-03 15:51:16,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,755:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:16,755:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:16,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,783:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,783:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,783:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,784:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,784:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,784:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,784:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-12-03 15:51:16,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,785:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 15:51:16,785:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:16,785:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,815:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,815:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,815:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,816:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,816:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,816:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,816:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-12-03 15:51:16,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,817:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 15:51:16,817:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:16,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,842:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,842:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.
2025-12-03 15:51:16,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,843:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:16,843:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:16,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,866:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,866:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,866:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,868:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,868:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,869:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,869:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,869:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,870:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.
2025-12-03 15:51:16,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,870:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,870:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:16,870:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:16,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,901:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,901:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,901:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,902:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,902:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,902:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,903:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-12-03 15:51:16,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:16,903:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:16,904:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:16,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,935:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,935:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,935:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,936:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,936:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,936:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,936:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-12-03 15:51:16,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,937:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:16,937:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:16,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,970:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,970:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,970:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,971:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,971:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,971:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:16,971:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:16,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.
2025-12-03 15:51:16,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:16,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:16,971:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:16,972:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:16,972:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:16,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:16,999:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:16,999:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:16,999:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,000:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,000:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,000:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,000:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2025-12-03 15:51:17,001:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,001:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 15:51:17,001:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:17,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,031:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,032:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
2025-12-03 15:51:17,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,032:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 15:51:17,032:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:17,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,054:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,054:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,054:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,055:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,055:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,055:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,055:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.
2025-12-03 15:51:17,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,055:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:17,055:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:17,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,080:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,080:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,080:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,082:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,082:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,082:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,083:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,083:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,083:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,083:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-12-03 15:51:17,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,084:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:17,084:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:17,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,114:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,114:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,114:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,115:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,115:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,115:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,116:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2025-12-03 15:51:17,116:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,116:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:17,116:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:17,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,146:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,146:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,146:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,147:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,147:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,147:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-12-03 15:51:17,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,148:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:17,148:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:17,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,181:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,181:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,181:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,182:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,182:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,182:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,182:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-12-03 15:51:17,183:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,183:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,183:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:17,183:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:17,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,211:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,211:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2025-12-03 15:51:17,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,212:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:17,212:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:17,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,244:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,244:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,244:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,245:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,245:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,245:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,245:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.
2025-12-03 15:51:17,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,246:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:17,246:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:17,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,271:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,271:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.
2025-12-03 15:51:17,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,272:INFO:[LightGBM] [Info] Total Bins 30
2025-12-03 15:51:17,272:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 3
2025-12-03 15:51:17,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,297:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,297:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,297:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,299:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,300:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
2025-12-03 15:51:17,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,301:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:17,301:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:17,301:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,301:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,333:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,333:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,333:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,334:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,334:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,334:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,334:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-12-03 15:51:17,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,335:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:17,335:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:17,335:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,335:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,364:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,364:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,365:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,365:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,365:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,365:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
2025-12-03 15:51:17,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,366:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:17,366:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:17,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,366:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,395:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,395:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,395:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,396:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,396:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,396:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,396:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-12-03 15:51:17,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,397:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:17,397:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:17,397:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,397:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,423:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,423:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,423:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,424:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,424:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,424:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,424:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2025-12-03 15:51:17,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,425:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:17,425:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:17,425:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,425:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,456:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,456:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,456:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,457:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,457:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,457:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,457:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.
2025-12-03 15:51:17,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,458:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:17,458:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:17,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,458:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,482:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,482:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,482:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,483:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,483:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,483:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:17,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.
2025-12-03 15:51:17,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,484:INFO:[LightGBM] [Info] Total Bins 36
2025-12-03 15:51:17,484:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:17,484:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:17,484:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:17,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,508:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,508:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,509:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,509:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,509:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,510:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,510:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,510:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,511:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-12-03 15:51:17,511:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,511:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,511:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:17,512:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:17,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,512:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,544:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,544:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,544:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,544:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
2025-12-03 15:51:17,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,545:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:17,545:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:17,545:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,545:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,576:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,576:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,577:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,577:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,577:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,577:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.
2025-12-03 15:51:17,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,578:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:17,578:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:17,578:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,579:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,611:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,611:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,611:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,612:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,612:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,612:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,613:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-12-03 15:51:17,613:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,613:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:17,613:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:17,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,613:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,640:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,641:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,641:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,641:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,641:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2025-12-03 15:51:17,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,642:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:17,642:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:17,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,642:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,673:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,673:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,673:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,674:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,674:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,674:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.
2025-12-03 15:51:17,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,674:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:17,675:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:17,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,675:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,697:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,697:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,697:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,698:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,698:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,698:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,698:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:17,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000263 seconds.
2025-12-03 15:51:17,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,699:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:17,699:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 3
2025-12-03 15:51:17,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:17,699:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:17,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,722:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,722:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,724:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,724:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,725:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,725:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,725:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,725:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-12-03 15:51:17,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,726:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:17,726:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:17,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,757:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,757:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,757:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,758:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,758:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,758:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,758:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-12-03 15:51:17,759:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,759:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,759:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:17,759:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:17,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,790:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,790:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,790:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,791:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,791:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,791:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,791:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-12-03 15:51:17,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,792:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:17,792:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:17,792:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,824:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,824:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,825:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,825:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,825:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,825:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-12-03 15:51:17,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,826:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:17,826:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:17,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,852:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,852:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,852:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,853:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,853:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,853:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,853:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,854:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-12-03 15:51:17,854:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,854:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 15:51:17,854:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:17,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,884:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,884:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,884:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,885:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,885:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,885:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,885:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2025-12-03 15:51:17,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,886:INFO:[LightGBM] [Info] Total Bins 55
2025-12-03 15:51:17,886:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:17,886:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,910:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,910:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,910:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,912:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,912:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,912:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,913:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,913:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,913:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,913:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-12-03 15:51:17,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,914:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:17,914:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:17,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,946:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,946:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,946:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,947:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,947:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,947:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,947:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2025-12-03 15:51:17,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:17,948:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:17,948:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:17,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,979:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,979:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,979:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,980:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:17,980:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:17,980:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:17,980:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:17,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2025-12-03 15:51:17,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:17,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:17,981:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:17,981:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:17,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:17,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:17,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,015:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,015:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,015:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,016:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,016:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,016:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,016:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2025-12-03 15:51:18,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,017:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:18,017:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:18,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,044:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,044:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,045:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,045:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,045:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,045:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2025-12-03 15:51:18,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,046:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 15:51:18,046:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:18,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,075:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,076:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,076:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,076:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,076:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,076:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,076:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.
2025-12-03 15:51:18,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,077:INFO:[LightGBM] [Info] Total Bins 54
2025-12-03 15:51:18,077:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:18,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,099:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,099:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,099:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,101:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,101:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,101:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,102:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,102:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,102:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,102:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.
2025-12-03 15:51:18,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,103:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:18,103:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:18,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,132:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,132:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,133:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,133:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,133:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,133:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2025-12-03 15:51:18,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,134:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:18,134:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:18,134:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,164:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,164:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,164:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,165:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,165:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,165:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,165:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-12-03 15:51:18,166:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,166:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,166:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:18,166:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:18,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,200:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,200:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,200:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,201:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,201:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,201:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,201:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2025-12-03 15:51:18,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,202:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:18,202:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:18,202:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,229:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,229:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,230:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,230:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,230:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,230:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2025-12-03 15:51:18,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,231:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:18,231:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:18,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,263:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,263:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,263:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,264:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,264:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,264:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-12-03 15:51:18,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,265:INFO:[LightGBM] [Info] Total Bins 37
2025-12-03 15:51:18,265:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 4
2025-12-03 15:51:18,265:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,289:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,289:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,289:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,291:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,291:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,291:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,292:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,292:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,292:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,292:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-12-03 15:51:18,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,293:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:18,293:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:18,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,293:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,325:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,325:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,325:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,326:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,326:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,326:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,326:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
2025-12-03 15:51:18,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,327:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:18,327:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:18,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,328:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,357:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-12-03 15:51:18,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,358:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,387:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,387:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,387:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,388:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,388:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,388:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,388:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2025-12-03 15:51:18,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,389:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:18,389:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:18,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,389:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,417:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,417:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,418:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2025-12-03 15:51:18,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,418:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:18,418:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:18,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,418:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,449:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.
2025-12-03 15:51:18,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:18,450:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:18,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,474:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,474:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,474:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,476:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,476:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,477:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,477:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,477:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-12-03 15:51:18,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,478:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:18,478:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:18,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,478:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,510:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,510:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,511:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,511:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,511:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,512:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-12-03 15:51:18,512:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,512:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:18,512:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:18,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,512:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,543:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,543:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,544:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,544:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,544:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,544:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2025-12-03 15:51:18,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,545:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:18,545:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:18,545:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,545:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,578:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,578:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,579:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,579:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,579:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2025-12-03 15:51:18,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,580:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:18,580:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:18,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,580:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,608:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,608:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,608:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,609:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,609:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,609:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2025-12-03 15:51:18,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,610:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:18,610:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:18,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,610:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,640:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,641:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,641:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,641:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,641:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:18,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-12-03 15:51:18,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,642:INFO:[LightGBM] [Info] Total Bins 43
2025-12-03 15:51:18,642:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 4
2025-12-03 15:51:18,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:18,642:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:18,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,664:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,664:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,664:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,667:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,667:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,667:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,668:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,668:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,668:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.
2025-12-03 15:51:18,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,669:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:18,669:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:18,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,701:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,701:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,701:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,702:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,702:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,702:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,702:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-12-03 15:51:18,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,703:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:18,703:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:18,703:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,734:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,734:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,734:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,735:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,735:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,735:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,735:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-12-03 15:51:18,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,736:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:18,736:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:18,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,768:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,768:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,768:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,769:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,769:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,769:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,769:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2025-12-03 15:51:18,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,770:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:18,770:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:18,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,797:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,797:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,797:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,798:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,798:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,798:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,798:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,799:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-12-03 15:51:18,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,799:INFO:[LightGBM] [Info] Total Bins 57
2025-12-03 15:51:18,799:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:18,799:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,829:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,829:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,829:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,831:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,831:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,832:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,832:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,832:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,832:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-12-03 15:51:18,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,833:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,833:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:18,833:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:18,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,864:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,864:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,864:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,865:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,865:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,865:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,866:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,866:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2025-12-03 15:51:18,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,866:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:18,866:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:18,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,897:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,897:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,898:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,898:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,898:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,898:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.
2025-12-03 15:51:18,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,899:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:18,899:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:18,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,933:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,933:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,933:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,934:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,934:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,934:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,934:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,935:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2025-12-03 15:51:18,935:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,935:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:18,935:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:18,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,962:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,962:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,962:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,963:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,963:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,963:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,963:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2025-12-03 15:51:18,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:18,964:INFO:[LightGBM] [Info] Total Bins 56
2025-12-03 15:51:18,964:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:18,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:18,993:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,993:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,993:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,995:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,995:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,995:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,996:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:18,996:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:18,996:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:18,996:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:18,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2025-12-03 15:51:18,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:18,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:18,997:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:18,997:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:18,997:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:18,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,028:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,028:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,029:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,029:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,029:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.
2025-12-03 15:51:19,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,030:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:19,030:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:19,030:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,061:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,061:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,061:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,062:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,062:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,062:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,062:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-12-03 15:51:19,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,063:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:19,063:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:19,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,096:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,096:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,096:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,097:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,097:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,097:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,097:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-12-03 15:51:19,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,098:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:19,098:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:19,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,126:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,126:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,126:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,127:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,127:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,127:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,127:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,128:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2025-12-03 15:51:19,128:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,128:INFO:[LightGBM] [Info] Total Bins 46
2025-12-03 15:51:19,128:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 5
2025-12-03 15:51:19,128:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,156:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,156:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,156:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,158:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,158:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,158:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,159:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,159:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,159:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,159:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.
2025-12-03 15:51:19,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,160:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:19,160:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:19,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,160:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,191:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,191:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,191:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,191:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,192:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,192:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,192:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.
2025-12-03 15:51:19,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,193:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:19,193:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:19,193:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,193:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,218:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,218:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,218:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,219:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,219:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,219:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,219:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.
2025-12-03 15:51:19,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,220:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:19,220:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:19,220:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,220:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,253:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,253:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,254:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,254:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,254:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,254:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-12-03 15:51:19,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,255:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:19,255:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:19,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,255:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,283:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,283:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,284:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,284:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,284:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,284:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-12-03 15:51:19,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,284:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:19,285:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:19,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,285:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,315:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,315:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,315:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,316:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,316:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,317:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,317:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,317:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,317:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:19,318:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-12-03 15:51:19,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,318:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:19,318:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:19,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:19,319:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:19,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,349:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,349:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,349:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,350:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,350:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,350:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,350:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:19,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2025-12-03 15:51:19,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,351:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:19,351:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:19,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:19,351:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:19,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,381:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,381:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,381:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,382:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,382:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,382:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,382:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:19,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-12-03 15:51:19,383:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,383:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:19,383:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:19,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:19,383:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:19,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,414:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,414:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,414:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,415:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,415:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,415:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,415:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:19,415:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2025-12-03 15:51:19,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,415:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:19,415:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:19,416:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:19,416:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:19,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,443:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,443:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,443:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,444:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,444:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,444:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:19,445:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2025-12-03 15:51:19,445:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,445:INFO:[LightGBM] [Info] Total Bins 45
2025-12-03 15:51:19,445:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 5
2025-12-03 15:51:19,445:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:19,445:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:19,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,475:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,475:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,477:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,477:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,478:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,478:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,478:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,478:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-12-03 15:51:19,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,479:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:19,479:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:19,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,512:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,512:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,512:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,512:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,512:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,513:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,513:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-12-03 15:51:19,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,514:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:19,514:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:19,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,544:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,544:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,544:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,545:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,545:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,545:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,545:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.
2025-12-03 15:51:19,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,546:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:19,546:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:19,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,578:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,578:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,579:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,579:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,579:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2025-12-03 15:51:19,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,580:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:19,580:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:19,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,607:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,607:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,607:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,608:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,608:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,608:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,609:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,609:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,609:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.
2025-12-03 15:51:19,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,610:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:19,611:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:19,611:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,642:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,642:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,642:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,643:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,643:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,643:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,643:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2025-12-03 15:51:19,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,644:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:19,644:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:19,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,675:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,675:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,675:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,676:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,676:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,676:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,676:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
2025-12-03 15:51:19,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,677:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:19,677:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:19,677:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,710:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,710:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,710:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,711:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,711:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,711:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-12-03 15:51:19,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,711:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:19,711:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:19,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,738:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,738:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,738:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,740:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,740:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,740:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,741:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,741:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,741:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,741:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.
2025-12-03 15:51:19,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,742:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:19,742:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:19,742:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,773:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,773:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,773:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,774:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,774:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,774:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,774:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-12-03 15:51:19,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,775:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:19,775:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:19,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,806:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,806:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,806:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,807:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,807:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,807:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,807:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.
2025-12-03 15:51:19,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,807:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:19,808:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:19,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,839:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,839:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,839:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,840:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,840:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,840:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,840:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:19,841:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2025-12-03 15:51:19,841:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,841:INFO:[LightGBM] [Info] Total Bins 48
2025-12-03 15:51:19,841:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 6
2025-12-03 15:51:19,841:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,868:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,868:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,869:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,869:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,870:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,870:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,870:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,870:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-12-03 15:51:19,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,871:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:19,872:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:19,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,872:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,904:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,904:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,904:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,905:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,905:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,905:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,905:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-12-03 15:51:19,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,906:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:19,906:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:19,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,906:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,936:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,936:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,936:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,937:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,937:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,937:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,937:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2025-12-03 15:51:19,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:19,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:19,938:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:19,938:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:19,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,938:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,971:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,971:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,971:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,972:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:19,972:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:19,972:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:19,972:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:19,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2025-12-03 15:51:19,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:19,973:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:19,973:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:19,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:19,973:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,000:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,000:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,000:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,001:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,001:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,001:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,002:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,002:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,002:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,002:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.
2025-12-03 15:51:20,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,003:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,003:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:20,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,004:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,036:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,036:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,036:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,037:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,037:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,037:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,037:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2025-12-03 15:51:20,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,038:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:20,038:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:20,038:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,038:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,069:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,069:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,069:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,070:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,070:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,070:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-12-03 15:51:20,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,071:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:20,071:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:20,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,071:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,103:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,103:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,103:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,104:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,104:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,104:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,104:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2025-12-03 15:51:20,105:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,105:INFO:[LightGBM] [Info] Total Bins 47
2025-12-03 15:51:20,105:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 6
2025-12-03 15:51:20,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,105:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,132:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,132:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,135:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,135:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,136:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,136:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,136:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,136:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.
2025-12-03 15:51:20,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,137:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:20,137:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,170:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,170:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,170:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,171:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,171:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,171:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,171:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
2025-12-03 15:51:20,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,172:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:20,172:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,172:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,203:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,203:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,204:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,204:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,204:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,204:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.
2025-12-03 15:51:20,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,205:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,205:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:20,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,235:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,235:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,237:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,237:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,237:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,238:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,238:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,238:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,238:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-12-03 15:51:20,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,239:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:20,239:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,270:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,270:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,270:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,271:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,271:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,271:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,271:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2025-12-03 15:51:20,272:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,272:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:20,272:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,302:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,302:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,302:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,303:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,303:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,303:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,303:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-12-03 15:51:20,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,304:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:20,304:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:20,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,336:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,336:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,336:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,337:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,337:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,338:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,338:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,338:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,339:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,339:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2025-12-03 15:51:20,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,340:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:20,340:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,370:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,370:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,370:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,371:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,371:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,371:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,371:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2025-12-03 15:51:20,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,372:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:20,372:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,373:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,403:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,403:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,404:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,404:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,404:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,404:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.
2025-12-03 15:51:20,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,405:INFO:[LightGBM] [Info] Total Bins 50
2025-12-03 15:51:20,405:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 7
2025-12-03 15:51:20,405:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,437:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,437:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,438:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,438:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,439:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,439:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,439:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,439:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:20,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.
2025-12-03 15:51:20,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,440:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,440:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:20,441:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:20,441:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:20,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,471:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,471:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,471:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,472:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,472:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,472:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,472:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:20,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-12-03 15:51:20,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,473:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:20,473:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:20,473:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:20,473:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:20,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,503:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,503:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,503:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,504:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,504:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,504:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,504:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:20,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.
2025-12-03 15:51:20,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,505:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:20,505:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:20,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:20,505:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:20,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,537:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,537:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,537:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,539:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,539:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,539:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,540:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,540:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,540:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.
2025-12-03 15:51:20,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,541:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,541:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:20,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,541:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,573:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,573:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,573:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,574:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,574:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,574:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,574:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-12-03 15:51:20,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,575:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:20,575:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:20,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,575:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,606:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,606:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,606:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,607:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,607:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,607:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,607:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-12-03 15:51:20,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,608:INFO:[LightGBM] [Info] Total Bins 49
2025-12-03 15:51:20,608:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 7
2025-12-03 15:51:20,608:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,608:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,640:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,643:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,643:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,643:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,644:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,644:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,644:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,644:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.
2025-12-03 15:51:20,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,645:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:20,645:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,677:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,677:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,677:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,678:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,678:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,678:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,678:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,679:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.
2025-12-03 15:51:20,679:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,679:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,679:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:20,679:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,679:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,709:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,709:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,709:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,711:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,711:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,712:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,712:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,712:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2025-12-03 15:51:20,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,713:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:20,713:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,746:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,746:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,746:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,747:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,747:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,747:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2025-12-03 15:51:20,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,748:INFO:[LightGBM] [Info] Total Bins 72
2025-12-03 15:51:20,748:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,779:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,779:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,779:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,780:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,780:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,780:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,781:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,781:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,781:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,781:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-12-03 15:51:20,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,782:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:20,782:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,814:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,814:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,814:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,815:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,815:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,815:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,815:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-12-03 15:51:20,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,816:INFO:[LightGBM] [Info] Total Bins 58
2025-12-03 15:51:20,816:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 8
2025-12-03 15:51:20,816:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,846:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,846:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,846:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,848:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,848:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,848:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,848:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,849:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,849:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,849:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:20,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-12-03 15:51:20,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,850:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,850:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:20,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:20,850:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:20,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,882:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,882:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,883:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,883:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,883:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:20,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-12-03 15:51:20,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,884:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:20,884:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:20,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:20,884:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:20,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,914:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,914:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,916:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,916:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,916:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,917:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,917:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,917:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,917:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.
2025-12-03 15:51:20,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,918:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:20,918:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:20,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,918:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,950:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,950:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,950:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,951:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,951:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,951:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:20,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-12-03 15:51:20,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-03 15:51:20,952:INFO:[LightGBM] [Info] Total Bins 59
2025-12-03 15:51:20,952:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 8
2025-12-03 15:51:20,952:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:20,952:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:20,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,982:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,982:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,982:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,985:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,985:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,986:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:20,986:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:20,986:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:20,986:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:20,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-12-03 15:51:20,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:20,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:20,987:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:20,987:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:20,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:20,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:20,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,019:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,019:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,019:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,020:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,020:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,020:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,021:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,021:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,021:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,021:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:21,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
2025-12-03 15:51:21,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:21,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:21,022:INFO:[LightGBM] [Info] Total Bins 74
2025-12-03 15:51:21,023:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:21,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:21,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,054:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,054:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,054:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,055:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,055:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,055:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,056:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,056:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,056:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,056:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-03 15:51:21,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.
2025-12-03 15:51:21,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:21,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:21,057:INFO:[LightGBM] [Info] Total Bins 60
2025-12-03 15:51:21,057:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 9
2025-12-03 15:51:21,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:21,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,088:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,088:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,090:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,090:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,090:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,091:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,091:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,091:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,091:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3311
2025-12-03 15:51:21,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2025-12-03 15:51:21,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:21,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:21,092:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:21,092:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:21,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500075 -> initscore=0.000302
2025-12-03 15:51:21,092:INFO:[LightGBM] [Info] Start training from score 0.000302
2025-12-03 15:51:21,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,123:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,123:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,123:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,125:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,125:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,125:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,126:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,126:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,126:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,126:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3312
2025-12-03 15:51:21,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-12-03 15:51:21,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:21,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:21,127:INFO:[LightGBM] [Info] Total Bins 61
2025-12-03 15:51:21,127:INFO:[LightGBM] [Info] Number of data points in the train set: 6623, number of used features: 9
2025-12-03 15:51:21,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499925 -> initscore=-0.000302
2025-12-03 15:51:21,127:INFO:[LightGBM] [Info] Start training from score -0.000302
2025-12-03 15:51:21,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,159:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,159:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,159:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,160:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,160:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,160:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,161:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:21,161:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:21,161:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:21,161:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-03 15:51:21,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2025-12-03 15:51:21,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-03 15:51:21,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-03 15:51:21,162:INFO:[LightGBM] [Info] Total Bins 76
2025-12-03 15:51:21,163:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 9
2025-12-03 15:51:21,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-03 15:51:21,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-03 15:51:21,260:INFO:Visual Rendered Successfully
2025-12-03 15:51:21,489:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:27,515:INFO:Initializing plot_model()
2025-12-03 15:51:27,516:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:27,517:INFO:Checking exceptions
2025-12-03 15:51:27,524:INFO:Preloading libraries
2025-12-03 15:51:27,525:INFO:Copying training dataset
2025-12-03 15:51:27,525:INFO:Plot type: feature
2025-12-03 15:51:27,526:WARNING:No coef_ found. Trying feature_importances_
2025-12-03 15:51:27,610:INFO:Visual Rendered Successfully
2025-12-03 15:51:27,795:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:30,995:INFO:Initializing plot_model()
2025-12-03 15:51:30,995:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:30,996:INFO:Checking exceptions
2025-12-03 15:51:31,000:INFO:Preloading libraries
2025-12-03 15:51:31,002:INFO:Copying training dataset
2025-12-03 15:51:31,002:INFO:Plot type: feature_all
2025-12-03 15:51:31,044:WARNING:No coef_ found. Trying feature_importances_
2025-12-03 15:51:31,096:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/matplotlib/_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-12-03 15:51:31,096:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/matplotlib/_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-12-03 15:51:31,098:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/matplotlib/patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-12-03 15:51:31,099:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/matplotlib/transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-12-03 15:51:31,111:INFO:Visual Rendered Successfully
2025-12-03 15:51:31,205:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:35,008:INFO:Initializing plot_model()
2025-12-03 15:51:35,009:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:35,009:INFO:Checking exceptions
2025-12-03 15:51:35,012:INFO:Preloading libraries
2025-12-03 15:51:35,014:INFO:Copying training dataset
2025-12-03 15:51:35,014:INFO:Plot type: boundary
2025-12-03 15:51:35,063:INFO:Fitting StandardScaler()
2025-12-03 15:51:35,064:INFO:Fitting PCA()
2025-12-03 15:51:35,458:INFO:Fitting Model
2025-12-03 15:51:36,688:INFO:Initializing plot_model()
2025-12-03 15:51:36,689:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:36,689:INFO:Checking exceptions
2025-12-03 15:51:36,693:INFO:Preloading libraries
2025-12-03 15:51:36,694:INFO:Copying training dataset
2025-12-03 15:51:36,694:INFO:Plot type: lift
2025-12-03 15:51:36,695:INFO:Generating predictions / predict_proba on X_test
2025-12-03 15:51:36,726:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:36,726:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:36,726:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:36,785:INFO:Visual Rendered Successfully
2025-12-03 15:51:36,957:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:37,757:INFO:Initializing plot_model()
2025-12-03 15:51:37,757:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=ks, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:37,757:INFO:Checking exceptions
2025-12-03 15:51:37,760:INFO:Preloading libraries
2025-12-03 15:51:37,760:INFO:Copying training dataset
2025-12-03 15:51:37,760:INFO:Plot type: ks
2025-12-03 15:51:37,761:INFO:Generating predictions / predict_proba on X_test
2025-12-03 15:51:37,789:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:37,789:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:37,789:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:37,867:INFO:Visual Rendered Successfully
2025-12-03 15:51:37,965:INFO:plot_model() successfully completed......................................
2025-12-03 15:51:38,892:INFO:Initializing plot_model()
2025-12-03 15:51:38,892:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:38,893:INFO:Checking exceptions
2025-12-03 15:51:39,781:INFO:Initializing plot_model()
2025-12-03 15:51:39,782:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e41ed50>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=20, n_jobs=-1, num_leaves=100, objective=None,
               random_state=42, reg_alpha=0.01, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-12-03 15:51:39,782:INFO:Checking exceptions
2025-12-03 15:51:39,784:INFO:Preloading libraries
2025-12-03 15:51:39,786:INFO:Copying training dataset
2025-12-03 15:51:39,786:INFO:Plot type: gain
2025-12-03 15:51:39,788:INFO:Generating predictions / predict_proba on X_test
2025-12-03 15:51:39,809:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-12-03 15:51:39,809:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-12-03 15:51:39,809:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-03 15:51:39,874:INFO:Visual Rendered Successfully
2025-12-03 15:51:39,979:INFO:plot_model() successfully completed......................................
2025-12-04 16:49:54,883:INFO:PyCaret ClassificationExperiment
2025-12-04 16:49:54,883:INFO:Logging name: clf-default-name
2025-12-04 16:49:54,884:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-04 16:49:54,884:INFO:version 3.3.2
2025-12-04 16:49:54,884:INFO:Initializing setup()
2025-12-04 16:49:54,884:INFO:self.USI: fe27
2025-12-04 16:49:54,884:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-04 16:49:54,886:INFO:Checking environment
2025-12-04 16:49:54,886:INFO:python_version: 3.11.14
2025-12-04 16:49:54,886:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-04 16:49:54,887:INFO:machine: arm64
2025-12-04 16:49:54,889:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:49:54,893:INFO:Memory: svmem(total=8589934592, available=1286684672, percent=85.0, used=2932523008, free=63815680, active=1240940544, inactive=1108901888, wired=1691582464)
2025-12-04 16:49:54,893:INFO:Physical Core: 8
2025-12-04 16:49:54,893:INFO:Logical Core: 8
2025-12-04 16:49:54,894:INFO:Checking libraries
2025-12-04 16:49:54,894:INFO:System:
2025-12-04 16:49:54,894:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-04 16:49:54,894:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-04 16:49:54,894:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:49:54,894:INFO:PyCaret required dependencies:
2025-12-04 16:49:54,896:INFO:                 pip: 25.3
2025-12-04 16:49:54,896:INFO:          setuptools: 80.9.0
2025-12-04 16:49:54,896:INFO:             pycaret: 3.3.2
2025-12-04 16:49:54,896:INFO:             IPython: 9.7.0
2025-12-04 16:49:54,896:INFO:          ipywidgets: 8.1.8
2025-12-04 16:49:54,896:INFO:                tqdm: 4.67.1
2025-12-04 16:49:54,896:INFO:               numpy: 1.26.4
2025-12-04 16:49:54,896:INFO:              pandas: 2.1.4
2025-12-04 16:49:54,896:INFO:              jinja2: 3.1.6
2025-12-04 16:49:54,896:INFO:               scipy: 1.11.4
2025-12-04 16:49:54,896:INFO:              joblib: 1.3.2
2025-12-04 16:49:54,896:INFO:             sklearn: 1.4.2
2025-12-04 16:49:54,896:INFO:                pyod: 2.0.5
2025-12-04 16:49:54,896:INFO:            imblearn: 0.14.0
2025-12-04 16:49:54,896:INFO:   category_encoders: 2.7.0
2025-12-04 16:49:54,896:INFO:            lightgbm: 4.6.0
2025-12-04 16:49:54,896:INFO:               numba: 0.62.1
2025-12-04 16:49:54,896:INFO:            requests: 2.32.5
2025-12-04 16:49:54,896:INFO:          matplotlib: 3.7.5
2025-12-04 16:49:54,896:INFO:          scikitplot: 0.3.7
2025-12-04 16:49:54,896:INFO:         yellowbrick: 1.5
2025-12-04 16:49:54,896:INFO:              plotly: 6.5.0
2025-12-04 16:49:54,896:INFO:    plotly-resampler: Not installed
2025-12-04 16:49:54,896:INFO:             kaleido: 1.2.0
2025-12-04 16:49:54,896:INFO:           schemdraw: 0.15
2025-12-04 16:49:54,896:INFO:         statsmodels: 0.14.5
2025-12-04 16:49:54,896:INFO:              sktime: 0.26.0
2025-12-04 16:49:54,896:INFO:               tbats: 1.1.3
2025-12-04 16:49:54,896:INFO:            pmdarima: 2.0.4
2025-12-04 16:49:54,897:INFO:              psutil: 7.1.3
2025-12-04 16:49:54,897:INFO:          markupsafe: 3.0.3
2025-12-04 16:49:54,897:INFO:             pickle5: Not installed
2025-12-04 16:49:54,897:INFO:         cloudpickle: 3.1.2
2025-12-04 16:49:54,897:INFO:         deprecation: 2.1.0
2025-12-04 16:49:54,897:INFO:              xxhash: 3.6.0
2025-12-04 16:49:54,897:INFO:           wurlitzer: 3.1.1
2025-12-04 16:49:54,897:INFO:PyCaret optional dependencies:
2025-12-04 16:49:54,897:INFO:                shap: Not installed
2025-12-04 16:49:54,897:INFO:           interpret: Not installed
2025-12-04 16:49:54,897:INFO:                umap: Not installed
2025-12-04 16:49:54,897:INFO:     ydata_profiling: Not installed
2025-12-04 16:49:54,897:INFO:  explainerdashboard: Not installed
2025-12-04 16:49:54,897:INFO:             autoviz: Not installed
2025-12-04 16:49:54,897:INFO:           fairlearn: Not installed
2025-12-04 16:49:54,897:INFO:          deepchecks: Not installed
2025-12-04 16:49:54,897:INFO:             xgboost: Not installed
2025-12-04 16:49:54,897:INFO:            catboost: Not installed
2025-12-04 16:49:54,897:INFO:              kmodes: Not installed
2025-12-04 16:49:54,897:INFO:             mlxtend: Not installed
2025-12-04 16:49:54,897:INFO:       statsforecast: Not installed
2025-12-04 16:49:54,897:INFO:        tune_sklearn: Not installed
2025-12-04 16:49:54,897:INFO:                 ray: Not installed
2025-12-04 16:49:54,897:INFO:            hyperopt: Not installed
2025-12-04 16:49:54,897:INFO:              optuna: Not installed
2025-12-04 16:49:54,897:INFO:               skopt: Not installed
2025-12-04 16:49:54,897:INFO:              mlflow: Not installed
2025-12-04 16:49:54,897:INFO:              gradio: Not installed
2025-12-04 16:49:54,897:INFO:             fastapi: Not installed
2025-12-04 16:49:54,897:INFO:             uvicorn: Not installed
2025-12-04 16:49:54,897:INFO:              m2cgen: Not installed
2025-12-04 16:49:54,897:INFO:           evidently: Not installed
2025-12-04 16:49:54,897:INFO:               fugue: Not installed
2025-12-04 16:49:54,897:INFO:           streamlit: Not installed
2025-12-04 16:49:54,897:INFO:             prophet: Not installed
2025-12-04 16:49:54,897:INFO:None
2025-12-04 16:49:54,898:INFO:Set up data.
2025-12-04 16:49:55,081:INFO:Set up folding strategy.
2025-12-04 16:49:55,104:INFO:Set up train/test split.
2025-12-04 16:49:55,395:INFO:Set up index.
2025-12-04 16:49:55,397:INFO:Assigning column types.
2025-12-04 16:49:55,409:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-04 16:49:55,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,583:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-04 16:49:55,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:49:55,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,655:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-04 16:49:55,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:55,742:INFO:Preparing preprocessing pipeline...
2025-12-04 16:49:55,744:INFO:Set up simple imputation.
2025-12-04 16:49:55,745:INFO:Set up imbalanced handling.
2025-12-04 16:49:55,750:INFO:Set up column name cleaning.
2025-12-04 16:49:55,896:INFO:Finished creating preprocessing pipeline.
2025-12-04 16:49:55,900:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'partner',
                                             'married'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=Tru...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-04 16:49:55,900:INFO:Creating final display dataframe.
2025-12-04 16:49:56,006:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              fe27
2025-12-04 16:49:56,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:56,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:56,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:56,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:49:56,158:INFO:setup() successfully completed in 1.41s...............
2025-12-04 16:49:56,160:INFO:Initializing compare_models()
2025-12-04 16:49:56,160:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-04 16:49:56,160:INFO:Checking exceptions
2025-12-04 16:49:56,170:INFO:Preparing display monitor
2025-12-04 16:49:56,240:INFO:Initializing Logistic Regression
2025-12-04 16:49:56,241:INFO:Total runtime is 1.7682711283365886e-06 minutes
2025-12-04 16:49:56,242:INFO:SubProcess create_model() called ==================================
2025-12-04 16:49:56,244:INFO:Initializing create_model()
2025-12-04 16:49:56,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e2ec290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:49:56,244:INFO:Checking exceptions
2025-12-04 16:49:56,244:INFO:Importing libraries
2025-12-04 16:49:56,244:INFO:Copying training dataset
2025-12-04 16:49:56,248:INFO:Defining folds
2025-12-04 16:49:56,248:INFO:Declaring metric variables
2025-12-04 16:49:56,249:INFO:Importing untrained model
2025-12-04 16:49:56,250:INFO:Logistic Regression Imported successfully
2025-12-04 16:49:56,252:INFO:Starting cross validation
2025-12-04 16:49:56,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:50:01,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:01,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:01,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:01,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:01,349:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:01,602:INFO:Calculating mean and std
2025-12-04 16:50:01,617:INFO:Creating metrics dataframe
2025-12-04 16:50:01,680:INFO:Uploading results into container
2025-12-04 16:50:01,684:INFO:Uploading model into container now
2025-12-04 16:50:01,686:INFO:_master_model_container: 1
2025-12-04 16:50:01,686:INFO:_display_container: 2
2025-12-04 16:50:01,687:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 16:50:01,687:INFO:create_model() successfully completed......................................
2025-12-04 16:50:03,424:INFO:SubProcess create_model() end ==================================
2025-12-04 16:50:03,424:INFO:Creating metrics dataframe
2025-12-04 16:50:03,434:INFO:Initializing Quadratic Discriminant Analysis
2025-12-04 16:50:03,434:INFO:Total runtime is 0.11988921562830608 minutes
2025-12-04 16:50:03,435:INFO:SubProcess create_model() called ==================================
2025-12-04 16:50:03,435:INFO:Initializing create_model()
2025-12-04 16:50:03,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e2ec290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:50:03,436:INFO:Checking exceptions
2025-12-04 16:50:03,436:INFO:Importing libraries
2025-12-04 16:50:03,436:INFO:Copying training dataset
2025-12-04 16:50:03,443:INFO:Defining folds
2025-12-04 16:50:03,443:INFO:Declaring metric variables
2025-12-04 16:50:03,444:INFO:Importing untrained model
2025-12-04 16:50:03,445:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-04 16:50:03,447:INFO:Starting cross validation
2025-12-04 16:50:03,449:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:50:03,519:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 16:50:03,525:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 16:50:03,530:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 16:50:04,756:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:04,756:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:04,828:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 16:50:04,828:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-04 16:50:04,850:INFO:Calculating mean and std
2025-12-04 16:50:04,851:INFO:Creating metrics dataframe
2025-12-04 16:50:04,853:INFO:Uploading results into container
2025-12-04 16:50:04,854:INFO:Uploading model into container now
2025-12-04 16:50:04,859:INFO:_master_model_container: 2
2025-12-04 16:50:04,860:INFO:_display_container: 2
2025-12-04 16:50:04,865:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-04 16:50:04,865:INFO:create_model() successfully completed......................................
2025-12-04 16:50:05,044:INFO:SubProcess create_model() end ==================================
2025-12-04 16:50:05,044:INFO:Creating metrics dataframe
2025-12-04 16:50:05,047:INFO:Initializing Light Gradient Boosting Machine
2025-12-04 16:50:05,047:INFO:Total runtime is 0.14678340355555217 minutes
2025-12-04 16:50:05,049:INFO:SubProcess create_model() called ==================================
2025-12-04 16:50:05,049:INFO:Initializing create_model()
2025-12-04 16:50:05,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e2ec290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:50:05,049:INFO:Checking exceptions
2025-12-04 16:50:05,049:INFO:Importing libraries
2025-12-04 16:50:05,049:INFO:Copying training dataset
2025-12-04 16:50:05,052:INFO:Defining folds
2025-12-04 16:50:05,052:INFO:Declaring metric variables
2025-12-04 16:50:05,053:INFO:Importing untrained model
2025-12-04 16:50:05,056:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:50:05,059:INFO:Starting cross validation
2025-12-04 16:50:05,061:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:50:06,595:INFO:Calculating mean and std
2025-12-04 16:50:06,596:INFO:Creating metrics dataframe
2025-12-04 16:50:06,597:INFO:Uploading results into container
2025-12-04 16:50:06,597:INFO:Uploading model into container now
2025-12-04 16:50:06,597:INFO:_master_model_container: 3
2025-12-04 16:50:06,597:INFO:_display_container: 2
2025-12-04 16:50:06,598:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:50:06,598:INFO:create_model() successfully completed......................................
2025-12-04 16:50:06,695:INFO:SubProcess create_model() end ==================================
2025-12-04 16:50:06,695:INFO:Creating metrics dataframe
2025-12-04 16:50:06,698:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-04 16:50:06,702:INFO:Initializing create_model()
2025-12-04 16:50:06,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:50:06,702:INFO:Checking exceptions
2025-12-04 16:50:06,703:INFO:Importing libraries
2025-12-04 16:50:06,703:INFO:Copying training dataset
2025-12-04 16:50:06,706:INFO:Defining folds
2025-12-04 16:50:06,706:INFO:Declaring metric variables
2025-12-04 16:50:06,706:INFO:Importing untrained model
2025-12-04 16:50:06,706:INFO:Declaring custom model
2025-12-04 16:50:06,706:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:50:06,707:INFO:Cross validation set to False
2025-12-04 16:50:06,707:INFO:Fitting Model
2025-12-04 16:50:06,736:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:50:06,738:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:50:06,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001109 seconds.
2025-12-04 16:50:06,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:50:06,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:50:06,741:INFO:[LightGBM] [Info] Total Bins 86
2025-12-04 16:50:06,745:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-04 16:50:06,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:50:07,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:50:07,120:INFO:create_model() successfully completed......................................
2025-12-04 16:50:07,218:INFO:_master_model_container: 3
2025-12-04 16:50:07,218:INFO:_display_container: 2
2025-12-04 16:50:07,218:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:50:07,218:INFO:compare_models() successfully completed......................................
2025-12-04 16:50:12,146:INFO:Initializing create_model()
2025-12-04 16:50:12,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:50:12,147:INFO:Checking exceptions
2025-12-04 16:50:12,169:INFO:Importing libraries
2025-12-04 16:50:12,170:INFO:Copying training dataset
2025-12-04 16:50:12,180:INFO:Defining folds
2025-12-04 16:50:12,180:INFO:Declaring metric variables
2025-12-04 16:50:12,182:INFO:Importing untrained model
2025-12-04 16:50:12,184:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:50:12,189:INFO:Starting cross validation
2025-12-04 16:50:12,192:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:50:13,840:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-04 16:50:14,246:INFO:Calculating mean and std
2025-12-04 16:50:14,247:INFO:Creating metrics dataframe
2025-12-04 16:50:14,249:INFO:Finalizing model
2025-12-04 16:50:14,283:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:50:14,283:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:50:14,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.
2025-12-04 16:50:14,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:50:14,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:50:14,285:INFO:[LightGBM] [Info] Total Bins 86
2025-12-04 16:50:14,285:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-04 16:50:14,286:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:50:14,661:INFO:Uploading results into container
2025-12-04 16:50:14,662:INFO:Uploading model into container now
2025-12-04 16:50:14,667:INFO:_master_model_container: 4
2025-12-04 16:50:14,667:INFO:_display_container: 3
2025-12-04 16:50:14,667:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:50:14,668:INFO:create_model() successfully completed......................................
2025-12-04 16:50:14,860:INFO:Initializing tune_model()
2025-12-04 16:50:14,861:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-04 16:50:14,861:INFO:Checking exceptions
2025-12-04 16:50:14,868:INFO:Copying training dataset
2025-12-04 16:50:14,872:INFO:Checking base model
2025-12-04 16:50:14,872:INFO:Base model : Light Gradient Boosting Machine
2025-12-04 16:50:14,874:INFO:Declaring metric variables
2025-12-04 16:50:14,876:INFO:Defining Hyperparameters
2025-12-04 16:50:15,099:INFO:Tuning with n_jobs=-1
2025-12-04 16:50:15,099:INFO:Initializing RandomizedSearchCV
2025-12-04 16:50:56,187:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2025-12-04 16:50:56,255:INFO:Hyperparameter search completed
2025-12-04 16:50:56,255:INFO:SubProcess create_model() called ==================================
2025-12-04 16:50:56,256:INFO:Initializing create_model()
2025-12-04 16:50:56,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5c290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2025-12-04 16:50:56,256:INFO:Checking exceptions
2025-12-04 16:50:56,256:INFO:Importing libraries
2025-12-04 16:50:56,264:INFO:Copying training dataset
2025-12-04 16:50:56,307:INFO:Defining folds
2025-12-04 16:50:56,307:INFO:Declaring metric variables
2025-12-04 16:50:56,340:INFO:Importing untrained model
2025-12-04 16:50:56,340:INFO:Declaring custom model
2025-12-04 16:50:56,364:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:50:56,370:INFO:Starting cross validation
2025-12-04 16:50:56,376:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:50:57,776:INFO:Calculating mean and std
2025-12-04 16:50:57,781:INFO:Creating metrics dataframe
2025-12-04 16:50:57,789:INFO:Finalizing model
2025-12-04 16:50:57,829:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-12-04 16:50:57,829:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-04 16:50:57,829:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-12-04 16:50:57,831:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:50:57,832:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-12-04 16:50:57,832:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-04 16:50:57,832:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-12-04 16:50:57,832:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:50:57,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-12-04 16:50:57,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:50:57,833:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:50:57,833:INFO:[LightGBM] [Info] Total Bins 86
2025-12-04 16:50:57,833:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-04 16:50:57,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:50:57,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:57,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-04 16:50:58,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-04 16:50:58,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:50:58,085:INFO:Uploading results into container
2025-12-04 16:50:58,085:INFO:Uploading model into container now
2025-12-04 16:50:58,086:INFO:_master_model_container: 5
2025-12-04 16:50:58,087:INFO:_display_container: 4
2025-12-04 16:50:58,089:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:50:58,090:INFO:create_model() successfully completed......................................
2025-12-04 16:50:58,326:INFO:SubProcess create_model() end ==================================
2025-12-04 16:50:58,326:INFO:choose_better activated
2025-12-04 16:50:58,327:INFO:SubProcess create_model() called ==================================
2025-12-04 16:50:58,328:INFO:Initializing create_model()
2025-12-04 16:50:58,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319b249d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:50:58,328:INFO:Checking exceptions
2025-12-04 16:50:58,329:INFO:Importing libraries
2025-12-04 16:50:58,329:INFO:Copying training dataset
2025-12-04 16:50:58,332:INFO:Defining folds
2025-12-04 16:50:58,332:INFO:Declaring metric variables
2025-12-04 16:50:58,332:INFO:Importing untrained model
2025-12-04 16:50:58,332:INFO:Declaring custom model
2025-12-04 16:50:58,333:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:50:58,333:INFO:Starting cross validation
2025-12-04 16:50:58,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:51:00,603:INFO:Calculating mean and std
2025-12-04 16:51:00,603:INFO:Creating metrics dataframe
2025-12-04 16:51:00,608:INFO:Finalizing model
2025-12-04 16:51:00,638:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:51:00,638:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:51:00,639:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.
2025-12-04 16:51:00,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:51:00,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:51:00,639:INFO:[LightGBM] [Info] Total Bins 86
2025-12-04 16:51:00,639:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-04 16:51:00,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:51:01,015:INFO:Uploading results into container
2025-12-04 16:51:01,015:INFO:Uploading model into container now
2025-12-04 16:51:01,015:INFO:_master_model_container: 6
2025-12-04 16:51:01,015:INFO:_display_container: 5
2025-12-04 16:51:01,015:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:01,016:INFO:create_model() successfully completed......................................
2025-12-04 16:51:01,163:INFO:SubProcess create_model() end ==================================
2025-12-04 16:51:01,164:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8789
2025-12-04 16:51:01,164:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8816
2025-12-04 16:51:01,164:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-04 16:51:01,164:INFO:choose_better completed
2025-12-04 16:51:01,182:INFO:_master_model_container: 6
2025-12-04 16:51:01,182:INFO:_display_container: 4
2025-12-04 16:51:01,183:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:01,183:INFO:tune_model() successfully completed......................................
2025-12-04 16:51:36,749:INFO:PyCaret ClassificationExperiment
2025-12-04 16:51:36,749:INFO:Logging name: clf-default-name
2025-12-04 16:51:36,749:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-04 16:51:36,749:INFO:version 3.3.2
2025-12-04 16:51:36,749:INFO:Initializing setup()
2025-12-04 16:51:36,749:INFO:self.USI: 837a
2025-12-04 16:51:36,749:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-04 16:51:36,749:INFO:Checking environment
2025-12-04 16:51:36,749:INFO:python_version: 3.11.14
2025-12-04 16:51:36,749:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-04 16:51:36,749:INFO:machine: arm64
2025-12-04 16:51:36,749:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:51:36,750:INFO:Memory: svmem(total=8589934592, available=1310883840, percent=84.7, used=3009118208, free=65208320, active=1257422848, inactive=1226670080, wired=1751695360)
2025-12-04 16:51:36,750:INFO:Physical Core: 8
2025-12-04 16:51:36,750:INFO:Logical Core: 8
2025-12-04 16:51:36,750:INFO:Checking libraries
2025-12-04 16:51:36,750:INFO:System:
2025-12-04 16:51:36,750:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-04 16:51:36,750:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-04 16:51:36,750:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:51:36,750:INFO:PyCaret required dependencies:
2025-12-04 16:51:36,750:INFO:                 pip: 25.3
2025-12-04 16:51:36,750:INFO:          setuptools: 80.9.0
2025-12-04 16:51:36,750:INFO:             pycaret: 3.3.2
2025-12-04 16:51:36,750:INFO:             IPython: 9.7.0
2025-12-04 16:51:36,750:INFO:          ipywidgets: 8.1.8
2025-12-04 16:51:36,750:INFO:                tqdm: 4.67.1
2025-12-04 16:51:36,750:INFO:               numpy: 1.26.4
2025-12-04 16:51:36,750:INFO:              pandas: 2.1.4
2025-12-04 16:51:36,751:INFO:              jinja2: 3.1.6
2025-12-04 16:51:36,751:INFO:               scipy: 1.11.4
2025-12-04 16:51:36,751:INFO:              joblib: 1.3.2
2025-12-04 16:51:36,751:INFO:             sklearn: 1.4.2
2025-12-04 16:51:36,751:INFO:                pyod: 2.0.5
2025-12-04 16:51:36,751:INFO:            imblearn: 0.14.0
2025-12-04 16:51:36,751:INFO:   category_encoders: 2.7.0
2025-12-04 16:51:36,751:INFO:            lightgbm: 4.6.0
2025-12-04 16:51:36,751:INFO:               numba: 0.62.1
2025-12-04 16:51:36,751:INFO:            requests: 2.32.5
2025-12-04 16:51:36,751:INFO:          matplotlib: 3.7.5
2025-12-04 16:51:36,751:INFO:          scikitplot: 0.3.7
2025-12-04 16:51:36,751:INFO:         yellowbrick: 1.5
2025-12-04 16:51:36,751:INFO:              plotly: 6.5.0
2025-12-04 16:51:36,751:INFO:    plotly-resampler: Not installed
2025-12-04 16:51:36,751:INFO:             kaleido: 1.2.0
2025-12-04 16:51:36,751:INFO:           schemdraw: 0.15
2025-12-04 16:51:36,751:INFO:         statsmodels: 0.14.5
2025-12-04 16:51:36,751:INFO:              sktime: 0.26.0
2025-12-04 16:51:36,751:INFO:               tbats: 1.1.3
2025-12-04 16:51:36,751:INFO:            pmdarima: 2.0.4
2025-12-04 16:51:36,751:INFO:              psutil: 7.1.3
2025-12-04 16:51:36,751:INFO:          markupsafe: 3.0.3
2025-12-04 16:51:36,751:INFO:             pickle5: Not installed
2025-12-04 16:51:36,751:INFO:         cloudpickle: 3.1.2
2025-12-04 16:51:36,751:INFO:         deprecation: 2.1.0
2025-12-04 16:51:36,751:INFO:              xxhash: 3.6.0
2025-12-04 16:51:36,751:INFO:           wurlitzer: 3.1.1
2025-12-04 16:51:36,751:INFO:PyCaret optional dependencies:
2025-12-04 16:51:36,751:INFO:                shap: Not installed
2025-12-04 16:51:36,751:INFO:           interpret: Not installed
2025-12-04 16:51:36,751:INFO:                umap: Not installed
2025-12-04 16:51:36,751:INFO:     ydata_profiling: Not installed
2025-12-04 16:51:36,751:INFO:  explainerdashboard: Not installed
2025-12-04 16:51:36,751:INFO:             autoviz: Not installed
2025-12-04 16:51:36,751:INFO:           fairlearn: Not installed
2025-12-04 16:51:36,751:INFO:          deepchecks: Not installed
2025-12-04 16:51:36,751:INFO:             xgboost: Not installed
2025-12-04 16:51:36,751:INFO:            catboost: Not installed
2025-12-04 16:51:36,751:INFO:              kmodes: Not installed
2025-12-04 16:51:36,751:INFO:             mlxtend: Not installed
2025-12-04 16:51:36,751:INFO:       statsforecast: Not installed
2025-12-04 16:51:36,751:INFO:        tune_sklearn: Not installed
2025-12-04 16:51:36,751:INFO:                 ray: Not installed
2025-12-04 16:51:36,751:INFO:            hyperopt: Not installed
2025-12-04 16:51:36,751:INFO:              optuna: Not installed
2025-12-04 16:51:36,751:INFO:               skopt: Not installed
2025-12-04 16:51:36,751:INFO:              mlflow: Not installed
2025-12-04 16:51:36,751:INFO:              gradio: Not installed
2025-12-04 16:51:36,751:INFO:             fastapi: Not installed
2025-12-04 16:51:36,751:INFO:             uvicorn: Not installed
2025-12-04 16:51:36,751:INFO:              m2cgen: Not installed
2025-12-04 16:51:36,751:INFO:           evidently: Not installed
2025-12-04 16:51:36,751:INFO:               fugue: Not installed
2025-12-04 16:51:36,751:INFO:           streamlit: Not installed
2025-12-04 16:51:36,751:INFO:             prophet: Not installed
2025-12-04 16:51:36,751:INFO:None
2025-12-04 16:51:36,751:INFO:Set up data.
2025-12-04 16:51:36,767:INFO:Set up folding strategy.
2025-12-04 16:51:36,767:INFO:Set up train/test split.
2025-12-04 16:51:36,778:INFO:Set up index.
2025-12-04 16:51:36,778:INFO:Assigning column types.
2025-12-04 16:51:36,780:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-04 16:51:36,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,842:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-04 16:51:36,860:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,890:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:51:36,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,900:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-04 16:51:36,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:36,958:INFO:Preparing preprocessing pipeline...
2025-12-04 16:51:36,959:INFO:Set up simple imputation.
2025-12-04 16:51:36,959:INFO:Set up imbalanced handling.
2025-12-04 16:51:36,960:INFO:Set up column name cleaning.
2025-12-04 16:51:36,999:INFO:Finished creating preprocessing pipeline.
2025-12-04 16:51:37,001:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support',
                                             'married'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_val...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-04 16:51:37,001:INFO:Creating final display dataframe.
2025-12-04 16:51:37,064:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 11)
4        Transformed data shape        (9687, 11)
5   Transformed train set shape        (8278, 11)
6    Transformed test set shape        (1409, 11)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              837a
2025-12-04 16:51:37,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:37,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:37,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:37,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:51:37,130:INFO:setup() successfully completed in 0.39s...............
2025-12-04 16:51:37,134:INFO:Initializing compare_models()
2025-12-04 16:51:37,134:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-04 16:51:37,134:INFO:Checking exceptions
2025-12-04 16:51:37,136:INFO:Preparing display monitor
2025-12-04 16:51:37,150:INFO:Initializing Logistic Regression
2025-12-04 16:51:37,150:INFO:Total runtime is 1.9351641337076824e-06 minutes
2025-12-04 16:51:37,151:INFO:SubProcess create_model() called ==================================
2025-12-04 16:51:37,151:INFO:Initializing create_model()
2025-12-04 16:51:37,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5c710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:51:37,151:INFO:Checking exceptions
2025-12-04 16:51:37,151:INFO:Importing libraries
2025-12-04 16:51:37,151:INFO:Copying training dataset
2025-12-04 16:51:37,158:INFO:Defining folds
2025-12-04 16:51:37,158:INFO:Declaring metric variables
2025-12-04 16:51:37,160:INFO:Importing untrained model
2025-12-04 16:51:37,161:INFO:Logistic Regression Imported successfully
2025-12-04 16:51:37,169:INFO:Starting cross validation
2025-12-04 16:51:37,171:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:51:37,425:INFO:Calculating mean and std
2025-12-04 16:51:37,425:INFO:Creating metrics dataframe
2025-12-04 16:51:37,426:INFO:Uploading results into container
2025-12-04 16:51:37,426:INFO:Uploading model into container now
2025-12-04 16:51:37,426:INFO:_master_model_container: 1
2025-12-04 16:51:37,426:INFO:_display_container: 2
2025-12-04 16:51:37,426:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 16:51:37,426:INFO:create_model() successfully completed......................................
2025-12-04 16:51:37,682:INFO:SubProcess create_model() end ==================================
2025-12-04 16:51:37,682:INFO:Creating metrics dataframe
2025-12-04 16:51:37,688:INFO:Initializing Quadratic Discriminant Analysis
2025-12-04 16:51:37,688:INFO:Total runtime is 0.008977166811625163 minutes
2025-12-04 16:51:37,690:INFO:SubProcess create_model() called ==================================
2025-12-04 16:51:37,690:INFO:Initializing create_model()
2025-12-04 16:51:37,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5c710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:51:37,690:INFO:Checking exceptions
2025-12-04 16:51:37,690:INFO:Importing libraries
2025-12-04 16:51:37,690:INFO:Copying training dataset
2025-12-04 16:51:37,696:INFO:Defining folds
2025-12-04 16:51:37,696:INFO:Declaring metric variables
2025-12-04 16:51:37,697:INFO:Importing untrained model
2025-12-04 16:51:37,699:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-04 16:51:37,703:INFO:Starting cross validation
2025-12-04 16:51:37,705:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:51:37,848:INFO:Calculating mean and std
2025-12-04 16:51:37,848:INFO:Creating metrics dataframe
2025-12-04 16:51:37,850:INFO:Uploading results into container
2025-12-04 16:51:37,850:INFO:Uploading model into container now
2025-12-04 16:51:37,850:INFO:_master_model_container: 2
2025-12-04 16:51:37,850:INFO:_display_container: 2
2025-12-04 16:51:37,850:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-04 16:51:37,850:INFO:create_model() successfully completed......................................
2025-12-04 16:51:37,945:INFO:SubProcess create_model() end ==================================
2025-12-04 16:51:37,945:INFO:Creating metrics dataframe
2025-12-04 16:51:37,948:INFO:Initializing Light Gradient Boosting Machine
2025-12-04 16:51:37,948:INFO:Total runtime is 0.013300581773122152 minutes
2025-12-04 16:51:37,949:INFO:SubProcess create_model() called ==================================
2025-12-04 16:51:37,950:INFO:Initializing create_model()
2025-12-04 16:51:37,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5c710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:51:37,950:INFO:Checking exceptions
2025-12-04 16:51:37,950:INFO:Importing libraries
2025-12-04 16:51:37,950:INFO:Copying training dataset
2025-12-04 16:51:37,952:INFO:Defining folds
2025-12-04 16:51:37,952:INFO:Declaring metric variables
2025-12-04 16:51:37,954:INFO:Importing untrained model
2025-12-04 16:51:37,956:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:51:37,964:INFO:Starting cross validation
2025-12-04 16:51:37,966:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:51:39,593:INFO:Calculating mean and std
2025-12-04 16:51:39,596:INFO:Creating metrics dataframe
2025-12-04 16:51:39,600:INFO:Uploading results into container
2025-12-04 16:51:39,600:INFO:Uploading model into container now
2025-12-04 16:51:39,601:INFO:_master_model_container: 3
2025-12-04 16:51:39,601:INFO:_display_container: 2
2025-12-04 16:51:39,606:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:39,607:INFO:create_model() successfully completed......................................
2025-12-04 16:51:39,772:INFO:SubProcess create_model() end ==================================
2025-12-04 16:51:39,772:INFO:Creating metrics dataframe
2025-12-04 16:51:39,776:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-04 16:51:39,780:INFO:Initializing create_model()
2025-12-04 16:51:39,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:51:39,780:INFO:Checking exceptions
2025-12-04 16:51:39,781:INFO:Importing libraries
2025-12-04 16:51:39,781:INFO:Copying training dataset
2025-12-04 16:51:39,783:INFO:Defining folds
2025-12-04 16:51:39,783:INFO:Declaring metric variables
2025-12-04 16:51:39,784:INFO:Importing untrained model
2025-12-04 16:51:39,784:INFO:Declaring custom model
2025-12-04 16:51:39,784:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:51:39,784:INFO:Cross validation set to False
2025-12-04 16:51:39,784:INFO:Fitting Model
2025-12-04 16:51:39,807:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:51:39,807:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:51:39,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.
2025-12-04 16:51:39,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:51:39,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:51:39,809:INFO:[LightGBM] [Info] Total Bins 85
2025-12-04 16:51:39,809:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 10
2025-12-04 16:51:39,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:51:40,176:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:40,176:INFO:create_model() successfully completed......................................
2025-12-04 16:51:40,266:INFO:_master_model_container: 3
2025-12-04 16:51:40,267:INFO:_display_container: 2
2025-12-04 16:51:40,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:40,267:INFO:compare_models() successfully completed......................................
2025-12-04 16:51:50,992:INFO:Initializing create_model()
2025-12-04 16:51:50,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:51:50,992:INFO:Checking exceptions
2025-12-04 16:51:51,018:INFO:Importing libraries
2025-12-04 16:51:51,018:INFO:Copying training dataset
2025-12-04 16:51:51,026:INFO:Defining folds
2025-12-04 16:51:51,026:INFO:Declaring metric variables
2025-12-04 16:51:51,028:INFO:Importing untrained model
2025-12-04 16:51:51,029:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:51:51,033:INFO:Starting cross validation
2025-12-04 16:51:51,036:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:51:52,587:INFO:Calculating mean and std
2025-12-04 16:51:52,588:INFO:Creating metrics dataframe
2025-12-04 16:51:52,592:INFO:Finalizing model
2025-12-04 16:51:52,619:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:51:52,620:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:51:52,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.
2025-12-04 16:51:52,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:51:52,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:51:52,621:INFO:[LightGBM] [Info] Total Bins 85
2025-12-04 16:51:52,621:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 10
2025-12-04 16:51:52,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:51:52,986:INFO:Uploading results into container
2025-12-04 16:51:52,986:INFO:Uploading model into container now
2025-12-04 16:51:52,992:INFO:_master_model_container: 4
2025-12-04 16:51:52,992:INFO:_display_container: 3
2025-12-04 16:51:52,993:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:51:52,993:INFO:create_model() successfully completed......................................
2025-12-04 16:51:53,172:INFO:Initializing tune_model()
2025-12-04 16:51:53,172:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-04 16:51:53,172:INFO:Checking exceptions
2025-12-04 16:51:53,184:INFO:Copying training dataset
2025-12-04 16:51:53,187:INFO:Checking base model
2025-12-04 16:51:53,187:INFO:Base model : Light Gradient Boosting Machine
2025-12-04 16:51:53,189:INFO:Declaring metric variables
2025-12-04 16:51:53,190:INFO:Defining Hyperparameters
2025-12-04 16:51:53,352:INFO:Tuning with n_jobs=-1
2025-12-04 16:51:53,352:INFO:Initializing RandomizedSearchCV
2025-12-04 16:52:32,706:INFO:best_params: {'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 81, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.6}
2025-12-04 16:52:32,728:INFO:Hyperparameter search completed
2025-12-04 16:52:32,728:INFO:SubProcess create_model() called ==================================
2025-12-04 16:52:32,734:INFO:Initializing create_model()
2025-12-04 16:52:32,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c565210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.7, 'reg_alpha': 0.0005, 'num_leaves': 40, 'n_estimators': 90, 'min_split_gain': 0.1, 'min_child_samples': 81, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 3, 'bagging_fraction': 0.6})
2025-12-04 16:52:32,734:INFO:Checking exceptions
2025-12-04 16:52:32,734:INFO:Importing libraries
2025-12-04 16:52:32,735:INFO:Copying training dataset
2025-12-04 16:52:32,741:INFO:Defining folds
2025-12-04 16:52:32,741:INFO:Declaring metric variables
2025-12-04 16:52:32,743:INFO:Importing untrained model
2025-12-04 16:52:32,744:INFO:Declaring custom model
2025-12-04 16:52:32,745:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:52:32,747:INFO:Starting cross validation
2025-12-04 16:52:32,750:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:52:33,327:INFO:Calculating mean and std
2025-12-04 16:52:33,327:INFO:Creating metrics dataframe
2025-12-04 16:52:33,330:INFO:Finalizing model
2025-12-04 16:52:33,352:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 16:52:33,352:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 16:52:33,352:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 16:52:33,355:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:52:33,356:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 16:52:33,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 16:52:33,356:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 16:52:33,356:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:52:33,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-12-04 16:52:33,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:52:33,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:52:33,357:INFO:[LightGBM] [Info] Total Bins 85
2025-12-04 16:52:33,357:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 10
2025-12-04 16:52:33,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:52:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 16:52:33,531:INFO:Uploading results into container
2025-12-04 16:52:33,531:INFO:Uploading model into container now
2025-12-04 16:52:33,532:INFO:_master_model_container: 5
2025-12-04 16:52:33,532:INFO:_display_container: 4
2025-12-04 16:52:33,532:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=90, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.0005, reg_lambda=0.7, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:52:33,532:INFO:create_model() successfully completed......................................
2025-12-04 16:52:33,770:INFO:SubProcess create_model() end ==================================
2025-12-04 16:52:33,770:INFO:choose_better activated
2025-12-04 16:52:33,772:INFO:SubProcess create_model() called ==================================
2025-12-04 16:52:33,772:INFO:Initializing create_model()
2025-12-04 16:52:33,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e39c290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:52:33,772:INFO:Checking exceptions
2025-12-04 16:52:33,773:INFO:Importing libraries
2025-12-04 16:52:33,773:INFO:Copying training dataset
2025-12-04 16:52:33,775:INFO:Defining folds
2025-12-04 16:52:33,776:INFO:Declaring metric variables
2025-12-04 16:52:33,776:INFO:Importing untrained model
2025-12-04 16:52:33,776:INFO:Declaring custom model
2025-12-04 16:52:33,776:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:52:33,776:INFO:Starting cross validation
2025-12-04 16:52:33,776:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:52:35,015:INFO:Calculating mean and std
2025-12-04 16:52:35,015:INFO:Creating metrics dataframe
2025-12-04 16:52:35,016:INFO:Finalizing model
2025-12-04 16:52:35,036:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:52:35,036:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:52:35,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.
2025-12-04 16:52:35,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:52:35,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:52:35,037:INFO:[LightGBM] [Info] Total Bins 85
2025-12-04 16:52:35,037:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 10
2025-12-04 16:52:35,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:52:35,426:INFO:Uploading results into container
2025-12-04 16:52:35,427:INFO:Uploading model into container now
2025-12-04 16:52:35,427:INFO:_master_model_container: 6
2025-12-04 16:52:35,427:INFO:_display_container: 5
2025-12-04 16:52:35,427:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:52:35,427:INFO:create_model() successfully completed......................................
2025-12-04 16:52:35,527:INFO:SubProcess create_model() end ==================================
2025-12-04 16:52:35,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8796
2025-12-04 16:52:35,528:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=90, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.0005, reg_lambda=0.7, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8836
2025-12-04 16:52:35,528:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=90, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.0005, reg_lambda=0.7, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-04 16:52:35,528:INFO:choose_better completed
2025-12-04 16:52:35,533:INFO:_master_model_container: 6
2025-12-04 16:52:35,533:INFO:_display_container: 4
2025-12-04 16:52:35,534:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=90, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.0005, reg_lambda=0.7, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:52:35,534:INFO:tune_model() successfully completed......................................
2025-12-04 16:54:30,582:WARNING:/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/ipykernel_73561/3180370655.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_top10['married_senior'] = ((df_top10['married'] == 1) & (df_top10['senior_citizen'] == 1)).astype(int)

2025-12-04 16:54:37,189:WARNING:/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/ipykernel_73561/3191820079.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_top10['married_senior'] = ((df_top10['married'] == 1) & (df_top10['senior_citizen'] == 1)).astype(int)

2025-12-04 16:54:41,237:INFO:PyCaret ClassificationExperiment
2025-12-04 16:54:41,237:INFO:Logging name: clf-default-name
2025-12-04 16:54:41,237:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-04 16:54:41,237:INFO:version 3.3.2
2025-12-04 16:54:41,237:INFO:Initializing setup()
2025-12-04 16:54:41,237:INFO:self.USI: 9e4f
2025-12-04 16:54:41,237:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-04 16:54:41,237:INFO:Checking environment
2025-12-04 16:54:41,237:INFO:python_version: 3.11.14
2025-12-04 16:54:41,237:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-04 16:54:41,237:INFO:machine: arm64
2025-12-04 16:54:41,237:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:54:41,238:INFO:Memory: svmem(total=8589934592, available=1300824064, percent=84.9, used=2944794624, free=60375040, active=1256931328, inactive=1232322560, wired=1687863296)
2025-12-04 16:54:41,238:INFO:Physical Core: 8
2025-12-04 16:54:41,238:INFO:Logical Core: 8
2025-12-04 16:54:41,238:INFO:Checking libraries
2025-12-04 16:54:41,238:INFO:System:
2025-12-04 16:54:41,238:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-04 16:54:41,238:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-04 16:54:41,238:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-04 16:54:41,238:INFO:PyCaret required dependencies:
2025-12-04 16:54:41,239:INFO:                 pip: 25.3
2025-12-04 16:54:41,239:INFO:          setuptools: 80.9.0
2025-12-04 16:54:41,239:INFO:             pycaret: 3.3.2
2025-12-04 16:54:41,239:INFO:             IPython: 9.7.0
2025-12-04 16:54:41,239:INFO:          ipywidgets: 8.1.8
2025-12-04 16:54:41,239:INFO:                tqdm: 4.67.1
2025-12-04 16:54:41,239:INFO:               numpy: 1.26.4
2025-12-04 16:54:41,239:INFO:              pandas: 2.1.4
2025-12-04 16:54:41,239:INFO:              jinja2: 3.1.6
2025-12-04 16:54:41,239:INFO:               scipy: 1.11.4
2025-12-04 16:54:41,239:INFO:              joblib: 1.3.2
2025-12-04 16:54:41,239:INFO:             sklearn: 1.4.2
2025-12-04 16:54:41,239:INFO:                pyod: 2.0.5
2025-12-04 16:54:41,239:INFO:            imblearn: 0.14.0
2025-12-04 16:54:41,239:INFO:   category_encoders: 2.7.0
2025-12-04 16:54:41,239:INFO:            lightgbm: 4.6.0
2025-12-04 16:54:41,239:INFO:               numba: 0.62.1
2025-12-04 16:54:41,239:INFO:            requests: 2.32.5
2025-12-04 16:54:41,239:INFO:          matplotlib: 3.7.5
2025-12-04 16:54:41,239:INFO:          scikitplot: 0.3.7
2025-12-04 16:54:41,239:INFO:         yellowbrick: 1.5
2025-12-04 16:54:41,239:INFO:              plotly: 6.5.0
2025-12-04 16:54:41,239:INFO:    plotly-resampler: Not installed
2025-12-04 16:54:41,239:INFO:             kaleido: 1.2.0
2025-12-04 16:54:41,239:INFO:           schemdraw: 0.15
2025-12-04 16:54:41,239:INFO:         statsmodels: 0.14.5
2025-12-04 16:54:41,239:INFO:              sktime: 0.26.0
2025-12-04 16:54:41,239:INFO:               tbats: 1.1.3
2025-12-04 16:54:41,239:INFO:            pmdarima: 2.0.4
2025-12-04 16:54:41,239:INFO:              psutil: 7.1.3
2025-12-04 16:54:41,239:INFO:          markupsafe: 3.0.3
2025-12-04 16:54:41,239:INFO:             pickle5: Not installed
2025-12-04 16:54:41,239:INFO:         cloudpickle: 3.1.2
2025-12-04 16:54:41,239:INFO:         deprecation: 2.1.0
2025-12-04 16:54:41,239:INFO:              xxhash: 3.6.0
2025-12-04 16:54:41,239:INFO:           wurlitzer: 3.1.1
2025-12-04 16:54:41,239:INFO:PyCaret optional dependencies:
2025-12-04 16:54:41,239:INFO:                shap: Not installed
2025-12-04 16:54:41,239:INFO:           interpret: Not installed
2025-12-04 16:54:41,239:INFO:                umap: Not installed
2025-12-04 16:54:41,239:INFO:     ydata_profiling: Not installed
2025-12-04 16:54:41,239:INFO:  explainerdashboard: Not installed
2025-12-04 16:54:41,239:INFO:             autoviz: Not installed
2025-12-04 16:54:41,239:INFO:           fairlearn: Not installed
2025-12-04 16:54:41,239:INFO:          deepchecks: Not installed
2025-12-04 16:54:41,239:INFO:             xgboost: Not installed
2025-12-04 16:54:41,239:INFO:            catboost: Not installed
2025-12-04 16:54:41,240:INFO:              kmodes: Not installed
2025-12-04 16:54:41,240:INFO:             mlxtend: Not installed
2025-12-04 16:54:41,240:INFO:       statsforecast: Not installed
2025-12-04 16:54:41,240:INFO:        tune_sklearn: Not installed
2025-12-04 16:54:41,240:INFO:                 ray: Not installed
2025-12-04 16:54:41,240:INFO:            hyperopt: Not installed
2025-12-04 16:54:41,240:INFO:              optuna: Not installed
2025-12-04 16:54:41,240:INFO:               skopt: Not installed
2025-12-04 16:54:41,240:INFO:              mlflow: Not installed
2025-12-04 16:54:41,240:INFO:              gradio: Not installed
2025-12-04 16:54:41,240:INFO:             fastapi: Not installed
2025-12-04 16:54:41,241:INFO:             uvicorn: Not installed
2025-12-04 16:54:41,241:INFO:              m2cgen: Not installed
2025-12-04 16:54:41,241:INFO:           evidently: Not installed
2025-12-04 16:54:41,241:INFO:               fugue: Not installed
2025-12-04 16:54:41,241:INFO:           streamlit: Not installed
2025-12-04 16:54:41,241:INFO:             prophet: Not installed
2025-12-04 16:54:41,241:INFO:None
2025-12-04 16:54:41,241:INFO:Set up data.
2025-12-04 16:54:41,260:INFO:Set up folding strategy.
2025-12-04 16:54:41,260:INFO:Set up train/test split.
2025-12-04 16:54:41,270:INFO:Set up index.
2025-12-04 16:54:41,270:INFO:Assigning column types.
2025-12-04 16:54:41,273:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-04 16:54:41,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,328:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-04 16:54:41,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-04 16:54:41,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,399:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-04 16:54:41,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,463:INFO:Preparing preprocessing pipeline...
2025-12-04 16:54:41,465:INFO:Set up simple imputation.
2025-12-04 16:54:41,465:INFO:Set up imbalanced handling.
2025-12-04 16:54:41,465:INFO:Set up column name cleaning.
2025-12-04 16:54:41,504:INFO:Finished creating preprocessing pipeline.
2025-12-04 16:54:41,506:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-04 16:54:41,506:INFO:Creating final display dataframe.
2025-12-04 16:54:41,574:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              9e4f
2025-12-04 16:54:41,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-04 16:54:41,641:INFO:setup() successfully completed in 0.41s...............
2025-12-04 16:54:41,645:INFO:Initializing compare_models()
2025-12-04 16:54:41,645:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-04 16:54:41,645:INFO:Checking exceptions
2025-12-04 16:54:41,647:INFO:Preparing display monitor
2025-12-04 16:54:41,663:INFO:Initializing Logistic Regression
2025-12-04 16:54:41,663:INFO:Total runtime is 7.271766662597656e-06 minutes
2025-12-04 16:54:41,665:INFO:SubProcess create_model() called ==================================
2025-12-04 16:54:41,666:INFO:Initializing create_model()
2025-12-04 16:54:41,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326eafb90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:54:41,666:INFO:Checking exceptions
2025-12-04 16:54:41,666:INFO:Importing libraries
2025-12-04 16:54:41,666:INFO:Copying training dataset
2025-12-04 16:54:41,671:INFO:Defining folds
2025-12-04 16:54:41,671:INFO:Declaring metric variables
2025-12-04 16:54:41,672:INFO:Importing untrained model
2025-12-04 16:54:41,674:INFO:Logistic Regression Imported successfully
2025-12-04 16:54:41,677:INFO:Starting cross validation
2025-12-04 16:54:41,678:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:54:41,824:INFO:Calculating mean and std
2025-12-04 16:54:41,824:INFO:Creating metrics dataframe
2025-12-04 16:54:41,825:INFO:Uploading results into container
2025-12-04 16:54:41,825:INFO:Uploading model into container now
2025-12-04 16:54:41,825:INFO:_master_model_container: 1
2025-12-04 16:54:41,825:INFO:_display_container: 2
2025-12-04 16:54:41,825:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-04 16:54:41,825:INFO:create_model() successfully completed......................................
2025-12-04 16:54:42,053:INFO:SubProcess create_model() end ==================================
2025-12-04 16:54:42,053:INFO:Creating metrics dataframe
2025-12-04 16:54:42,057:INFO:Initializing Quadratic Discriminant Analysis
2025-12-04 16:54:42,057:INFO:Total runtime is 0.006564434369405111 minutes
2025-12-04 16:54:42,058:INFO:SubProcess create_model() called ==================================
2025-12-04 16:54:42,058:INFO:Initializing create_model()
2025-12-04 16:54:42,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326eafb90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:54:42,058:INFO:Checking exceptions
2025-12-04 16:54:42,058:INFO:Importing libraries
2025-12-04 16:54:42,059:INFO:Copying training dataset
2025-12-04 16:54:42,061:INFO:Defining folds
2025-12-04 16:54:42,061:INFO:Declaring metric variables
2025-12-04 16:54:42,062:INFO:Importing untrained model
2025-12-04 16:54:42,063:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-04 16:54:42,065:INFO:Starting cross validation
2025-12-04 16:54:42,065:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:54:42,196:INFO:Calculating mean and std
2025-12-04 16:54:42,196:INFO:Creating metrics dataframe
2025-12-04 16:54:42,197:INFO:Uploading results into container
2025-12-04 16:54:42,198:INFO:Uploading model into container now
2025-12-04 16:54:42,198:INFO:_master_model_container: 2
2025-12-04 16:54:42,198:INFO:_display_container: 2
2025-12-04 16:54:42,198:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-04 16:54:42,198:INFO:create_model() successfully completed......................................
2025-12-04 16:54:42,294:INFO:SubProcess create_model() end ==================================
2025-12-04 16:54:42,294:INFO:Creating metrics dataframe
2025-12-04 16:54:42,296:INFO:Initializing Light Gradient Boosting Machine
2025-12-04 16:54:42,296:INFO:Total runtime is 0.010555005073547364 minutes
2025-12-04 16:54:42,297:INFO:SubProcess create_model() called ==================================
2025-12-04 16:54:42,297:INFO:Initializing create_model()
2025-12-04 16:54:42,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326eafb90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:54:42,298:INFO:Checking exceptions
2025-12-04 16:54:42,298:INFO:Importing libraries
2025-12-04 16:54:42,298:INFO:Copying training dataset
2025-12-04 16:54:42,300:INFO:Defining folds
2025-12-04 16:54:42,300:INFO:Declaring metric variables
2025-12-04 16:54:42,301:INFO:Importing untrained model
2025-12-04 16:54:42,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:54:42,305:INFO:Starting cross validation
2025-12-04 16:54:42,306:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-04 16:54:43,718:INFO:Calculating mean and std
2025-12-04 16:54:43,719:INFO:Creating metrics dataframe
2025-12-04 16:54:43,720:INFO:Uploading results into container
2025-12-04 16:54:43,720:INFO:Uploading model into container now
2025-12-04 16:54:43,721:INFO:_master_model_container: 3
2025-12-04 16:54:43,721:INFO:_display_container: 2
2025-12-04 16:54:43,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:54:43,721:INFO:create_model() successfully completed......................................
2025-12-04 16:54:43,835:INFO:SubProcess create_model() end ==================================
2025-12-04 16:54:43,835:INFO:Creating metrics dataframe
2025-12-04 16:54:43,839:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-04 16:54:43,843:INFO:Initializing create_model()
2025-12-04 16:54:43,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-04 16:54:43,843:INFO:Checking exceptions
2025-12-04 16:54:43,844:INFO:Importing libraries
2025-12-04 16:54:43,844:INFO:Copying training dataset
2025-12-04 16:54:43,846:INFO:Defining folds
2025-12-04 16:54:43,846:INFO:Declaring metric variables
2025-12-04 16:54:43,846:INFO:Importing untrained model
2025-12-04 16:54:43,846:INFO:Declaring custom model
2025-12-04 16:54:43,847:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-04 16:54:43,847:INFO:Cross validation set to False
2025-12-04 16:54:43,847:INFO:Fitting Model
2025-12-04 16:54:43,871:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 16:54:43,872:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-04 16:54:43,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000900 seconds.
2025-12-04 16:54:43,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 16:54:43,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 16:54:43,873:INFO:[LightGBM] [Info] Total Bins 85
2025-12-04 16:54:43,873:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-04 16:54:43,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 16:54:44,241:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:54:44,241:INFO:create_model() successfully completed......................................
2025-12-04 16:54:44,331:INFO:_master_model_container: 3
2025-12-04 16:54:44,331:INFO:_display_container: 2
2025-12-04 16:54:44,331:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-04 16:54:44,331:INFO:compare_models() successfully completed......................................
2025-12-04 17:00:33,356:INFO:Initializing plot_model()
2025-12-04 17:00:33,359:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e2d3f50>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=90, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.0005, reg_lambda=0.7, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=threshold, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-04 17:00:33,359:INFO:Checking exceptions
2025-12-04 17:00:33,439:INFO:Preloading libraries
2025-12-04 17:00:33,461:INFO:Copying training dataset
2025-12-04 17:00:33,461:INFO:Plot type: threshold
2025-12-04 17:00:33,609:INFO:Fitting Model
2025-12-04 17:00:33,621:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,621:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,621:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,630:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:33,630:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,630:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,630:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,630:INFO:[LightGBM] [Info] Number of positive: 3718, number of negative: 3732
2025-12-04 17:00:33,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.
2025-12-04 17:00:33,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:33,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:33,633:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:33,633:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:33,634:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499060 -> initscore=-0.003758
2025-12-04 17:00:33,634:INFO:[LightGBM] [Info] Start training from score -0.003758
2025-12-04 17:00:33,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,786:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,786:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,792:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,792:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,792:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,796:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:33,796:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,796:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,796:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,796:INFO:[LightGBM] [Info] Number of positive: 3741, number of negative: 3709
2025-12-04 17:00:33,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.
2025-12-04 17:00:33,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:33,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:33,797:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:33,797:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:33,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502148 -> initscore=0.008591
2025-12-04 17:00:33,797:INFO:[LightGBM] [Info] Start training from score 0.008591
2025-12-04 17:00:33,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,944:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,944:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,947:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,947:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,947:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,948:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:33,948:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:33,948:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:33,948:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:33,948:INFO:[LightGBM] [Info] Number of positive: 3746, number of negative: 3704
2025-12-04 17:00:33,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.
2025-12-04 17:00:33,949:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:33,949:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:33,949:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:33,949:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:33,949:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502819 -> initscore=0.011275
2025-12-04 17:00:33,949:INFO:[LightGBM] [Info] Start training from score 0.011275
2025-12-04 17:00:33,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:33,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,101:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,101:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,101:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,104:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,104:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,104:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,106:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,106:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,106:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,106:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,106:INFO:[LightGBM] [Info] Number of positive: 3710, number of negative: 3740
2025-12-04 17:00:34,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.
2025-12-04 17:00:34,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,107:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:34,107:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497987 -> initscore=-0.008054
2025-12-04 17:00:34,107:INFO:[LightGBM] [Info] Start training from score -0.008054
2025-12-04 17:00:34,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,248:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,248:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,248:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,251:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,251:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,251:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,252:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,252:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,252:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,252:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,253:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:34,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-12-04 17:00:34,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,253:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:34,254:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:34,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,404:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,405:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,408:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,408:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,408:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,409:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,409:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,409:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,409:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,409:INFO:[LightGBM] [Info] Number of positive: 3728, number of negative: 3722
2025-12-04 17:00:34,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-12-04 17:00:34,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,410:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:34,410:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500403 -> initscore=0.001611
2025-12-04 17:00:34,410:INFO:[LightGBM] [Info] Start training from score 0.001611
2025-12-04 17:00:34,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,567:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,567:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,567:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,570:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,570:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,570:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,572:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,572:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,572:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,572:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,572:INFO:[LightGBM] [Info] Number of positive: 3714, number of negative: 3736
2025-12-04 17:00:34,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.
2025-12-04 17:00:34,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,573:INFO:[LightGBM] [Info] Total Bins 83
2025-12-04 17:00:34,573:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498523 -> initscore=-0.005906
2025-12-04 17:00:34,573:INFO:[LightGBM] [Info] Start training from score -0.005906
2025-12-04 17:00:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,729:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,729:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,732:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,732:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,732:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,733:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,733:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,733:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,733:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,733:INFO:[LightGBM] [Info] Number of positive: 3719, number of negative: 3731
2025-12-04 17:00:34,735:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.
2025-12-04 17:00:34,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,735:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:34,735:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499195 -> initscore=-0.003221
2025-12-04 17:00:34,735:INFO:[LightGBM] [Info] Start training from score -0.003221
2025-12-04 17:00:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,892:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,892:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,895:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,895:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,895:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,896:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:34,897:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:34,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:34,897:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:34,897:INFO:[LightGBM] [Info] Number of positive: 3723, number of negative: 3727
2025-12-04 17:00:34,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.
2025-12-04 17:00:34,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:34,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:34,898:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:34,898:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:34,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499732 -> initscore=-0.001074
2025-12-04 17:00:34,898:INFO:[LightGBM] [Info] Start training from score -0.001074
2025-12-04 17:00:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,063:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,066:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,066:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,066:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,067:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,068:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,068:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,068:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,068:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-04 17:00:35,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.
2025-12-04 17:00:35,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,069:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:35,069:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-04 17:00:35,069:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-04 17:00:35,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,229:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,229:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,233:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,233:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,234:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,234:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,234:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,234:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,234:INFO:[LightGBM] [Info] Number of positive: 3706, number of negative: 3744
2025-12-04 17:00:35,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000731 seconds.
2025-12-04 17:00:35,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,236:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:35,236:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497450 -> initscore=-0.010201
2025-12-04 17:00:35,236:INFO:[LightGBM] [Info] Start training from score -0.010201
2025-12-04 17:00:35,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,417:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,417:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,417:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,421:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,422:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,422:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,422:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-04 17:00:35,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.
2025-12-04 17:00:35,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,423:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:35,423:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-04 17:00:35,424:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-04 17:00:35,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,578:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,578:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,581:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,581:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,581:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,582:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,582:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,582:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,582:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,582:INFO:[LightGBM] [Info] Number of positive: 3730, number of negative: 3720
2025-12-04 17:00:35,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.
2025-12-04 17:00:35,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,583:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:35,584:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500671 -> initscore=0.002685
2025-12-04 17:00:35,584:INFO:[LightGBM] [Info] Start training from score 0.002685
2025-12-04 17:00:35,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2025-12-04 17:00:35,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,742:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,742:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,742:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,746:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,746:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,746:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,747:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,747:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,747:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,748:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:35,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-12-04 17:00:35,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,749:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:35,749:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:35,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,908:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,908:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,908:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,911:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,911:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,911:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,913:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:35,913:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:35,913:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:35,913:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:35,913:INFO:[LightGBM] [Info] Number of positive: 3712, number of negative: 3738
2025-12-04 17:00:35,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.
2025-12-04 17:00:35,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:35,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:35,914:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:35,914:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:35,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498255 -> initscore=-0.006980
2025-12-04 17:00:35,914:INFO:[LightGBM] [Info] Start training from score -0.006980
2025-12-04 17:00:35,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,088:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,091:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,091:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,091:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,092:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,093:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,093:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,093:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,093:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:36,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.
2025-12-04 17:00:36,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,094:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:36,094:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:36,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,255:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,255:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,255:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,258:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,258:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,260:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,260:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,260:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,260:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,260:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-04 17:00:36,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.
2025-12-04 17:00:36,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,261:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:36,261:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-04 17:00:36,261:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-04 17:00:36,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,420:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,420:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,420:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,423:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,423:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,423:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,425:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,425:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,425:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,426:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-04 17:00:36,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.
2025-12-04 17:00:36,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,428:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:36,428:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-04 17:00:36,428:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-04 17:00:36,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,591:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,591:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,591:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,595:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,595:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,595:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,596:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,596:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,596:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-04 17:00:36,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2025-12-04 17:00:36,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,597:INFO:[LightGBM] [Info] Total Bins 83
2025-12-04 17:00:36,598:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-04 17:00:36,598:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-04 17:00:36,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,754:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,754:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,754:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,757:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,757:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,758:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,759:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,759:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,759:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,759:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,759:INFO:[LightGBM] [Info] Number of positive: 3749, number of negative: 3701
2025-12-04 17:00:36,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.
2025-12-04 17:00:36,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,760:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:36,760:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503221 -> initscore=0.012886
2025-12-04 17:00:36,761:INFO:[LightGBM] [Info] Start training from score 0.012886
2025-12-04 17:00:36,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2025-12-04 17:00:36,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,909:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,909:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,909:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,912:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,912:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,912:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,914:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:36,914:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:36,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:36,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:36,914:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-04 17:00:36,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-12-04 17:00:36,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:36,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:36,915:INFO:[LightGBM] [Info] Total Bins 83
2025-12-04 17:00:36,915:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:36,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-04 17:00:36,915:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-04 17:00:36,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:36,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,062:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,062:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,062:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,065:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,065:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,066:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,067:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,067:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,067:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,067:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,067:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:37,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.
2025-12-04 17:00:37,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,068:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:37,068:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,068:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:37,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,219:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,219:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,219:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,223:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,223:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,223:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,224:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,224:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,224:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,224:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,224:INFO:[LightGBM] [Info] Number of positive: 3746, number of negative: 3704
2025-12-04 17:00:37,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-12-04 17:00:37,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,225:INFO:[LightGBM] [Info] Total Bins 83
2025-12-04 17:00:37,225:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502819 -> initscore=0.011275
2025-12-04 17:00:37,225:INFO:[LightGBM] [Info] Start training from score 0.011275
2025-12-04 17:00:37,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,387:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,387:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,387:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,390:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,390:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,390:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,391:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,391:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,391:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,391:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,391:INFO:[LightGBM] [Info] Number of positive: 3727, number of negative: 3723
2025-12-04 17:00:37,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.
2025-12-04 17:00:37,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,392:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:37,392:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,392:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500268 -> initscore=0.001074
2025-12-04 17:00:37,392:INFO:[LightGBM] [Info] Start training from score 0.001074
2025-12-04 17:00:37,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,553:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,556:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,556:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,556:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,557:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,557:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,557:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,557:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,557:INFO:[LightGBM] [Info] Number of positive: 3733, number of negative: 3717
2025-12-04 17:00:37,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
2025-12-04 17:00:37,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,558:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:37,558:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501074 -> initscore=0.004295
2025-12-04 17:00:37,559:INFO:[LightGBM] [Info] Start training from score 0.004295
2025-12-04 17:00:37,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,710:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,714:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,714:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,714:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,715:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,715:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,715:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,715:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,715:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:37,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
2025-12-04 17:00:37,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,716:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:37,716:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,716:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:37,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,872:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,872:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,872:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,875:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,876:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,876:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,877:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:37,877:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:37,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:37,877:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:37,877:INFO:[LightGBM] [Info] Number of positive: 3727, number of negative: 3723
2025-12-04 17:00:37,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.
2025-12-04 17:00:37,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:37,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:37,878:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:37,878:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:37,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500268 -> initscore=0.001074
2025-12-04 17:00:37,878:INFO:[LightGBM] [Info] Start training from score 0.001074
2025-12-04 17:00:37,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:37,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,037:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,037:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,037:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,040:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,041:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,041:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,041:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,041:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,041:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-04 17:00:38,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.
2025-12-04 17:00:38,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,042:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:38,042:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-04 17:00:38,042:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-04 17:00:38,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,205:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,205:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,205:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,208:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,208:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,209:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,209:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,209:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,209:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,209:INFO:[LightGBM] [Info] Number of positive: 3694, number of negative: 3756
2025-12-04 17:00:38,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-12-04 17:00:38,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,210:INFO:[LightGBM] [Info] Total Bins 78
2025-12-04 17:00:38,211:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495839 -> initscore=-0.016645
2025-12-04 17:00:38,211:INFO:[LightGBM] [Info] Start training from score -0.016645
2025-12-04 17:00:38,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,373:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,373:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,373:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,376:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,377:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,377:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,378:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,378:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,378:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,378:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,378:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-04 17:00:38,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-12-04 17:00:38,379:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,379:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,379:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:38,379:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-04 17:00:38,379:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-04 17:00:38,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,535:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,535:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,535:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,540:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,541:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,541:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,541:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,541:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,541:INFO:[LightGBM] [Info] Number of positive: 3738, number of negative: 3712
2025-12-04 17:00:38,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2025-12-04 17:00:38,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,542:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:38,542:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501745 -> initscore=0.006980
2025-12-04 17:00:38,542:INFO:[LightGBM] [Info] Start training from score 0.006980
2025-12-04 17:00:38,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,694:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,694:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,694:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,698:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,699:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,699:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,701:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,701:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,701:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,701:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,702:INFO:[LightGBM] [Info] Number of positive: 3725, number of negative: 3725
2025-12-04 17:00:38,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.
2025-12-04 17:00:38,704:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,704:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,704:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:38,705:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,705:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-04 17:00:38,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,942:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,942:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,942:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,945:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,945:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,945:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,946:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:38,946:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:38,946:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:38,946:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:38,947:INFO:[LightGBM] [Info] Number of positive: 3763, number of negative: 3687
2025-12-04 17:00:38,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.
2025-12-04 17:00:38,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:38,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:38,948:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:38,948:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:38,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505101 -> initscore=0.020403
2025-12-04 17:00:38,948:INFO:[LightGBM] [Info] Start training from score 0.020403
2025-12-04 17:00:38,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:38,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,111:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,111:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,111:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,115:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,115:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,116:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,116:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,116:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,116:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,116:INFO:[LightGBM] [Info] Number of positive: 3720, number of negative: 3730
2025-12-04 17:00:39,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.
2025-12-04 17:00:39,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,117:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:39,117:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499329 -> initscore=-0.002685
2025-12-04 17:00:39,117:INFO:[LightGBM] [Info] Start training from score -0.002685
2025-12-04 17:00:39,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,304:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,304:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,304:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,308:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,308:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,308:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,310:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,310:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,310:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,310:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,310:INFO:[LightGBM] [Info] Number of positive: 3782, number of negative: 3668
2025-12-04 17:00:39,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
2025-12-04 17:00:39,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,311:INFO:[LightGBM] [Info] Total Bins 84
2025-12-04 17:00:39,311:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030606
2025-12-04 17:00:39,312:INFO:[LightGBM] [Info] Start training from score 0.030606
2025-12-04 17:00:39,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,475:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,478:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,478:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,478:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,480:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,480:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,480:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,480:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,480:INFO:[LightGBM] [Info] Number of positive: 3723, number of negative: 3727
2025-12-04 17:00:39,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.
2025-12-04 17:00:39,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,481:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:39,481:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,481:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499732 -> initscore=-0.001074
2025-12-04 17:00:39,481:INFO:[LightGBM] [Info] Start training from score -0.001074
2025-12-04 17:00:39,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,635:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,635:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,635:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,639:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,639:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,639:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,640:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,640:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,640:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,640:INFO:[LightGBM] [Info] Number of positive: 3721, number of negative: 3729
2025-12-04 17:00:39,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.
2025-12-04 17:00:39,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,641:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:39,641:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499463 -> initscore=-0.002148
2025-12-04 17:00:39,641:INFO:[LightGBM] [Info] Start training from score -0.002148
2025-12-04 17:00:39,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,793:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,793:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,793:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,797:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,797:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,797:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,798:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,798:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,798:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,798:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,798:INFO:[LightGBM] [Info] Number of positive: 3731, number of negative: 3719
2025-12-04 17:00:39,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.
2025-12-04 17:00:39,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,799:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:39,799:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,799:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500805 -> initscore=0.003221
2025-12-04 17:00:39,799:INFO:[LightGBM] [Info] Start training from score 0.003221
2025-12-04 17:00:39,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,952:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,953:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,953:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,956:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,956:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,956:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,957:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:39,957:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:39,957:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:39,957:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:39,957:INFO:[LightGBM] [Info] Number of positive: 3711, number of negative: 3739
2025-12-04 17:00:39,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.
2025-12-04 17:00:39,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:39,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:39,958:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:39,958:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:39,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498121 -> initscore=-0.007517
2025-12-04 17:00:39,958:INFO:[LightGBM] [Info] Start training from score -0.007517
2025-12-04 17:00:39,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,134:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,134:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,134:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,139:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,139:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,139:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,142:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:40,143:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,143:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,143:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,144:INFO:[LightGBM] [Info] Number of positive: 3704, number of negative: 3746
2025-12-04 17:00:40,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.
2025-12-04 17:00:40,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:40,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:40,146:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:40,146:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:40,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497181 -> initscore=-0.011275
2025-12-04 17:00:40,147:INFO:[LightGBM] [Info] Start training from score -0.011275
2025-12-04 17:00:40,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,320:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,320:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,320:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,323:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,323:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,323:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,324:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:40,324:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,324:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,324:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,324:INFO:[LightGBM] [Info] Number of positive: 3740, number of negative: 3710
2025-12-04 17:00:40,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.
2025-12-04 17:00:40,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:40,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:40,325:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:40,325:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:40,325:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502013 -> initscore=0.008054
2025-12-04 17:00:40,325:INFO:[LightGBM] [Info] Start training from score 0.008054
2025-12-04 17:00:40,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,488:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,488:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,491:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,491:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,491:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,492:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:40,492:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,492:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,492:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,492:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-04 17:00:40,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.
2025-12-04 17:00:40,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:40,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:40,493:INFO:[LightGBM] [Info] Total Bins 83
2025-12-04 17:00:40,493:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:40,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-04 17:00:40,493:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-04 17:00:40,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,695:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,695:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,695:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,711:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,711:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,711:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,720:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:40,720:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,721:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,721:INFO:[LightGBM] [Info] Number of positive: 3734, number of negative: 3716
2025-12-04 17:00:40,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.
2025-12-04 17:00:40,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:40,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:40,725:INFO:[LightGBM] [Info] Total Bins 81
2025-12-04 17:00:40,725:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:40,725:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501208 -> initscore=0.004832
2025-12-04 17:00:40,725:INFO:[LightGBM] [Info] Start training from score 0.004832
2025-12-04 17:00:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,923:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,923:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,923:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,927:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,927:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,929:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:40,929:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:40,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:40,929:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:40,929:INFO:[LightGBM] [Info] Number of positive: 3726, number of negative: 3724
2025-12-04 17:00:40,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.
2025-12-04 17:00:40,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:40,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:40,930:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:40,930:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:40,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537
2025-12-04 17:00:40,930:INFO:[LightGBM] [Info] Start training from score 0.000537
2025-12-04 17:00:40,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:40,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,083:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,083:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,083:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,086:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,086:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,087:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,088:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,088:INFO:[LightGBM] [Info] Number of positive: 3729, number of negative: 3721
2025-12-04 17:00:41,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.
2025-12-04 17:00:41,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,089:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:41,089:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500537 -> initscore=0.002148
2025-12-04 17:00:41,089:INFO:[LightGBM] [Info] Start training from score 0.002148
2025-12-04 17:00:41,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,244:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,244:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,244:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,247:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,247:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,247:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,248:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,249:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,249:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,249:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,249:INFO:[LightGBM] [Info] Number of positive: 3750, number of negative: 3700
2025-12-04 17:00:41,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.
2025-12-04 17:00:41,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,250:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:41,250:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503356 -> initscore=0.013423
2025-12-04 17:00:41,250:INFO:[LightGBM] [Info] Start training from score 0.013423
2025-12-04 17:00:41,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,426:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,426:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,426:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,434:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,434:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,434:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,436:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,436:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,436:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,436:INFO:[LightGBM] [Info] Number of positive: 3731, number of negative: 3719
2025-12-04 17:00:41,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.
2025-12-04 17:00:41,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,437:INFO:[LightGBM] [Info] Total Bins 82
2025-12-04 17:00:41,437:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500805 -> initscore=0.003221
2025-12-04 17:00:41,437:INFO:[LightGBM] [Info] Start training from score 0.003221
2025-12-04 17:00:41,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,613:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,613:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,613:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,617:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,617:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,619:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,619:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,619:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,619:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,619:INFO:[LightGBM] [Info] Number of positive: 3724, number of negative: 3726
2025-12-04 17:00:41,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.
2025-12-04 17:00:41,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,620:INFO:[LightGBM] [Info] Total Bins 80
2025-12-04 17:00:41,620:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000537
2025-12-04 17:00:41,621:INFO:[LightGBM] [Info] Start training from score -0.000537
2025-12-04 17:00:41,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,789:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,789:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,789:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,793:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,793:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,793:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,794:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,794:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,794:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,794:INFO:[LightGBM] [Info] Number of positive: 3713, number of negative: 3737
2025-12-04 17:00:41,795:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2025-12-04 17:00:41,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,795:INFO:[LightGBM] [Info] Total Bins 77
2025-12-04 17:00:41,795:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,795:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498389 -> initscore=-0.006443
2025-12-04 17:00:41,795:INFO:[LightGBM] [Info] Start training from score -0.006443
2025-12-04 17:00:41,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,956:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,956:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,956:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,959:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,959:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,959:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,960:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-04 17:00:41,960:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:41,960:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:41,960:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:41,960:INFO:[LightGBM] [Info] Number of positive: 3739, number of negative: 3711
2025-12-04 17:00:41,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2025-12-04 17:00:41,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-04 17:00:41,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-04 17:00:41,961:INFO:[LightGBM] [Info] Total Bins 79
2025-12-04 17:00:41,961:INFO:[LightGBM] [Info] Number of data points in the train set: 7450, number of used features: 11
2025-12-04 17:00:41,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501879 -> initscore=0.007517
2025-12-04 17:00:41,961:INFO:[LightGBM] [Info] Start training from score 0.007517
2025-12-04 17:00:41,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:41,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-04 17:00:42,112:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:42,112:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:42,112:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:42,182:INFO:Scoring test/hold-out set
2025-12-04 17:00:42,183:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-04 17:00:42,183:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-04 17:00:42,183:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-12-04 17:00:42,186:WARNING:[LightGBM] [Fatal] The number of features in data (11) is not the same as it was in training data (10).
2025-12-04 17:00:42,186:WARNING:You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.
2025-12-07 13:20:47,318:INFO:PyCaret ClassificationExperiment
2025-12-07 13:20:47,319:INFO:Logging name: clf-default-name
2025-12-07 13:20:47,320:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:20:47,320:INFO:version 3.3.2
2025-12-07 13:20:47,321:INFO:Initializing setup()
2025-12-07 13:20:47,321:INFO:self.USI: 3691
2025-12-07 13:20:47,321:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:20:47,322:INFO:Checking environment
2025-12-07 13:20:47,322:INFO:python_version: 3.11.14
2025-12-07 13:20:47,322:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:20:47,322:INFO:machine: arm64
2025-12-07 13:20:47,323:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:20:47,327:INFO:Memory: svmem(total=8589934592, available=1382711296, percent=83.9, used=2947710976, free=74727424, active=1320828928, inactive=1268973568, wired=1626882048)
2025-12-07 13:20:47,328:INFO:Physical Core: 8
2025-12-07 13:20:47,328:INFO:Logical Core: 8
2025-12-07 13:20:47,328:INFO:Checking libraries
2025-12-07 13:20:47,329:INFO:System:
2025-12-07 13:20:47,329:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:20:47,329:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:20:47,329:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:20:47,329:INFO:PyCaret required dependencies:
2025-12-07 13:20:47,330:INFO:                 pip: 25.3
2025-12-07 13:20:47,330:INFO:          setuptools: 80.9.0
2025-12-07 13:20:47,330:INFO:             pycaret: 3.3.2
2025-12-07 13:20:47,330:INFO:             IPython: 9.7.0
2025-12-07 13:20:47,330:INFO:          ipywidgets: 8.1.8
2025-12-07 13:20:47,330:INFO:                tqdm: 4.67.1
2025-12-07 13:20:47,330:INFO:               numpy: 1.26.4
2025-12-07 13:20:47,330:INFO:              pandas: 2.1.4
2025-12-07 13:20:47,330:INFO:              jinja2: 3.1.6
2025-12-07 13:20:47,330:INFO:               scipy: 1.11.4
2025-12-07 13:20:47,330:INFO:              joblib: 1.3.2
2025-12-07 13:20:47,330:INFO:             sklearn: 1.4.2
2025-12-07 13:20:47,330:INFO:                pyod: 2.0.5
2025-12-07 13:20:47,330:INFO:            imblearn: 0.14.0
2025-12-07 13:20:47,330:INFO:   category_encoders: 2.7.0
2025-12-07 13:20:47,330:INFO:            lightgbm: 4.6.0
2025-12-07 13:20:47,330:INFO:               numba: 0.62.1
2025-12-07 13:20:47,330:INFO:            requests: 2.32.5
2025-12-07 13:20:47,330:INFO:          matplotlib: 3.7.5
2025-12-07 13:20:47,330:INFO:          scikitplot: 0.3.7
2025-12-07 13:20:47,330:INFO:         yellowbrick: 1.5
2025-12-07 13:20:47,330:INFO:              plotly: 6.5.0
2025-12-07 13:20:47,330:INFO:    plotly-resampler: Not installed
2025-12-07 13:20:47,330:INFO:             kaleido: 1.2.0
2025-12-07 13:20:47,330:INFO:           schemdraw: 0.15
2025-12-07 13:20:47,330:INFO:         statsmodels: 0.14.5
2025-12-07 13:20:47,330:INFO:              sktime: 0.26.0
2025-12-07 13:20:47,330:INFO:               tbats: 1.1.3
2025-12-07 13:20:47,330:INFO:            pmdarima: 2.0.4
2025-12-07 13:20:47,330:INFO:              psutil: 7.1.3
2025-12-07 13:20:47,330:INFO:          markupsafe: 3.0.3
2025-12-07 13:20:47,330:INFO:             pickle5: Not installed
2025-12-07 13:20:47,330:INFO:         cloudpickle: 3.1.2
2025-12-07 13:20:47,330:INFO:         deprecation: 2.1.0
2025-12-07 13:20:47,330:INFO:              xxhash: 3.6.0
2025-12-07 13:20:47,330:INFO:           wurlitzer: 3.1.1
2025-12-07 13:20:47,330:INFO:PyCaret optional dependencies:
2025-12-07 13:20:47,331:INFO:                shap: Not installed
2025-12-07 13:20:47,331:INFO:           interpret: Not installed
2025-12-07 13:20:47,331:INFO:                umap: Not installed
2025-12-07 13:20:47,331:INFO:     ydata_profiling: Not installed
2025-12-07 13:20:47,331:INFO:  explainerdashboard: Not installed
2025-12-07 13:20:47,331:INFO:             autoviz: Not installed
2025-12-07 13:20:47,331:INFO:           fairlearn: Not installed
2025-12-07 13:20:47,331:INFO:          deepchecks: Not installed
2025-12-07 13:20:47,331:INFO:             xgboost: Not installed
2025-12-07 13:20:47,331:INFO:            catboost: Not installed
2025-12-07 13:20:47,331:INFO:              kmodes: Not installed
2025-12-07 13:20:47,331:INFO:             mlxtend: Not installed
2025-12-07 13:20:47,331:INFO:       statsforecast: Not installed
2025-12-07 13:20:47,331:INFO:        tune_sklearn: Not installed
2025-12-07 13:20:47,331:INFO:                 ray: Not installed
2025-12-07 13:20:47,331:INFO:            hyperopt: Not installed
2025-12-07 13:20:47,331:INFO:              optuna: Not installed
2025-12-07 13:20:47,331:INFO:               skopt: Not installed
2025-12-07 13:20:47,331:INFO:              mlflow: Not installed
2025-12-07 13:20:47,331:INFO:              gradio: Not installed
2025-12-07 13:20:47,331:INFO:             fastapi: Not installed
2025-12-07 13:20:47,331:INFO:             uvicorn: Not installed
2025-12-07 13:20:47,331:INFO:              m2cgen: Not installed
2025-12-07 13:20:47,331:INFO:           evidently: Not installed
2025-12-07 13:20:47,331:INFO:               fugue: Not installed
2025-12-07 13:20:47,331:INFO:           streamlit: Not installed
2025-12-07 13:20:47,331:INFO:             prophet: Not installed
2025-12-07 13:20:47,331:INFO:None
2025-12-07 13:20:47,331:INFO:Set up data.
2025-12-07 13:20:47,368:INFO:Set up folding strategy.
2025-12-07 13:20:47,373:INFO:Set up train/test split.
2025-12-07 13:20:47,404:INFO:Set up index.
2025-12-07 13:20:47,406:INFO:Assigning column types.
2025-12-07 13:20:47,415:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:20:47,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,495:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,505:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:20:47,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:20:47,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,574:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:20:47,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,655:INFO:Preparing preprocessing pipeline...
2025-12-07 13:20:47,657:INFO:Set up simple imputation.
2025-12-07 13:20:47,658:INFO:Set up imbalanced handling.
2025-12-07 13:20:47,660:INFO:Set up column name cleaning.
2025-12-07 13:20:47,726:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:20:47,729:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'tenure', 'monthly_ charges',
                                             'contract_x_paperless'],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:20:47,729:INFO:Creating final display dataframe.
2025-12-07 13:20:47,790:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 14)
4        Transformed data shape        (9687, 14)
5   Transformed train set shape        (8278, 14)
6    Transformed test set shape        (1409, 14)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3691
2025-12-07 13:20:47,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:20:47,913:INFO:setup() successfully completed in 0.63s...............
2025-12-07 13:20:47,915:INFO:Initializing compare_models()
2025-12-07 13:20:47,915:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:20:47,915:INFO:Checking exceptions
2025-12-07 13:20:47,920:INFO:Preparing display monitor
2025-12-07 13:20:47,949:INFO:Initializing Logistic Regression
2025-12-07 13:20:47,949:INFO:Total runtime is 2.7855237325032553e-06 minutes
2025-12-07 13:20:47,950:INFO:SubProcess create_model() called ==================================
2025-12-07 13:20:47,953:INFO:Initializing create_model()
2025-12-07 13:20:47,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:20:47,953:INFO:Checking exceptions
2025-12-07 13:20:47,953:INFO:Importing libraries
2025-12-07 13:20:47,953:INFO:Copying training dataset
2025-12-07 13:20:47,957:INFO:Defining folds
2025-12-07 13:20:47,957:INFO:Declaring metric variables
2025-12-07 13:20:47,958:INFO:Importing untrained model
2025-12-07 13:20:47,960:INFO:Logistic Regression Imported successfully
2025-12-07 13:20:47,962:INFO:Starting cross validation
2025-12-07 13:20:47,964:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:20:52,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:52,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:52,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:52,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:52,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:52,587:INFO:Calculating mean and std
2025-12-07 13:20:52,593:INFO:Creating metrics dataframe
2025-12-07 13:20:52,607:INFO:Uploading results into container
2025-12-07 13:20:52,608:INFO:Uploading model into container now
2025-12-07 13:20:52,608:INFO:_master_model_container: 1
2025-12-07 13:20:52,609:INFO:_display_container: 2
2025-12-07 13:20:52,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:20:52,610:INFO:create_model() successfully completed......................................
2025-12-07 13:20:55,046:INFO:SubProcess create_model() end ==================================
2025-12-07 13:20:55,046:INFO:Creating metrics dataframe
2025-12-07 13:20:55,049:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:20:55,050:INFO:Total runtime is 0.11834746599197388 minutes
2025-12-07 13:20:55,054:INFO:SubProcess create_model() called ==================================
2025-12-07 13:20:55,055:INFO:Initializing create_model()
2025-12-07 13:20:55,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:20:55,055:INFO:Checking exceptions
2025-12-07 13:20:55,055:INFO:Importing libraries
2025-12-07 13:20:55,055:INFO:Copying training dataset
2025-12-07 13:20:55,059:INFO:Defining folds
2025-12-07 13:20:55,060:INFO:Declaring metric variables
2025-12-07 13:20:55,062:INFO:Importing untrained model
2025-12-07 13:20:55,063:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:20:55,067:INFO:Starting cross validation
2025-12-07 13:20:55,068:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:20:56,599:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:56,723:INFO:Calculating mean and std
2025-12-07 13:20:56,738:INFO:Creating metrics dataframe
2025-12-07 13:20:56,743:INFO:Uploading results into container
2025-12-07 13:20:56,744:INFO:Uploading model into container now
2025-12-07 13:20:56,747:INFO:_master_model_container: 2
2025-12-07 13:20:56,747:INFO:_display_container: 2
2025-12-07 13:20:56,751:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:20:56,752:INFO:create_model() successfully completed......................................
2025-12-07 13:20:57,069:INFO:SubProcess create_model() end ==================================
2025-12-07 13:20:57,069:INFO:Creating metrics dataframe
2025-12-07 13:20:57,076:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:20:57,076:INFO:Total runtime is 0.15211703379948935 minutes
2025-12-07 13:20:57,080:INFO:SubProcess create_model() called ==================================
2025-12-07 13:20:57,080:INFO:Initializing create_model()
2025-12-07 13:20:57,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:20:57,080:INFO:Checking exceptions
2025-12-07 13:20:57,080:INFO:Importing libraries
2025-12-07 13:20:57,080:INFO:Copying training dataset
2025-12-07 13:20:57,086:INFO:Defining folds
2025-12-07 13:20:57,086:INFO:Declaring metric variables
2025-12-07 13:20:57,089:INFO:Importing untrained model
2025-12-07 13:20:57,092:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:20:57,096:INFO:Starting cross validation
2025-12-07 13:20:57,098:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:20:59,299:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:59,314:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-07 13:20:59,965:INFO:Calculating mean and std
2025-12-07 13:20:59,974:INFO:Creating metrics dataframe
2025-12-07 13:20:59,985:INFO:Uploading results into container
2025-12-07 13:20:59,986:INFO:Uploading model into container now
2025-12-07 13:20:59,988:INFO:_master_model_container: 3
2025-12-07 13:20:59,988:INFO:_display_container: 2
2025-12-07 13:20:59,990:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:20:59,990:INFO:create_model() successfully completed......................................
2025-12-07 13:21:00,222:INFO:SubProcess create_model() end ==================================
2025-12-07 13:21:00,222:INFO:Creating metrics dataframe
2025-12-07 13:21:00,225:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:21:00,229:INFO:Initializing create_model()
2025-12-07 13:21:00,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31e1be8d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:21:00,229:INFO:Checking exceptions
2025-12-07 13:21:00,230:INFO:Importing libraries
2025-12-07 13:21:00,230:INFO:Copying training dataset
2025-12-07 13:21:00,235:INFO:Defining folds
2025-12-07 13:21:00,235:INFO:Declaring metric variables
2025-12-07 13:21:00,235:INFO:Importing untrained model
2025-12-07 13:21:00,235:INFO:Declaring custom model
2025-12-07 13:21:00,235:INFO:Logistic Regression Imported successfully
2025-12-07 13:21:00,236:INFO:Cross validation set to False
2025-12-07 13:21:00,236:INFO:Fitting Model
2025-12-07 13:21:00,528:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:21:00,528:INFO:create_model() successfully completed......................................
2025-12-07 13:21:00,723:INFO:_master_model_container: 3
2025-12-07 13:21:00,723:INFO:_display_container: 2
2025-12-07 13:21:00,724:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:21:00,724:INFO:compare_models() successfully completed......................................
2025-12-07 13:21:00,840:INFO:PyCaret ClassificationExperiment
2025-12-07 13:21:00,840:INFO:Logging name: clf-default-name
2025-12-07 13:21:00,840:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:21:00,840:INFO:version 3.3.2
2025-12-07 13:21:00,840:INFO:Initializing setup()
2025-12-07 13:21:00,840:INFO:self.USI: a163
2025-12-07 13:21:00,840:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:21:00,840:INFO:Checking environment
2025-12-07 13:21:00,840:INFO:python_version: 3.11.14
2025-12-07 13:21:00,840:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:21:00,840:INFO:machine: arm64
2025-12-07 13:21:00,840:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:21:00,840:INFO:Memory: svmem(total=8589934592, available=1334312960, percent=84.5, used=3028369408, free=62177280, active=1288404992, inactive=1152843776, wired=1739964416)
2025-12-07 13:21:00,840:INFO:Physical Core: 8
2025-12-07 13:21:00,840:INFO:Logical Core: 8
2025-12-07 13:21:00,840:INFO:Checking libraries
2025-12-07 13:21:00,840:INFO:System:
2025-12-07 13:21:00,840:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:21:00,840:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:21:00,840:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:21:00,840:INFO:PyCaret required dependencies:
2025-12-07 13:21:00,840:INFO:                 pip: 25.3
2025-12-07 13:21:00,840:INFO:          setuptools: 80.9.0
2025-12-07 13:21:00,840:INFO:             pycaret: 3.3.2
2025-12-07 13:21:00,840:INFO:             IPython: 9.7.0
2025-12-07 13:21:00,840:INFO:          ipywidgets: 8.1.8
2025-12-07 13:21:00,840:INFO:                tqdm: 4.67.1
2025-12-07 13:21:00,840:INFO:               numpy: 1.26.4
2025-12-07 13:21:00,841:INFO:              pandas: 2.1.4
2025-12-07 13:21:00,841:INFO:              jinja2: 3.1.6
2025-12-07 13:21:00,841:INFO:               scipy: 1.11.4
2025-12-07 13:21:00,841:INFO:              joblib: 1.3.2
2025-12-07 13:21:00,841:INFO:             sklearn: 1.4.2
2025-12-07 13:21:00,841:INFO:                pyod: 2.0.5
2025-12-07 13:21:00,841:INFO:            imblearn: 0.14.0
2025-12-07 13:21:00,841:INFO:   category_encoders: 2.7.0
2025-12-07 13:21:00,841:INFO:            lightgbm: 4.6.0
2025-12-07 13:21:00,841:INFO:               numba: 0.62.1
2025-12-07 13:21:00,841:INFO:            requests: 2.32.5
2025-12-07 13:21:00,841:INFO:          matplotlib: 3.7.5
2025-12-07 13:21:00,841:INFO:          scikitplot: 0.3.7
2025-12-07 13:21:00,841:INFO:         yellowbrick: 1.5
2025-12-07 13:21:00,841:INFO:              plotly: 6.5.0
2025-12-07 13:21:00,841:INFO:    plotly-resampler: Not installed
2025-12-07 13:21:00,841:INFO:             kaleido: 1.2.0
2025-12-07 13:21:00,841:INFO:           schemdraw: 0.15
2025-12-07 13:21:00,841:INFO:         statsmodels: 0.14.5
2025-12-07 13:21:00,841:INFO:              sktime: 0.26.0
2025-12-07 13:21:00,841:INFO:               tbats: 1.1.3
2025-12-07 13:21:00,841:INFO:            pmdarima: 2.0.4
2025-12-07 13:21:00,841:INFO:              psutil: 7.1.3
2025-12-07 13:21:00,841:INFO:          markupsafe: 3.0.3
2025-12-07 13:21:00,841:INFO:             pickle5: Not installed
2025-12-07 13:21:00,841:INFO:         cloudpickle: 3.1.2
2025-12-07 13:21:00,841:INFO:         deprecation: 2.1.0
2025-12-07 13:21:00,841:INFO:              xxhash: 3.6.0
2025-12-07 13:21:00,841:INFO:           wurlitzer: 3.1.1
2025-12-07 13:21:00,841:INFO:PyCaret optional dependencies:
2025-12-07 13:21:00,841:INFO:                shap: Not installed
2025-12-07 13:21:00,841:INFO:           interpret: Not installed
2025-12-07 13:21:00,841:INFO:                umap: Not installed
2025-12-07 13:21:00,841:INFO:     ydata_profiling: Not installed
2025-12-07 13:21:00,841:INFO:  explainerdashboard: Not installed
2025-12-07 13:21:00,841:INFO:             autoviz: Not installed
2025-12-07 13:21:00,841:INFO:           fairlearn: Not installed
2025-12-07 13:21:00,841:INFO:          deepchecks: Not installed
2025-12-07 13:21:00,841:INFO:             xgboost: Not installed
2025-12-07 13:21:00,841:INFO:            catboost: Not installed
2025-12-07 13:21:00,841:INFO:              kmodes: Not installed
2025-12-07 13:21:00,841:INFO:             mlxtend: Not installed
2025-12-07 13:21:00,841:INFO:       statsforecast: Not installed
2025-12-07 13:21:00,841:INFO:        tune_sklearn: Not installed
2025-12-07 13:21:00,841:INFO:                 ray: Not installed
2025-12-07 13:21:00,841:INFO:            hyperopt: Not installed
2025-12-07 13:21:00,841:INFO:              optuna: Not installed
2025-12-07 13:21:00,841:INFO:               skopt: Not installed
2025-12-07 13:21:00,841:INFO:              mlflow: Not installed
2025-12-07 13:21:00,841:INFO:              gradio: Not installed
2025-12-07 13:21:00,841:INFO:             fastapi: Not installed
2025-12-07 13:21:00,841:INFO:             uvicorn: Not installed
2025-12-07 13:21:00,841:INFO:              m2cgen: Not installed
2025-12-07 13:21:00,841:INFO:           evidently: Not installed
2025-12-07 13:21:00,841:INFO:               fugue: Not installed
2025-12-07 13:21:00,841:INFO:           streamlit: Not installed
2025-12-07 13:21:00,841:INFO:             prophet: Not installed
2025-12-07 13:21:00,841:INFO:None
2025-12-07 13:21:00,841:INFO:Set up data.
2025-12-07 13:21:00,865:INFO:Set up folding strategy.
2025-12-07 13:21:00,865:INFO:Set up train/test split.
2025-12-07 13:21:00,875:INFO:Set up index.
2025-12-07 13:21:00,875:INFO:Assigning column types.
2025-12-07 13:21:00,878:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:21:00,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,934:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:21:00,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,979:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:21:00,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:00,990:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:21:01,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,045:INFO:Preparing preprocessing pipeline...
2025-12-07 13:21:01,046:INFO:Set up simple imputation.
2025-12-07 13:21:01,046:INFO:Set up imbalanced handling.
2025-12-07 13:21:01,047:INFO:Set up column name cleaning.
2025-12-07 13:21:01,077:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:21:01,079:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:21:01,079:INFO:Creating final display dataframe.
2025-12-07 13:21:01,143:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              a163
2025-12-07 13:21:01,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:21:01,209:INFO:setup() successfully completed in 0.37s...............
2025-12-07 13:21:01,212:INFO:Initializing compare_models()
2025-12-07 13:21:01,212:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:21:01,212:INFO:Checking exceptions
2025-12-07 13:21:01,214:INFO:Preparing display monitor
2025-12-07 13:21:01,223:INFO:Initializing Logistic Regression
2025-12-07 13:21:01,223:INFO:Total runtime is 1.4146169026692709e-06 minutes
2025-12-07 13:21:01,224:INFO:SubProcess create_model() called ==================================
2025-12-07 13:21:01,225:INFO:Initializing create_model()
2025-12-07 13:21:01,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e7abd50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:21:01,225:INFO:Checking exceptions
2025-12-07 13:21:01,225:INFO:Importing libraries
2025-12-07 13:21:01,225:INFO:Copying training dataset
2025-12-07 13:21:01,229:INFO:Defining folds
2025-12-07 13:21:01,229:INFO:Declaring metric variables
2025-12-07 13:21:01,230:INFO:Importing untrained model
2025-12-07 13:21:01,232:INFO:Logistic Regression Imported successfully
2025-12-07 13:21:01,234:INFO:Starting cross validation
2025-12-07 13:21:01,236:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:21:01,383:INFO:Calculating mean and std
2025-12-07 13:21:01,384:INFO:Creating metrics dataframe
2025-12-07 13:21:01,384:INFO:Uploading results into container
2025-12-07 13:21:01,385:INFO:Uploading model into container now
2025-12-07 13:21:01,385:INFO:_master_model_container: 1
2025-12-07 13:21:01,385:INFO:_display_container: 2
2025-12-07 13:21:01,385:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:21:01,385:INFO:create_model() successfully completed......................................
2025-12-07 13:21:01,626:INFO:SubProcess create_model() end ==================================
2025-12-07 13:21:01,626:INFO:Creating metrics dataframe
2025-12-07 13:21:01,629:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:21:01,629:INFO:Total runtime is 0.006768051783243815 minutes
2025-12-07 13:21:01,631:INFO:SubProcess create_model() called ==================================
2025-12-07 13:21:01,631:INFO:Initializing create_model()
2025-12-07 13:21:01,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e7abd50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:21:01,631:INFO:Checking exceptions
2025-12-07 13:21:01,631:INFO:Importing libraries
2025-12-07 13:21:01,631:INFO:Copying training dataset
2025-12-07 13:21:01,639:INFO:Defining folds
2025-12-07 13:21:01,639:INFO:Declaring metric variables
2025-12-07 13:21:01,641:INFO:Importing untrained model
2025-12-07 13:21:01,642:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:21:01,645:INFO:Starting cross validation
2025-12-07 13:21:01,645:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:21:01,798:INFO:Calculating mean and std
2025-12-07 13:21:01,799:INFO:Creating metrics dataframe
2025-12-07 13:21:01,801:INFO:Uploading results into container
2025-12-07 13:21:01,801:INFO:Uploading model into container now
2025-12-07 13:21:01,802:INFO:_master_model_container: 2
2025-12-07 13:21:01,802:INFO:_display_container: 2
2025-12-07 13:21:01,802:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:21:01,802:INFO:create_model() successfully completed......................................
2025-12-07 13:21:01,966:INFO:SubProcess create_model() end ==================================
2025-12-07 13:21:01,966:INFO:Creating metrics dataframe
2025-12-07 13:21:01,970:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:21:01,970:INFO:Total runtime is 0.012450063228607177 minutes
2025-12-07 13:21:01,972:INFO:SubProcess create_model() called ==================================
2025-12-07 13:21:01,972:INFO:Initializing create_model()
2025-12-07 13:21:01,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e7abd50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:21:01,972:INFO:Checking exceptions
2025-12-07 13:21:01,972:INFO:Importing libraries
2025-12-07 13:21:01,972:INFO:Copying training dataset
2025-12-07 13:21:01,974:INFO:Defining folds
2025-12-07 13:21:01,974:INFO:Declaring metric variables
2025-12-07 13:21:01,975:INFO:Importing untrained model
2025-12-07 13:21:01,976:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:21:01,979:INFO:Starting cross validation
2025-12-07 13:21:01,979:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:21:03,744:INFO:Calculating mean and std
2025-12-07 13:21:03,747:INFO:Creating metrics dataframe
2025-12-07 13:21:03,751:INFO:Uploading results into container
2025-12-07 13:21:03,752:INFO:Uploading model into container now
2025-12-07 13:21:03,753:INFO:_master_model_container: 3
2025-12-07 13:21:03,754:INFO:_display_container: 2
2025-12-07 13:21:03,755:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:21:03,756:INFO:create_model() successfully completed......................................
2025-12-07 13:21:04,008:INFO:SubProcess create_model() end ==================================
2025-12-07 13:21:04,008:INFO:Creating metrics dataframe
2025-12-07 13:21:04,012:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:21:04,016:INFO:Initializing create_model()
2025-12-07 13:21:04,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:21:04,016:INFO:Checking exceptions
2025-12-07 13:21:04,017:INFO:Importing libraries
2025-12-07 13:21:04,018:INFO:Copying training dataset
2025-12-07 13:21:04,023:INFO:Defining folds
2025-12-07 13:21:04,023:INFO:Declaring metric variables
2025-12-07 13:21:04,023:INFO:Importing untrained model
2025-12-07 13:21:04,023:INFO:Declaring custom model
2025-12-07 13:21:04,024:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:21:04,024:INFO:Cross validation set to False
2025-12-07 13:21:04,024:INFO:Fitting Model
2025-12-07 13:21:04,053:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:21:04,054:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:21:04,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000816 seconds.
2025-12-07 13:21:04,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:21:04,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:21:04,055:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:21:04,055:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:21:04,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:21:04,596:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:21:04,596:INFO:create_model() successfully completed......................................
2025-12-07 13:21:04,912:INFO:_master_model_container: 3
2025-12-07 13:21:04,913:INFO:_display_container: 2
2025-12-07 13:21:04,913:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:21:04,913:INFO:compare_models() successfully completed......................................
2025-12-07 13:22:06,197:INFO:Initializing compare_models()
2025-12-07 13:22:06,199:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:22:06,200:INFO:Checking exceptions
2025-12-07 13:22:06,239:INFO:Preparing display monitor
2025-12-07 13:22:06,279:INFO:Initializing Logistic Regression
2025-12-07 13:22:06,279:INFO:Total runtime is 3.731250762939453e-06 minutes
2025-12-07 13:22:06,280:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:06,281:INFO:Initializing create_model()
2025-12-07 13:22:06,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f6ac290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:06,281:INFO:Checking exceptions
2025-12-07 13:22:06,282:INFO:Importing libraries
2025-12-07 13:22:06,282:INFO:Copying training dataset
2025-12-07 13:22:06,312:INFO:Defining folds
2025-12-07 13:22:06,312:INFO:Declaring metric variables
2025-12-07 13:22:06,313:INFO:Importing untrained model
2025-12-07 13:22:06,315:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:06,317:INFO:Starting cross validation
2025-12-07 13:22:06,322:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:06,491:INFO:Calculating mean and std
2025-12-07 13:22:06,491:INFO:Creating metrics dataframe
2025-12-07 13:22:06,492:INFO:Uploading results into container
2025-12-07 13:22:06,492:INFO:Uploading model into container now
2025-12-07 13:22:06,492:INFO:_master_model_container: 4
2025-12-07 13:22:06,492:INFO:_display_container: 3
2025-12-07 13:22:06,493:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:06,493:INFO:create_model() successfully completed......................................
2025-12-07 13:22:06,683:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:06,683:INFO:Creating metrics dataframe
2025-12-07 13:22:06,685:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:22:06,685:INFO:Total runtime is 0.006781113147735596 minutes
2025-12-07 13:22:06,687:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:06,687:INFO:Initializing create_model()
2025-12-07 13:22:06,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f6ac290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:06,687:INFO:Checking exceptions
2025-12-07 13:22:06,687:INFO:Importing libraries
2025-12-07 13:22:06,687:INFO:Copying training dataset
2025-12-07 13:22:06,690:INFO:Defining folds
2025-12-07 13:22:06,690:INFO:Declaring metric variables
2025-12-07 13:22:06,691:INFO:Importing untrained model
2025-12-07 13:22:06,692:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:22:06,694:INFO:Starting cross validation
2025-12-07 13:22:06,695:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:06,798:INFO:Calculating mean and std
2025-12-07 13:22:06,798:INFO:Creating metrics dataframe
2025-12-07 13:22:06,799:INFO:Uploading results into container
2025-12-07 13:22:06,799:INFO:Uploading model into container now
2025-12-07 13:22:06,799:INFO:_master_model_container: 5
2025-12-07 13:22:06,799:INFO:_display_container: 3
2025-12-07 13:22:06,799:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:22:06,799:INFO:create_model() successfully completed......................................
2025-12-07 13:22:06,910:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:06,910:INFO:Creating metrics dataframe
2025-12-07 13:22:06,912:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:22:06,912:INFO:Total runtime is 0.010561128457387289 minutes
2025-12-07 13:22:06,914:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:06,914:INFO:Initializing create_model()
2025-12-07 13:22:06,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f6ac290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:06,914:INFO:Checking exceptions
2025-12-07 13:22:06,914:INFO:Importing libraries
2025-12-07 13:22:06,914:INFO:Copying training dataset
2025-12-07 13:22:06,917:INFO:Defining folds
2025-12-07 13:22:06,917:INFO:Declaring metric variables
2025-12-07 13:22:06,918:INFO:Importing untrained model
2025-12-07 13:22:06,919:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:06,922:INFO:Starting cross validation
2025-12-07 13:22:06,924:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:08,364:INFO:Calculating mean and std
2025-12-07 13:22:08,365:INFO:Creating metrics dataframe
2025-12-07 13:22:08,366:INFO:Uploading results into container
2025-12-07 13:22:08,366:INFO:Uploading model into container now
2025-12-07 13:22:08,366:INFO:_master_model_container: 6
2025-12-07 13:22:08,367:INFO:_display_container: 3
2025-12-07 13:22:08,367:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:08,367:INFO:create_model() successfully completed......................................
2025-12-07 13:22:08,592:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:08,592:INFO:Creating metrics dataframe
2025-12-07 13:22:08,595:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:22:08,599:INFO:Initializing create_model()
2025-12-07 13:22:08,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:08,599:INFO:Checking exceptions
2025-12-07 13:22:08,602:INFO:Importing libraries
2025-12-07 13:22:08,602:INFO:Copying training dataset
2025-12-07 13:22:08,607:INFO:Defining folds
2025-12-07 13:22:08,607:INFO:Declaring metric variables
2025-12-07 13:22:08,607:INFO:Importing untrained model
2025-12-07 13:22:08,607:INFO:Declaring custom model
2025-12-07 13:22:08,608:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:08,608:INFO:Cross validation set to False
2025-12-07 13:22:08,608:INFO:Fitting Model
2025-12-07 13:22:08,716:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:22:08,719:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:22:08,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.
2025-12-07 13:22:08,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:22:08,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:22:08,722:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:22:08,722:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:22:08,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:22:09,086:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:09,086:INFO:create_model() successfully completed......................................
2025-12-07 13:22:09,198:INFO:_master_model_container: 6
2025-12-07 13:22:09,198:INFO:_display_container: 3
2025-12-07 13:22:09,198:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:09,198:INFO:compare_models() successfully completed......................................
2025-12-07 13:22:09,200:INFO:Initializing compare_models()
2025-12-07 13:22:09,200:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:22:09,200:INFO:Checking exceptions
2025-12-07 13:22:09,201:INFO:Preparing display monitor
2025-12-07 13:22:09,208:INFO:Initializing Logistic Regression
2025-12-07 13:22:09,208:INFO:Total runtime is 1.6609827677408854e-06 minutes
2025-12-07 13:22:09,210:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:09,210:INFO:Initializing create_model()
2025-12-07 13:22:09,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3af690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:09,210:INFO:Checking exceptions
2025-12-07 13:22:09,210:INFO:Importing libraries
2025-12-07 13:22:09,210:INFO:Copying training dataset
2025-12-07 13:22:09,217:INFO:Defining folds
2025-12-07 13:22:09,217:INFO:Declaring metric variables
2025-12-07 13:22:09,218:INFO:Importing untrained model
2025-12-07 13:22:09,220:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:09,222:INFO:Starting cross validation
2025-12-07 13:22:09,222:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:09,358:INFO:Calculating mean and std
2025-12-07 13:22:09,358:INFO:Creating metrics dataframe
2025-12-07 13:22:09,359:INFO:Uploading results into container
2025-12-07 13:22:09,359:INFO:Uploading model into container now
2025-12-07 13:22:09,359:INFO:_master_model_container: 7
2025-12-07 13:22:09,359:INFO:_display_container: 4
2025-12-07 13:22:09,359:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:09,359:INFO:create_model() successfully completed......................................
2025-12-07 13:22:09,563:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:09,563:INFO:Creating metrics dataframe
2025-12-07 13:22:09,566:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:22:09,566:INFO:Total runtime is 0.005958294868469239 minutes
2025-12-07 13:22:09,567:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:09,567:INFO:Initializing create_model()
2025-12-07 13:22:09,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3af690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:09,567:INFO:Checking exceptions
2025-12-07 13:22:09,568:INFO:Importing libraries
2025-12-07 13:22:09,568:INFO:Copying training dataset
2025-12-07 13:22:09,572:INFO:Defining folds
2025-12-07 13:22:09,572:INFO:Declaring metric variables
2025-12-07 13:22:09,574:INFO:Importing untrained model
2025-12-07 13:22:09,575:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:22:09,577:INFO:Starting cross validation
2025-12-07 13:22:09,578:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:09,654:INFO:Calculating mean and std
2025-12-07 13:22:09,654:INFO:Creating metrics dataframe
2025-12-07 13:22:09,655:INFO:Uploading results into container
2025-12-07 13:22:09,655:INFO:Uploading model into container now
2025-12-07 13:22:09,655:INFO:_master_model_container: 8
2025-12-07 13:22:09,655:INFO:_display_container: 4
2025-12-07 13:22:09,655:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:22:09,655:INFO:create_model() successfully completed......................................
2025-12-07 13:22:09,758:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:09,758:INFO:Creating metrics dataframe
2025-12-07 13:22:09,760:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:22:09,761:INFO:Total runtime is 0.009202778339385986 minutes
2025-12-07 13:22:09,762:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:09,762:INFO:Initializing create_model()
2025-12-07 13:22:09,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3af690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:09,762:INFO:Checking exceptions
2025-12-07 13:22:09,762:INFO:Importing libraries
2025-12-07 13:22:09,762:INFO:Copying training dataset
2025-12-07 13:22:09,764:INFO:Defining folds
2025-12-07 13:22:09,764:INFO:Declaring metric variables
2025-12-07 13:22:09,765:INFO:Importing untrained model
2025-12-07 13:22:09,766:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:09,769:INFO:Starting cross validation
2025-12-07 13:22:09,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:11,166:INFO:Calculating mean and std
2025-12-07 13:22:11,167:INFO:Creating metrics dataframe
2025-12-07 13:22:11,168:INFO:Uploading results into container
2025-12-07 13:22:11,168:INFO:Uploading model into container now
2025-12-07 13:22:11,168:INFO:_master_model_container: 9
2025-12-07 13:22:11,168:INFO:_display_container: 4
2025-12-07 13:22:11,168:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:11,169:INFO:create_model() successfully completed......................................
2025-12-07 13:22:11,277:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:11,277:INFO:Creating metrics dataframe
2025-12-07 13:22:11,280:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:22:11,284:INFO:Initializing create_model()
2025-12-07 13:22:11,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31da34d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:11,284:INFO:Checking exceptions
2025-12-07 13:22:11,285:INFO:Importing libraries
2025-12-07 13:22:11,285:INFO:Copying training dataset
2025-12-07 13:22:11,288:INFO:Defining folds
2025-12-07 13:22:11,288:INFO:Declaring metric variables
2025-12-07 13:22:11,288:INFO:Importing untrained model
2025-12-07 13:22:11,288:INFO:Declaring custom model
2025-12-07 13:22:11,288:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:11,288:INFO:Cross validation set to False
2025-12-07 13:22:11,288:INFO:Fitting Model
2025-12-07 13:22:11,310:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:22:11,311:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:22:11,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000663 seconds.
2025-12-07 13:22:11,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:22:11,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:22:11,312:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:22:11,312:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:22:11,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:22:11,663:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:11,663:INFO:create_model() successfully completed......................................
2025-12-07 13:22:11,768:INFO:_master_model_container: 9
2025-12-07 13:22:11,769:INFO:_display_container: 4
2025-12-07 13:22:11,769:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:11,769:INFO:compare_models() successfully completed......................................
2025-12-07 13:22:34,534:INFO:PyCaret ClassificationExperiment
2025-12-07 13:22:34,535:INFO:Logging name: clf-default-name
2025-12-07 13:22:34,535:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:22:34,535:INFO:version 3.3.2
2025-12-07 13:22:34,535:INFO:Initializing setup()
2025-12-07 13:22:34,535:INFO:self.USI: 3377
2025-12-07 13:22:34,535:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:22:34,536:INFO:Checking environment
2025-12-07 13:22:34,536:INFO:python_version: 3.11.14
2025-12-07 13:22:34,536:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:22:34,536:INFO:machine: arm64
2025-12-07 13:22:34,536:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:22:34,536:INFO:Memory: svmem(total=8589934592, available=1379287040, percent=83.9, used=3067019264, free=63995904, active=1328332800, inactive=1310539776, wired=1738686464)
2025-12-07 13:22:34,536:INFO:Physical Core: 8
2025-12-07 13:22:34,536:INFO:Logical Core: 8
2025-12-07 13:22:34,536:INFO:Checking libraries
2025-12-07 13:22:34,536:INFO:System:
2025-12-07 13:22:34,536:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:22:34,536:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:22:34,536:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:22:34,536:INFO:PyCaret required dependencies:
2025-12-07 13:22:34,537:INFO:                 pip: 25.3
2025-12-07 13:22:34,537:INFO:          setuptools: 80.9.0
2025-12-07 13:22:34,537:INFO:             pycaret: 3.3.2
2025-12-07 13:22:34,537:INFO:             IPython: 9.7.0
2025-12-07 13:22:34,537:INFO:          ipywidgets: 8.1.8
2025-12-07 13:22:34,537:INFO:                tqdm: 4.67.1
2025-12-07 13:22:34,537:INFO:               numpy: 1.26.4
2025-12-07 13:22:34,537:INFO:              pandas: 2.1.4
2025-12-07 13:22:34,537:INFO:              jinja2: 3.1.6
2025-12-07 13:22:34,537:INFO:               scipy: 1.11.4
2025-12-07 13:22:34,537:INFO:              joblib: 1.3.2
2025-12-07 13:22:34,537:INFO:             sklearn: 1.4.2
2025-12-07 13:22:34,537:INFO:                pyod: 2.0.5
2025-12-07 13:22:34,537:INFO:            imblearn: 0.14.0
2025-12-07 13:22:34,537:INFO:   category_encoders: 2.7.0
2025-12-07 13:22:34,537:INFO:            lightgbm: 4.6.0
2025-12-07 13:22:34,537:INFO:               numba: 0.62.1
2025-12-07 13:22:34,537:INFO:            requests: 2.32.5
2025-12-07 13:22:34,537:INFO:          matplotlib: 3.7.5
2025-12-07 13:22:34,537:INFO:          scikitplot: 0.3.7
2025-12-07 13:22:34,537:INFO:         yellowbrick: 1.5
2025-12-07 13:22:34,537:INFO:              plotly: 6.5.0
2025-12-07 13:22:34,537:INFO:    plotly-resampler: Not installed
2025-12-07 13:22:34,537:INFO:             kaleido: 1.2.0
2025-12-07 13:22:34,537:INFO:           schemdraw: 0.15
2025-12-07 13:22:34,537:INFO:         statsmodels: 0.14.5
2025-12-07 13:22:34,537:INFO:              sktime: 0.26.0
2025-12-07 13:22:34,537:INFO:               tbats: 1.1.3
2025-12-07 13:22:34,537:INFO:            pmdarima: 2.0.4
2025-12-07 13:22:34,537:INFO:              psutil: 7.1.3
2025-12-07 13:22:34,537:INFO:          markupsafe: 3.0.3
2025-12-07 13:22:34,537:INFO:             pickle5: Not installed
2025-12-07 13:22:34,537:INFO:         cloudpickle: 3.1.2
2025-12-07 13:22:34,537:INFO:         deprecation: 2.1.0
2025-12-07 13:22:34,537:INFO:              xxhash: 3.6.0
2025-12-07 13:22:34,537:INFO:           wurlitzer: 3.1.1
2025-12-07 13:22:34,537:INFO:PyCaret optional dependencies:
2025-12-07 13:22:34,537:INFO:                shap: Not installed
2025-12-07 13:22:34,537:INFO:           interpret: Not installed
2025-12-07 13:22:34,537:INFO:                umap: Not installed
2025-12-07 13:22:34,537:INFO:     ydata_profiling: Not installed
2025-12-07 13:22:34,537:INFO:  explainerdashboard: Not installed
2025-12-07 13:22:34,537:INFO:             autoviz: Not installed
2025-12-07 13:22:34,537:INFO:           fairlearn: Not installed
2025-12-07 13:22:34,537:INFO:          deepchecks: Not installed
2025-12-07 13:22:34,537:INFO:             xgboost: Not installed
2025-12-07 13:22:34,537:INFO:            catboost: Not installed
2025-12-07 13:22:34,537:INFO:              kmodes: Not installed
2025-12-07 13:22:34,537:INFO:             mlxtend: Not installed
2025-12-07 13:22:34,537:INFO:       statsforecast: Not installed
2025-12-07 13:22:34,537:INFO:        tune_sklearn: Not installed
2025-12-07 13:22:34,537:INFO:                 ray: Not installed
2025-12-07 13:22:34,537:INFO:            hyperopt: Not installed
2025-12-07 13:22:34,538:INFO:              optuna: Not installed
2025-12-07 13:22:34,538:INFO:               skopt: Not installed
2025-12-07 13:22:34,538:INFO:              mlflow: Not installed
2025-12-07 13:22:34,538:INFO:              gradio: Not installed
2025-12-07 13:22:34,538:INFO:             fastapi: Not installed
2025-12-07 13:22:34,538:INFO:             uvicorn: Not installed
2025-12-07 13:22:34,538:INFO:              m2cgen: Not installed
2025-12-07 13:22:34,538:INFO:           evidently: Not installed
2025-12-07 13:22:34,538:INFO:               fugue: Not installed
2025-12-07 13:22:34,538:INFO:           streamlit: Not installed
2025-12-07 13:22:34,538:INFO:             prophet: Not installed
2025-12-07 13:22:34,538:INFO:None
2025-12-07 13:22:34,538:INFO:Set up data.
2025-12-07 13:22:34,554:INFO:Set up folding strategy.
2025-12-07 13:22:34,554:INFO:Set up train/test split.
2025-12-07 13:22:34,561:INFO:Set up index.
2025-12-07 13:22:34,561:INFO:Assigning column types.
2025-12-07 13:22:34,564:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:22:34,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,613:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,614:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,625:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:22:34,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:22:34,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,680:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:22:34,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,735:INFO:Preparing preprocessing pipeline...
2025-12-07 13:22:34,737:INFO:Set up simple imputation.
2025-12-07 13:22:34,737:INFO:Set up imbalanced handling.
2025-12-07 13:22:34,737:INFO:Set up column name cleaning.
2025-12-07 13:22:34,759:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:22:34,761:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'tenure', 'monthly_ charges',
                                             'contract_x_paperless'],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:22:34,761:INFO:Creating final display dataframe.
2025-12-07 13:22:34,811:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 14)
4        Transformed data shape        (9687, 14)
5   Transformed train set shape        (8278, 14)
6    Transformed test set shape        (1409, 14)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3377
2025-12-07 13:22:34,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:22:34,874:INFO:setup() successfully completed in 0.35s...............
2025-12-07 13:22:34,875:INFO:Initializing compare_models()
2025-12-07 13:22:34,875:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:22:34,875:INFO:Checking exceptions
2025-12-07 13:22:34,877:INFO:Preparing display monitor
2025-12-07 13:22:34,886:INFO:Initializing Logistic Regression
2025-12-07 13:22:34,886:INFO:Total runtime is 3.166993459065755e-06 minutes
2025-12-07 13:22:34,888:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:34,888:INFO:Initializing create_model()
2025-12-07 13:22:34,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319c64cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:34,888:INFO:Checking exceptions
2025-12-07 13:22:34,888:INFO:Importing libraries
2025-12-07 13:22:34,888:INFO:Copying training dataset
2025-12-07 13:22:34,894:INFO:Defining folds
2025-12-07 13:22:34,894:INFO:Declaring metric variables
2025-12-07 13:22:34,895:INFO:Importing untrained model
2025-12-07 13:22:34,898:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:34,903:INFO:Starting cross validation
2025-12-07 13:22:34,905:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:35,218:INFO:Calculating mean and std
2025-12-07 13:22:35,219:INFO:Creating metrics dataframe
2025-12-07 13:22:35,219:INFO:Uploading results into container
2025-12-07 13:22:35,220:INFO:Uploading model into container now
2025-12-07 13:22:35,220:INFO:_master_model_container: 1
2025-12-07 13:22:35,220:INFO:_display_container: 2
2025-12-07 13:22:35,220:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:35,220:INFO:create_model() successfully completed......................................
2025-12-07 13:22:35,403:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:35,403:INFO:Creating metrics dataframe
2025-12-07 13:22:35,405:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:22:35,405:INFO:Total runtime is 0.008652218182881673 minutes
2025-12-07 13:22:35,406:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:35,406:INFO:Initializing create_model()
2025-12-07 13:22:35,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319c64cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:35,407:INFO:Checking exceptions
2025-12-07 13:22:35,407:INFO:Importing libraries
2025-12-07 13:22:35,407:INFO:Copying training dataset
2025-12-07 13:22:35,409:INFO:Defining folds
2025-12-07 13:22:35,409:INFO:Declaring metric variables
2025-12-07 13:22:35,410:INFO:Importing untrained model
2025-12-07 13:22:35,411:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:22:35,413:INFO:Starting cross validation
2025-12-07 13:22:35,414:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:35,513:INFO:Calculating mean and std
2025-12-07 13:22:35,513:INFO:Creating metrics dataframe
2025-12-07 13:22:35,514:INFO:Uploading results into container
2025-12-07 13:22:35,514:INFO:Uploading model into container now
2025-12-07 13:22:35,515:INFO:_master_model_container: 2
2025-12-07 13:22:35,515:INFO:_display_container: 2
2025-12-07 13:22:35,515:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:22:35,515:INFO:create_model() successfully completed......................................
2025-12-07 13:22:35,625:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:35,625:INFO:Creating metrics dataframe
2025-12-07 13:22:35,627:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:22:35,628:INFO:Total runtime is 0.0123602827390035 minutes
2025-12-07 13:22:35,629:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:35,629:INFO:Initializing create_model()
2025-12-07 13:22:35,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319c64cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:35,629:INFO:Checking exceptions
2025-12-07 13:22:35,629:INFO:Importing libraries
2025-12-07 13:22:35,629:INFO:Copying training dataset
2025-12-07 13:22:35,632:INFO:Defining folds
2025-12-07 13:22:35,632:INFO:Declaring metric variables
2025-12-07 13:22:35,633:INFO:Importing untrained model
2025-12-07 13:22:35,634:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:35,636:INFO:Starting cross validation
2025-12-07 13:22:35,637:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:37,058:INFO:Calculating mean and std
2025-12-07 13:22:37,059:INFO:Creating metrics dataframe
2025-12-07 13:22:37,060:INFO:Uploading results into container
2025-12-07 13:22:37,060:INFO:Uploading model into container now
2025-12-07 13:22:37,060:INFO:_master_model_container: 3
2025-12-07 13:22:37,060:INFO:_display_container: 2
2025-12-07 13:22:37,061:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:37,061:INFO:create_model() successfully completed......................................
2025-12-07 13:22:37,176:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:37,176:INFO:Creating metrics dataframe
2025-12-07 13:22:37,178:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:22:37,182:INFO:Initializing create_model()
2025-12-07 13:22:37,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:37,183:INFO:Checking exceptions
2025-12-07 13:22:37,183:INFO:Importing libraries
2025-12-07 13:22:37,183:INFO:Copying training dataset
2025-12-07 13:22:37,186:INFO:Defining folds
2025-12-07 13:22:37,186:INFO:Declaring metric variables
2025-12-07 13:22:37,186:INFO:Importing untrained model
2025-12-07 13:22:37,186:INFO:Declaring custom model
2025-12-07 13:22:37,187:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:37,187:INFO:Cross validation set to False
2025-12-07 13:22:37,187:INFO:Fitting Model
2025-12-07 13:22:37,361:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:37,361:INFO:create_model() successfully completed......................................
2025-12-07 13:22:37,547:INFO:_master_model_container: 3
2025-12-07 13:22:37,547:INFO:_display_container: 2
2025-12-07 13:22:37,547:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:37,547:INFO:compare_models() successfully completed......................................
2025-12-07 13:22:41,643:INFO:Initializing compare_models()
2025-12-07 13:22:41,644:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:22:41,644:INFO:Checking exceptions
2025-12-07 13:22:41,648:INFO:Preparing display monitor
2025-12-07 13:22:41,663:INFO:Initializing Logistic Regression
2025-12-07 13:22:41,663:INFO:Total runtime is 2.8649965922037762e-06 minutes
2025-12-07 13:22:41,665:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:41,665:INFO:Initializing create_model()
2025-12-07 13:22:41,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3a6390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:41,665:INFO:Checking exceptions
2025-12-07 13:22:41,665:INFO:Importing libraries
2025-12-07 13:22:41,665:INFO:Copying training dataset
2025-12-07 13:22:41,670:INFO:Defining folds
2025-12-07 13:22:41,671:INFO:Declaring metric variables
2025-12-07 13:22:41,672:INFO:Importing untrained model
2025-12-07 13:22:41,673:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:41,676:INFO:Starting cross validation
2025-12-07 13:22:41,678:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:41,938:INFO:Calculating mean and std
2025-12-07 13:22:41,938:INFO:Creating metrics dataframe
2025-12-07 13:22:41,939:INFO:Uploading results into container
2025-12-07 13:22:41,939:INFO:Uploading model into container now
2025-12-07 13:22:41,939:INFO:_master_model_container: 4
2025-12-07 13:22:41,939:INFO:_display_container: 3
2025-12-07 13:22:41,940:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:41,940:INFO:create_model() successfully completed......................................
2025-12-07 13:22:42,049:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:42,049:INFO:Creating metrics dataframe
2025-12-07 13:22:42,051:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:22:42,051:INFO:Total runtime is 0.006462204456329346 minutes
2025-12-07 13:22:42,052:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:42,053:INFO:Initializing create_model()
2025-12-07 13:22:42,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3a6390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:42,053:INFO:Checking exceptions
2025-12-07 13:22:42,053:INFO:Importing libraries
2025-12-07 13:22:42,053:INFO:Copying training dataset
2025-12-07 13:22:42,055:INFO:Defining folds
2025-12-07 13:22:42,055:INFO:Declaring metric variables
2025-12-07 13:22:42,056:INFO:Importing untrained model
2025-12-07 13:22:42,057:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:22:42,060:INFO:Starting cross validation
2025-12-07 13:22:42,060:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:42,145:INFO:Calculating mean and std
2025-12-07 13:22:42,145:INFO:Creating metrics dataframe
2025-12-07 13:22:42,146:INFO:Uploading results into container
2025-12-07 13:22:42,146:INFO:Uploading model into container now
2025-12-07 13:22:42,146:INFO:_master_model_container: 5
2025-12-07 13:22:42,146:INFO:_display_container: 3
2025-12-07 13:22:42,146:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:22:42,146:INFO:create_model() successfully completed......................................
2025-12-07 13:22:42,252:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:42,252:INFO:Creating metrics dataframe
2025-12-07 13:22:42,254:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:22:42,254:INFO:Total runtime is 0.009853418668111166 minutes
2025-12-07 13:22:42,256:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:42,256:INFO:Initializing create_model()
2025-12-07 13:22:42,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f3a6390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:42,256:INFO:Checking exceptions
2025-12-07 13:22:42,256:INFO:Importing libraries
2025-12-07 13:22:42,257:INFO:Copying training dataset
2025-12-07 13:22:42,259:INFO:Defining folds
2025-12-07 13:22:42,259:INFO:Declaring metric variables
2025-12-07 13:22:42,260:INFO:Importing untrained model
2025-12-07 13:22:42,261:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:42,263:INFO:Starting cross validation
2025-12-07 13:22:42,264:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:43,642:INFO:Calculating mean and std
2025-12-07 13:22:43,645:INFO:Creating metrics dataframe
2025-12-07 13:22:43,649:INFO:Uploading results into container
2025-12-07 13:22:43,649:INFO:Uploading model into container now
2025-12-07 13:22:43,649:INFO:_master_model_container: 6
2025-12-07 13:22:43,649:INFO:_display_container: 3
2025-12-07 13:22:43,650:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:43,651:INFO:create_model() successfully completed......................................
2025-12-07 13:22:43,762:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:43,762:INFO:Creating metrics dataframe
2025-12-07 13:22:43,765:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:22:43,769:INFO:Initializing create_model()
2025-12-07 13:22:43,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:43,769:INFO:Checking exceptions
2025-12-07 13:22:43,770:INFO:Importing libraries
2025-12-07 13:22:43,770:INFO:Copying training dataset
2025-12-07 13:22:43,773:INFO:Defining folds
2025-12-07 13:22:43,773:INFO:Declaring metric variables
2025-12-07 13:22:43,773:INFO:Importing untrained model
2025-12-07 13:22:43,773:INFO:Declaring custom model
2025-12-07 13:22:43,773:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:43,773:INFO:Cross validation set to False
2025-12-07 13:22:43,773:INFO:Fitting Model
2025-12-07 13:22:43,937:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:43,937:INFO:create_model() successfully completed......................................
2025-12-07 13:22:44,091:INFO:_master_model_container: 6
2025-12-07 13:22:44,092:INFO:_display_container: 3
2025-12-07 13:22:44,092:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:44,092:INFO:compare_models() successfully completed......................................
2025-12-07 13:22:44,093:INFO:Initializing compare_models()
2025-12-07 13:22:44,093:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:22:44,093:INFO:Checking exceptions
2025-12-07 13:22:44,101:INFO:Preparing display monitor
2025-12-07 13:22:44,151:INFO:Initializing Logistic Regression
2025-12-07 13:22:44,152:INFO:Total runtime is 1.680453618367513e-05 minutes
2025-12-07 13:22:44,160:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:44,160:INFO:Initializing create_model()
2025-12-07 13:22:44,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f4b2190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:44,160:INFO:Checking exceptions
2025-12-07 13:22:44,160:INFO:Importing libraries
2025-12-07 13:22:44,160:INFO:Copying training dataset
2025-12-07 13:22:44,163:INFO:Defining folds
2025-12-07 13:22:44,163:INFO:Declaring metric variables
2025-12-07 13:22:44,186:INFO:Importing untrained model
2025-12-07 13:22:44,192:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:44,201:INFO:Starting cross validation
2025-12-07 13:22:44,202:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:44,327:INFO:Calculating mean and std
2025-12-07 13:22:44,327:INFO:Creating metrics dataframe
2025-12-07 13:22:44,328:INFO:Uploading results into container
2025-12-07 13:22:44,328:INFO:Uploading model into container now
2025-12-07 13:22:44,328:INFO:_master_model_container: 7
2025-12-07 13:22:44,328:INFO:_display_container: 4
2025-12-07 13:22:44,328:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:44,328:INFO:create_model() successfully completed......................................
2025-12-07 13:22:44,427:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:44,427:INFO:Creating metrics dataframe
2025-12-07 13:22:44,429:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:22:44,429:INFO:Total runtime is 0.004633669058481852 minutes
2025-12-07 13:22:44,430:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:44,430:INFO:Initializing create_model()
2025-12-07 13:22:44,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f4b2190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:44,430:INFO:Checking exceptions
2025-12-07 13:22:44,431:INFO:Importing libraries
2025-12-07 13:22:44,431:INFO:Copying training dataset
2025-12-07 13:22:44,433:INFO:Defining folds
2025-12-07 13:22:44,434:INFO:Declaring metric variables
2025-12-07 13:22:44,434:INFO:Importing untrained model
2025-12-07 13:22:44,435:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:22:44,438:INFO:Starting cross validation
2025-12-07 13:22:44,438:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:44,501:INFO:Calculating mean and std
2025-12-07 13:22:44,501:INFO:Creating metrics dataframe
2025-12-07 13:22:44,502:INFO:Uploading results into container
2025-12-07 13:22:44,502:INFO:Uploading model into container now
2025-12-07 13:22:44,502:INFO:_master_model_container: 8
2025-12-07 13:22:44,502:INFO:_display_container: 4
2025-12-07 13:22:44,502:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:22:44,502:INFO:create_model() successfully completed......................................
2025-12-07 13:22:44,601:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:44,601:INFO:Creating metrics dataframe
2025-12-07 13:22:44,603:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:22:44,603:INFO:Total runtime is 0.0075416048367818195 minutes
2025-12-07 13:22:44,605:INFO:SubProcess create_model() called ==================================
2025-12-07 13:22:44,605:INFO:Initializing create_model()
2025-12-07 13:22:44,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f4b2190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:44,605:INFO:Checking exceptions
2025-12-07 13:22:44,605:INFO:Importing libraries
2025-12-07 13:22:44,605:INFO:Copying training dataset
2025-12-07 13:22:44,608:INFO:Defining folds
2025-12-07 13:22:44,608:INFO:Declaring metric variables
2025-12-07 13:22:44,609:INFO:Importing untrained model
2025-12-07 13:22:44,610:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:22:44,612:INFO:Starting cross validation
2025-12-07 13:22:44,613:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:22:46,032:INFO:Calculating mean and std
2025-12-07 13:22:46,032:INFO:Creating metrics dataframe
2025-12-07 13:22:46,033:INFO:Uploading results into container
2025-12-07 13:22:46,033:INFO:Uploading model into container now
2025-12-07 13:22:46,033:INFO:_master_model_container: 9
2025-12-07 13:22:46,034:INFO:_display_container: 4
2025-12-07 13:22:46,035:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:22:46,035:INFO:create_model() successfully completed......................................
2025-12-07 13:22:46,259:INFO:SubProcess create_model() end ==================================
2025-12-07 13:22:46,259:INFO:Creating metrics dataframe
2025-12-07 13:22:46,262:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:22:46,267:INFO:Initializing create_model()
2025-12-07 13:22:46,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:22:46,267:INFO:Checking exceptions
2025-12-07 13:22:46,268:INFO:Importing libraries
2025-12-07 13:22:46,268:INFO:Copying training dataset
2025-12-07 13:22:46,271:INFO:Defining folds
2025-12-07 13:22:46,271:INFO:Declaring metric variables
2025-12-07 13:22:46,271:INFO:Importing untrained model
2025-12-07 13:22:46,271:INFO:Declaring custom model
2025-12-07 13:22:46,271:INFO:Logistic Regression Imported successfully
2025-12-07 13:22:46,272:INFO:Cross validation set to False
2025-12-07 13:22:46,272:INFO:Fitting Model
2025-12-07 13:22:46,467:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:46,467:INFO:create_model() successfully completed......................................
2025-12-07 13:22:46,654:INFO:_master_model_container: 9
2025-12-07 13:22:46,654:INFO:_display_container: 4
2025-12-07 13:22:46,654:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:22:46,655:INFO:compare_models() successfully completed......................................
2025-12-07 13:23:16,126:INFO:Initializing create_model()
2025-12-07 13:23:16,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:23:16,128:INFO:Checking exceptions
2025-12-07 13:23:16,151:INFO:Importing libraries
2025-12-07 13:23:16,152:INFO:Copying training dataset
2025-12-07 13:23:16,159:INFO:Defining folds
2025-12-07 13:23:16,159:INFO:Declaring metric variables
2025-12-07 13:23:16,161:INFO:Importing untrained model
2025-12-07 13:23:16,164:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:23:16,167:INFO:Starting cross validation
2025-12-07 13:23:16,172:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:23:17,743:INFO:Calculating mean and std
2025-12-07 13:23:17,744:INFO:Creating metrics dataframe
2025-12-07 13:23:17,747:INFO:Finalizing model
2025-12-07 13:23:17,764:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:23:17,765:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:23:17,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.
2025-12-07 13:23:17,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:23:17,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:23:17,766:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:23:17,767:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:23:17,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:23:18,135:INFO:Uploading results into container
2025-12-07 13:23:18,136:INFO:Uploading model into container now
2025-12-07 13:23:18,140:INFO:_master_model_container: 10
2025-12-07 13:23:18,140:INFO:_display_container: 5
2025-12-07 13:23:18,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:23:18,141:INFO:create_model() successfully completed......................................
2025-12-07 13:23:18,312:INFO:Initializing tune_model()
2025-12-07 13:23:18,312:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:23:18,312:INFO:Checking exceptions
2025-12-07 13:23:18,319:INFO:Copying training dataset
2025-12-07 13:23:18,322:INFO:Checking base model
2025-12-07 13:23:18,322:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:23:18,323:INFO:Declaring metric variables
2025-12-07 13:23:18,324:INFO:Defining Hyperparameters
2025-12-07 13:23:18,441:INFO:Tuning with n_jobs=-1
2025-12-07 13:23:18,441:INFO:Initializing RandomizedSearchCV
2025-12-07 13:24:40,221:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 6, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-07 13:24:40,230:INFO:Hyperparameter search completed
2025-12-07 13:24:40,230:INFO:SubProcess create_model() called ==================================
2025-12-07 13:24:40,233:INFO:Initializing create_model()
2025-12-07 13:24:40,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319c6afd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 10, 'reg_alpha': 3, 'num_leaves': 6, 'n_estimators': 220, 'min_split_gain': 0.5, 'min_child_samples': 66, 'learning_rate': 0.0005, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-07 13:24:40,233:INFO:Checking exceptions
2025-12-07 13:24:40,234:INFO:Importing libraries
2025-12-07 13:24:40,237:INFO:Copying training dataset
2025-12-07 13:24:40,246:INFO:Defining folds
2025-12-07 13:24:40,247:INFO:Declaring metric variables
2025-12-07 13:24:40,253:INFO:Importing untrained model
2025-12-07 13:24:40,253:INFO:Declaring custom model
2025-12-07 13:24:40,256:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:24:40,259:INFO:Starting cross validation
2025-12-07 13:24:40,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:24:41,026:INFO:Calculating mean and std
2025-12-07 13:24:41,026:INFO:Creating metrics dataframe
2025-12-07 13:24:41,029:INFO:Finalizing model
2025-12-07 13:24:41,050:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:24:41,050:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:24:41,050:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-07 13:24:41,053:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:24:41,053:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:24:41,053:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:24:41,053:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-07 13:24:41,053:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:24:41,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.
2025-12-07 13:24:41,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:24:41,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:24:41,054:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:24:41,055:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:24:41,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:24:41,265:INFO:Uploading results into container
2025-12-07 13:24:41,266:INFO:Uploading model into container now
2025-12-07 13:24:41,267:INFO:_master_model_container: 11
2025-12-07 13:24:41,267:INFO:_display_container: 6
2025-12-07 13:24:41,268:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:24:41,268:INFO:create_model() successfully completed......................................
2025-12-07 13:24:41,514:INFO:SubProcess create_model() end ==================================
2025-12-07 13:24:41,514:INFO:choose_better activated
2025-12-07 13:24:41,515:INFO:SubProcess create_model() called ==================================
2025-12-07 13:24:41,516:INFO:Initializing create_model()
2025-12-07 13:24:41,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31df874d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:24:41,516:INFO:Checking exceptions
2025-12-07 13:24:41,517:INFO:Importing libraries
2025-12-07 13:24:41,517:INFO:Copying training dataset
2025-12-07 13:24:41,519:INFO:Defining folds
2025-12-07 13:24:41,519:INFO:Declaring metric variables
2025-12-07 13:24:41,519:INFO:Importing untrained model
2025-12-07 13:24:41,519:INFO:Declaring custom model
2025-12-07 13:24:41,520:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:24:41,520:INFO:Starting cross validation
2025-12-07 13:24:41,520:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:24:43,058:INFO:Calculating mean and std
2025-12-07 13:24:43,058:INFO:Creating metrics dataframe
2025-12-07 13:24:43,061:INFO:Finalizing model
2025-12-07 13:24:43,086:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:24:43,086:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:24:43,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.
2025-12-07 13:24:43,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:24:43,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:24:43,088:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:24:43,088:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:24:43,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:24:43,462:INFO:Uploading results into container
2025-12-07 13:24:43,464:INFO:Uploading model into container now
2025-12-07 13:24:43,465:INFO:_master_model_container: 12
2025-12-07 13:24:43,465:INFO:_display_container: 7
2025-12-07 13:24:43,467:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:24:43,467:INFO:create_model() successfully completed......................................
2025-12-07 13:24:43,675:INFO:SubProcess create_model() end ==================================
2025-12-07 13:24:43,675:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7224
2025-12-07 13:24:43,675:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8428
2025-12-07 13:24:43,676:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:24:43,676:INFO:choose_better completed
2025-12-07 13:24:43,685:INFO:_master_model_container: 12
2025-12-07 13:24:43,685:INFO:_display_container: 6
2025-12-07 13:24:43,685:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:24:43,686:INFO:tune_model() successfully completed......................................
2025-12-07 13:25:26,613:INFO:PyCaret ClassificationExperiment
2025-12-07 13:25:26,613:INFO:Logging name: clf-default-name
2025-12-07 13:25:26,613:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:25:26,613:INFO:version 3.3.2
2025-12-07 13:25:26,613:INFO:Initializing setup()
2025-12-07 13:25:26,613:INFO:self.USI: 080a
2025-12-07 13:25:26,613:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:25:26,614:INFO:Checking environment
2025-12-07 13:25:26,614:INFO:python_version: 3.11.14
2025-12-07 13:25:26,614:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:25:26,614:INFO:machine: arm64
2025-12-07 13:25:26,614:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:25:26,615:INFO:Memory: svmem(total=8589934592, available=1340178432, percent=84.4, used=2970714112, free=67928064, active=1286127616, inactive=1226407936, wired=1684586496)
2025-12-07 13:25:26,615:INFO:Physical Core: 8
2025-12-07 13:25:26,615:INFO:Logical Core: 8
2025-12-07 13:25:26,615:INFO:Checking libraries
2025-12-07 13:25:26,615:INFO:System:
2025-12-07 13:25:26,615:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:25:26,615:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:25:26,615:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:25:26,615:INFO:PyCaret required dependencies:
2025-12-07 13:25:26,615:INFO:                 pip: 25.3
2025-12-07 13:25:26,615:INFO:          setuptools: 80.9.0
2025-12-07 13:25:26,615:INFO:             pycaret: 3.3.2
2025-12-07 13:25:26,615:INFO:             IPython: 9.7.0
2025-12-07 13:25:26,615:INFO:          ipywidgets: 8.1.8
2025-12-07 13:25:26,615:INFO:                tqdm: 4.67.1
2025-12-07 13:25:26,615:INFO:               numpy: 1.26.4
2025-12-07 13:25:26,615:INFO:              pandas: 2.1.4
2025-12-07 13:25:26,615:INFO:              jinja2: 3.1.6
2025-12-07 13:25:26,615:INFO:               scipy: 1.11.4
2025-12-07 13:25:26,615:INFO:              joblib: 1.3.2
2025-12-07 13:25:26,615:INFO:             sklearn: 1.4.2
2025-12-07 13:25:26,615:INFO:                pyod: 2.0.5
2025-12-07 13:25:26,615:INFO:            imblearn: 0.14.0
2025-12-07 13:25:26,615:INFO:   category_encoders: 2.7.0
2025-12-07 13:25:26,615:INFO:            lightgbm: 4.6.0
2025-12-07 13:25:26,615:INFO:               numba: 0.62.1
2025-12-07 13:25:26,615:INFO:            requests: 2.32.5
2025-12-07 13:25:26,615:INFO:          matplotlib: 3.7.5
2025-12-07 13:25:26,615:INFO:          scikitplot: 0.3.7
2025-12-07 13:25:26,615:INFO:         yellowbrick: 1.5
2025-12-07 13:25:26,615:INFO:              plotly: 6.5.0
2025-12-07 13:25:26,615:INFO:    plotly-resampler: Not installed
2025-12-07 13:25:26,615:INFO:             kaleido: 1.2.0
2025-12-07 13:25:26,615:INFO:           schemdraw: 0.15
2025-12-07 13:25:26,615:INFO:         statsmodels: 0.14.5
2025-12-07 13:25:26,615:INFO:              sktime: 0.26.0
2025-12-07 13:25:26,615:INFO:               tbats: 1.1.3
2025-12-07 13:25:26,615:INFO:            pmdarima: 2.0.4
2025-12-07 13:25:26,615:INFO:              psutil: 7.1.3
2025-12-07 13:25:26,615:INFO:          markupsafe: 3.0.3
2025-12-07 13:25:26,615:INFO:             pickle5: Not installed
2025-12-07 13:25:26,615:INFO:         cloudpickle: 3.1.2
2025-12-07 13:25:26,615:INFO:         deprecation: 2.1.0
2025-12-07 13:25:26,615:INFO:              xxhash: 3.6.0
2025-12-07 13:25:26,615:INFO:           wurlitzer: 3.1.1
2025-12-07 13:25:26,615:INFO:PyCaret optional dependencies:
2025-12-07 13:25:26,615:INFO:                shap: Not installed
2025-12-07 13:25:26,615:INFO:           interpret: Not installed
2025-12-07 13:25:26,615:INFO:                umap: Not installed
2025-12-07 13:25:26,615:INFO:     ydata_profiling: Not installed
2025-12-07 13:25:26,616:INFO:  explainerdashboard: Not installed
2025-12-07 13:25:26,616:INFO:             autoviz: Not installed
2025-12-07 13:25:26,616:INFO:           fairlearn: Not installed
2025-12-07 13:25:26,616:INFO:          deepchecks: Not installed
2025-12-07 13:25:26,616:INFO:             xgboost: Not installed
2025-12-07 13:25:26,616:INFO:            catboost: Not installed
2025-12-07 13:25:26,616:INFO:              kmodes: Not installed
2025-12-07 13:25:26,616:INFO:             mlxtend: Not installed
2025-12-07 13:25:26,616:INFO:       statsforecast: Not installed
2025-12-07 13:25:26,616:INFO:        tune_sklearn: Not installed
2025-12-07 13:25:26,616:INFO:                 ray: Not installed
2025-12-07 13:25:26,616:INFO:            hyperopt: Not installed
2025-12-07 13:25:26,616:INFO:              optuna: Not installed
2025-12-07 13:25:26,616:INFO:               skopt: Not installed
2025-12-07 13:25:26,616:INFO:              mlflow: Not installed
2025-12-07 13:25:26,616:INFO:              gradio: Not installed
2025-12-07 13:25:26,616:INFO:             fastapi: Not installed
2025-12-07 13:25:26,616:INFO:             uvicorn: Not installed
2025-12-07 13:25:26,616:INFO:              m2cgen: Not installed
2025-12-07 13:25:26,617:INFO:           evidently: Not installed
2025-12-07 13:25:26,617:INFO:               fugue: Not installed
2025-12-07 13:25:26,617:INFO:           streamlit: Not installed
2025-12-07 13:25:26,617:INFO:             prophet: Not installed
2025-12-07 13:25:26,617:INFO:None
2025-12-07 13:25:26,617:INFO:Set up data.
2025-12-07 13:25:26,649:INFO:Set up folding strategy.
2025-12-07 13:25:26,649:INFO:Set up train/test split.
2025-12-07 13:25:26,658:INFO:Set up index.
2025-12-07 13:25:26,659:INFO:Assigning column types.
2025-12-07 13:25:26,663:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:25:26,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,712:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,724:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:25:26,741:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:25:26,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,781:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:25:26,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,838:INFO:Preparing preprocessing pipeline...
2025-12-07 13:25:26,840:INFO:Set up simple imputation.
2025-12-07 13:25:26,841:INFO:Set up imbalanced handling.
2025-12-07 13:25:26,842:INFO:Set up column name cleaning.
2025-12-07 13:25:26,881:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:25:26,884:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:25:26,884:INFO:Creating final display dataframe.
2025-12-07 13:25:26,952:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              080a
2025-12-07 13:25:26,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:26,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:27,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:27,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:25:27,028:INFO:setup() successfully completed in 0.43s...............
2025-12-07 13:25:27,034:INFO:Initializing compare_models()
2025-12-07 13:25:27,034:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:25:27,034:INFO:Checking exceptions
2025-12-07 13:25:27,036:INFO:Preparing display monitor
2025-12-07 13:25:27,050:INFO:Initializing Logistic Regression
2025-12-07 13:25:27,050:INFO:Total runtime is 9.401639302571614e-06 minutes
2025-12-07 13:25:27,054:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:27,055:INFO:Initializing create_model()
2025-12-07 13:25:27,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f597390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:27,055:INFO:Checking exceptions
2025-12-07 13:25:27,055:INFO:Importing libraries
2025-12-07 13:25:27,055:INFO:Copying training dataset
2025-12-07 13:25:27,061:INFO:Defining folds
2025-12-07 13:25:27,061:INFO:Declaring metric variables
2025-12-07 13:25:27,063:INFO:Importing untrained model
2025-12-07 13:25:27,064:INFO:Logistic Regression Imported successfully
2025-12-07 13:25:27,066:INFO:Starting cross validation
2025-12-07 13:25:27,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:27,213:INFO:Calculating mean and std
2025-12-07 13:25:27,214:INFO:Creating metrics dataframe
2025-12-07 13:25:27,214:INFO:Uploading results into container
2025-12-07 13:25:27,215:INFO:Uploading model into container now
2025-12-07 13:25:27,215:INFO:_master_model_container: 1
2025-12-07 13:25:27,215:INFO:_display_container: 2
2025-12-07 13:25:27,215:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:25:27,215:INFO:create_model() successfully completed......................................
2025-12-07 13:25:27,431:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:27,432:INFO:Creating metrics dataframe
2025-12-07 13:25:27,434:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:25:27,434:INFO:Total runtime is 0.0064093152681986496 minutes
2025-12-07 13:25:27,435:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:27,435:INFO:Initializing create_model()
2025-12-07 13:25:27,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f597390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:27,435:INFO:Checking exceptions
2025-12-07 13:25:27,436:INFO:Importing libraries
2025-12-07 13:25:27,436:INFO:Copying training dataset
2025-12-07 13:25:27,440:INFO:Defining folds
2025-12-07 13:25:27,440:INFO:Declaring metric variables
2025-12-07 13:25:27,447:INFO:Importing untrained model
2025-12-07 13:25:27,453:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:25:27,468:INFO:Starting cross validation
2025-12-07 13:25:27,471:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:27,604:INFO:Calculating mean and std
2025-12-07 13:25:27,605:INFO:Creating metrics dataframe
2025-12-07 13:25:27,605:INFO:Uploading results into container
2025-12-07 13:25:27,606:INFO:Uploading model into container now
2025-12-07 13:25:27,606:INFO:_master_model_container: 2
2025-12-07 13:25:27,606:INFO:_display_container: 2
2025-12-07 13:25:27,606:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:25:27,606:INFO:create_model() successfully completed......................................
2025-12-07 13:25:27,745:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:27,745:INFO:Creating metrics dataframe
2025-12-07 13:25:27,761:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:25:27,762:INFO:Total runtime is 0.01187144915262858 minutes
2025-12-07 13:25:27,771:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:27,771:INFO:Initializing create_model()
2025-12-07 13:25:27,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f597390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:27,772:INFO:Checking exceptions
2025-12-07 13:25:27,772:INFO:Importing libraries
2025-12-07 13:25:27,772:INFO:Copying training dataset
2025-12-07 13:25:27,811:INFO:Defining folds
2025-12-07 13:25:27,811:INFO:Declaring metric variables
2025-12-07 13:25:27,819:INFO:Importing untrained model
2025-12-07 13:25:27,825:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:27,829:INFO:Starting cross validation
2025-12-07 13:25:27,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:29,222:INFO:Calculating mean and std
2025-12-07 13:25:29,223:INFO:Creating metrics dataframe
2025-12-07 13:25:29,225:INFO:Uploading results into container
2025-12-07 13:25:29,226:INFO:Uploading model into container now
2025-12-07 13:25:29,226:INFO:_master_model_container: 3
2025-12-07 13:25:29,226:INFO:_display_container: 2
2025-12-07 13:25:29,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:29,227:INFO:create_model() successfully completed......................................
2025-12-07 13:25:29,391:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:29,391:INFO:Creating metrics dataframe
2025-12-07 13:25:29,394:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:25:29,399:INFO:Initializing create_model()
2025-12-07 13:25:29,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:29,399:INFO:Checking exceptions
2025-12-07 13:25:29,400:INFO:Importing libraries
2025-12-07 13:25:29,400:INFO:Copying training dataset
2025-12-07 13:25:29,402:INFO:Defining folds
2025-12-07 13:25:29,402:INFO:Declaring metric variables
2025-12-07 13:25:29,402:INFO:Importing untrained model
2025-12-07 13:25:29,402:INFO:Declaring custom model
2025-12-07 13:25:29,403:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:29,403:INFO:Cross validation set to False
2025-12-07 13:25:29,403:INFO:Fitting Model
2025-12-07 13:25:29,426:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:25:29,427:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:25:29,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-12-07 13:25:29,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:25:29,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:25:29,428:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:25:29,428:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:25:29,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:25:29,798:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:29,798:INFO:create_model() successfully completed......................................
2025-12-07 13:25:29,905:INFO:_master_model_container: 3
2025-12-07 13:25:29,905:INFO:_display_container: 2
2025-12-07 13:25:29,905:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:29,905:INFO:compare_models() successfully completed......................................
2025-12-07 13:25:39,452:INFO:Initializing compare_models()
2025-12-07 13:25:39,452:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:25:39,452:INFO:Checking exceptions
2025-12-07 13:25:39,460:INFO:Preparing display monitor
2025-12-07 13:25:39,478:INFO:Initializing Logistic Regression
2025-12-07 13:25:39,478:INFO:Total runtime is 2.2172927856445314e-06 minutes
2025-12-07 13:25:39,480:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:39,481:INFO:Initializing create_model()
2025-12-07 13:25:39,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd6e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:39,481:INFO:Checking exceptions
2025-12-07 13:25:39,481:INFO:Importing libraries
2025-12-07 13:25:39,481:INFO:Copying training dataset
2025-12-07 13:25:39,489:INFO:Defining folds
2025-12-07 13:25:39,489:INFO:Declaring metric variables
2025-12-07 13:25:39,491:INFO:Importing untrained model
2025-12-07 13:25:39,493:INFO:Logistic Regression Imported successfully
2025-12-07 13:25:39,496:INFO:Starting cross validation
2025-12-07 13:25:39,498:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:39,638:INFO:Calculating mean and std
2025-12-07 13:25:39,639:INFO:Creating metrics dataframe
2025-12-07 13:25:39,639:INFO:Uploading results into container
2025-12-07 13:25:39,639:INFO:Uploading model into container now
2025-12-07 13:25:39,640:INFO:_master_model_container: 4
2025-12-07 13:25:39,640:INFO:_display_container: 3
2025-12-07 13:25:39,640:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:25:39,640:INFO:create_model() successfully completed......................................
2025-12-07 13:25:39,819:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:39,819:INFO:Creating metrics dataframe
2025-12-07 13:25:39,822:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:25:39,822:INFO:Total runtime is 0.0057297150293986 minutes
2025-12-07 13:25:39,824:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:39,824:INFO:Initializing create_model()
2025-12-07 13:25:39,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd6e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:39,824:INFO:Checking exceptions
2025-12-07 13:25:39,825:INFO:Importing libraries
2025-12-07 13:25:39,825:INFO:Copying training dataset
2025-12-07 13:25:39,827:INFO:Defining folds
2025-12-07 13:25:39,827:INFO:Declaring metric variables
2025-12-07 13:25:39,828:INFO:Importing untrained model
2025-12-07 13:25:39,829:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:25:39,832:INFO:Starting cross validation
2025-12-07 13:25:39,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:39,924:INFO:Calculating mean and std
2025-12-07 13:25:39,925:INFO:Creating metrics dataframe
2025-12-07 13:25:39,925:INFO:Uploading results into container
2025-12-07 13:25:39,925:INFO:Uploading model into container now
2025-12-07 13:25:39,925:INFO:_master_model_container: 5
2025-12-07 13:25:39,925:INFO:_display_container: 3
2025-12-07 13:25:39,926:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:25:39,926:INFO:create_model() successfully completed......................................
2025-12-07 13:25:40,029:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:40,029:INFO:Creating metrics dataframe
2025-12-07 13:25:40,032:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:25:40,032:INFO:Total runtime is 0.009235533078511556 minutes
2025-12-07 13:25:40,033:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:40,033:INFO:Initializing create_model()
2025-12-07 13:25:40,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd6e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:40,034:INFO:Checking exceptions
2025-12-07 13:25:40,034:INFO:Importing libraries
2025-12-07 13:25:40,034:INFO:Copying training dataset
2025-12-07 13:25:40,036:INFO:Defining folds
2025-12-07 13:25:40,036:INFO:Declaring metric variables
2025-12-07 13:25:40,037:INFO:Importing untrained model
2025-12-07 13:25:40,038:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:40,040:INFO:Starting cross validation
2025-12-07 13:25:40,041:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:41,758:INFO:Calculating mean and std
2025-12-07 13:25:41,762:INFO:Creating metrics dataframe
2025-12-07 13:25:41,765:INFO:Uploading results into container
2025-12-07 13:25:41,766:INFO:Uploading model into container now
2025-12-07 13:25:41,766:INFO:_master_model_container: 6
2025-12-07 13:25:41,766:INFO:_display_container: 3
2025-12-07 13:25:41,767:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:41,767:INFO:create_model() successfully completed......................................
2025-12-07 13:25:41,961:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:41,962:INFO:Creating metrics dataframe
2025-12-07 13:25:41,966:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:25:41,969:INFO:Initializing create_model()
2025-12-07 13:25:41,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:41,969:INFO:Checking exceptions
2025-12-07 13:25:41,971:INFO:Importing libraries
2025-12-07 13:25:41,971:INFO:Copying training dataset
2025-12-07 13:25:41,975:INFO:Defining folds
2025-12-07 13:25:41,975:INFO:Declaring metric variables
2025-12-07 13:25:41,975:INFO:Importing untrained model
2025-12-07 13:25:41,975:INFO:Declaring custom model
2025-12-07 13:25:41,976:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:41,976:INFO:Cross validation set to False
2025-12-07 13:25:41,976:INFO:Fitting Model
2025-12-07 13:25:42,005:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:25:42,006:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:25:42,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.
2025-12-07 13:25:42,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:25:42,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:25:42,007:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:25:42,007:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:25:42,007:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:25:42,355:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:42,355:INFO:create_model() successfully completed......................................
2025-12-07 13:25:42,476:INFO:_master_model_container: 6
2025-12-07 13:25:42,476:INFO:_display_container: 3
2025-12-07 13:25:42,476:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:42,476:INFO:compare_models() successfully completed......................................
2025-12-07 13:25:42,477:INFO:Initializing compare_models()
2025-12-07 13:25:42,477:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:25:42,477:INFO:Checking exceptions
2025-12-07 13:25:42,479:INFO:Preparing display monitor
2025-12-07 13:25:42,486:INFO:Initializing Logistic Regression
2025-12-07 13:25:42,487:INFO:Total runtime is 1.637140909830729e-06 minutes
2025-12-07 13:25:42,488:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:42,489:INFO:Initializing create_model()
2025-12-07 13:25:42,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5d050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:42,489:INFO:Checking exceptions
2025-12-07 13:25:42,489:INFO:Importing libraries
2025-12-07 13:25:42,490:INFO:Copying training dataset
2025-12-07 13:25:42,505:INFO:Defining folds
2025-12-07 13:25:42,505:INFO:Declaring metric variables
2025-12-07 13:25:42,519:INFO:Importing untrained model
2025-12-07 13:25:42,522:INFO:Logistic Regression Imported successfully
2025-12-07 13:25:42,524:INFO:Starting cross validation
2025-12-07 13:25:42,525:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:42,619:INFO:Calculating mean and std
2025-12-07 13:25:42,620:INFO:Creating metrics dataframe
2025-12-07 13:25:42,620:INFO:Uploading results into container
2025-12-07 13:25:42,620:INFO:Uploading model into container now
2025-12-07 13:25:42,621:INFO:_master_model_container: 7
2025-12-07 13:25:42,621:INFO:_display_container: 4
2025-12-07 13:25:42,621:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:25:42,621:INFO:create_model() successfully completed......................................
2025-12-07 13:25:42,721:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:42,721:INFO:Creating metrics dataframe
2025-12-07 13:25:42,724:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:25:42,724:INFO:Total runtime is 0.003954168160756428 minutes
2025-12-07 13:25:42,725:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:42,725:INFO:Initializing create_model()
2025-12-07 13:25:42,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5d050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:42,725:INFO:Checking exceptions
2025-12-07 13:25:42,725:INFO:Importing libraries
2025-12-07 13:25:42,725:INFO:Copying training dataset
2025-12-07 13:25:42,728:INFO:Defining folds
2025-12-07 13:25:42,728:INFO:Declaring metric variables
2025-12-07 13:25:42,729:INFO:Importing untrained model
2025-12-07 13:25:42,730:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:25:42,732:INFO:Starting cross validation
2025-12-07 13:25:42,733:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:42,798:INFO:Calculating mean and std
2025-12-07 13:25:42,798:INFO:Creating metrics dataframe
2025-12-07 13:25:42,798:INFO:Uploading results into container
2025-12-07 13:25:42,798:INFO:Uploading model into container now
2025-12-07 13:25:42,799:INFO:_master_model_container: 8
2025-12-07 13:25:42,799:INFO:_display_container: 4
2025-12-07 13:25:42,799:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:25:42,799:INFO:create_model() successfully completed......................................
2025-12-07 13:25:42,913:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:42,913:INFO:Creating metrics dataframe
2025-12-07 13:25:42,915:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:25:42,916:INFO:Total runtime is 0.0071522355079650865 minutes
2025-12-07 13:25:42,917:INFO:SubProcess create_model() called ==================================
2025-12-07 13:25:42,917:INFO:Initializing create_model()
2025-12-07 13:25:42,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31de5d050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:42,917:INFO:Checking exceptions
2025-12-07 13:25:42,918:INFO:Importing libraries
2025-12-07 13:25:42,918:INFO:Copying training dataset
2025-12-07 13:25:42,920:INFO:Defining folds
2025-12-07 13:25:42,920:INFO:Declaring metric variables
2025-12-07 13:25:42,921:INFO:Importing untrained model
2025-12-07 13:25:42,922:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:42,925:INFO:Starting cross validation
2025-12-07 13:25:42,926:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:44,399:INFO:Calculating mean and std
2025-12-07 13:25:44,404:INFO:Creating metrics dataframe
2025-12-07 13:25:44,410:INFO:Uploading results into container
2025-12-07 13:25:44,411:INFO:Uploading model into container now
2025-12-07 13:25:44,412:INFO:_master_model_container: 9
2025-12-07 13:25:44,412:INFO:_display_container: 4
2025-12-07 13:25:44,414:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:44,414:INFO:create_model() successfully completed......................................
2025-12-07 13:25:44,610:INFO:SubProcess create_model() end ==================================
2025-12-07 13:25:44,610:INFO:Creating metrics dataframe
2025-12-07 13:25:44,614:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:25:44,618:INFO:Initializing create_model()
2025-12-07 13:25:44,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:44,618:INFO:Checking exceptions
2025-12-07 13:25:44,619:INFO:Importing libraries
2025-12-07 13:25:44,620:INFO:Copying training dataset
2025-12-07 13:25:44,624:INFO:Defining folds
2025-12-07 13:25:44,625:INFO:Declaring metric variables
2025-12-07 13:25:44,625:INFO:Importing untrained model
2025-12-07 13:25:44,625:INFO:Declaring custom model
2025-12-07 13:25:44,625:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:44,625:INFO:Cross validation set to False
2025-12-07 13:25:44,625:INFO:Fitting Model
2025-12-07 13:25:44,655:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:25:44,655:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:25:44,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2025-12-07 13:25:44,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:25:44,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:25:44,656:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:25:44,656:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:25:44,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:25:45,003:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:45,003:INFO:create_model() successfully completed......................................
2025-12-07 13:25:45,110:INFO:_master_model_container: 9
2025-12-07 13:25:45,110:INFO:_display_container: 4
2025-12-07 13:25:45,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:45,110:INFO:compare_models() successfully completed......................................
2025-12-07 13:25:50,114:INFO:Initializing create_model()
2025-12-07 13:25:50,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:25:50,116:INFO:Checking exceptions
2025-12-07 13:25:50,135:INFO:Importing libraries
2025-12-07 13:25:50,135:INFO:Copying training dataset
2025-12-07 13:25:50,144:INFO:Defining folds
2025-12-07 13:25:50,144:INFO:Declaring metric variables
2025-12-07 13:25:50,148:INFO:Importing untrained model
2025-12-07 13:25:50,150:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:25:50,155:INFO:Starting cross validation
2025-12-07 13:25:50,156:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:25:51,590:INFO:Calculating mean and std
2025-12-07 13:25:51,590:INFO:Creating metrics dataframe
2025-12-07 13:25:51,593:INFO:Finalizing model
2025-12-07 13:25:51,616:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:25:51,616:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:25:51,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.
2025-12-07 13:25:51,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:25:51,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:25:51,618:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:25:51,618:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:25:51,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:25:51,977:INFO:Uploading results into container
2025-12-07 13:25:51,977:INFO:Uploading model into container now
2025-12-07 13:25:51,983:INFO:_master_model_container: 10
2025-12-07 13:25:51,983:INFO:_display_container: 5
2025-12-07 13:25:51,983:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:25:51,983:INFO:create_model() successfully completed......................................
2025-12-07 13:25:52,176:INFO:Initializing tune_model()
2025-12-07 13:25:52,176:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:25:52,177:INFO:Checking exceptions
2025-12-07 13:25:52,223:INFO:Copying training dataset
2025-12-07 13:25:52,240:INFO:Checking base model
2025-12-07 13:25:52,240:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:25:52,246:INFO:Declaring metric variables
2025-12-07 13:25:52,254:INFO:Defining Hyperparameters
2025-12-07 13:25:52,380:INFO:Tuning with n_jobs=-1
2025-12-07 13:25:52,381:INFO:Initializing RandomizedSearchCV
2025-12-07 13:26:35,158:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:26:35,171:INFO:Hyperparameter search completed
2025-12-07 13:26:35,171:INFO:SubProcess create_model() called ==================================
2025-12-07 13:26:35,172:INFO:Initializing create_model()
2025-12-07 13:26:35,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327fcf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-07 13:26:35,172:INFO:Checking exceptions
2025-12-07 13:26:35,172:INFO:Importing libraries
2025-12-07 13:26:35,172:INFO:Copying training dataset
2025-12-07 13:26:35,177:INFO:Defining folds
2025-12-07 13:26:35,177:INFO:Declaring metric variables
2025-12-07 13:26:35,184:INFO:Importing untrained model
2025-12-07 13:26:35,184:INFO:Declaring custom model
2025-12-07 13:26:35,190:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:26:35,192:INFO:Starting cross validation
2025-12-07 13:26:35,193:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:26:36,142:INFO:Calculating mean and std
2025-12-07 13:26:36,142:INFO:Creating metrics dataframe
2025-12-07 13:26:36,145:INFO:Finalizing model
2025-12-07 13:26:36,174:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-07 13:26:36,174:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:26:36,174:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:26:36,176:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:26:36,176:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-07 13:26:36,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:26:36,176:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:26:36,176:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:26:36,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2025-12-07 13:26:36,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:26:36,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:26:36,177:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:26:36,177:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:26:36,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:26:36,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:26:36,443:INFO:Uploading results into container
2025-12-07 13:26:36,444:INFO:Uploading model into container now
2025-12-07 13:26:36,445:INFO:_master_model_container: 11
2025-12-07 13:26:36,445:INFO:_display_container: 6
2025-12-07 13:26:36,446:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:26:36,446:INFO:create_model() successfully completed......................................
2025-12-07 13:26:36,683:INFO:SubProcess create_model() end ==================================
2025-12-07 13:26:36,683:INFO:choose_better activated
2025-12-07 13:26:36,684:INFO:SubProcess create_model() called ==================================
2025-12-07 13:26:36,685:INFO:Initializing create_model()
2025-12-07 13:26:36,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f521d50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:26:36,685:INFO:Checking exceptions
2025-12-07 13:26:36,686:INFO:Importing libraries
2025-12-07 13:26:36,686:INFO:Copying training dataset
2025-12-07 13:26:36,688:INFO:Defining folds
2025-12-07 13:26:36,688:INFO:Declaring metric variables
2025-12-07 13:26:36,688:INFO:Importing untrained model
2025-12-07 13:26:36,688:INFO:Declaring custom model
2025-12-07 13:26:36,689:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:26:36,689:INFO:Starting cross validation
2025-12-07 13:26:36,689:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:26:38,136:INFO:Calculating mean and std
2025-12-07 13:26:38,136:INFO:Creating metrics dataframe
2025-12-07 13:26:38,137:INFO:Finalizing model
2025-12-07 13:26:38,159:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:26:38,159:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:26:38,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.
2025-12-07 13:26:38,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:26:38,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:26:38,161:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:26:38,161:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:26:38,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:26:38,519:INFO:Uploading results into container
2025-12-07 13:26:38,520:INFO:Uploading model into container now
2025-12-07 13:26:38,520:INFO:_master_model_container: 12
2025-12-07 13:26:38,520:INFO:_display_container: 7
2025-12-07 13:26:38,520:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:26:38,520:INFO:create_model() successfully completed......................................
2025-12-07 13:26:38,630:INFO:SubProcess create_model() end ==================================
2025-12-07 13:26:38,631:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:26:38,631:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-07 13:26:38,631:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:26:38,631:INFO:choose_better completed
2025-12-07 13:26:38,637:INFO:_master_model_container: 12
2025-12-07 13:26:38,637:INFO:_display_container: 6
2025-12-07 13:26:38,638:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:26:38,638:INFO:tune_model() successfully completed......................................
2025-12-07 13:27:53,575:INFO:PyCaret ClassificationExperiment
2025-12-07 13:27:53,575:INFO:Logging name: clf-default-name
2025-12-07 13:27:53,575:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:27:53,575:INFO:version 3.3.2
2025-12-07 13:27:53,575:INFO:Initializing setup()
2025-12-07 13:27:53,575:INFO:self.USI: c739
2025-12-07 13:27:53,575:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:27:53,576:INFO:Checking environment
2025-12-07 13:27:53,576:INFO:python_version: 3.11.14
2025-12-07 13:27:53,576:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:27:53,576:INFO:machine: arm64
2025-12-07 13:27:53,577:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:27:53,577:INFO:Memory: svmem(total=8589934592, available=1564786688, percent=81.8, used=3094839296, free=60751872, active=1520943104, inactive=1498791936, wired=1573896192)
2025-12-07 13:27:53,577:INFO:Physical Core: 8
2025-12-07 13:27:53,577:INFO:Logical Core: 8
2025-12-07 13:27:53,577:INFO:Checking libraries
2025-12-07 13:27:53,577:INFO:System:
2025-12-07 13:27:53,577:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:27:53,577:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:27:53,577:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:27:53,577:INFO:PyCaret required dependencies:
2025-12-07 13:27:53,577:INFO:                 pip: 25.3
2025-12-07 13:27:53,577:INFO:          setuptools: 80.9.0
2025-12-07 13:27:53,577:INFO:             pycaret: 3.3.2
2025-12-07 13:27:53,577:INFO:             IPython: 9.7.0
2025-12-07 13:27:53,577:INFO:          ipywidgets: 8.1.8
2025-12-07 13:27:53,577:INFO:                tqdm: 4.67.1
2025-12-07 13:27:53,577:INFO:               numpy: 1.26.4
2025-12-07 13:27:53,577:INFO:              pandas: 2.1.4
2025-12-07 13:27:53,577:INFO:              jinja2: 3.1.6
2025-12-07 13:27:53,577:INFO:               scipy: 1.11.4
2025-12-07 13:27:53,577:INFO:              joblib: 1.3.2
2025-12-07 13:27:53,578:INFO:             sklearn: 1.4.2
2025-12-07 13:27:53,578:INFO:                pyod: 2.0.5
2025-12-07 13:27:53,578:INFO:            imblearn: 0.14.0
2025-12-07 13:27:53,578:INFO:   category_encoders: 2.7.0
2025-12-07 13:27:53,578:INFO:            lightgbm: 4.6.0
2025-12-07 13:27:53,578:INFO:               numba: 0.62.1
2025-12-07 13:27:53,578:INFO:            requests: 2.32.5
2025-12-07 13:27:53,578:INFO:          matplotlib: 3.7.5
2025-12-07 13:27:53,578:INFO:          scikitplot: 0.3.7
2025-12-07 13:27:53,578:INFO:         yellowbrick: 1.5
2025-12-07 13:27:53,578:INFO:              plotly: 6.5.0
2025-12-07 13:27:53,578:INFO:    plotly-resampler: Not installed
2025-12-07 13:27:53,578:INFO:             kaleido: 1.2.0
2025-12-07 13:27:53,578:INFO:           schemdraw: 0.15
2025-12-07 13:27:53,578:INFO:         statsmodels: 0.14.5
2025-12-07 13:27:53,578:INFO:              sktime: 0.26.0
2025-12-07 13:27:53,578:INFO:               tbats: 1.1.3
2025-12-07 13:27:53,578:INFO:            pmdarima: 2.0.4
2025-12-07 13:27:53,578:INFO:              psutil: 7.1.3
2025-12-07 13:27:53,578:INFO:          markupsafe: 3.0.3
2025-12-07 13:27:53,578:INFO:             pickle5: Not installed
2025-12-07 13:27:53,578:INFO:         cloudpickle: 3.1.2
2025-12-07 13:27:53,578:INFO:         deprecation: 2.1.0
2025-12-07 13:27:53,578:INFO:              xxhash: 3.6.0
2025-12-07 13:27:53,578:INFO:           wurlitzer: 3.1.1
2025-12-07 13:27:53,578:INFO:PyCaret optional dependencies:
2025-12-07 13:27:53,578:INFO:                shap: Not installed
2025-12-07 13:27:53,578:INFO:           interpret: Not installed
2025-12-07 13:27:53,578:INFO:                umap: Not installed
2025-12-07 13:27:53,578:INFO:     ydata_profiling: Not installed
2025-12-07 13:27:53,578:INFO:  explainerdashboard: Not installed
2025-12-07 13:27:53,578:INFO:             autoviz: Not installed
2025-12-07 13:27:53,578:INFO:           fairlearn: Not installed
2025-12-07 13:27:53,578:INFO:          deepchecks: Not installed
2025-12-07 13:27:53,578:INFO:             xgboost: Not installed
2025-12-07 13:27:53,578:INFO:            catboost: Not installed
2025-12-07 13:27:53,578:INFO:              kmodes: Not installed
2025-12-07 13:27:53,578:INFO:             mlxtend: Not installed
2025-12-07 13:27:53,578:INFO:       statsforecast: Not installed
2025-12-07 13:27:53,578:INFO:        tune_sklearn: Not installed
2025-12-07 13:27:53,578:INFO:                 ray: Not installed
2025-12-07 13:27:53,578:INFO:            hyperopt: Not installed
2025-12-07 13:27:53,578:INFO:              optuna: Not installed
2025-12-07 13:27:53,578:INFO:               skopt: Not installed
2025-12-07 13:27:53,578:INFO:              mlflow: Not installed
2025-12-07 13:27:53,578:INFO:              gradio: Not installed
2025-12-07 13:27:53,578:INFO:             fastapi: Not installed
2025-12-07 13:27:53,578:INFO:             uvicorn: Not installed
2025-12-07 13:27:53,578:INFO:              m2cgen: Not installed
2025-12-07 13:27:53,578:INFO:           evidently: Not installed
2025-12-07 13:27:53,578:INFO:               fugue: Not installed
2025-12-07 13:27:53,578:INFO:           streamlit: Not installed
2025-12-07 13:27:53,578:INFO:             prophet: Not installed
2025-12-07 13:27:53,578:INFO:None
2025-12-07 13:27:53,578:INFO:Set up data.
2025-12-07 13:27:53,591:INFO:Set up folding strategy.
2025-12-07 13:27:53,591:INFO:Set up train/test split.
2025-12-07 13:27:53,602:INFO:Set up index.
2025-12-07 13:27:53,602:INFO:Assigning column types.
2025-12-07 13:27:53,605:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:27:53,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,665:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:27:53,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:27:53,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,719:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:27:53,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,774:INFO:Preparing preprocessing pipeline...
2025-12-07 13:27:53,776:INFO:Set up simple imputation.
2025-12-07 13:27:53,776:INFO:Set up imbalanced handling.
2025-12-07 13:27:53,777:INFO:Set up column name cleaning.
2025-12-07 13:27:53,799:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:27:53,801:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'tenure', 'monthly_ charges',
                                             'contract_x_paperless'],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:27:53,801:INFO:Creating final display dataframe.
2025-12-07 13:27:53,856:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 14)
4        Transformed data shape        (9687, 14)
5   Transformed train set shape        (8278, 14)
6    Transformed test set shape        (1409, 14)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              c739
2025-12-07 13:27:53,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:27:53,924:INFO:setup() successfully completed in 0.35s...............
2025-12-07 13:27:53,925:INFO:Initializing compare_models()
2025-12-07 13:27:53,925:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:27:53,925:INFO:Checking exceptions
2025-12-07 13:27:53,928:INFO:Preparing display monitor
2025-12-07 13:27:53,936:INFO:Initializing Logistic Regression
2025-12-07 13:27:53,936:INFO:Total runtime is 1.8517176310221354e-06 minutes
2025-12-07 13:27:53,937:INFO:SubProcess create_model() called ==================================
2025-12-07 13:27:53,937:INFO:Initializing create_model()
2025-12-07 13:27:53,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd7910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:27:53,938:INFO:Checking exceptions
2025-12-07 13:27:53,938:INFO:Importing libraries
2025-12-07 13:27:53,938:INFO:Copying training dataset
2025-12-07 13:27:53,942:INFO:Defining folds
2025-12-07 13:27:53,942:INFO:Declaring metric variables
2025-12-07 13:27:53,944:INFO:Importing untrained model
2025-12-07 13:27:53,946:INFO:Logistic Regression Imported successfully
2025-12-07 13:27:53,949:INFO:Starting cross validation
2025-12-07 13:27:53,950:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:27:54,146:INFO:Calculating mean and std
2025-12-07 13:27:54,146:INFO:Creating metrics dataframe
2025-12-07 13:27:54,147:INFO:Uploading results into container
2025-12-07 13:27:54,147:INFO:Uploading model into container now
2025-12-07 13:27:54,147:INFO:_master_model_container: 1
2025-12-07 13:27:54,147:INFO:_display_container: 2
2025-12-07 13:27:54,147:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:27:54,147:INFO:create_model() successfully completed......................................
2025-12-07 13:27:54,330:INFO:SubProcess create_model() end ==================================
2025-12-07 13:27:54,330:INFO:Creating metrics dataframe
2025-12-07 13:27:54,332:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:27:54,332:INFO:Total runtime is 0.006604703267415364 minutes
2025-12-07 13:27:54,334:INFO:SubProcess create_model() called ==================================
2025-12-07 13:27:54,334:INFO:Initializing create_model()
2025-12-07 13:27:54,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd7910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:27:54,334:INFO:Checking exceptions
2025-12-07 13:27:54,334:INFO:Importing libraries
2025-12-07 13:27:54,334:INFO:Copying training dataset
2025-12-07 13:27:54,337:INFO:Defining folds
2025-12-07 13:27:54,337:INFO:Declaring metric variables
2025-12-07 13:27:54,338:INFO:Importing untrained model
2025-12-07 13:27:54,339:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:27:54,341:INFO:Starting cross validation
2025-12-07 13:27:54,341:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:27:54,491:INFO:Calculating mean and std
2025-12-07 13:27:54,491:INFO:Creating metrics dataframe
2025-12-07 13:27:54,492:INFO:Uploading results into container
2025-12-07 13:27:54,492:INFO:Uploading model into container now
2025-12-07 13:27:54,492:INFO:_master_model_container: 2
2025-12-07 13:27:54,492:INFO:_display_container: 2
2025-12-07 13:27:54,492:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:27:54,492:INFO:create_model() successfully completed......................................
2025-12-07 13:27:54,600:INFO:SubProcess create_model() end ==================================
2025-12-07 13:27:54,600:INFO:Creating metrics dataframe
2025-12-07 13:27:54,603:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:27:54,603:INFO:Total runtime is 0.011111736297607422 minutes
2025-12-07 13:27:54,604:INFO:SubProcess create_model() called ==================================
2025-12-07 13:27:54,604:INFO:Initializing create_model()
2025-12-07 13:27:54,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddd7910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:27:54,604:INFO:Checking exceptions
2025-12-07 13:27:54,605:INFO:Importing libraries
2025-12-07 13:27:54,605:INFO:Copying training dataset
2025-12-07 13:27:54,607:INFO:Defining folds
2025-12-07 13:27:54,607:INFO:Declaring metric variables
2025-12-07 13:27:54,608:INFO:Importing untrained model
2025-12-07 13:27:54,609:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:27:54,611:INFO:Starting cross validation
2025-12-07 13:27:54,612:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:27:55,966:INFO:Calculating mean and std
2025-12-07 13:27:55,967:INFO:Creating metrics dataframe
2025-12-07 13:27:55,968:INFO:Uploading results into container
2025-12-07 13:27:55,968:INFO:Uploading model into container now
2025-12-07 13:27:55,969:INFO:_master_model_container: 3
2025-12-07 13:27:55,969:INFO:_display_container: 2
2025-12-07 13:27:55,969:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:27:55,969:INFO:create_model() successfully completed......................................
2025-12-07 13:27:56,150:INFO:SubProcess create_model() end ==================================
2025-12-07 13:27:56,150:INFO:Creating metrics dataframe
2025-12-07 13:27:56,153:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:27:56,156:INFO:Initializing create_model()
2025-12-07 13:27:56,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:27:56,156:INFO:Checking exceptions
2025-12-07 13:27:56,157:INFO:Importing libraries
2025-12-07 13:27:56,157:INFO:Copying training dataset
2025-12-07 13:27:56,161:INFO:Defining folds
2025-12-07 13:27:56,161:INFO:Declaring metric variables
2025-12-07 13:27:56,161:INFO:Importing untrained model
2025-12-07 13:27:56,161:INFO:Declaring custom model
2025-12-07 13:27:56,161:INFO:Logistic Regression Imported successfully
2025-12-07 13:27:56,162:INFO:Cross validation set to False
2025-12-07 13:27:56,162:INFO:Fitting Model
2025-12-07 13:27:56,467:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:27:56,467:INFO:create_model() successfully completed......................................
2025-12-07 13:27:56,643:INFO:_master_model_container: 3
2025-12-07 13:27:56,643:INFO:_display_container: 2
2025-12-07 13:27:56,644:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:27:56,644:INFO:compare_models() successfully completed......................................
2025-12-07 13:28:51,419:INFO:Initializing create_model()
2025-12-07 13:28:51,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:28:51,421:INFO:Checking exceptions
2025-12-07 13:28:51,558:INFO:Importing libraries
2025-12-07 13:28:51,561:INFO:Copying training dataset
2025-12-07 13:28:51,570:INFO:Defining folds
2025-12-07 13:28:51,570:INFO:Declaring metric variables
2025-12-07 13:28:51,572:INFO:Importing untrained model
2025-12-07 13:28:51,574:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:28:51,576:INFO:Starting cross validation
2025-12-07 13:28:51,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:28:53,061:INFO:Calculating mean and std
2025-12-07 13:28:53,062:INFO:Creating metrics dataframe
2025-12-07 13:28:53,065:INFO:Finalizing model
2025-12-07 13:28:53,095:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:28:53,095:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:28:53,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
2025-12-07 13:28:53,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:28:53,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:28:53,097:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:28:53,097:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:28:53,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:28:53,468:INFO:Uploading results into container
2025-12-07 13:28:53,469:INFO:Uploading model into container now
2025-12-07 13:28:53,473:INFO:_master_model_container: 4
2025-12-07 13:28:53,473:INFO:_display_container: 3
2025-12-07 13:28:53,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:28:53,474:INFO:create_model() successfully completed......................................
2025-12-07 13:28:53,739:INFO:Initializing tune_model()
2025-12-07 13:28:53,740:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:28:53,740:INFO:Checking exceptions
2025-12-07 13:28:53,747:INFO:Copying training dataset
2025-12-07 13:28:53,750:INFO:Checking base model
2025-12-07 13:28:53,750:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:28:53,752:INFO:Declaring metric variables
2025-12-07 13:28:53,753:INFO:Defining Hyperparameters
2025-12-07 13:28:53,938:INFO:Tuning with n_jobs=-1
2025-12-07 13:28:53,939:INFO:Initializing RandomizedSearchCV
2025-12-07 13:30:15,700:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 6, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-12-07 13:30:15,715:INFO:Hyperparameter search completed
2025-12-07 13:30:15,715:INFO:SubProcess create_model() called ==================================
2025-12-07 13:30:15,718:INFO:Initializing create_model()
2025-12-07 13:30:15,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 10, 'reg_alpha': 3, 'num_leaves': 6, 'n_estimators': 220, 'min_split_gain': 0.5, 'min_child_samples': 66, 'learning_rate': 0.0005, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-12-07 13:30:15,718:INFO:Checking exceptions
2025-12-07 13:30:15,718:INFO:Importing libraries
2025-12-07 13:30:15,720:INFO:Copying training dataset
2025-12-07 13:30:15,732:INFO:Defining folds
2025-12-07 13:30:15,733:INFO:Declaring metric variables
2025-12-07 13:30:15,736:INFO:Importing untrained model
2025-12-07 13:30:15,736:INFO:Declaring custom model
2025-12-07 13:30:15,738:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:30:15,741:INFO:Starting cross validation
2025-12-07 13:30:15,743:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:30:16,639:INFO:Calculating mean and std
2025-12-07 13:30:16,640:INFO:Creating metrics dataframe
2025-12-07 13:30:16,643:INFO:Finalizing model
2025-12-07 13:30:16,660:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:30:16,660:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:30:16,660:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-07 13:30:16,665:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:30:16,665:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:30:16,665:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:30:16,665:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-12-07 13:30:16,665:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:30:16,666:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.
2025-12-07 13:30:16,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:30:16,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:30:16,666:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:30:16,666:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:30:16,666:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:30:16,879:INFO:Uploading results into container
2025-12-07 13:30:16,880:INFO:Uploading model into container now
2025-12-07 13:30:16,882:INFO:_master_model_container: 5
2025-12-07 13:30:16,882:INFO:_display_container: 4
2025-12-07 13:30:16,883:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:30:16,883:INFO:create_model() successfully completed......................................
2025-12-07 13:30:17,161:INFO:SubProcess create_model() end ==================================
2025-12-07 13:30:17,161:INFO:choose_better activated
2025-12-07 13:30:17,162:INFO:SubProcess create_model() called ==================================
2025-12-07 13:30:17,163:INFO:Initializing create_model()
2025-12-07 13:30:17,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31c3eddd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:30:17,163:INFO:Checking exceptions
2025-12-07 13:30:17,164:INFO:Importing libraries
2025-12-07 13:30:17,164:INFO:Copying training dataset
2025-12-07 13:30:17,167:INFO:Defining folds
2025-12-07 13:30:17,167:INFO:Declaring metric variables
2025-12-07 13:30:17,167:INFO:Importing untrained model
2025-12-07 13:30:17,167:INFO:Declaring custom model
2025-12-07 13:30:17,168:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:30:17,168:INFO:Starting cross validation
2025-12-07 13:30:17,168:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:30:18,514:INFO:Calculating mean and std
2025-12-07 13:30:18,514:INFO:Creating metrics dataframe
2025-12-07 13:30:18,515:INFO:Finalizing model
2025-12-07 13:30:18,531:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:30:18,531:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:30:18,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
2025-12-07 13:30:18,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-07 13:30:18,533:INFO:[LightGBM] [Info] Total Bins 1972
2025-12-07 13:30:18,533:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 13
2025-12-07 13:30:18,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:30:18,962:INFO:Uploading results into container
2025-12-07 13:30:18,962:INFO:Uploading model into container now
2025-12-07 13:30:18,963:INFO:_master_model_container: 6
2025-12-07 13:30:18,963:INFO:_display_container: 5
2025-12-07 13:30:18,963:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:30:18,963:INFO:create_model() successfully completed......................................
2025-12-07 13:30:19,072:INFO:SubProcess create_model() end ==================================
2025-12-07 13:30:19,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7224
2025-12-07 13:30:19,073:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8428
2025-12-07 13:30:19,073:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:30:19,073:INFO:choose_better completed
2025-12-07 13:30:19,079:INFO:_master_model_container: 6
2025-12-07 13:30:19,079:INFO:_display_container: 4
2025-12-07 13:30:19,079:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=220, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=3, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:30:19,079:INFO:tune_model() successfully completed......................................
2025-12-07 13:34:59,363:INFO:PyCaret ClassificationExperiment
2025-12-07 13:34:59,364:INFO:Logging name: clf-default-name
2025-12-07 13:34:59,364:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:34:59,364:INFO:version 3.3.2
2025-12-07 13:34:59,364:INFO:Initializing setup()
2025-12-07 13:34:59,364:INFO:self.USI: 6c14
2025-12-07 13:34:59,364:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:34:59,364:INFO:Checking environment
2025-12-07 13:34:59,364:INFO:python_version: 3.11.14
2025-12-07 13:34:59,364:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:34:59,364:INFO:machine: arm64
2025-12-07 13:34:59,364:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:34:59,366:INFO:Memory: svmem(total=8589934592, available=1411760128, percent=83.6, used=3005726720, free=63848448, active=1369276416, inactive=1330806784, wired=1636450304)
2025-12-07 13:34:59,366:INFO:Physical Core: 8
2025-12-07 13:34:59,366:INFO:Logical Core: 8
2025-12-07 13:34:59,366:INFO:Checking libraries
2025-12-07 13:34:59,366:INFO:System:
2025-12-07 13:34:59,366:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:34:59,366:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:34:59,366:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:34:59,366:INFO:PyCaret required dependencies:
2025-12-07 13:34:59,366:INFO:                 pip: 25.3
2025-12-07 13:34:59,366:INFO:          setuptools: 80.9.0
2025-12-07 13:34:59,367:INFO:             pycaret: 3.3.2
2025-12-07 13:34:59,367:INFO:             IPython: 9.7.0
2025-12-07 13:34:59,367:INFO:          ipywidgets: 8.1.8
2025-12-07 13:34:59,367:INFO:                tqdm: 4.67.1
2025-12-07 13:34:59,367:INFO:               numpy: 1.26.4
2025-12-07 13:34:59,367:INFO:              pandas: 2.1.4
2025-12-07 13:34:59,367:INFO:              jinja2: 3.1.6
2025-12-07 13:34:59,367:INFO:               scipy: 1.11.4
2025-12-07 13:34:59,367:INFO:              joblib: 1.3.2
2025-12-07 13:34:59,367:INFO:             sklearn: 1.4.2
2025-12-07 13:34:59,367:INFO:                pyod: 2.0.5
2025-12-07 13:34:59,367:INFO:            imblearn: 0.14.0
2025-12-07 13:34:59,367:INFO:   category_encoders: 2.7.0
2025-12-07 13:34:59,367:INFO:            lightgbm: 4.6.0
2025-12-07 13:34:59,367:INFO:               numba: 0.62.1
2025-12-07 13:34:59,367:INFO:            requests: 2.32.5
2025-12-07 13:34:59,367:INFO:          matplotlib: 3.7.5
2025-12-07 13:34:59,367:INFO:          scikitplot: 0.3.7
2025-12-07 13:34:59,367:INFO:         yellowbrick: 1.5
2025-12-07 13:34:59,367:INFO:              plotly: 6.5.0
2025-12-07 13:34:59,367:INFO:    plotly-resampler: Not installed
2025-12-07 13:34:59,367:INFO:             kaleido: 1.2.0
2025-12-07 13:34:59,367:INFO:           schemdraw: 0.15
2025-12-07 13:34:59,367:INFO:         statsmodels: 0.14.5
2025-12-07 13:34:59,367:INFO:              sktime: 0.26.0
2025-12-07 13:34:59,367:INFO:               tbats: 1.1.3
2025-12-07 13:34:59,367:INFO:            pmdarima: 2.0.4
2025-12-07 13:34:59,367:INFO:              psutil: 7.1.3
2025-12-07 13:34:59,367:INFO:          markupsafe: 3.0.3
2025-12-07 13:34:59,367:INFO:             pickle5: Not installed
2025-12-07 13:34:59,367:INFO:         cloudpickle: 3.1.2
2025-12-07 13:34:59,367:INFO:         deprecation: 2.1.0
2025-12-07 13:34:59,367:INFO:              xxhash: 3.6.0
2025-12-07 13:34:59,367:INFO:           wurlitzer: 3.1.1
2025-12-07 13:34:59,367:INFO:PyCaret optional dependencies:
2025-12-07 13:34:59,367:INFO:                shap: Not installed
2025-12-07 13:34:59,367:INFO:           interpret: Not installed
2025-12-07 13:34:59,367:INFO:                umap: Not installed
2025-12-07 13:34:59,367:INFO:     ydata_profiling: Not installed
2025-12-07 13:34:59,367:INFO:  explainerdashboard: Not installed
2025-12-07 13:34:59,367:INFO:             autoviz: Not installed
2025-12-07 13:34:59,367:INFO:           fairlearn: Not installed
2025-12-07 13:34:59,367:INFO:          deepchecks: Not installed
2025-12-07 13:34:59,367:INFO:             xgboost: Not installed
2025-12-07 13:34:59,367:INFO:            catboost: Not installed
2025-12-07 13:34:59,367:INFO:              kmodes: Not installed
2025-12-07 13:34:59,367:INFO:             mlxtend: Not installed
2025-12-07 13:34:59,367:INFO:       statsforecast: Not installed
2025-12-07 13:34:59,367:INFO:        tune_sklearn: Not installed
2025-12-07 13:34:59,367:INFO:                 ray: Not installed
2025-12-07 13:34:59,367:INFO:            hyperopt: Not installed
2025-12-07 13:34:59,367:INFO:              optuna: Not installed
2025-12-07 13:34:59,367:INFO:               skopt: Not installed
2025-12-07 13:34:59,367:INFO:              mlflow: Not installed
2025-12-07 13:34:59,367:INFO:              gradio: Not installed
2025-12-07 13:34:59,367:INFO:             fastapi: Not installed
2025-12-07 13:34:59,367:INFO:             uvicorn: Not installed
2025-12-07 13:34:59,367:INFO:              m2cgen: Not installed
2025-12-07 13:34:59,367:INFO:           evidently: Not installed
2025-12-07 13:34:59,367:INFO:               fugue: Not installed
2025-12-07 13:34:59,367:INFO:           streamlit: Not installed
2025-12-07 13:34:59,367:INFO:             prophet: Not installed
2025-12-07 13:34:59,367:INFO:None
2025-12-07 13:34:59,367:INFO:Set up data.
2025-12-07 13:34:59,389:INFO:Set up folding strategy.
2025-12-07 13:34:59,389:INFO:Set up train/test split.
2025-12-07 13:34:59,405:INFO:Set up index.
2025-12-07 13:34:59,406:INFO:Assigning column types.
2025-12-07 13:34:59,408:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:34:59,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,430:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,465:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,476:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:34:59,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:34:59,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,531:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:34:59,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,589:INFO:Preparing preprocessing pipeline...
2025-12-07 13:34:59,591:INFO:Set up simple imputation.
2025-12-07 13:34:59,592:INFO:Set up imbalanced handling.
2025-12-07 13:34:59,593:INFO:Set up column name cleaning.
2025-12-07 13:34:59,694:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:34:59,697:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'tenure', 'monthly_ charges',
                                             'contract_x_paperless',
                                             'num_services',...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:34:59,697:INFO:Creating final display dataframe.
2025-12-07 13:34:59,850:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 17)
4        Transformed data shape        (9687, 17)
5   Transformed train set shape        (8278, 17)
6    Transformed test set shape        (1409, 17)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6c14
2025-12-07 13:34:59,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:34:59,951:INFO:setup() successfully completed in 0.6s...............
2025-12-07 13:34:59,957:INFO:Initializing compare_models()
2025-12-07 13:34:59,957:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:34:59,957:INFO:Checking exceptions
2025-12-07 13:34:59,960:INFO:Preparing display monitor
2025-12-07 13:34:59,971:INFO:Initializing Logistic Regression
2025-12-07 13:34:59,971:INFO:Total runtime is 1.637140909830729e-06 minutes
2025-12-07 13:34:59,973:INFO:SubProcess create_model() called ==================================
2025-12-07 13:34:59,973:INFO:Initializing create_model()
2025-12-07 13:34:59,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326e69250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:34:59,974:INFO:Checking exceptions
2025-12-07 13:34:59,974:INFO:Importing libraries
2025-12-07 13:34:59,974:INFO:Copying training dataset
2025-12-07 13:34:59,980:INFO:Defining folds
2025-12-07 13:34:59,980:INFO:Declaring metric variables
2025-12-07 13:34:59,983:INFO:Importing untrained model
2025-12-07 13:34:59,984:INFO:Logistic Regression Imported successfully
2025-12-07 13:34:59,988:INFO:Starting cross validation
2025-12-07 13:34:59,989:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:35:00,287:INFO:Calculating mean and std
2025-12-07 13:35:00,287:INFO:Creating metrics dataframe
2025-12-07 13:35:00,288:INFO:Uploading results into container
2025-12-07 13:35:00,288:INFO:Uploading model into container now
2025-12-07 13:35:00,288:INFO:_master_model_container: 1
2025-12-07 13:35:00,288:INFO:_display_container: 2
2025-12-07 13:35:00,289:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:35:00,289:INFO:create_model() successfully completed......................................
2025-12-07 13:35:00,781:INFO:SubProcess create_model() end ==================================
2025-12-07 13:35:00,781:INFO:Creating metrics dataframe
2025-12-07 13:35:00,786:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:35:00,786:INFO:Total runtime is 0.013573086261749268 minutes
2025-12-07 13:35:00,788:INFO:SubProcess create_model() called ==================================
2025-12-07 13:35:00,789:INFO:Initializing create_model()
2025-12-07 13:35:00,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326e69250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:35:00,789:INFO:Checking exceptions
2025-12-07 13:35:00,789:INFO:Importing libraries
2025-12-07 13:35:00,789:INFO:Copying training dataset
2025-12-07 13:35:00,793:INFO:Defining folds
2025-12-07 13:35:00,793:INFO:Declaring metric variables
2025-12-07 13:35:00,794:INFO:Importing untrained model
2025-12-07 13:35:00,795:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:35:00,797:INFO:Starting cross validation
2025-12-07 13:35:00,798:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:35:01,036:INFO:Calculating mean and std
2025-12-07 13:35:01,037:INFO:Creating metrics dataframe
2025-12-07 13:35:01,038:INFO:Uploading results into container
2025-12-07 13:35:01,039:INFO:Uploading model into container now
2025-12-07 13:35:01,039:INFO:_master_model_container: 2
2025-12-07 13:35:01,039:INFO:_display_container: 2
2025-12-07 13:35:01,039:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:35:01,039:INFO:create_model() successfully completed......................................
2025-12-07 13:35:01,180:INFO:SubProcess create_model() end ==================================
2025-12-07 13:35:01,180:INFO:Creating metrics dataframe
2025-12-07 13:35:01,182:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:35:01,183:INFO:Total runtime is 0.020187687873840333 minutes
2025-12-07 13:35:01,184:INFO:SubProcess create_model() called ==================================
2025-12-07 13:35:01,184:INFO:Initializing create_model()
2025-12-07 13:35:01,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x326e69250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:35:01,184:INFO:Checking exceptions
2025-12-07 13:35:01,184:INFO:Importing libraries
2025-12-07 13:35:01,184:INFO:Copying training dataset
2025-12-07 13:35:01,188:INFO:Defining folds
2025-12-07 13:35:01,188:INFO:Declaring metric variables
2025-12-07 13:35:01,189:INFO:Importing untrained model
2025-12-07 13:35:01,191:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:35:01,193:INFO:Starting cross validation
2025-12-07 13:35:01,194:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:35:02,684:INFO:Calculating mean and std
2025-12-07 13:35:02,690:INFO:Creating metrics dataframe
2025-12-07 13:35:02,696:INFO:Uploading results into container
2025-12-07 13:35:02,696:INFO:Uploading model into container now
2025-12-07 13:35:02,697:INFO:_master_model_container: 3
2025-12-07 13:35:02,697:INFO:_display_container: 2
2025-12-07 13:35:02,698:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:35:02,698:INFO:create_model() successfully completed......................................
2025-12-07 13:35:02,814:INFO:SubProcess create_model() end ==================================
2025-12-07 13:35:02,814:INFO:Creating metrics dataframe
2025-12-07 13:35:02,817:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:35:02,821:INFO:Initializing create_model()
2025-12-07 13:35:02,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f27ea90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:35:02,821:INFO:Checking exceptions
2025-12-07 13:35:02,822:INFO:Importing libraries
2025-12-07 13:35:02,822:INFO:Copying training dataset
2025-12-07 13:35:02,825:INFO:Defining folds
2025-12-07 13:35:02,825:INFO:Declaring metric variables
2025-12-07 13:35:02,825:INFO:Importing untrained model
2025-12-07 13:35:02,825:INFO:Declaring custom model
2025-12-07 13:35:02,825:INFO:Logistic Regression Imported successfully
2025-12-07 13:35:02,825:INFO:Cross validation set to False
2025-12-07 13:35:02,825:INFO:Fitting Model
2025-12-07 13:35:03,045:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:35:03,048:INFO:create_model() successfully completed......................................
2025-12-07 13:35:03,206:INFO:_master_model_container: 3
2025-12-07 13:35:03,206:INFO:_display_container: 2
2025-12-07 13:35:03,207:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:35:03,207:INFO:compare_models() successfully completed......................................
2025-12-07 13:36:49,741:INFO:PyCaret ClassificationExperiment
2025-12-07 13:36:49,741:INFO:Logging name: clf-default-name
2025-12-07 13:36:49,741:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:36:49,741:INFO:version 3.3.2
2025-12-07 13:36:49,741:INFO:Initializing setup()
2025-12-07 13:36:49,741:INFO:self.USI: 033b
2025-12-07 13:36:49,741:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:36:49,741:INFO:Checking environment
2025-12-07 13:36:49,741:INFO:python_version: 3.11.14
2025-12-07 13:36:49,741:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:36:49,741:INFO:machine: arm64
2025-12-07 13:36:49,741:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:36:49,743:INFO:Memory: svmem(total=8589934592, available=1575862272, percent=81.7, used=3173859328, free=59342848, active=1523302400, inactive=1503264768, wired=1650556928)
2025-12-07 13:36:49,743:INFO:Physical Core: 8
2025-12-07 13:36:49,743:INFO:Logical Core: 8
2025-12-07 13:36:49,743:INFO:Checking libraries
2025-12-07 13:36:49,743:INFO:System:
2025-12-07 13:36:49,743:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:36:49,743:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:36:49,743:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:36:49,743:INFO:PyCaret required dependencies:
2025-12-07 13:36:49,743:INFO:                 pip: 25.3
2025-12-07 13:36:49,743:INFO:          setuptools: 80.9.0
2025-12-07 13:36:49,743:INFO:             pycaret: 3.3.2
2025-12-07 13:36:49,743:INFO:             IPython: 9.7.0
2025-12-07 13:36:49,743:INFO:          ipywidgets: 8.1.8
2025-12-07 13:36:49,743:INFO:                tqdm: 4.67.1
2025-12-07 13:36:49,743:INFO:               numpy: 1.26.4
2025-12-07 13:36:49,743:INFO:              pandas: 2.1.4
2025-12-07 13:36:49,743:INFO:              jinja2: 3.1.6
2025-12-07 13:36:49,743:INFO:               scipy: 1.11.4
2025-12-07 13:36:49,743:INFO:              joblib: 1.3.2
2025-12-07 13:36:49,743:INFO:             sklearn: 1.4.2
2025-12-07 13:36:49,743:INFO:                pyod: 2.0.5
2025-12-07 13:36:49,743:INFO:            imblearn: 0.14.0
2025-12-07 13:36:49,743:INFO:   category_encoders: 2.7.0
2025-12-07 13:36:49,743:INFO:            lightgbm: 4.6.0
2025-12-07 13:36:49,743:INFO:               numba: 0.62.1
2025-12-07 13:36:49,743:INFO:            requests: 2.32.5
2025-12-07 13:36:49,743:INFO:          matplotlib: 3.7.5
2025-12-07 13:36:49,743:INFO:          scikitplot: 0.3.7
2025-12-07 13:36:49,743:INFO:         yellowbrick: 1.5
2025-12-07 13:36:49,743:INFO:              plotly: 6.5.0
2025-12-07 13:36:49,743:INFO:    plotly-resampler: Not installed
2025-12-07 13:36:49,743:INFO:             kaleido: 1.2.0
2025-12-07 13:36:49,743:INFO:           schemdraw: 0.15
2025-12-07 13:36:49,743:INFO:         statsmodels: 0.14.5
2025-12-07 13:36:49,743:INFO:              sktime: 0.26.0
2025-12-07 13:36:49,743:INFO:               tbats: 1.1.3
2025-12-07 13:36:49,743:INFO:            pmdarima: 2.0.4
2025-12-07 13:36:49,743:INFO:              psutil: 7.1.3
2025-12-07 13:36:49,744:INFO:          markupsafe: 3.0.3
2025-12-07 13:36:49,744:INFO:             pickle5: Not installed
2025-12-07 13:36:49,744:INFO:         cloudpickle: 3.1.2
2025-12-07 13:36:49,744:INFO:         deprecation: 2.1.0
2025-12-07 13:36:49,744:INFO:              xxhash: 3.6.0
2025-12-07 13:36:49,744:INFO:           wurlitzer: 3.1.1
2025-12-07 13:36:49,744:INFO:PyCaret optional dependencies:
2025-12-07 13:36:49,744:INFO:                shap: Not installed
2025-12-07 13:36:49,744:INFO:           interpret: Not installed
2025-12-07 13:36:49,744:INFO:                umap: Not installed
2025-12-07 13:36:49,744:INFO:     ydata_profiling: Not installed
2025-12-07 13:36:49,744:INFO:  explainerdashboard: Not installed
2025-12-07 13:36:49,744:INFO:             autoviz: Not installed
2025-12-07 13:36:49,744:INFO:           fairlearn: Not installed
2025-12-07 13:36:49,744:INFO:          deepchecks: Not installed
2025-12-07 13:36:49,744:INFO:             xgboost: Not installed
2025-12-07 13:36:49,744:INFO:            catboost: Not installed
2025-12-07 13:36:49,744:INFO:              kmodes: Not installed
2025-12-07 13:36:49,744:INFO:             mlxtend: Not installed
2025-12-07 13:36:49,744:INFO:       statsforecast: Not installed
2025-12-07 13:36:49,744:INFO:        tune_sklearn: Not installed
2025-12-07 13:36:49,744:INFO:                 ray: Not installed
2025-12-07 13:36:49,744:INFO:            hyperopt: Not installed
2025-12-07 13:36:49,744:INFO:              optuna: Not installed
2025-12-07 13:36:49,744:INFO:               skopt: Not installed
2025-12-07 13:36:49,744:INFO:              mlflow: Not installed
2025-12-07 13:36:49,744:INFO:              gradio: Not installed
2025-12-07 13:36:49,744:INFO:             fastapi: Not installed
2025-12-07 13:36:49,744:INFO:             uvicorn: Not installed
2025-12-07 13:36:49,744:INFO:              m2cgen: Not installed
2025-12-07 13:36:49,744:INFO:           evidently: Not installed
2025-12-07 13:36:49,744:INFO:               fugue: Not installed
2025-12-07 13:36:49,744:INFO:           streamlit: Not installed
2025-12-07 13:36:49,744:INFO:             prophet: Not installed
2025-12-07 13:36:49,744:INFO:None
2025-12-07 13:36:49,744:INFO:Set up data.
2025-12-07 13:36:49,799:INFO:Set up folding strategy.
2025-12-07 13:36:49,799:INFO:Set up train/test split.
2025-12-07 13:36:49,810:INFO:Set up index.
2025-12-07 13:36:49,811:INFO:Assigning column types.
2025-12-07 13:36:49,813:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:36:49,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,832:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,873:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:36:49,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:36:49,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,928:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:36:49,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:49,986:INFO:Preparing preprocessing pipeline...
2025-12-07 13:36:49,988:INFO:Set up simple imputation.
2025-12-07 13:36:49,988:INFO:Set up imbalanced handling.
2025-12-07 13:36:49,988:INFO:Set up column name cleaning.
2025-12-07 13:36:50,031:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:36:50,033:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:36:50,033:INFO:Creating final display dataframe.
2025-12-07 13:36:50,097:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              033b
2025-12-07 13:36:50,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:50,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:50,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:50,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:36:50,175:INFO:setup() successfully completed in 0.45s...............
2025-12-07 13:36:50,179:INFO:Initializing compare_models()
2025-12-07 13:36:50,179:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:36:50,179:INFO:Checking exceptions
2025-12-07 13:36:50,181:INFO:Preparing display monitor
2025-12-07 13:36:50,192:INFO:Initializing Logistic Regression
2025-12-07 13:36:50,193:INFO:Total runtime is 1.4662742614746095e-06 minutes
2025-12-07 13:36:50,194:INFO:SubProcess create_model() called ==================================
2025-12-07 13:36:50,194:INFO:Initializing create_model()
2025-12-07 13:36:50,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e246510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:36:50,194:INFO:Checking exceptions
2025-12-07 13:36:50,194:INFO:Importing libraries
2025-12-07 13:36:50,194:INFO:Copying training dataset
2025-12-07 13:36:50,198:INFO:Defining folds
2025-12-07 13:36:50,198:INFO:Declaring metric variables
2025-12-07 13:36:50,200:INFO:Importing untrained model
2025-12-07 13:36:50,202:INFO:Logistic Regression Imported successfully
2025-12-07 13:36:50,205:INFO:Starting cross validation
2025-12-07 13:36:50,207:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:36:50,526:INFO:Calculating mean and std
2025-12-07 13:36:50,527:INFO:Creating metrics dataframe
2025-12-07 13:36:50,528:INFO:Uploading results into container
2025-12-07 13:36:50,528:INFO:Uploading model into container now
2025-12-07 13:36:50,528:INFO:_master_model_container: 1
2025-12-07 13:36:50,528:INFO:_display_container: 2
2025-12-07 13:36:50,528:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:36:50,528:INFO:create_model() successfully completed......................................
2025-12-07 13:36:51,193:INFO:SubProcess create_model() end ==================================
2025-12-07 13:36:51,193:INFO:Creating metrics dataframe
2025-12-07 13:36:51,196:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:36:51,196:INFO:Total runtime is 0.016725881894429525 minutes
2025-12-07 13:36:51,198:INFO:SubProcess create_model() called ==================================
2025-12-07 13:36:51,198:INFO:Initializing create_model()
2025-12-07 13:36:51,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e246510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:36:51,198:INFO:Checking exceptions
2025-12-07 13:36:51,199:INFO:Importing libraries
2025-12-07 13:36:51,199:INFO:Copying training dataset
2025-12-07 13:36:51,205:INFO:Defining folds
2025-12-07 13:36:51,205:INFO:Declaring metric variables
2025-12-07 13:36:51,206:INFO:Importing untrained model
2025-12-07 13:36:51,207:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:36:51,211:INFO:Starting cross validation
2025-12-07 13:36:51,212:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:36:51,362:INFO:Calculating mean and std
2025-12-07 13:36:51,363:INFO:Creating metrics dataframe
2025-12-07 13:36:51,364:INFO:Uploading results into container
2025-12-07 13:36:51,365:INFO:Uploading model into container now
2025-12-07 13:36:51,365:INFO:_master_model_container: 2
2025-12-07 13:36:51,365:INFO:_display_container: 2
2025-12-07 13:36:51,365:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:36:51,366:INFO:create_model() successfully completed......................................
2025-12-07 13:36:51,478:INFO:SubProcess create_model() end ==================================
2025-12-07 13:36:51,478:INFO:Creating metrics dataframe
2025-12-07 13:36:51,485:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:36:51,485:INFO:Total runtime is 0.02154083251953125 minutes
2025-12-07 13:36:51,487:INFO:SubProcess create_model() called ==================================
2025-12-07 13:36:51,488:INFO:Initializing create_model()
2025-12-07 13:36:51,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e246510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:36:51,488:INFO:Checking exceptions
2025-12-07 13:36:51,488:INFO:Importing libraries
2025-12-07 13:36:51,488:INFO:Copying training dataset
2025-12-07 13:36:51,491:INFO:Defining folds
2025-12-07 13:36:51,491:INFO:Declaring metric variables
2025-12-07 13:36:51,494:INFO:Importing untrained model
2025-12-07 13:36:51,496:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:36:51,502:INFO:Starting cross validation
2025-12-07 13:36:51,503:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:36:53,127:INFO:Calculating mean and std
2025-12-07 13:36:53,133:INFO:Creating metrics dataframe
2025-12-07 13:36:53,136:INFO:Uploading results into container
2025-12-07 13:36:53,136:INFO:Uploading model into container now
2025-12-07 13:36:53,137:INFO:_master_model_container: 3
2025-12-07 13:36:53,137:INFO:_display_container: 2
2025-12-07 13:36:53,138:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:36:53,138:INFO:create_model() successfully completed......................................
2025-12-07 13:36:53,305:INFO:SubProcess create_model() end ==================================
2025-12-07 13:36:53,305:INFO:Creating metrics dataframe
2025-12-07 13:36:53,309:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:36:53,312:INFO:Initializing create_model()
2025-12-07 13:36:53,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31f3a7090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:36:53,312:INFO:Checking exceptions
2025-12-07 13:36:53,314:INFO:Importing libraries
2025-12-07 13:36:53,314:INFO:Copying training dataset
2025-12-07 13:36:53,316:INFO:Defining folds
2025-12-07 13:36:53,316:INFO:Declaring metric variables
2025-12-07 13:36:53,316:INFO:Importing untrained model
2025-12-07 13:36:53,316:INFO:Declaring custom model
2025-12-07 13:36:53,317:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:36:53,318:INFO:Cross validation set to False
2025-12-07 13:36:53,318:INFO:Fitting Model
2025-12-07 13:36:53,344:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:36:53,344:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:36:53,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.
2025-12-07 13:36:53,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:36:53,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:36:53,345:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:36:53,345:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:36:53,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:36:53,706:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:36:53,707:INFO:create_model() successfully completed......................................
2025-12-07 13:36:53,812:INFO:_master_model_container: 3
2025-12-07 13:36:53,812:INFO:_display_container: 2
2025-12-07 13:36:53,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:36:53,813:INFO:compare_models() successfully completed......................................
2025-12-07 13:37:02,886:INFO:PyCaret ClassificationExperiment
2025-12-07 13:37:02,886:INFO:Logging name: clf-default-name
2025-12-07 13:37:02,887:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-07 13:37:02,887:INFO:version 3.3.2
2025-12-07 13:37:02,887:INFO:Initializing setup()
2025-12-07 13:37:02,887:INFO:self.USI: 68b2
2025-12-07 13:37:02,887:INFO:self._variable_keys: {'X', 'y_train', 'memory', 'gpu_param', 'data', 'target_param', 'gpu_n_jobs_param', '_available_plots', 'X_train', 'is_multiclass', 'log_plots_param', 'html_param', 'fold_generator', 'n_jobs_param', 'pipeline', 'y_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'exp_name_log', 'y', 'X_test', 'fold_groups_param', 'logging_param', 'USI', 'seed', 'exp_id', 'idx'}
2025-12-07 13:37:02,887:INFO:Checking environment
2025-12-07 13:37:02,887:INFO:python_version: 3.11.14
2025-12-07 13:37:02,887:INFO:python_build: ('main', 'Oct 21 2025 18:27:30')
2025-12-07 13:37:02,887:INFO:machine: arm64
2025-12-07 13:37:02,887:INFO:platform: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:37:02,887:INFO:Memory: svmem(total=8589934592, available=1398751232, percent=83.7, used=3011772416, free=63782912, active=1352433664, inactive=1324924928, wired=1659338752)
2025-12-07 13:37:02,887:INFO:Physical Core: 8
2025-12-07 13:37:02,887:INFO:Logical Core: 8
2025-12-07 13:37:02,887:INFO:Checking libraries
2025-12-07 13:37:02,887:INFO:System:
2025-12-07 13:37:02,887:INFO:    python: 3.11.14 (main, Oct 21 2025, 18:27:30) [Clang 20.1.8 ]
2025-12-07 13:37:02,888:INFO:executable: /opt/miniconda3/envs/churn_prediction/bin/python
2025-12-07 13:37:02,888:INFO:   machine: macOS-26.0.1-arm64-arm-64bit
2025-12-07 13:37:02,888:INFO:PyCaret required dependencies:
2025-12-07 13:37:02,891:INFO:                 pip: 25.3
2025-12-07 13:37:02,891:INFO:          setuptools: 80.9.0
2025-12-07 13:37:02,892:INFO:             pycaret: 3.3.2
2025-12-07 13:37:02,892:INFO:             IPython: 9.7.0
2025-12-07 13:37:02,892:INFO:          ipywidgets: 8.1.8
2025-12-07 13:37:02,892:INFO:                tqdm: 4.67.1
2025-12-07 13:37:02,892:INFO:               numpy: 1.26.4
2025-12-07 13:37:02,892:INFO:              pandas: 2.1.4
2025-12-07 13:37:02,892:INFO:              jinja2: 3.1.6
2025-12-07 13:37:02,892:INFO:               scipy: 1.11.4
2025-12-07 13:37:02,892:INFO:              joblib: 1.3.2
2025-12-07 13:37:02,892:INFO:             sklearn: 1.4.2
2025-12-07 13:37:02,892:INFO:                pyod: 2.0.5
2025-12-07 13:37:02,892:INFO:            imblearn: 0.14.0
2025-12-07 13:37:02,892:INFO:   category_encoders: 2.7.0
2025-12-07 13:37:02,892:INFO:            lightgbm: 4.6.0
2025-12-07 13:37:02,892:INFO:               numba: 0.62.1
2025-12-07 13:37:02,892:INFO:            requests: 2.32.5
2025-12-07 13:37:02,892:INFO:          matplotlib: 3.7.5
2025-12-07 13:37:02,892:INFO:          scikitplot: 0.3.7
2025-12-07 13:37:02,892:INFO:         yellowbrick: 1.5
2025-12-07 13:37:02,892:INFO:              plotly: 6.5.0
2025-12-07 13:37:02,892:INFO:    plotly-resampler: Not installed
2025-12-07 13:37:02,892:INFO:             kaleido: 1.2.0
2025-12-07 13:37:02,892:INFO:           schemdraw: 0.15
2025-12-07 13:37:02,892:INFO:         statsmodels: 0.14.5
2025-12-07 13:37:02,892:INFO:              sktime: 0.26.0
2025-12-07 13:37:02,892:INFO:               tbats: 1.1.3
2025-12-07 13:37:02,892:INFO:            pmdarima: 2.0.4
2025-12-07 13:37:02,892:INFO:              psutil: 7.1.3
2025-12-07 13:37:02,892:INFO:          markupsafe: 3.0.3
2025-12-07 13:37:02,892:INFO:             pickle5: Not installed
2025-12-07 13:37:02,892:INFO:         cloudpickle: 3.1.2
2025-12-07 13:37:02,892:INFO:         deprecation: 2.1.0
2025-12-07 13:37:02,892:INFO:              xxhash: 3.6.0
2025-12-07 13:37:02,892:INFO:           wurlitzer: 3.1.1
2025-12-07 13:37:02,893:INFO:PyCaret optional dependencies:
2025-12-07 13:37:02,893:INFO:                shap: Not installed
2025-12-07 13:37:02,893:INFO:           interpret: Not installed
2025-12-07 13:37:02,893:INFO:                umap: Not installed
2025-12-07 13:37:02,893:INFO:     ydata_profiling: Not installed
2025-12-07 13:37:02,893:INFO:  explainerdashboard: Not installed
2025-12-07 13:37:02,893:INFO:             autoviz: Not installed
2025-12-07 13:37:02,893:INFO:           fairlearn: Not installed
2025-12-07 13:37:02,893:INFO:          deepchecks: Not installed
2025-12-07 13:37:02,893:INFO:             xgboost: Not installed
2025-12-07 13:37:02,893:INFO:            catboost: Not installed
2025-12-07 13:37:02,893:INFO:              kmodes: Not installed
2025-12-07 13:37:02,893:INFO:             mlxtend: Not installed
2025-12-07 13:37:02,893:INFO:       statsforecast: Not installed
2025-12-07 13:37:02,893:INFO:        tune_sklearn: Not installed
2025-12-07 13:37:02,893:INFO:                 ray: Not installed
2025-12-07 13:37:02,893:INFO:            hyperopt: Not installed
2025-12-07 13:37:02,893:INFO:              optuna: Not installed
2025-12-07 13:37:02,893:INFO:               skopt: Not installed
2025-12-07 13:37:02,893:INFO:              mlflow: Not installed
2025-12-07 13:37:02,893:INFO:              gradio: Not installed
2025-12-07 13:37:02,893:INFO:             fastapi: Not installed
2025-12-07 13:37:02,893:INFO:             uvicorn: Not installed
2025-12-07 13:37:02,893:INFO:              m2cgen: Not installed
2025-12-07 13:37:02,893:INFO:           evidently: Not installed
2025-12-07 13:37:02,893:INFO:               fugue: Not installed
2025-12-07 13:37:02,893:INFO:           streamlit: Not installed
2025-12-07 13:37:02,893:INFO:             prophet: Not installed
2025-12-07 13:37:02,893:INFO:None
2025-12-07 13:37:02,893:INFO:Set up data.
2025-12-07 13:37:02,903:INFO:Set up folding strategy.
2025-12-07 13:37:02,903:INFO:Set up train/test split.
2025-12-07 13:37:02,907:INFO:Set up index.
2025-12-07 13:37:02,908:INFO:Assigning column types.
2025-12-07 13:37:02,913:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-07 13:37:02,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:37:02,936:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:37:02,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:02,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:02,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-07 13:37:02,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:37:02,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:02,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:02,976:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-07 13:37:02,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:37:03,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-07 13:37:03,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,031:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-07 13:37:03,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,086:INFO:Preparing preprocessing pipeline...
2025-12-07 13:37:03,088:INFO:Set up simple imputation.
2025-12-07 13:37:03,090:INFO:Set up imbalanced handling.
2025-12-07 13:37:03,091:INFO:Set up column name cleaning.
2025-12-07 13:37:03,120:INFO:Finished creating preprocessing pipeline.
2025-12-07 13:37:03,122:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-12-07 13:37:03,122:INFO:Creating final display dataframe.
2025-12-07 13:37:03,192:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target       churn_value
2                   Target type            Binary
3           Original data shape        (7043, 12)
4        Transformed data shape        (9687, 12)
5   Transformed train set shape        (8278, 12)
6    Transformed test set shape        (1409, 12)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              68b2
2025-12-07 13:37:03,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-07 13:37:03,258:INFO:setup() successfully completed in 0.38s...............
2025-12-07 13:37:03,259:INFO:Initializing compare_models()
2025-12-07 13:37:03,259:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:37:03,259:INFO:Checking exceptions
2025-12-07 13:37:03,260:INFO:Preparing display monitor
2025-12-07 13:37:03,272:INFO:Initializing Logistic Regression
2025-12-07 13:37:03,273:INFO:Total runtime is 2.09808349609375e-06 minutes
2025-12-07 13:37:03,274:INFO:SubProcess create_model() called ==================================
2025-12-07 13:37:03,274:INFO:Initializing create_model()
2025-12-07 13:37:03,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db921d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:37:03,274:INFO:Checking exceptions
2025-12-07 13:37:03,274:INFO:Importing libraries
2025-12-07 13:37:03,274:INFO:Copying training dataset
2025-12-07 13:37:03,279:INFO:Defining folds
2025-12-07 13:37:03,279:INFO:Declaring metric variables
2025-12-07 13:37:03,281:INFO:Importing untrained model
2025-12-07 13:37:03,282:INFO:Logistic Regression Imported successfully
2025-12-07 13:37:03,286:INFO:Starting cross validation
2025-12-07 13:37:03,287:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:37:03,447:INFO:Calculating mean and std
2025-12-07 13:37:03,447:INFO:Creating metrics dataframe
2025-12-07 13:37:03,449:INFO:Uploading results into container
2025-12-07 13:37:03,449:INFO:Uploading model into container now
2025-12-07 13:37:03,450:INFO:_master_model_container: 1
2025-12-07 13:37:03,450:INFO:_display_container: 2
2025-12-07 13:37:03,450:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:37:03,450:INFO:create_model() successfully completed......................................
2025-12-07 13:37:03,692:INFO:SubProcess create_model() end ==================================
2025-12-07 13:37:03,692:INFO:Creating metrics dataframe
2025-12-07 13:37:03,695:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:37:03,695:INFO:Total runtime is 0.007039034366607666 minutes
2025-12-07 13:37:03,696:INFO:SubProcess create_model() called ==================================
2025-12-07 13:37:03,697:INFO:Initializing create_model()
2025-12-07 13:37:03,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db921d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:37:03,697:INFO:Checking exceptions
2025-12-07 13:37:03,697:INFO:Importing libraries
2025-12-07 13:37:03,697:INFO:Copying training dataset
2025-12-07 13:37:03,700:INFO:Defining folds
2025-12-07 13:37:03,700:INFO:Declaring metric variables
2025-12-07 13:37:03,701:INFO:Importing untrained model
2025-12-07 13:37:03,704:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:37:03,706:INFO:Starting cross validation
2025-12-07 13:37:03,707:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:37:03,825:INFO:Calculating mean and std
2025-12-07 13:37:03,825:INFO:Creating metrics dataframe
2025-12-07 13:37:03,826:INFO:Uploading results into container
2025-12-07 13:37:03,826:INFO:Uploading model into container now
2025-12-07 13:37:03,826:INFO:_master_model_container: 2
2025-12-07 13:37:03,826:INFO:_display_container: 2
2025-12-07 13:37:03,826:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:37:03,826:INFO:create_model() successfully completed......................................
2025-12-07 13:37:03,949:INFO:SubProcess create_model() end ==================================
2025-12-07 13:37:03,949:INFO:Creating metrics dataframe
2025-12-07 13:37:03,952:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:37:03,952:INFO:Total runtime is 0.011330803235371906 minutes
2025-12-07 13:37:03,954:INFO:SubProcess create_model() called ==================================
2025-12-07 13:37:03,954:INFO:Initializing create_model()
2025-12-07 13:37:03,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db921d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:37:03,954:INFO:Checking exceptions
2025-12-07 13:37:03,954:INFO:Importing libraries
2025-12-07 13:37:03,954:INFO:Copying training dataset
2025-12-07 13:37:03,957:INFO:Defining folds
2025-12-07 13:37:03,957:INFO:Declaring metric variables
2025-12-07 13:37:03,957:INFO:Importing untrained model
2025-12-07 13:37:03,959:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:37:03,961:INFO:Starting cross validation
2025-12-07 13:37:03,962:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:37:05,839:INFO:Calculating mean and std
2025-12-07 13:37:05,841:INFO:Creating metrics dataframe
2025-12-07 13:37:05,845:INFO:Uploading results into container
2025-12-07 13:37:05,845:INFO:Uploading model into container now
2025-12-07 13:37:05,846:INFO:_master_model_container: 3
2025-12-07 13:37:05,846:INFO:_display_container: 2
2025-12-07 13:37:05,848:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:37:05,848:INFO:create_model() successfully completed......................................
2025-12-07 13:37:06,038:INFO:SubProcess create_model() end ==================================
2025-12-07 13:37:06,038:INFO:Creating metrics dataframe
2025-12-07 13:37:06,041:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:37:06,045:INFO:Initializing create_model()
2025-12-07 13:37:06,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:37:06,045:INFO:Checking exceptions
2025-12-07 13:37:06,046:INFO:Importing libraries
2025-12-07 13:37:06,046:INFO:Copying training dataset
2025-12-07 13:37:06,050:INFO:Defining folds
2025-12-07 13:37:06,050:INFO:Declaring metric variables
2025-12-07 13:37:06,050:INFO:Importing untrained model
2025-12-07 13:37:06,051:INFO:Declaring custom model
2025-12-07 13:37:06,051:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:37:06,051:INFO:Cross validation set to False
2025-12-07 13:37:06,051:INFO:Fitting Model
2025-12-07 13:37:06,074:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:37:06,074:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:37:06,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.
2025-12-07 13:37:06,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:37:06,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:37:06,076:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:37:06,076:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:37:06,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:37:06,442:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:37:06,442:INFO:create_model() successfully completed......................................
2025-12-07 13:37:06,561:INFO:_master_model_container: 3
2025-12-07 13:37:06,561:INFO:_display_container: 2
2025-12-07 13:37:06,562:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:37:06,562:INFO:compare_models() successfully completed......................................
2025-12-07 13:38:59,886:INFO:Initializing compare_models()
2025-12-07 13:38:59,891:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, include=['lr', 'qda', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, 'include': ['lr', 'qda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-07 13:38:59,891:INFO:Checking exceptions
2025-12-07 13:38:59,918:INFO:Preparing display monitor
2025-12-07 13:38:59,945:INFO:Initializing Logistic Regression
2025-12-07 13:38:59,945:INFO:Total runtime is 1.8874804178873699e-06 minutes
2025-12-07 13:38:59,949:INFO:SubProcess create_model() called ==================================
2025-12-07 13:38:59,950:INFO:Initializing create_model()
2025-12-07 13:38:59,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:38:59,950:INFO:Checking exceptions
2025-12-07 13:38:59,950:INFO:Importing libraries
2025-12-07 13:38:59,950:INFO:Copying training dataset
2025-12-07 13:38:59,962:INFO:Defining folds
2025-12-07 13:38:59,962:INFO:Declaring metric variables
2025-12-07 13:38:59,963:INFO:Importing untrained model
2025-12-07 13:38:59,965:INFO:Logistic Regression Imported successfully
2025-12-07 13:38:59,968:INFO:Starting cross validation
2025-12-07 13:38:59,974:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:39:00,163:INFO:Calculating mean and std
2025-12-07 13:39:00,163:INFO:Creating metrics dataframe
2025-12-07 13:39:00,164:INFO:Uploading results into container
2025-12-07 13:39:00,164:INFO:Uploading model into container now
2025-12-07 13:39:00,165:INFO:_master_model_container: 4
2025-12-07 13:39:00,165:INFO:_display_container: 3
2025-12-07 13:39:00,165:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-07 13:39:00,165:INFO:create_model() successfully completed......................................
2025-12-07 13:39:00,452:INFO:SubProcess create_model() end ==================================
2025-12-07 13:39:00,452:INFO:Creating metrics dataframe
2025-12-07 13:39:00,455:INFO:Initializing Quadratic Discriminant Analysis
2025-12-07 13:39:00,455:INFO:Total runtime is 0.008505554993947347 minutes
2025-12-07 13:39:00,456:INFO:SubProcess create_model() called ==================================
2025-12-07 13:39:00,456:INFO:Initializing create_model()
2025-12-07 13:39:00,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:39:00,456:INFO:Checking exceptions
2025-12-07 13:39:00,456:INFO:Importing libraries
2025-12-07 13:39:00,456:INFO:Copying training dataset
2025-12-07 13:39:00,459:INFO:Defining folds
2025-12-07 13:39:00,459:INFO:Declaring metric variables
2025-12-07 13:39:00,460:INFO:Importing untrained model
2025-12-07 13:39:00,461:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-07 13:39:00,464:INFO:Starting cross validation
2025-12-07 13:39:00,465:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:39:00,551:INFO:Calculating mean and std
2025-12-07 13:39:00,552:INFO:Creating metrics dataframe
2025-12-07 13:39:00,552:INFO:Uploading results into container
2025-12-07 13:39:00,553:INFO:Uploading model into container now
2025-12-07 13:39:00,553:INFO:_master_model_container: 5
2025-12-07 13:39:00,553:INFO:_display_container: 3
2025-12-07 13:39:00,553:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-07 13:39:00,553:INFO:create_model() successfully completed......................................
2025-12-07 13:39:00,679:INFO:SubProcess create_model() end ==================================
2025-12-07 13:39:00,679:INFO:Creating metrics dataframe
2025-12-07 13:39:00,681:INFO:Initializing Light Gradient Boosting Machine
2025-12-07 13:39:00,681:INFO:Total runtime is 0.012281370162963866 minutes
2025-12-07 13:39:00,683:INFO:SubProcess create_model() called ==================================
2025-12-07 13:39:00,683:INFO:Initializing create_model()
2025-12-07 13:39:00,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:39:00,683:INFO:Checking exceptions
2025-12-07 13:39:00,683:INFO:Importing libraries
2025-12-07 13:39:00,683:INFO:Copying training dataset
2025-12-07 13:39:00,686:INFO:Defining folds
2025-12-07 13:39:00,686:INFO:Declaring metric variables
2025-12-07 13:39:00,688:INFO:Importing untrained model
2025-12-07 13:39:00,690:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:39:00,692:INFO:Starting cross validation
2025-12-07 13:39:00,694:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:39:02,397:INFO:Calculating mean and std
2025-12-07 13:39:02,402:INFO:Creating metrics dataframe
2025-12-07 13:39:02,406:INFO:Uploading results into container
2025-12-07 13:39:02,406:INFO:Uploading model into container now
2025-12-07 13:39:02,407:INFO:_master_model_container: 6
2025-12-07 13:39:02,407:INFO:_display_container: 3
2025-12-07 13:39:02,408:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:02,409:INFO:create_model() successfully completed......................................
2025-12-07 13:39:02,650:INFO:SubProcess create_model() end ==================================
2025-12-07 13:39:02,650:INFO:Creating metrics dataframe
2025-12-07 13:39:02,655:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-07 13:39:02,658:INFO:Initializing create_model()
2025-12-07 13:39:02,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:39:02,659:INFO:Checking exceptions
2025-12-07 13:39:02,660:INFO:Importing libraries
2025-12-07 13:39:02,660:INFO:Copying training dataset
2025-12-07 13:39:02,664:INFO:Defining folds
2025-12-07 13:39:02,664:INFO:Declaring metric variables
2025-12-07 13:39:02,664:INFO:Importing untrained model
2025-12-07 13:39:02,664:INFO:Declaring custom model
2025-12-07 13:39:02,664:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:39:02,665:INFO:Cross validation set to False
2025-12-07 13:39:02,665:INFO:Fitting Model
2025-12-07 13:39:02,692:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:39:02,693:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:39:02,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.
2025-12-07 13:39:02,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:39:02,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:39:02,694:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:39:02,694:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:39:02,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:39:03,057:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:03,057:INFO:create_model() successfully completed......................................
2025-12-07 13:39:03,183:INFO:_master_model_container: 6
2025-12-07 13:39:03,183:INFO:_display_container: 3
2025-12-07 13:39:03,183:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:03,184:INFO:compare_models() successfully completed......................................
2025-12-07 13:39:06,990:INFO:Initializing tune_model()
2025-12-07 13:39:06,991:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:39:06,991:INFO:Checking exceptions
2025-12-07 13:39:07,013:INFO:Copying training dataset
2025-12-07 13:39:07,018:INFO:Checking base model
2025-12-07 13:39:07,018:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:39:07,020:INFO:Declaring metric variables
2025-12-07 13:39:07,021:INFO:Defining Hyperparameters
2025-12-07 13:39:07,213:INFO:Tuning with n_jobs=-1
2025-12-07 13:39:07,213:INFO:Initializing RandomizedSearchCV
2025-12-07 13:39:14,169:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:39:14,170:INFO:Hyperparameter search completed
2025-12-07 13:39:14,173:INFO:SubProcess create_model() called ==================================
2025-12-07 13:39:14,177:INFO:Initializing create_model()
2025-12-07 13:39:14,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31db7a3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 1, 'num_leaves': 90, 'n_estimators': 100, 'min_split_gain': 0.7, 'min_child_samples': 16, 'learning_rate': 0.4, 'feature_fraction': 0.8, 'bagging_freq': 7, 'bagging_fraction': 0.8})
2025-12-07 13:39:14,177:INFO:Checking exceptions
2025-12-07 13:39:14,178:INFO:Importing libraries
2025-12-07 13:39:14,178:INFO:Copying training dataset
2025-12-07 13:39:14,184:INFO:Defining folds
2025-12-07 13:39:14,184:INFO:Declaring metric variables
2025-12-07 13:39:14,187:INFO:Importing untrained model
2025-12-07 13:39:14,187:INFO:Declaring custom model
2025-12-07 13:39:14,190:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:39:14,192:INFO:Starting cross validation
2025-12-07 13:39:14,193:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:39:14,420:INFO:Calculating mean and std
2025-12-07 13:39:14,421:INFO:Creating metrics dataframe
2025-12-07 13:39:14,423:INFO:Finalizing model
2025-12-07 13:39:14,449:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-07 13:39:14,449:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:39:14,449:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:39:14,453:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:39:14,454:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-07 13:39:14,454:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:39:14,454:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:39:14,454:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:39:14,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.
2025-12-07 13:39:14,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:39:14,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:39:14,455:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:39:14,455:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:39:14,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:39:14,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:39:14,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-12-07 13:39:14,498:INFO:Uploading results into container
2025-12-07 13:39:14,498:INFO:Uploading model into container now
2025-12-07 13:39:14,499:INFO:_master_model_container: 7
2025-12-07 13:39:14,499:INFO:_display_container: 4
2025-12-07 13:39:14,500:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=100, n_jobs=-1, num_leaves=90, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:14,500:INFO:create_model() successfully completed......................................
2025-12-07 13:39:14,696:INFO:SubProcess create_model() end ==================================
2025-12-07 13:39:14,696:INFO:choose_better activated
2025-12-07 13:39:14,697:INFO:SubProcess create_model() called ==================================
2025-12-07 13:39:14,698:INFO:Initializing create_model()
2025-12-07 13:39:14,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:39:14,698:INFO:Checking exceptions
2025-12-07 13:39:14,698:INFO:Importing libraries
2025-12-07 13:39:14,698:INFO:Copying training dataset
2025-12-07 13:39:14,701:INFO:Defining folds
2025-12-07 13:39:14,701:INFO:Declaring metric variables
2025-12-07 13:39:14,701:INFO:Importing untrained model
2025-12-07 13:39:14,701:INFO:Declaring custom model
2025-12-07 13:39:14,701:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:39:14,702:INFO:Starting cross validation
2025-12-07 13:39:14,702:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:39:16,152:INFO:Calculating mean and std
2025-12-07 13:39:16,152:INFO:Creating metrics dataframe
2025-12-07 13:39:16,153:INFO:Finalizing model
2025-12-07 13:39:16,173:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:39:16,173:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:39:16,174:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.
2025-12-07 13:39:16,174:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:39:16,174:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:39:16,175:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:39:16,175:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:39:16,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:39:16,530:INFO:Uploading results into container
2025-12-07 13:39:16,530:INFO:Uploading model into container now
2025-12-07 13:39:16,530:INFO:_master_model_container: 8
2025-12-07 13:39:16,530:INFO:_display_container: 5
2025-12-07 13:39:16,530:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:16,530:INFO:create_model() successfully completed......................................
2025-12-07 13:39:16,632:INFO:SubProcess create_model() end ==================================
2025-12-07 13:39:16,633:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:39:16,633:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=100, n_jobs=-1, num_leaves=90, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8783
2025-12-07 13:39:16,633:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:39:16,633:INFO:choose_better completed
2025-12-07 13:39:16,633:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-07 13:39:16,637:INFO:_master_model_container: 8
2025-12-07 13:39:16,637:INFO:_display_container: 4
2025-12-07 13:39:16,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:39:16,638:INFO:tune_model() successfully completed......................................
2025-12-07 13:40:07,940:INFO:Initializing create_model()
2025-12-07 13:40:07,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:40:07,943:INFO:Checking exceptions
2025-12-07 13:40:07,977:INFO:Importing libraries
2025-12-07 13:40:07,980:INFO:Copying training dataset
2025-12-07 13:40:07,997:INFO:Defining folds
2025-12-07 13:40:07,997:INFO:Declaring metric variables
2025-12-07 13:40:08,000:INFO:Importing untrained model
2025-12-07 13:40:08,005:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:40:08,008:INFO:Starting cross validation
2025-12-07 13:40:08,015:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:40:09,659:INFO:Calculating mean and std
2025-12-07 13:40:09,660:INFO:Creating metrics dataframe
2025-12-07 13:40:09,664:INFO:Finalizing model
2025-12-07 13:40:09,696:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:40:09,697:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:40:09,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000895 seconds.
2025-12-07 13:40:09,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:40:09,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:40:09,699:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:40:09,699:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:40:09,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:40:10,095:INFO:Uploading results into container
2025-12-07 13:40:10,098:INFO:Uploading model into container now
2025-12-07 13:40:10,104:INFO:_master_model_container: 9
2025-12-07 13:40:10,104:INFO:_display_container: 5
2025-12-07 13:40:10,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:40:10,104:INFO:create_model() successfully completed......................................
2025-12-07 13:40:10,356:INFO:Initializing tune_model()
2025-12-07 13:40:10,356:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:40:10,356:INFO:Checking exceptions
2025-12-07 13:40:10,363:INFO:Copying training dataset
2025-12-07 13:40:10,370:INFO:Checking base model
2025-12-07 13:40:10,371:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:40:10,373:INFO:Declaring metric variables
2025-12-07 13:40:10,374:INFO:Defining Hyperparameters
2025-12-07 13:40:10,486:INFO:Tuning with n_jobs=-1
2025-12-07 13:40:10,486:INFO:Initializing RandomizedSearchCV
2025-12-07 13:40:56,367:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:40:56,392:INFO:Hyperparameter search completed
2025-12-07 13:40:56,393:INFO:SubProcess create_model() called ==================================
2025-12-07 13:40:56,400:INFO:Initializing create_model()
2025-12-07 13:40:56,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6f5d10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-07 13:40:56,400:INFO:Checking exceptions
2025-12-07 13:40:56,401:INFO:Importing libraries
2025-12-07 13:40:56,402:INFO:Copying training dataset
2025-12-07 13:40:56,430:INFO:Defining folds
2025-12-07 13:40:56,430:INFO:Declaring metric variables
2025-12-07 13:40:56,437:INFO:Importing untrained model
2025-12-07 13:40:56,437:INFO:Declaring custom model
2025-12-07 13:40:56,441:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:40:56,446:INFO:Starting cross validation
2025-12-07 13:40:56,456:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:40:58,193:INFO:Calculating mean and std
2025-12-07 13:40:58,195:INFO:Creating metrics dataframe
2025-12-07 13:40:58,203:INFO:Finalizing model
2025-12-07 13:40:58,243:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-07 13:40:58,243:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:40:58,243:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:40:58,246:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:40:58,246:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-07 13:40:58,246:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-07 13:40:58,246:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:40:58,246:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:40:58,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.
2025-12-07 13:40:58,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:40:58,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:40:58,248:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:40:58,248:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:40:58,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:40:58,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-07 13:40:58,511:INFO:Uploading results into container
2025-12-07 13:40:58,511:INFO:Uploading model into container now
2025-12-07 13:40:58,512:INFO:_master_model_container: 10
2025-12-07 13:40:58,512:INFO:_display_container: 6
2025-12-07 13:40:58,514:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:40:58,514:INFO:create_model() successfully completed......................................
2025-12-07 13:40:59,034:INFO:SubProcess create_model() end ==================================
2025-12-07 13:40:59,034:INFO:choose_better activated
2025-12-07 13:40:59,035:INFO:SubProcess create_model() called ==================================
2025-12-07 13:40:59,036:INFO:Initializing create_model()
2025-12-07 13:40:59,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:40:59,036:INFO:Checking exceptions
2025-12-07 13:40:59,037:INFO:Importing libraries
2025-12-07 13:40:59,037:INFO:Copying training dataset
2025-12-07 13:40:59,040:INFO:Defining folds
2025-12-07 13:40:59,040:INFO:Declaring metric variables
2025-12-07 13:40:59,040:INFO:Importing untrained model
2025-12-07 13:40:59,040:INFO:Declaring custom model
2025-12-07 13:40:59,040:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:40:59,040:INFO:Starting cross validation
2025-12-07 13:40:59,041:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:41:00,616:INFO:Calculating mean and std
2025-12-07 13:41:00,617:INFO:Creating metrics dataframe
2025-12-07 13:41:00,621:INFO:Finalizing model
2025-12-07 13:41:00,651:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:41:00,652:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:41:00,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.
2025-12-07 13:41:00,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:41:00,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:41:00,653:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:41:00,653:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:41:00,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:41:01,020:INFO:Uploading results into container
2025-12-07 13:41:01,021:INFO:Uploading model into container now
2025-12-07 13:41:01,022:INFO:_master_model_container: 11
2025-12-07 13:41:01,022:INFO:_display_container: 7
2025-12-07 13:41:01,023:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:41:01,023:INFO:create_model() successfully completed......................................
2025-12-07 13:41:01,230:INFO:SubProcess create_model() end ==================================
2025-12-07 13:41:01,230:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:41:01,231:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-07 13:41:01,231:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:41:01,231:INFO:choose_better completed
2025-12-07 13:41:01,237:INFO:_master_model_container: 11
2025-12-07 13:41:01,237:INFO:_display_container: 6
2025-12-07 13:41:01,237:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:41:01,238:INFO:tune_model() successfully completed......................................
2025-12-07 13:41:10,096:INFO:Initializing create_model()
2025-12-07 13:41:10,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:41:10,097:INFO:Checking exceptions
2025-12-07 13:41:10,152:INFO:Importing libraries
2025-12-07 13:41:10,153:INFO:Copying training dataset
2025-12-07 13:41:10,169:INFO:Defining folds
2025-12-07 13:41:10,169:INFO:Declaring metric variables
2025-12-07 13:41:10,171:INFO:Importing untrained model
2025-12-07 13:41:10,175:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:41:10,178:INFO:Starting cross validation
2025-12-07 13:41:10,181:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:41:11,781:INFO:Calculating mean and std
2025-12-07 13:41:11,783:INFO:Creating metrics dataframe
2025-12-07 13:41:11,790:INFO:Finalizing model
2025-12-07 13:41:11,834:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:41:11,834:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:41:11,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-12-07 13:41:11,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:41:11,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:41:11,836:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:41:11,836:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:41:11,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:41:12,212:INFO:Uploading results into container
2025-12-07 13:41:12,213:INFO:Uploading model into container now
2025-12-07 13:41:12,218:INFO:_master_model_container: 12
2025-12-07 13:41:12,218:INFO:_display_container: 7
2025-12-07 13:41:12,218:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:41:12,218:INFO:create_model() successfully completed......................................
2025-12-07 13:41:12,392:INFO:Initializing tune_model()
2025-12-07 13:41:12,393:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=100, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:41:12,393:INFO:Checking exceptions
2025-12-07 13:41:12,399:INFO:Copying training dataset
2025-12-07 13:41:12,402:INFO:Checking base model
2025-12-07 13:41:12,402:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:41:12,404:INFO:Declaring metric variables
2025-12-07 13:41:12,405:INFO:Defining Hyperparameters
2025-12-07 13:41:12,573:INFO:Tuning with n_jobs=-1
2025-12-07 13:41:12,574:INFO:Initializing RandomizedSearchCV
2025-12-07 13:42:23,280:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 5, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:42:23,285:INFO:Hyperparameter search completed
2025-12-07 13:42:23,286:INFO:SubProcess create_model() called ==================================
2025-12-07 13:42:23,287:INFO:Initializing create_model()
2025-12-07 13:42:23,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c5a90d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 5, 'num_leaves': 2, 'n_estimators': 230, 'min_split_gain': 0.5, 'min_child_samples': 76, 'learning_rate': 1e-07, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-12-07 13:42:23,287:INFO:Checking exceptions
2025-12-07 13:42:23,287:INFO:Importing libraries
2025-12-07 13:42:23,287:INFO:Copying training dataset
2025-12-07 13:42:23,293:INFO:Defining folds
2025-12-07 13:42:23,293:INFO:Declaring metric variables
2025-12-07 13:42:23,299:INFO:Importing untrained model
2025-12-07 13:42:23,299:INFO:Declaring custom model
2025-12-07 13:42:23,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:42:23,305:INFO:Starting cross validation
2025-12-07 13:42:23,307:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:42:23,662:INFO:Calculating mean and std
2025-12-07 13:42:23,663:INFO:Creating metrics dataframe
2025-12-07 13:42:23,665:INFO:Finalizing model
2025-12-07 13:42:23,693:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:42:23,693:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:42:23,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:42:23,695:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:42:23,695:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:42:23,695:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:42:23,695:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:42:23,695:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:42:23,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.
2025-12-07 13:42:23,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:42:23,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:42:23,697:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:42:23,697:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:42:23,698:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:42:23,790:INFO:Uploading results into container
2025-12-07 13:42:23,790:INFO:Uploading model into container now
2025-12-07 13:42:23,791:INFO:_master_model_container: 13
2025-12-07 13:42:23,791:INFO:_display_container: 8
2025-12-07 13:42:23,792:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:42:23,792:INFO:create_model() successfully completed......................................
2025-12-07 13:42:23,987:INFO:SubProcess create_model() end ==================================
2025-12-07 13:42:23,987:INFO:choose_better activated
2025-12-07 13:42:23,989:INFO:SubProcess create_model() called ==================================
2025-12-07 13:42:23,989:INFO:Initializing create_model()
2025-12-07 13:42:23,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:42:23,989:INFO:Checking exceptions
2025-12-07 13:42:23,990:INFO:Importing libraries
2025-12-07 13:42:23,990:INFO:Copying training dataset
2025-12-07 13:42:23,993:INFO:Defining folds
2025-12-07 13:42:23,993:INFO:Declaring metric variables
2025-12-07 13:42:23,993:INFO:Importing untrained model
2025-12-07 13:42:23,993:INFO:Declaring custom model
2025-12-07 13:42:23,993:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:42:23,993:INFO:Starting cross validation
2025-12-07 13:42:23,994:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:42:25,363:INFO:Calculating mean and std
2025-12-07 13:42:25,363:INFO:Creating metrics dataframe
2025-12-07 13:42:25,364:INFO:Finalizing model
2025-12-07 13:42:25,386:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:42:25,386:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:42:25,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2025-12-07 13:42:25,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:42:25,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:42:25,387:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:42:25,387:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:42:25,387:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:42:25,754:INFO:Uploading results into container
2025-12-07 13:42:25,754:INFO:Uploading model into container now
2025-12-07 13:42:25,755:INFO:_master_model_container: 14
2025-12-07 13:42:25,755:INFO:_display_container: 9
2025-12-07 13:42:25,755:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:42:25,755:INFO:create_model() successfully completed......................................
2025-12-07 13:42:25,853:INFO:SubProcess create_model() end ==================================
2025-12-07 13:42:25,854:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:42:25,854:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9739
2025-12-07 13:42:25,854:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:42:25,854:INFO:choose_better completed
2025-12-07 13:42:25,858:INFO:_master_model_container: 14
2025-12-07 13:42:25,858:INFO:_display_container: 8
2025-12-07 13:42:25,858:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:42:25,858:INFO:tune_model() successfully completed......................................
2025-12-07 13:44:11,142:INFO:Initializing create_model()
2025-12-07 13:44:11,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:44:11,148:INFO:Checking exceptions
2025-12-07 13:44:11,277:INFO:Importing libraries
2025-12-07 13:44:11,279:INFO:Copying training dataset
2025-12-07 13:44:11,290:INFO:Defining folds
2025-12-07 13:44:11,290:INFO:Declaring metric variables
2025-12-07 13:44:11,291:INFO:Importing untrained model
2025-12-07 13:44:11,293:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:44:11,297:INFO:Starting cross validation
2025-12-07 13:44:11,305:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:44:13,111:INFO:Calculating mean and std
2025-12-07 13:44:13,113:INFO:Creating metrics dataframe
2025-12-07 13:44:13,122:INFO:Finalizing model
2025-12-07 13:44:13,165:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:44:13,165:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:44:13,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.
2025-12-07 13:44:13,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:44:13,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:44:13,167:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:44:13,167:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:44:13,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:44:13,531:INFO:Uploading results into container
2025-12-07 13:44:13,534:INFO:Uploading model into container now
2025-12-07 13:44:13,545:INFO:_master_model_container: 15
2025-12-07 13:44:13,545:INFO:_display_container: 9
2025-12-07 13:44:13,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:44:13,545:INFO:create_model() successfully completed......................................
2025-12-07 13:44:13,807:INFO:Initializing tune_model()
2025-12-07 13:44:13,808:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=200, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:44:13,808:INFO:Checking exceptions
2025-12-07 13:44:13,814:INFO:Copying training dataset
2025-12-07 13:44:13,818:INFO:Checking base model
2025-12-07 13:44:13,818:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:44:13,819:INFO:Declaring metric variables
2025-12-07 13:44:13,820:INFO:Defining Hyperparameters
2025-12-07 13:44:13,926:INFO:Tuning with n_jobs=-1
2025-12-07 13:44:13,926:INFO:Initializing RandomizedSearchCV
2025-12-07 13:46:28,308:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 1e-06, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:46:28,324:INFO:Hyperparameter search completed
2025-12-07 13:46:28,326:INFO:SubProcess create_model() called ==================================
2025-12-07 13:46:28,328:INFO:Initializing create_model()
2025-12-07 13:46:28,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e70aa50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.2, 'num_leaves': 2, 'n_estimators': 120, 'min_split_gain': 0.9, 'min_child_samples': 1, 'learning_rate': 1e-06, 'feature_fraction': 0.9, 'bagging_freq': 1, 'bagging_fraction': 0.8})
2025-12-07 13:46:28,329:INFO:Checking exceptions
2025-12-07 13:46:28,329:INFO:Importing libraries
2025-12-07 13:46:28,330:INFO:Copying training dataset
2025-12-07 13:46:28,342:INFO:Defining folds
2025-12-07 13:46:28,342:INFO:Declaring metric variables
2025-12-07 13:46:28,349:INFO:Importing untrained model
2025-12-07 13:46:28,349:INFO:Declaring custom model
2025-12-07 13:46:28,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:46:28,356:INFO:Starting cross validation
2025-12-07 13:46:28,360:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:46:28,580:INFO:Calculating mean and std
2025-12-07 13:46:28,580:INFO:Creating metrics dataframe
2025-12-07 13:46:28,584:INFO:Finalizing model
2025-12-07 13:46:28,613:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-12-07 13:46:28,613:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-12-07 13:46:28,613:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:46:28,617:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:46:28,617:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-12-07 13:46:28,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-12-07 13:46:28,617:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:46:28,617:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:46:28,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.
2025-12-07 13:46:28,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:46:28,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:46:28,619:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:46:28,619:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:46:28,619:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:46:28,658:INFO:Uploading results into container
2025-12-07 13:46:28,659:INFO:Uploading model into container now
2025-12-07 13:46:28,660:INFO:_master_model_container: 16
2025-12-07 13:46:28,661:INFO:_display_container: 10
2025-12-07 13:46:28,661:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:46:28,661:INFO:create_model() successfully completed......................................
2025-12-07 13:46:28,917:INFO:SubProcess create_model() end ==================================
2025-12-07 13:46:28,917:INFO:choose_better activated
2025-12-07 13:46:28,919:INFO:SubProcess create_model() called ==================================
2025-12-07 13:46:28,919:INFO:Initializing create_model()
2025-12-07 13:46:28,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:46:28,919:INFO:Checking exceptions
2025-12-07 13:46:28,920:INFO:Importing libraries
2025-12-07 13:46:28,920:INFO:Copying training dataset
2025-12-07 13:46:28,922:INFO:Defining folds
2025-12-07 13:46:28,922:INFO:Declaring metric variables
2025-12-07 13:46:28,922:INFO:Importing untrained model
2025-12-07 13:46:28,923:INFO:Declaring custom model
2025-12-07 13:46:28,923:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:46:28,923:INFO:Starting cross validation
2025-12-07 13:46:28,923:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:46:30,269:INFO:Calculating mean and std
2025-12-07 13:46:30,269:INFO:Creating metrics dataframe
2025-12-07 13:46:30,270:INFO:Finalizing model
2025-12-07 13:46:30,292:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:46:30,292:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:46:30,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.
2025-12-07 13:46:30,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:46:30,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:46:30,293:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:46:30,293:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:46:30,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:46:30,655:INFO:Uploading results into container
2025-12-07 13:46:30,655:INFO:Uploading model into container now
2025-12-07 13:46:30,655:INFO:_master_model_container: 17
2025-12-07 13:46:30,655:INFO:_display_container: 11
2025-12-07 13:46:30,656:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:46:30,656:INFO:create_model() successfully completed......................................
2025-12-07 13:46:30,761:INFO:SubProcess create_model() end ==================================
2025-12-07 13:46:30,761:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:46:30,762:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9739
2025-12-07 13:46:30,762:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:46:30,762:INFO:choose_better completed
2025-12-07 13:46:30,768:INFO:_master_model_container: 17
2025-12-07 13:46:30,768:INFO:_display_container: 10
2025-12-07 13:46:30,769:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:46:30,769:INFO:tune_model() successfully completed......................................
2025-12-07 13:46:50,402:INFO:Initializing create_model()
2025-12-07 13:46:50,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:46:50,404:INFO:Checking exceptions
2025-12-07 13:46:50,437:INFO:Importing libraries
2025-12-07 13:46:50,438:INFO:Copying training dataset
2025-12-07 13:46:50,452:INFO:Defining folds
2025-12-07 13:46:50,453:INFO:Declaring metric variables
2025-12-07 13:46:50,455:INFO:Importing untrained model
2025-12-07 13:46:50,457:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:46:50,468:INFO:Starting cross validation
2025-12-07 13:46:50,470:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:46:52,010:INFO:Calculating mean and std
2025-12-07 13:46:52,012:INFO:Creating metrics dataframe
2025-12-07 13:46:52,015:INFO:Finalizing model
2025-12-07 13:46:52,047:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:46:52,047:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:46:52,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.
2025-12-07 13:46:52,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:46:52,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:46:52,048:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:46:52,048:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:46:52,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:46:52,418:INFO:Uploading results into container
2025-12-07 13:46:52,418:INFO:Uploading model into container now
2025-12-07 13:46:52,424:INFO:_master_model_container: 18
2025-12-07 13:46:52,424:INFO:_display_container: 11
2025-12-07 13:46:52,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:46:52,425:INFO:create_model() successfully completed......................................
2025-12-07 13:46:52,757:INFO:Initializing tune_model()
2025-12-07 13:46:52,757:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=75, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-07 13:46:52,757:INFO:Checking exceptions
2025-12-07 13:46:52,764:INFO:Copying training dataset
2025-12-07 13:46:52,768:INFO:Checking base model
2025-12-07 13:46:52,768:INFO:Base model : Light Gradient Boosting Machine
2025-12-07 13:46:52,770:INFO:Declaring metric variables
2025-12-07 13:46:52,772:INFO:Defining Hyperparameters
2025-12-07 13:46:52,916:INFO:Tuning with n_jobs=-1
2025-12-07 13:46:52,917:INFO:Initializing RandomizedSearchCV
2025-12-07 13:47:51,077:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 5, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-12-07 13:47:51,095:INFO:Hyperparameter search completed
2025-12-07 13:47:51,096:INFO:SubProcess create_model() called ==================================
2025-12-07 13:47:51,097:INFO:Initializing create_model()
2025-12-07 13:47:51,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e49a650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 5, 'num_leaves': 2, 'n_estimators': 230, 'min_split_gain': 0.5, 'min_child_samples': 76, 'learning_rate': 1e-07, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-12-07 13:47:51,097:INFO:Checking exceptions
2025-12-07 13:47:51,097:INFO:Importing libraries
2025-12-07 13:47:51,098:INFO:Copying training dataset
2025-12-07 13:47:51,115:INFO:Defining folds
2025-12-07 13:47:51,115:INFO:Declaring metric variables
2025-12-07 13:47:51,126:INFO:Importing untrained model
2025-12-07 13:47:51,126:INFO:Declaring custom model
2025-12-07 13:47:51,134:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:47:51,138:INFO:Starting cross validation
2025-12-07 13:47:51,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:47:52,452:INFO:Calculating mean and std
2025-12-07 13:47:52,456:INFO:Creating metrics dataframe
2025-12-07 13:47:52,465:INFO:Finalizing model
2025-12-07 13:47:52,516:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:47:52,516:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:47:52,517:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:47:52,522:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:47:52,522:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-12-07 13:47:52,522:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-12-07 13:47:52,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-07 13:47:52,523:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:47:52,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.
2025-12-07 13:47:52,524:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:47:52,524:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:47:52,524:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:47:52,524:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:47:52,524:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:47:52,633:INFO:Uploading results into container
2025-12-07 13:47:52,634:INFO:Uploading model into container now
2025-12-07 13:47:52,635:INFO:_master_model_container: 19
2025-12-07 13:47:52,635:INFO:_display_container: 12
2025-12-07 13:47:52,636:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:47:52,637:INFO:create_model() successfully completed......................................
2025-12-07 13:47:53,312:INFO:SubProcess create_model() end ==================================
2025-12-07 13:47:53,313:INFO:choose_better activated
2025-12-07 13:47:53,315:INFO:SubProcess create_model() called ==================================
2025-12-07 13:47:53,316:INFO:Initializing create_model()
2025-12-07 13:47:53,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-07 13:47:53,316:INFO:Checking exceptions
2025-12-07 13:47:53,317:INFO:Importing libraries
2025-12-07 13:47:53,317:INFO:Copying training dataset
2025-12-07 13:47:53,329:INFO:Defining folds
2025-12-07 13:47:53,330:INFO:Declaring metric variables
2025-12-07 13:47:53,330:INFO:Importing untrained model
2025-12-07 13:47:53,330:INFO:Declaring custom model
2025-12-07 13:47:53,331:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-07 13:47:53,331:INFO:Starting cross validation
2025-12-07 13:47:53,332:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-07 13:47:55,152:INFO:Calculating mean and std
2025-12-07 13:47:55,154:INFO:Creating metrics dataframe
2025-12-07 13:47:55,161:INFO:Finalizing model
2025-12-07 13:47:55,201:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-07 13:47:55,201:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-07 13:47:55,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.
2025-12-07 13:47:55,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-07 13:47:55,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-07 13:47:55,203:INFO:[LightGBM] [Info] Total Bins 85
2025-12-07 13:47:55,203:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-07 13:47:55,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-07 13:47:55,668:INFO:Uploading results into container
2025-12-07 13:47:55,669:INFO:Uploading model into container now
2025-12-07 13:47:55,669:INFO:_master_model_container: 20
2025-12-07 13:47:55,669:INFO:_display_container: 13
2025-12-07 13:47:55,670:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:47:55,670:INFO:create_model() successfully completed......................................
2025-12-07 13:47:55,884:INFO:SubProcess create_model() end ==================================
2025-12-07 13:47:55,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-07 13:47:55,885:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9739
2025-12-07 13:47:55,885:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-07 13:47:55,885:INFO:choose_better completed
2025-12-07 13:47:55,891:INFO:_master_model_container: 20
2025-12-07 13:47:55,892:INFO:_display_container: 12
2025-12-07 13:47:55,892:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=230, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=5, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-07 13:47:55,892:INFO:tune_model() successfully completed......................................
2025-12-08 11:19:32,339:INFO:Initializing create_model()
2025-12-08 11:19:32,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:19:32,347:INFO:Checking exceptions
2025-12-08 11:19:32,596:INFO:Importing libraries
2025-12-08 11:19:32,601:INFO:Copying training dataset
2025-12-08 11:19:32,769:INFO:Defining folds
2025-12-08 11:19:32,769:INFO:Declaring metric variables
2025-12-08 11:19:32,771:INFO:Importing untrained model
2025-12-08 11:19:32,775:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:19:32,779:INFO:Starting cross validation
2025-12-08 11:19:32,814:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:19:36,803:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:36,803:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:36,803:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:36,803:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:36,803:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:36,926:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:19:36,926:INFO:
2025-12-08 11:19:36,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:19:36,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:19:36,927:INFO:
2025-12-08 11:19:36,927:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-08 11:19:36,927:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3312[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-08 11:19:36,927:INFO:
2025-12-08 11:19:36,927:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-08 11:19:36,927:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-08 11:19:36,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002749 seconds.
2025-12-08 11:19:36,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:36,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:36,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002730 seconds.
2025-12-08 11:19:36,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:36,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002785 seconds.
2025-12-08 11:19:36,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:36,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.
2025-12-08 11:19:36,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:36,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002746 seconds.
2025-12-08 11:19:36,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:36,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Total Bins 81[LightGBM] [Info] Total Bins 77
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Total Bins 83
2025-12-08 11:19:36,933:INFO:
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Total Bins 91
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Total Bins 86
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Number of data points in the train set: 6624, number of used features: 11
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-08 11:19:36,933:INFO:
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:19:36,933:INFO:
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:19:36,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:19:36,934:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:19:38,339:INFO:Calculating mean and std
2025-12-08 11:19:38,351:INFO:Creating metrics dataframe
2025-12-08 11:19:38,377:INFO:Finalizing model
2025-12-08 11:19:38,485:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:19:38,487:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:19:38,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.
2025-12-08 11:19:38,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:19:38,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:19:38,489:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:19:38,490:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:19:38,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:19:38,851:INFO:Uploading results into container
2025-12-08 11:19:38,852:INFO:Uploading model into container now
2025-12-08 11:19:38,880:INFO:_master_model_container: 21
2025-12-08 11:19:38,880:INFO:_display_container: 13
2025-12-08 11:19:38,882:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:19:38,882:INFO:create_model() successfully completed......................................
2025-12-08 11:19:40,287:INFO:Initializing tune_model()
2025-12-08 11:19:40,288:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:19:40,288:INFO:Checking exceptions
2025-12-08 11:19:40,299:INFO:Copying training dataset
2025-12-08 11:19:40,301:INFO:Checking base model
2025-12-08 11:19:40,301:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:19:40,303:INFO:Declaring metric variables
2025-12-08 11:19:40,304:INFO:Defining Hyperparameters
2025-12-08 11:19:40,436:INFO:Tuning with n_jobs=-1
2025-12-08 11:19:40,436:INFO:Initializing RandomizedSearchCV
2025-12-08 11:19:43,704:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:43,847:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:19:44,001:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-08 11:20:17,681:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-08 11:20:17,689:INFO:Hyperparameter search completed
2025-12-08 11:20:17,689:INFO:SubProcess create_model() called ==================================
2025-12-08 11:20:17,690:INFO:Initializing create_model()
2025-12-08 11:20:17,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c1b6510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-08 11:20:17,690:INFO:Checking exceptions
2025-12-08 11:20:17,690:INFO:Importing libraries
2025-12-08 11:20:17,691:INFO:Copying training dataset
2025-12-08 11:20:17,701:INFO:Defining folds
2025-12-08 11:20:17,701:INFO:Declaring metric variables
2025-12-08 11:20:17,706:INFO:Importing untrained model
2025-12-08 11:20:17,706:INFO:Declaring custom model
2025-12-08 11:20:17,712:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:20:17,714:INFO:Starting cross validation
2025-12-08 11:20:17,716:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:20:18,690:INFO:Calculating mean and std
2025-12-08 11:20:18,690:INFO:Creating metrics dataframe
2025-12-08 11:20:18,693:INFO:Finalizing model
2025-12-08 11:20:18,724:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:20:18,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:20:18,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:20:18,726:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:20:18,726:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:20:18,726:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:20:18,726:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:20:18,726:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:20:18,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.
2025-12-08 11:20:18,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:20:18,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:20:18,727:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:20:18,728:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:20:18,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:20:18,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:20:18,994:INFO:Uploading results into container
2025-12-08 11:20:18,995:INFO:Uploading model into container now
2025-12-08 11:20:18,997:INFO:_master_model_container: 22
2025-12-08 11:20:18,997:INFO:_display_container: 14
2025-12-08 11:20:18,998:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:20:18,998:INFO:create_model() successfully completed......................................
2025-12-08 11:20:19,212:INFO:SubProcess create_model() end ==================================
2025-12-08 11:20:19,213:INFO:choose_better activated
2025-12-08 11:20:19,214:INFO:SubProcess create_model() called ==================================
2025-12-08 11:20:19,214:INFO:Initializing create_model()
2025-12-08 11:20:19,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:20:19,215:INFO:Checking exceptions
2025-12-08 11:20:19,215:INFO:Importing libraries
2025-12-08 11:20:19,216:INFO:Copying training dataset
2025-12-08 11:20:19,218:INFO:Defining folds
2025-12-08 11:20:19,218:INFO:Declaring metric variables
2025-12-08 11:20:19,218:INFO:Importing untrained model
2025-12-08 11:20:19,218:INFO:Declaring custom model
2025-12-08 11:20:19,218:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:20:19,219:INFO:Starting cross validation
2025-12-08 11:20:19,219:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:20:20,657:INFO:Calculating mean and std
2025-12-08 11:20:20,658:INFO:Creating metrics dataframe
2025-12-08 11:20:20,659:INFO:Finalizing model
2025-12-08 11:20:20,686:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:20:20,686:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:20:20,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.
2025-12-08 11:20:20,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:20:20,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:20:20,687:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:20:20,687:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:20:20,688:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:20:21,079:INFO:Uploading results into container
2025-12-08 11:20:21,079:INFO:Uploading model into container now
2025-12-08 11:20:21,079:INFO:_master_model_container: 23
2025-12-08 11:20:21,079:INFO:_display_container: 15
2025-12-08 11:20:21,080:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:20:21,080:INFO:create_model() successfully completed......................................
2025-12-08 11:20:21,225:INFO:SubProcess create_model() end ==================================
2025-12-08 11:20:21,225:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:20:21,226:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-08 11:20:21,226:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:20:21,226:INFO:choose_better completed
2025-12-08 11:20:21,230:INFO:_master_model_container: 23
2025-12-08 11:20:21,230:INFO:_display_container: 14
2025-12-08 11:20:21,230:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:20:21,230:INFO:tune_model() successfully completed......................................
2025-12-08 11:20:31,654:INFO:Initializing create_model()
2025-12-08 11:20:31,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:20:31,657:INFO:Checking exceptions
2025-12-08 11:20:31,682:INFO:Importing libraries
2025-12-08 11:20:31,682:INFO:Copying training dataset
2025-12-08 11:20:31,688:INFO:Defining folds
2025-12-08 11:20:31,688:INFO:Declaring metric variables
2025-12-08 11:20:31,691:INFO:Importing untrained model
2025-12-08 11:20:31,697:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:20:31,701:INFO:Starting cross validation
2025-12-08 11:20:31,706:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:20:33,149:INFO:Calculating mean and std
2025-12-08 11:20:33,149:INFO:Creating metrics dataframe
2025-12-08 11:20:33,152:INFO:Finalizing model
2025-12-08 11:20:33,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:20:33,179:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:20:33,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.
2025-12-08 11:20:33,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:20:33,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:20:33,180:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:20:33,180:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:20:33,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:20:33,550:INFO:Uploading results into container
2025-12-08 11:20:33,552:INFO:Uploading model into container now
2025-12-08 11:20:33,556:INFO:_master_model_container: 24
2025-12-08 11:20:33,556:INFO:_display_container: 15
2025-12-08 11:20:33,557:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:20:33,557:INFO:create_model() successfully completed......................................
2025-12-08 11:20:33,862:INFO:Initializing tune_model()
2025-12-08 11:20:33,862:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:20:33,862:INFO:Checking exceptions
2025-12-08 11:20:33,869:INFO:Copying training dataset
2025-12-08 11:20:33,874:INFO:Checking base model
2025-12-08 11:20:33,874:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:20:33,876:INFO:Declaring metric variables
2025-12-08 11:20:33,877:INFO:Defining Hyperparameters
2025-12-08 11:20:33,998:INFO:Tuning with n_jobs=-1
2025-12-08 11:20:33,998:INFO:Initializing RandomizedSearchCV
2025-12-08 11:21:15,149:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2025-12-08 11:21:15,154:INFO:Hyperparameter search completed
2025-12-08 11:21:15,155:INFO:SubProcess create_model() called ==================================
2025-12-08 11:21:15,160:INFO:Initializing create_model()
2025-12-08 11:21:15,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e41c950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.7, 'num_leaves': 2, 'n_estimators': 220, 'min_split_gain': 0.8, 'min_child_samples': 36, 'learning_rate': 0.0001, 'feature_fraction': 0.6, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2025-12-08 11:21:15,160:INFO:Checking exceptions
2025-12-08 11:21:15,160:INFO:Importing libraries
2025-12-08 11:21:15,161:INFO:Copying training dataset
2025-12-08 11:21:15,175:INFO:Defining folds
2025-12-08 11:21:15,175:INFO:Declaring metric variables
2025-12-08 11:21:15,186:INFO:Importing untrained model
2025-12-08 11:21:15,186:INFO:Declaring custom model
2025-12-08 11:21:15,192:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:21:15,195:INFO:Starting cross validation
2025-12-08 11:21:15,197:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:21:15,562:INFO:Calculating mean and std
2025-12-08 11:21:15,562:INFO:Creating metrics dataframe
2025-12-08 11:21:15,564:INFO:Finalizing model
2025-12-08 11:21:15,593:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:21:15,593:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:21:15,593:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:21:15,594:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:21:15,594:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:21:15,594:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:21:15,594:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:21:15,594:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:21:15,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.
2025-12-08 11:21:15,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:21:15,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:21:15,596:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:21:15,596:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:21:15,596:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:21:15,676:INFO:Uploading results into container
2025-12-08 11:21:15,676:INFO:Uploading model into container now
2025-12-08 11:21:15,677:INFO:_master_model_container: 25
2025-12-08 11:21:15,677:INFO:_display_container: 16
2025-12-08 11:21:15,677:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:21:15,677:INFO:create_model() successfully completed......................................
2025-12-08 11:21:15,893:INFO:SubProcess create_model() end ==================================
2025-12-08 11:21:15,893:INFO:choose_better activated
2025-12-08 11:21:15,894:INFO:SubProcess create_model() called ==================================
2025-12-08 11:21:15,895:INFO:Initializing create_model()
2025-12-08 11:21:15,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:21:15,895:INFO:Checking exceptions
2025-12-08 11:21:15,896:INFO:Importing libraries
2025-12-08 11:21:15,896:INFO:Copying training dataset
2025-12-08 11:21:15,899:INFO:Defining folds
2025-12-08 11:21:15,899:INFO:Declaring metric variables
2025-12-08 11:21:15,899:INFO:Importing untrained model
2025-12-08 11:21:15,899:INFO:Declaring custom model
2025-12-08 11:21:15,899:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:21:15,899:INFO:Starting cross validation
2025-12-08 11:21:15,899:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:21:17,324:INFO:Calculating mean and std
2025-12-08 11:21:17,325:INFO:Creating metrics dataframe
2025-12-08 11:21:17,328:INFO:Finalizing model
2025-12-08 11:21:17,355:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:21:17,356:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:21:17,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-12-08 11:21:17,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:21:17,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:21:17,357:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:21:17,357:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:21:17,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:21:17,735:INFO:Uploading results into container
2025-12-08 11:21:17,735:INFO:Uploading model into container now
2025-12-08 11:21:17,735:INFO:_master_model_container: 26
2025-12-08 11:21:17,735:INFO:_display_container: 17
2025-12-08 11:21:17,736:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:21:17,736:INFO:create_model() successfully completed......................................
2025-12-08 11:21:17,841:INFO:SubProcess create_model() end ==================================
2025-12-08 11:21:17,841:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:21:17,842:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9666
2025-12-08 11:21:17,842:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:21:17,842:INFO:choose_better completed
2025-12-08 11:21:17,846:INFO:_master_model_container: 26
2025-12-08 11:21:17,846:INFO:_display_container: 16
2025-12-08 11:21:17,846:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:21:17,846:INFO:tune_model() successfully completed......................................
2025-12-08 11:21:27,607:INFO:Initializing create_model()
2025-12-08 11:21:27,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:21:27,608:INFO:Checking exceptions
2025-12-08 11:21:27,645:INFO:Importing libraries
2025-12-08 11:21:27,645:INFO:Copying training dataset
2025-12-08 11:21:27,654:INFO:Defining folds
2025-12-08 11:21:27,654:INFO:Declaring metric variables
2025-12-08 11:21:27,655:INFO:Importing untrained model
2025-12-08 11:21:27,657:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:21:27,659:INFO:Starting cross validation
2025-12-08 11:21:27,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:21:29,330:INFO:Calculating mean and std
2025-12-08 11:21:29,332:INFO:Creating metrics dataframe
2025-12-08 11:21:29,356:INFO:Finalizing model
2025-12-08 11:21:29,392:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:21:29,392:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:21:29,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000729 seconds.
2025-12-08 11:21:29,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:21:29,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:21:29,394:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:21:29,394:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:21:29,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:21:29,816:INFO:Uploading results into container
2025-12-08 11:21:29,817:INFO:Uploading model into container now
2025-12-08 11:21:29,826:INFO:_master_model_container: 27
2025-12-08 11:21:29,826:INFO:_display_container: 17
2025-12-08 11:21:29,826:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:21:29,827:INFO:create_model() successfully completed......................................
2025-12-08 11:21:30,266:INFO:Initializing tune_model()
2025-12-08 11:21:30,266:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=55, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:21:30,266:INFO:Checking exceptions
2025-12-08 11:21:30,273:INFO:Copying training dataset
2025-12-08 11:21:30,279:INFO:Checking base model
2025-12-08 11:21:30,279:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:21:30,280:INFO:Declaring metric variables
2025-12-08 11:21:30,282:INFO:Defining Hyperparameters
2025-12-08 11:21:30,535:INFO:Tuning with n_jobs=-1
2025-12-08 11:21:30,536:INFO:Initializing RandomizedSearchCV
2025-12-08 11:22:15,288:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-08 11:22:15,298:INFO:Hyperparameter search completed
2025-12-08 11:22:15,298:INFO:SubProcess create_model() called ==================================
2025-12-08 11:22:15,300:INFO:Initializing create_model()
2025-12-08 11:22:15,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e03b9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-08 11:22:15,300:INFO:Checking exceptions
2025-12-08 11:22:15,301:INFO:Importing libraries
2025-12-08 11:22:15,302:INFO:Copying training dataset
2025-12-08 11:22:15,314:INFO:Defining folds
2025-12-08 11:22:15,314:INFO:Declaring metric variables
2025-12-08 11:22:15,317:INFO:Importing untrained model
2025-12-08 11:22:15,317:INFO:Declaring custom model
2025-12-08 11:22:15,322:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:22:15,325:INFO:Starting cross validation
2025-12-08 11:22:15,327:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:22:16,338:INFO:Calculating mean and std
2025-12-08 11:22:16,338:INFO:Creating metrics dataframe
2025-12-08 11:22:16,341:INFO:Finalizing model
2025-12-08 11:22:16,380:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:22:16,380:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:22:16,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:22:16,384:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:22:16,384:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:22:16,384:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:22:16,385:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:22:16,385:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:22:16,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.
2025-12-08 11:22:16,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:22:16,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:22:16,386:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:22:16,386:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:22:16,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:22:16,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:22:16,672:INFO:Uploading results into container
2025-12-08 11:22:16,672:INFO:Uploading model into container now
2025-12-08 11:22:16,673:INFO:_master_model_container: 28
2025-12-08 11:22:16,673:INFO:_display_container: 18
2025-12-08 11:22:16,674:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:22:16,674:INFO:create_model() successfully completed......................................
2025-12-08 11:22:16,925:INFO:SubProcess create_model() end ==================================
2025-12-08 11:22:16,926:INFO:choose_better activated
2025-12-08 11:22:16,927:INFO:SubProcess create_model() called ==================================
2025-12-08 11:22:16,927:INFO:Initializing create_model()
2025-12-08 11:22:16,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:22:16,927:INFO:Checking exceptions
2025-12-08 11:22:16,928:INFO:Importing libraries
2025-12-08 11:22:16,928:INFO:Copying training dataset
2025-12-08 11:22:16,931:INFO:Defining folds
2025-12-08 11:22:16,931:INFO:Declaring metric variables
2025-12-08 11:22:16,931:INFO:Importing untrained model
2025-12-08 11:22:16,931:INFO:Declaring custom model
2025-12-08 11:22:16,931:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:22:16,931:INFO:Starting cross validation
2025-12-08 11:22:16,932:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:22:18,414:INFO:Calculating mean and std
2025-12-08 11:22:18,414:INFO:Creating metrics dataframe
2025-12-08 11:22:18,416:INFO:Finalizing model
2025-12-08 11:22:18,442:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:22:18,442:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:22:18,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.
2025-12-08 11:22:18,443:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:22:18,443:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:22:18,443:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:22:18,443:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:22:18,443:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:22:18,856:INFO:Uploading results into container
2025-12-08 11:22:18,857:INFO:Uploading model into container now
2025-12-08 11:22:18,857:INFO:_master_model_container: 29
2025-12-08 11:22:18,857:INFO:_display_container: 19
2025-12-08 11:22:18,857:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:22:18,857:INFO:create_model() successfully completed......................................
2025-12-08 11:22:19,068:INFO:SubProcess create_model() end ==================================
2025-12-08 11:22:19,068:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:22:19,068:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-08 11:22:19,069:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:22:19,069:INFO:choose_better completed
2025-12-08 11:22:19,075:INFO:_master_model_container: 29
2025-12-08 11:22:19,075:INFO:_display_container: 18
2025-12-08 11:22:19,076:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:22:19,076:INFO:tune_model() successfully completed......................................
2025-12-08 11:22:54,239:INFO:Initializing create_model()
2025-12-08 11:22:54,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:22:54,241:INFO:Checking exceptions
2025-12-08 11:22:54,258:INFO:Importing libraries
2025-12-08 11:22:54,258:INFO:Copying training dataset
2025-12-08 11:22:54,264:INFO:Defining folds
2025-12-08 11:22:54,264:INFO:Declaring metric variables
2025-12-08 11:22:54,266:INFO:Importing untrained model
2025-12-08 11:22:54,269:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:22:54,272:INFO:Starting cross validation
2025-12-08 11:22:54,276:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:22:55,838:INFO:Calculating mean and std
2025-12-08 11:22:55,839:INFO:Creating metrics dataframe
2025-12-08 11:22:55,842:INFO:Finalizing model
2025-12-08 11:22:55,870:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:22:55,871:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:22:55,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.
2025-12-08 11:22:55,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:22:55,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:22:55,873:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:22:55,873:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:22:55,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:22:56,247:INFO:Uploading results into container
2025-12-08 11:22:56,247:INFO:Uploading model into container now
2025-12-08 11:22:56,254:INFO:_master_model_container: 30
2025-12-08 11:22:56,255:INFO:_display_container: 19
2025-12-08 11:22:56,255:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:22:56,255:INFO:create_model() successfully completed......................................
2025-12-08 11:22:56,462:INFO:Initializing tune_model()
2025-12-08 11:22:56,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:22:56,462:INFO:Checking exceptions
2025-12-08 11:22:56,469:INFO:Copying training dataset
2025-12-08 11:22:56,473:INFO:Checking base model
2025-12-08 11:22:56,473:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:22:56,474:INFO:Declaring metric variables
2025-12-08 11:22:56,475:INFO:Defining Hyperparameters
2025-12-08 11:22:56,597:INFO:Tuning with n_jobs=-1
2025-12-08 11:22:56,597:INFO:Initializing RandomizedSearchCV
2025-12-08 11:23:44,172:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2025-12-08 11:23:44,180:INFO:Hyperparameter search completed
2025-12-08 11:23:44,181:INFO:SubProcess create_model() called ==================================
2025-12-08 11:23:44,182:INFO:Initializing create_model()
2025-12-08 11:23:44,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f54fc90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.7, 'num_leaves': 2, 'n_estimators': 220, 'min_split_gain': 0.8, 'min_child_samples': 36, 'learning_rate': 0.0001, 'feature_fraction': 0.6, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2025-12-08 11:23:44,182:INFO:Checking exceptions
2025-12-08 11:23:44,182:INFO:Importing libraries
2025-12-08 11:23:44,183:INFO:Copying training dataset
2025-12-08 11:23:44,191:INFO:Defining folds
2025-12-08 11:23:44,191:INFO:Declaring metric variables
2025-12-08 11:23:44,196:INFO:Importing untrained model
2025-12-08 11:23:44,196:INFO:Declaring custom model
2025-12-08 11:23:44,200:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:23:44,202:INFO:Starting cross validation
2025-12-08 11:23:44,204:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:23:44,587:INFO:Calculating mean and std
2025-12-08 11:23:44,588:INFO:Creating metrics dataframe
2025-12-08 11:23:44,590:INFO:Finalizing model
2025-12-08 11:23:44,623:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:23:44,623:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:23:44,623:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:23:44,624:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:23:44,625:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:23:44,625:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:23:44,625:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:23:44,625:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:23:44,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.
2025-12-08 11:23:44,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:23:44,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:23:44,626:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:23:44,627:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:23:44,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:23:44,710:INFO:Uploading results into container
2025-12-08 11:23:44,710:INFO:Uploading model into container now
2025-12-08 11:23:44,713:INFO:_master_model_container: 31
2025-12-08 11:23:44,713:INFO:_display_container: 20
2025-12-08 11:23:44,714:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:23:44,714:INFO:create_model() successfully completed......................................
2025-12-08 11:23:44,962:INFO:SubProcess create_model() end ==================================
2025-12-08 11:23:44,962:INFO:choose_better activated
2025-12-08 11:23:44,963:INFO:SubProcess create_model() called ==================================
2025-12-08 11:23:44,964:INFO:Initializing create_model()
2025-12-08 11:23:44,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:23:44,964:INFO:Checking exceptions
2025-12-08 11:23:44,965:INFO:Importing libraries
2025-12-08 11:23:44,965:INFO:Copying training dataset
2025-12-08 11:23:44,968:INFO:Defining folds
2025-12-08 11:23:44,968:INFO:Declaring metric variables
2025-12-08 11:23:44,968:INFO:Importing untrained model
2025-12-08 11:23:44,968:INFO:Declaring custom model
2025-12-08 11:23:44,968:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:23:44,968:INFO:Starting cross validation
2025-12-08 11:23:44,969:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:23:46,436:INFO:Calculating mean and std
2025-12-08 11:23:46,437:INFO:Creating metrics dataframe
2025-12-08 11:23:46,440:INFO:Finalizing model
2025-12-08 11:23:46,469:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:23:46,469:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:23:46,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.
2025-12-08 11:23:46,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:23:46,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:23:46,470:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:23:46,470:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:23:46,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:23:46,832:INFO:Uploading results into container
2025-12-08 11:23:46,832:INFO:Uploading model into container now
2025-12-08 11:23:46,833:INFO:_master_model_container: 32
2025-12-08 11:23:46,833:INFO:_display_container: 21
2025-12-08 11:23:46,833:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:23:46,833:INFO:create_model() successfully completed......................................
2025-12-08 11:23:46,934:INFO:SubProcess create_model() end ==================================
2025-12-08 11:23:46,935:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:23:46,935:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9666
2025-12-08 11:23:46,935:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:23:46,935:INFO:choose_better completed
2025-12-08 11:23:46,944:INFO:_master_model_container: 32
2025-12-08 11:23:46,944:INFO:_display_container: 20
2025-12-08 11:23:46,944:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:23:46,944:INFO:tune_model() successfully completed......................................
2025-12-08 11:26:14,358:INFO:Initializing create_model()
2025-12-08 11:26:14,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:26:14,362:INFO:Checking exceptions
2025-12-08 11:26:14,417:INFO:Importing libraries
2025-12-08 11:26:14,419:INFO:Copying training dataset
2025-12-08 11:26:14,432:INFO:Defining folds
2025-12-08 11:26:14,432:INFO:Declaring metric variables
2025-12-08 11:26:14,433:INFO:Importing untrained model
2025-12-08 11:26:14,434:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:26:14,438:INFO:Starting cross validation
2025-12-08 11:26:14,452:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:26:16,057:INFO:Calculating mean and std
2025-12-08 11:26:16,058:INFO:Creating metrics dataframe
2025-12-08 11:26:16,062:INFO:Finalizing model
2025-12-08 11:26:16,104:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:26:16,105:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:26:16,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-12-08 11:26:16,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:26:16,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:26:16,106:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:26:16,106:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:26:16,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:26:16,464:INFO:Uploading results into container
2025-12-08 11:26:16,465:INFO:Uploading model into container now
2025-12-08 11:26:16,473:INFO:_master_model_container: 33
2025-12-08 11:26:16,473:INFO:_display_container: 21
2025-12-08 11:26:16,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:26:16,474:INFO:create_model() successfully completed......................................
2025-12-08 11:26:16,778:INFO:Initializing tune_model()
2025-12-08 11:26:16,778:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=57, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:26:16,778:INFO:Checking exceptions
2025-12-08 11:26:16,785:INFO:Copying training dataset
2025-12-08 11:26:16,793:INFO:Checking base model
2025-12-08 11:26:16,794:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:26:16,796:INFO:Declaring metric variables
2025-12-08 11:26:16,798:INFO:Defining Hyperparameters
2025-12-08 11:26:16,924:INFO:Tuning with n_jobs=-1
2025-12-08 11:26:16,924:INFO:Initializing RandomizedSearchCV
2025-12-08 11:27:00,670:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-08 11:27:00,692:INFO:Hyperparameter search completed
2025-12-08 11:27:00,696:INFO:SubProcess create_model() called ==================================
2025-12-08 11:27:00,701:INFO:Initializing create_model()
2025-12-08 11:27:00,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f4ce910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-08 11:27:00,701:INFO:Checking exceptions
2025-12-08 11:27:00,702:INFO:Importing libraries
2025-12-08 11:27:00,704:INFO:Copying training dataset
2025-12-08 11:27:00,725:INFO:Defining folds
2025-12-08 11:27:00,725:INFO:Declaring metric variables
2025-12-08 11:27:00,735:INFO:Importing untrained model
2025-12-08 11:27:00,735:INFO:Declaring custom model
2025-12-08 11:27:00,747:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:27:00,750:INFO:Starting cross validation
2025-12-08 11:27:00,752:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:27:01,701:INFO:Calculating mean and std
2025-12-08 11:27:01,701:INFO:Creating metrics dataframe
2025-12-08 11:27:01,705:INFO:Finalizing model
2025-12-08 11:27:01,737:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:27:01,737:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:27:01,737:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:27:01,740:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:27:01,740:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-08 11:27:01,740:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-08 11:27:01,740:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-08 11:27:01,740:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:27:01,741:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.
2025-12-08 11:27:01,741:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:27:01,741:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:27:01,741:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:27:01,741:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:27:01,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:27:01,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:01,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-08 11:27:02,005:INFO:Uploading results into container
2025-12-08 11:27:02,006:INFO:Uploading model into container now
2025-12-08 11:27:02,009:INFO:_master_model_container: 34
2025-12-08 11:27:02,009:INFO:_display_container: 22
2025-12-08 11:27:02,010:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:27:02,010:INFO:create_model() successfully completed......................................
2025-12-08 11:27:02,368:INFO:SubProcess create_model() end ==================================
2025-12-08 11:27:02,368:INFO:choose_better activated
2025-12-08 11:27:02,370:INFO:SubProcess create_model() called ==================================
2025-12-08 11:27:02,370:INFO:Initializing create_model()
2025-12-08 11:27:02,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:27:02,370:INFO:Checking exceptions
2025-12-08 11:27:02,371:INFO:Importing libraries
2025-12-08 11:27:02,371:INFO:Copying training dataset
2025-12-08 11:27:02,374:INFO:Defining folds
2025-12-08 11:27:02,374:INFO:Declaring metric variables
2025-12-08 11:27:02,374:INFO:Importing untrained model
2025-12-08 11:27:02,374:INFO:Declaring custom model
2025-12-08 11:27:02,375:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:27:02,375:INFO:Starting cross validation
2025-12-08 11:27:02,375:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:27:03,775:INFO:Calculating mean and std
2025-12-08 11:27:03,775:INFO:Creating metrics dataframe
2025-12-08 11:27:03,776:INFO:Finalizing model
2025-12-08 11:27:03,801:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:27:03,801:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:27:03,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.
2025-12-08 11:27:03,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:27:03,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:27:03,802:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:27:03,803:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:27:03,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:27:04,171:INFO:Uploading results into container
2025-12-08 11:27:04,171:INFO:Uploading model into container now
2025-12-08 11:27:04,171:INFO:_master_model_container: 35
2025-12-08 11:27:04,171:INFO:_display_container: 23
2025-12-08 11:27:04,172:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:27:04,172:INFO:create_model() successfully completed......................................
2025-12-08 11:27:04,270:INFO:SubProcess create_model() end ==================================
2025-12-08 11:27:04,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:27:04,271:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-08 11:27:04,271:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:27:04,271:INFO:choose_better completed
2025-12-08 11:27:04,276:INFO:_master_model_container: 35
2025-12-08 11:27:04,276:INFO:_display_container: 22
2025-12-08 11:27:04,276:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:27:04,276:INFO:tune_model() successfully completed......................................
2025-12-08 11:27:35,354:INFO:Initializing create_model()
2025-12-08 11:27:35,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:27:35,356:INFO:Checking exceptions
2025-12-08 11:27:35,376:INFO:Importing libraries
2025-12-08 11:27:35,378:INFO:Copying training dataset
2025-12-08 11:27:35,392:INFO:Defining folds
2025-12-08 11:27:35,392:INFO:Declaring metric variables
2025-12-08 11:27:35,394:INFO:Importing untrained model
2025-12-08 11:27:35,399:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:27:35,402:INFO:Starting cross validation
2025-12-08 11:27:35,408:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:27:37,104:INFO:Calculating mean and std
2025-12-08 11:27:37,105:INFO:Creating metrics dataframe
2025-12-08 11:27:37,109:INFO:Finalizing model
2025-12-08 11:27:37,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:27:37,149:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:27:37,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.
2025-12-08 11:27:37,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:27:37,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:27:37,151:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:27:37,151:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:27:37,151:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:27:37,455:INFO:Uploading results into container
2025-12-08 11:27:37,455:INFO:Uploading model into container now
2025-12-08 11:27:37,460:INFO:_master_model_container: 36
2025-12-08 11:27:37,461:INFO:_display_container: 23
2025-12-08 11:27:37,461:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:27:37,461:INFO:create_model() successfully completed......................................
2025-12-08 11:27:38,000:INFO:Initializing tune_model()
2025-12-08 11:27:38,000:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-08 11:27:38,000:INFO:Checking exceptions
2025-12-08 11:27:38,009:INFO:Copying training dataset
2025-12-08 11:27:38,019:INFO:Checking base model
2025-12-08 11:27:38,019:INFO:Base model : Light Gradient Boosting Machine
2025-12-08 11:27:38,021:INFO:Declaring metric variables
2025-12-08 11:27:38,023:INFO:Defining Hyperparameters
2025-12-08 11:27:38,145:INFO:Tuning with n_jobs=-1
2025-12-08 11:27:38,145:INFO:Initializing RandomizedSearchCV
2025-12-08 11:28:21,515:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2025-12-08 11:28:21,529:INFO:Hyperparameter search completed
2025-12-08 11:28:21,530:INFO:SubProcess create_model() called ==================================
2025-12-08 11:28:21,531:INFO:Initializing create_model()
2025-12-08 11:28:21,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c1b5f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.7, 'num_leaves': 2, 'n_estimators': 220, 'min_split_gain': 0.8, 'min_child_samples': 36, 'learning_rate': 0.0001, 'feature_fraction': 0.6, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2025-12-08 11:28:21,531:INFO:Checking exceptions
2025-12-08 11:28:21,532:INFO:Importing libraries
2025-12-08 11:28:21,532:INFO:Copying training dataset
2025-12-08 11:28:21,542:INFO:Defining folds
2025-12-08 11:28:21,542:INFO:Declaring metric variables
2025-12-08 11:28:21,545:INFO:Importing untrained model
2025-12-08 11:28:21,545:INFO:Declaring custom model
2025-12-08 11:28:21,548:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:28:21,550:INFO:Starting cross validation
2025-12-08 11:28:21,552:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:28:21,967:INFO:Calculating mean and std
2025-12-08 11:28:21,968:INFO:Creating metrics dataframe
2025-12-08 11:28:21,972:INFO:Finalizing model
2025-12-08 11:28:21,999:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:28:22,000:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:28:22,000:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:28:22,002:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:28:22,003:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:28:22,003:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:28:22,003:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:28:22,003:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:28:22,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.
2025-12-08 11:28:22,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:28:22,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:28:22,004:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:28:22,004:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:28:22,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:28:22,087:INFO:Uploading results into container
2025-12-08 11:28:22,087:INFO:Uploading model into container now
2025-12-08 11:28:22,088:INFO:_master_model_container: 37
2025-12-08 11:28:22,088:INFO:_display_container: 24
2025-12-08 11:28:22,088:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:28:22,088:INFO:create_model() successfully completed......................................
2025-12-08 11:28:22,651:INFO:SubProcess create_model() end ==================================
2025-12-08 11:28:22,651:INFO:choose_better activated
2025-12-08 11:28:22,653:INFO:SubProcess create_model() called ==================================
2025-12-08 11:28:22,654:INFO:Initializing create_model()
2025-12-08 11:28:22,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-08 11:28:22,655:INFO:Checking exceptions
2025-12-08 11:28:22,656:INFO:Importing libraries
2025-12-08 11:28:22,657:INFO:Copying training dataset
2025-12-08 11:28:22,662:INFO:Defining folds
2025-12-08 11:28:22,662:INFO:Declaring metric variables
2025-12-08 11:28:22,662:INFO:Importing untrained model
2025-12-08 11:28:22,662:INFO:Declaring custom model
2025-12-08 11:28:22,662:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-08 11:28:22,662:INFO:Starting cross validation
2025-12-08 11:28:22,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-08 11:28:24,672:INFO:Calculating mean and std
2025-12-08 11:28:24,676:INFO:Creating metrics dataframe
2025-12-08 11:28:24,680:INFO:Finalizing model
2025-12-08 11:28:24,721:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-08 11:28:24,721:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-08 11:28:24,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.
2025-12-08 11:28:24,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-08 11:28:24,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-08 11:28:24,723:INFO:[LightGBM] [Info] Total Bins 85
2025-12-08 11:28:24,723:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-08 11:28:24,723:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-08 11:28:25,077:INFO:Uploading results into container
2025-12-08 11:28:25,077:INFO:Uploading model into container now
2025-12-08 11:28:25,078:INFO:_master_model_container: 38
2025-12-08 11:28:25,078:INFO:_display_container: 25
2025-12-08 11:28:25,078:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:28:25,078:INFO:create_model() successfully completed......................................
2025-12-08 11:28:25,259:INFO:SubProcess create_model() end ==================================
2025-12-08 11:28:25,259:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-08 11:28:25,260:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9666
2025-12-08 11:28:25,260:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-08 11:28:25,260:INFO:choose_better completed
2025-12-08 11:28:25,264:INFO:_master_model_container: 38
2025-12-08 11:28:25,264:INFO:_display_container: 24
2025-12-08 11:28:25,265:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-08 11:28:25,265:INFO:tune_model() successfully completed......................................
2025-12-08 11:28:50,657:INFO:Initializing plot_model()
2025-12-08 11:28:50,658:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-08 11:28:50,658:INFO:Checking exceptions
2025-12-08 11:28:50,671:INFO:Preloading libraries
2025-12-08 11:28:50,676:INFO:Copying training dataset
2025-12-08 11:28:50,676:INFO:Plot type: confusion_matrix
2025-12-08 11:28:50,768:INFO:Fitting Model
2025-12-08 11:28:50,768:INFO:Scoring test/hold-out set
2025-12-08 11:28:50,769:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:28:50,769:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:28:50,769:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:28:50,772:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-08 11:28:50,772:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-08 11:28:50,772:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-08 11:28:50,852:INFO:Visual Rendered Successfully
2025-12-08 11:28:51,156:INFO:plot_model() successfully completed......................................
2025-12-09 00:11:49,000:INFO:Initializing create_model()
2025-12-09 00:11:49,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:11:49,007:INFO:Checking exceptions
2025-12-09 00:11:49,416:INFO:Importing libraries
2025-12-09 00:11:49,420:INFO:Copying training dataset
2025-12-09 00:11:49,476:INFO:Defining folds
2025-12-09 00:11:49,477:INFO:Declaring metric variables
2025-12-09 00:11:49,483:INFO:Importing untrained model
2025-12-09 00:11:49,501:INFO:Logistic Regression Imported successfully
2025-12-09 00:11:49,509:INFO:Starting cross validation
2025-12-09 00:11:49,558:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:11:54,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:11:54,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:11:54,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:11:54,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:11:54,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:11:55,233:INFO:Calculating mean and std
2025-12-09 00:11:55,250:INFO:Creating metrics dataframe
2025-12-09 00:11:55,328:INFO:Finalizing model
2025-12-09 00:11:55,568:INFO:Uploading results into container
2025-12-09 00:11:55,571:INFO:Uploading model into container now
2025-12-09 00:11:55,701:INFO:_master_model_container: 39
2025-12-09 00:11:55,701:INFO:_display_container: 25
2025-12-09 00:11:55,703:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:11:55,703:INFO:create_model() successfully completed......................................
2025-12-09 00:12:18,815:INFO:Initializing tune_model()
2025-12-09 00:12:18,816:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-09 00:12:18,817:INFO:Checking exceptions
2025-12-09 00:12:18,856:INFO:Copying training dataset
2025-12-09 00:12:18,860:INFO:Checking base model
2025-12-09 00:12:18,860:INFO:Base model : Logistic Regression
2025-12-09 00:12:18,863:INFO:Declaring metric variables
2025-12-09 00:12:18,864:INFO:Defining Hyperparameters
2025-12-09 00:12:19,076:INFO:Tuning with n_jobs=-1
2025-12-09 00:12:19,076:INFO:Initializing RandomizedSearchCV
2025-12-09 00:12:21,609:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:12:21,615:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:12:21,623:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-09 00:12:21,770:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1.577}
2025-12-09 00:12:21,776:INFO:Hyperparameter search completed
2025-12-09 00:12:21,776:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:21,777:INFO:Initializing create_model()
2025-12-09 00:12:21,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 1.577})
2025-12-09 00:12:21,777:INFO:Checking exceptions
2025-12-09 00:12:21,778:INFO:Importing libraries
2025-12-09 00:12:21,778:INFO:Copying training dataset
2025-12-09 00:12:21,788:INFO:Defining folds
2025-12-09 00:12:21,788:INFO:Declaring metric variables
2025-12-09 00:12:21,797:INFO:Importing untrained model
2025-12-09 00:12:21,797:INFO:Declaring custom model
2025-12-09 00:12:21,803:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:21,806:INFO:Starting cross validation
2025-12-09 00:12:21,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:21,916:INFO:Calculating mean and std
2025-12-09 00:12:21,916:INFO:Creating metrics dataframe
2025-12-09 00:12:21,918:INFO:Finalizing model
2025-12-09 00:12:21,985:INFO:Uploading results into container
2025-12-09 00:12:21,986:INFO:Uploading model into container now
2025-12-09 00:12:21,986:INFO:_master_model_container: 40
2025-12-09 00:12:21,986:INFO:_display_container: 26
2025-12-09 00:12:21,987:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:21,987:INFO:create_model() successfully completed......................................
2025-12-09 00:12:22,277:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:22,277:INFO:choose_better activated
2025-12-09 00:12:22,279:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:22,279:INFO:Initializing create_model()
2025-12-09 00:12:22,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:12:22,279:INFO:Checking exceptions
2025-12-09 00:12:22,280:INFO:Importing libraries
2025-12-09 00:12:22,280:INFO:Copying training dataset
2025-12-09 00:12:22,283:INFO:Defining folds
2025-12-09 00:12:22,283:INFO:Declaring metric variables
2025-12-09 00:12:22,283:INFO:Importing untrained model
2025-12-09 00:12:22,283:INFO:Declaring custom model
2025-12-09 00:12:22,283:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:22,283:INFO:Starting cross validation
2025-12-09 00:12:22,283:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:22,401:INFO:Calculating mean and std
2025-12-09 00:12:22,401:INFO:Creating metrics dataframe
2025-12-09 00:12:22,402:INFO:Finalizing model
2025-12-09 00:12:22,451:INFO:Uploading results into container
2025-12-09 00:12:22,451:INFO:Uploading model into container now
2025-12-09 00:12:22,452:INFO:_master_model_container: 41
2025-12-09 00:12:22,452:INFO:_display_container: 27
2025-12-09 00:12:22,453:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:22,453:INFO:create_model() successfully completed......................................
2025-12-09 00:12:22,605:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:22,606:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-09 00:12:22,606:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8769
2025-12-09 00:12:22,606:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-09 00:12:22,606:INFO:choose_better completed
2025-12-09 00:12:22,619:INFO:_master_model_container: 41
2025-12-09 00:12:22,619:INFO:_display_container: 26
2025-12-09 00:12:22,619:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:22,619:INFO:tune_model() successfully completed......................................
2025-12-09 00:12:34,049:INFO:Initializing tune_model()
2025-12-09 00:12:34,050:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-09 00:12:34,050:INFO:Checking exceptions
2025-12-09 00:12:34,077:INFO:Copying training dataset
2025-12-09 00:12:34,087:INFO:Checking base model
2025-12-09 00:12:34,087:INFO:Base model : Logistic Regression
2025-12-09 00:12:34,089:INFO:Declaring metric variables
2025-12-09 00:12:34,091:INFO:Defining Hyperparameters
2025-12-09 00:12:34,283:INFO:Tuning with n_jobs=-1
2025-12-09 00:12:34,284:INFO:Initializing RandomizedSearchCV
2025-12-09 00:12:35,987:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1.577}
2025-12-09 00:12:35,991:INFO:Hyperparameter search completed
2025-12-09 00:12:35,992:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:35,996:INFO:Initializing create_model()
2025-12-09 00:12:35,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddfd450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 1.577})
2025-12-09 00:12:35,996:INFO:Checking exceptions
2025-12-09 00:12:35,996:INFO:Importing libraries
2025-12-09 00:12:35,996:INFO:Copying training dataset
2025-12-09 00:12:36,002:INFO:Defining folds
2025-12-09 00:12:36,002:INFO:Declaring metric variables
2025-12-09 00:12:36,010:INFO:Importing untrained model
2025-12-09 00:12:36,010:INFO:Declaring custom model
2025-12-09 00:12:36,012:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:36,017:INFO:Starting cross validation
2025-12-09 00:12:36,019:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:36,080:INFO:Calculating mean and std
2025-12-09 00:12:36,080:INFO:Creating metrics dataframe
2025-12-09 00:12:36,082:INFO:Finalizing model
2025-12-09 00:12:36,143:INFO:Uploading results into container
2025-12-09 00:12:36,143:INFO:Uploading model into container now
2025-12-09 00:12:36,144:INFO:_master_model_container: 42
2025-12-09 00:12:36,144:INFO:_display_container: 27
2025-12-09 00:12:36,145:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:36,145:INFO:create_model() successfully completed......................................
2025-12-09 00:12:36,368:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:36,369:INFO:choose_better activated
2025-12-09 00:12:36,372:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:36,372:INFO:Initializing create_model()
2025-12-09 00:12:36,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:12:36,374:INFO:Checking exceptions
2025-12-09 00:12:36,378:INFO:Importing libraries
2025-12-09 00:12:36,378:INFO:Copying training dataset
2025-12-09 00:12:36,384:INFO:Defining folds
2025-12-09 00:12:36,384:INFO:Declaring metric variables
2025-12-09 00:12:36,384:INFO:Importing untrained model
2025-12-09 00:12:36,384:INFO:Declaring custom model
2025-12-09 00:12:36,385:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:36,385:INFO:Starting cross validation
2025-12-09 00:12:36,386:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:36,477:INFO:Calculating mean and std
2025-12-09 00:12:36,477:INFO:Creating metrics dataframe
2025-12-09 00:12:36,477:INFO:Finalizing model
2025-12-09 00:12:36,506:INFO:Uploading results into container
2025-12-09 00:12:36,507:INFO:Uploading model into container now
2025-12-09 00:12:36,507:INFO:_master_model_container: 43
2025-12-09 00:12:36,507:INFO:_display_container: 28
2025-12-09 00:12:36,507:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:36,507:INFO:create_model() successfully completed......................................
2025-12-09 00:12:36,643:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:36,643:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-09 00:12:36,643:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8769
2025-12-09 00:12:36,643:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-09 00:12:36,643:INFO:choose_better completed
2025-12-09 00:12:36,666:INFO:_master_model_container: 43
2025-12-09 00:12:36,666:INFO:_display_container: 27
2025-12-09 00:12:36,666:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:36,666:INFO:tune_model() successfully completed......................................
2025-12-09 00:12:44,218:INFO:Initializing tune_model()
2025-12-09 00:12:44,218:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=200, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-09 00:12:44,218:INFO:Checking exceptions
2025-12-09 00:12:44,252:INFO:Copying training dataset
2025-12-09 00:12:44,259:INFO:Checking base model
2025-12-09 00:12:44,259:INFO:Base model : Logistic Regression
2025-12-09 00:12:44,262:INFO:Declaring metric variables
2025-12-09 00:12:44,265:INFO:Defining Hyperparameters
2025-12-09 00:12:44,461:INFO:Tuning with n_jobs=-1
2025-12-09 00:12:44,461:INFO:Initializing RandomizedSearchCV
2025-12-09 00:12:50,854:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1.577}
2025-12-09 00:12:50,857:INFO:Hyperparameter search completed
2025-12-09 00:12:50,859:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:50,861:INFO:Initializing create_model()
2025-12-09 00:12:50,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319d5be50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 1.577})
2025-12-09 00:12:50,862:INFO:Checking exceptions
2025-12-09 00:12:50,862:INFO:Importing libraries
2025-12-09 00:12:50,862:INFO:Copying training dataset
2025-12-09 00:12:50,873:INFO:Defining folds
2025-12-09 00:12:50,873:INFO:Declaring metric variables
2025-12-09 00:12:50,876:INFO:Importing untrained model
2025-12-09 00:12:50,876:INFO:Declaring custom model
2025-12-09 00:12:50,878:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:50,880:INFO:Starting cross validation
2025-12-09 00:12:50,882:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:50,947:INFO:Calculating mean and std
2025-12-09 00:12:50,947:INFO:Creating metrics dataframe
2025-12-09 00:12:50,949:INFO:Finalizing model
2025-12-09 00:12:51,041:INFO:Uploading results into container
2025-12-09 00:12:51,041:INFO:Uploading model into container now
2025-12-09 00:12:51,042:INFO:_master_model_container: 44
2025-12-09 00:12:51,042:INFO:_display_container: 28
2025-12-09 00:12:51,042:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:51,042:INFO:create_model() successfully completed......................................
2025-12-09 00:12:51,293:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:51,294:INFO:choose_better activated
2025-12-09 00:12:51,296:INFO:SubProcess create_model() called ==================================
2025-12-09 00:12:51,296:INFO:Initializing create_model()
2025-12-09 00:12:51,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:12:51,296:INFO:Checking exceptions
2025-12-09 00:12:51,297:INFO:Importing libraries
2025-12-09 00:12:51,297:INFO:Copying training dataset
2025-12-09 00:12:51,299:INFO:Defining folds
2025-12-09 00:12:51,299:INFO:Declaring metric variables
2025-12-09 00:12:51,299:INFO:Importing untrained model
2025-12-09 00:12:51,299:INFO:Declaring custom model
2025-12-09 00:12:51,300:INFO:Logistic Regression Imported successfully
2025-12-09 00:12:51,300:INFO:Starting cross validation
2025-12-09 00:12:51,300:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:12:51,377:INFO:Calculating mean and std
2025-12-09 00:12:51,377:INFO:Creating metrics dataframe
2025-12-09 00:12:51,378:INFO:Finalizing model
2025-12-09 00:12:51,439:INFO:Uploading results into container
2025-12-09 00:12:51,439:INFO:Uploading model into container now
2025-12-09 00:12:51,440:INFO:_master_model_container: 45
2025-12-09 00:12:51,440:INFO:_display_container: 29
2025-12-09 00:12:51,440:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:51,440:INFO:create_model() successfully completed......................................
2025-12-09 00:12:51,606:INFO:SubProcess create_model() end ==================================
2025-12-09 00:12:51,606:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-09 00:12:51,607:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8769
2025-12-09 00:12:51,607:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-09 00:12:51,607:INFO:choose_better completed
2025-12-09 00:12:51,614:INFO:_master_model_container: 45
2025-12-09 00:12:51,614:INFO:_display_container: 28
2025-12-09 00:12:51,615:INFO:LogisticRegression(C=1.577, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:12:51,615:INFO:tune_model() successfully completed......................................
2025-12-09 00:13:11,144:INFO:Initializing tune_model()
2025-12-09 00:13:11,145:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=1000, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-09 00:13:11,145:INFO:Checking exceptions
2025-12-09 00:13:11,174:INFO:Copying training dataset
2025-12-09 00:13:11,250:INFO:Checking base model
2025-12-09 00:13:11,250:INFO:Base model : Logistic Regression
2025-12-09 00:13:11,259:INFO:Declaring metric variables
2025-12-09 00:13:11,278:INFO:Defining Hyperparameters
2025-12-09 00:13:11,466:INFO:Tuning with n_jobs=-1
2025-12-09 00:13:11,466:INFO:Initializing RandomizedSearchCV
2025-12-09 00:13:40,841:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.005}
2025-12-09 00:13:40,843:INFO:Hyperparameter search completed
2025-12-09 00:13:40,844:INFO:SubProcess create_model() called ==================================
2025-12-09 00:13:40,844:INFO:Initializing create_model()
2025-12-09 00:13:40,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e4c8a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 0.005})
2025-12-09 00:13:40,844:INFO:Checking exceptions
2025-12-09 00:13:40,845:INFO:Importing libraries
2025-12-09 00:13:40,845:INFO:Copying training dataset
2025-12-09 00:13:40,854:INFO:Defining folds
2025-12-09 00:13:40,855:INFO:Declaring metric variables
2025-12-09 00:13:40,860:INFO:Importing untrained model
2025-12-09 00:13:40,860:INFO:Declaring custom model
2025-12-09 00:13:40,865:INFO:Logistic Regression Imported successfully
2025-12-09 00:13:40,868:INFO:Starting cross validation
2025-12-09 00:13:40,870:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:13:40,944:INFO:Calculating mean and std
2025-12-09 00:13:40,945:INFO:Creating metrics dataframe
2025-12-09 00:13:40,947:INFO:Finalizing model
2025-12-09 00:13:41,037:INFO:Uploading results into container
2025-12-09 00:13:41,037:INFO:Uploading model into container now
2025-12-09 00:13:41,038:INFO:_master_model_container: 46
2025-12-09 00:13:41,038:INFO:_display_container: 29
2025-12-09 00:13:41,038:INFO:LogisticRegression(C=0.005, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:13:41,038:INFO:create_model() successfully completed......................................
2025-12-09 00:13:41,436:INFO:SubProcess create_model() end ==================================
2025-12-09 00:13:41,437:INFO:choose_better activated
2025-12-09 00:13:41,444:INFO:SubProcess create_model() called ==================================
2025-12-09 00:13:41,445:INFO:Initializing create_model()
2025-12-09 00:13:41,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:13:41,445:INFO:Checking exceptions
2025-12-09 00:13:41,447:INFO:Importing libraries
2025-12-09 00:13:41,447:INFO:Copying training dataset
2025-12-09 00:13:41,460:INFO:Defining folds
2025-12-09 00:13:41,461:INFO:Declaring metric variables
2025-12-09 00:13:41,461:INFO:Importing untrained model
2025-12-09 00:13:41,462:INFO:Declaring custom model
2025-12-09 00:13:41,464:INFO:Logistic Regression Imported successfully
2025-12-09 00:13:41,464:INFO:Starting cross validation
2025-12-09 00:13:41,466:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:13:41,951:INFO:Calculating mean and std
2025-12-09 00:13:41,951:INFO:Creating metrics dataframe
2025-12-09 00:13:41,953:INFO:Finalizing model
2025-12-09 00:13:42,014:INFO:Uploading results into container
2025-12-09 00:13:42,014:INFO:Uploading model into container now
2025-12-09 00:13:42,015:INFO:_master_model_container: 47
2025-12-09 00:13:42,015:INFO:_display_container: 30
2025-12-09 00:13:42,015:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:13:42,015:INFO:create_model() successfully completed......................................
2025-12-09 00:13:42,417:INFO:SubProcess create_model() end ==================================
2025-12-09 00:13:42,418:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-09 00:13:42,418:INFO:LogisticRegression(C=0.005, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.887
2025-12-09 00:13:42,418:INFO:LogisticRegression(C=0.005, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-09 00:13:42,418:INFO:choose_better completed
2025-12-09 00:13:42,436:INFO:_master_model_container: 47
2025-12-09 00:13:42,437:INFO:_display_container: 29
2025-12-09 00:13:42,437:INFO:LogisticRegression(C=0.005, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-09 00:13:42,437:INFO:tune_model() successfully completed......................................
2025-12-09 00:17:45,439:INFO:Initializing create_model()
2025-12-09 00:17:45,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:17:45,443:INFO:Checking exceptions
2025-12-09 00:17:45,482:INFO:Importing libraries
2025-12-09 00:17:45,485:INFO:Copying training dataset
2025-12-09 00:17:45,503:INFO:Defining folds
2025-12-09 00:17:45,503:INFO:Declaring metric variables
2025-12-09 00:17:45,506:INFO:Importing untrained model
2025-12-09 00:17:45,508:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-09 00:17:45,513:INFO:Starting cross validation
2025-12-09 00:17:45,522:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:17:45,846:INFO:Calculating mean and std
2025-12-09 00:17:45,847:INFO:Creating metrics dataframe
2025-12-09 00:17:45,849:INFO:Finalizing model
2025-12-09 00:17:45,949:INFO:Uploading results into container
2025-12-09 00:17:45,950:INFO:Uploading model into container now
2025-12-09 00:17:45,971:INFO:_master_model_container: 48
2025-12-09 00:17:45,971:INFO:_display_container: 30
2025-12-09 00:17:45,972:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-09 00:17:45,972:INFO:create_model() successfully completed......................................
2025-12-09 00:17:49,444:INFO:Initializing tune_model()
2025-12-09 00:17:49,444:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=40, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-09 00:17:49,444:INFO:Checking exceptions
2025-12-09 00:17:49,461:INFO:Copying training dataset
2025-12-09 00:17:49,471:INFO:Checking base model
2025-12-09 00:17:49,472:INFO:Base model : Quadratic Discriminant Analysis
2025-12-09 00:17:49,474:INFO:Declaring metric variables
2025-12-09 00:17:49,476:INFO:Defining Hyperparameters
2025-12-09 00:17:49,694:INFO:Tuning with n_jobs=-1
2025-12-09 00:17:49,694:INFO:Initializing RandomizedSearchCV
2025-12-09 00:17:50,760:INFO:best_params: {'actual_estimator__reg_param': 0.29}
2025-12-09 00:17:50,761:INFO:Hyperparameter search completed
2025-12-09 00:17:50,761:INFO:SubProcess create_model() called ==================================
2025-12-09 00:17:50,761:INFO:Initializing create_model()
2025-12-09 00:17:50,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.29})
2025-12-09 00:17:50,761:INFO:Checking exceptions
2025-12-09 00:17:50,761:INFO:Importing libraries
2025-12-09 00:17:50,761:INFO:Copying training dataset
2025-12-09 00:17:50,765:INFO:Defining folds
2025-12-09 00:17:50,765:INFO:Declaring metric variables
2025-12-09 00:17:50,767:INFO:Importing untrained model
2025-12-09 00:17:50,767:INFO:Declaring custom model
2025-12-09 00:17:50,768:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-09 00:17:50,770:INFO:Starting cross validation
2025-12-09 00:17:50,771:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:17:50,824:INFO:Calculating mean and std
2025-12-09 00:17:50,824:INFO:Creating metrics dataframe
2025-12-09 00:17:50,826:INFO:Finalizing model
2025-12-09 00:17:50,862:INFO:Uploading results into container
2025-12-09 00:17:50,863:INFO:Uploading model into container now
2025-12-09 00:17:50,864:INFO:_master_model_container: 49
2025-12-09 00:17:50,864:INFO:_display_container: 31
2025-12-09 00:17:50,864:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-12-09 00:17:50,864:INFO:create_model() successfully completed......................................
2025-12-09 00:17:51,060:INFO:SubProcess create_model() end ==================================
2025-12-09 00:17:51,061:INFO:choose_better activated
2025-12-09 00:17:51,064:INFO:SubProcess create_model() called ==================================
2025-12-09 00:17:51,064:INFO:Initializing create_model()
2025-12-09 00:17:51,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-09 00:17:51,064:INFO:Checking exceptions
2025-12-09 00:17:51,066:INFO:Importing libraries
2025-12-09 00:17:51,066:INFO:Copying training dataset
2025-12-09 00:17:51,072:INFO:Defining folds
2025-12-09 00:17:51,072:INFO:Declaring metric variables
2025-12-09 00:17:51,073:INFO:Importing untrained model
2025-12-09 00:17:51,073:INFO:Declaring custom model
2025-12-09 00:17:51,073:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-09 00:17:51,073:INFO:Starting cross validation
2025-12-09 00:17:51,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-09 00:17:51,145:INFO:Calculating mean and std
2025-12-09 00:17:51,146:INFO:Creating metrics dataframe
2025-12-09 00:17:51,146:INFO:Finalizing model
2025-12-09 00:17:51,167:INFO:Uploading results into container
2025-12-09 00:17:51,168:INFO:Uploading model into container now
2025-12-09 00:17:51,168:INFO:_master_model_container: 50
2025-12-09 00:17:51,168:INFO:_display_container: 32
2025-12-09 00:17:51,168:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-09 00:17:51,168:INFO:create_model() successfully completed......................................
2025-12-09 00:17:51,324:INFO:SubProcess create_model() end ==================================
2025-12-09 00:17:51,325:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8508
2025-12-09 00:17:51,325:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) result for Recall is 0.9538
2025-12-09 00:17:51,325:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) is best model
2025-12-09 00:17:51,325:INFO:choose_better completed
2025-12-09 00:17:51,332:INFO:_master_model_container: 50
2025-12-09 00:17:51,332:INFO:_display_container: 31
2025-12-09 00:17:51,332:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-12-09 00:17:51,333:INFO:tune_model() successfully completed......................................
2025-12-10 11:29:12,214:INFO:Initializing plot_model()
2025-12-10 11:29:12,224:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:29:12,224:INFO:Checking exceptions
2025-12-10 11:29:12,582:INFO:Preloading libraries
2025-12-10 11:29:12,644:INFO:Copying training dataset
2025-12-10 11:29:12,644:INFO:Plot type: pr
2025-12-10 11:29:13,142:INFO:Fitting Model
2025-12-10 11:29:13,147:INFO:Scoring test/hold-out set
2025-12-10 11:29:13,169:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-10 11:29:13,169:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-10 11:29:13,169:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-10 11:29:13,179:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-10 11:29:13,179:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-10 11:29:13,179:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-10 11:29:13,386:INFO:Visual Rendered Successfully
2025-12-10 11:29:15,126:INFO:plot_model() successfully completed......................................
2025-12-10 11:33:10,797:INFO:Initializing create_model()
2025-12-10 11:33:10,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:33:10,800:INFO:Checking exceptions
2025-12-10 11:33:10,942:INFO:Importing libraries
2025-12-10 11:33:10,947:INFO:Copying training dataset
2025-12-10 11:33:10,965:INFO:Defining folds
2025-12-10 11:33:10,965:INFO:Declaring metric variables
2025-12-10 11:33:10,967:INFO:Importing untrained model
2025-12-10 11:33:10,985:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:33:10,989:INFO:Starting cross validation
2025-12-10 11:33:11,016:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:33:16,858:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:16,858:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:16,858:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:16,858:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:16,858:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:16,989:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:16,990:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:16,990:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:16,990:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:16,990:INFO:
2025-12-10 11:33:16,990:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-10 11:33:16,990:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-10 11:33:16,990:INFO:
2025-12-10 11:33:16,990:INFO:[LightGBM] [Info] Number of positive: 3312, number of negative: 3312
2025-12-10 11:33:16,990:INFO:[LightGBM] [Info] Number of positive: 3311, number of negative: 3311
2025-12-10 11:33:16,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.
2025-12-10 11:33:16,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:16,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.
2025-12-10 11:33:16,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:16,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Total Bins 86
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002768 seconds.
2025-12-10 11:33:16,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:16,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002734 seconds.
2025-12-10 11:33:16,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:16,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Total Bins 91
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Total Bins 77
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002635 seconds.
2025-12-10 11:33:16,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:16,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Total Bins 83
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Total Bins 81
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Number of data points in the train set: 6624, number of used features: 11
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-10 11:33:16,995:INFO:[LightGBM] [Info] Number of data points in the train set: 6622, number of used features: 11
2025-12-10 11:33:17,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:17,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:17,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:17,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:17,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:18,419:INFO:Calculating mean and std
2025-12-10 11:33:18,422:INFO:Creating metrics dataframe
2025-12-10 11:33:18,448:INFO:Finalizing model
2025-12-10 11:33:18,668:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:18,668:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:33:18,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.
2025-12-10 11:33:18,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:18,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:18,670:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:33:18,670:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:33:18,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:19,032:INFO:Uploading results into container
2025-12-10 11:33:19,032:INFO:Uploading model into container now
2025-12-10 11:33:19,046:INFO:_master_model_container: 51
2025-12-10 11:33:19,046:INFO:_display_container: 32
2025-12-10 11:33:19,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:33:19,047:INFO:create_model() successfully completed......................................
2025-12-10 11:33:19,507:INFO:Initializing tune_model()
2025-12-10 11:33:19,508:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-10 11:33:19,508:INFO:Checking exceptions
2025-12-10 11:33:19,514:INFO:Copying training dataset
2025-12-10 11:33:19,518:INFO:Checking base model
2025-12-10 11:33:19,518:INFO:Base model : Light Gradient Boosting Machine
2025-12-10 11:33:19,519:INFO:Declaring metric variables
2025-12-10 11:33:19,521:INFO:Defining Hyperparameters
2025-12-10 11:33:19,642:INFO:Tuning with n_jobs=-1
2025-12-10 11:33:19,642:INFO:Initializing RandomizedSearchCV
2025-12-10 11:33:22,100:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:22,381:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:22,817:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:33:54,739:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-10 11:33:54,741:INFO:Hyperparameter search completed
2025-12-10 11:33:54,741:INFO:SubProcess create_model() called ==================================
2025-12-10 11:33:54,742:INFO:Initializing create_model()
2025-12-10 11:33:54,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e734290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-10 11:33:54,742:INFO:Checking exceptions
2025-12-10 11:33:54,742:INFO:Importing libraries
2025-12-10 11:33:54,742:INFO:Copying training dataset
2025-12-10 11:33:54,755:INFO:Defining folds
2025-12-10 11:33:54,755:INFO:Declaring metric variables
2025-12-10 11:33:54,759:INFO:Importing untrained model
2025-12-10 11:33:54,759:INFO:Declaring custom model
2025-12-10 11:33:54,772:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:33:54,775:INFO:Starting cross validation
2025-12-10 11:33:54,779:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:33:55,681:INFO:Calculating mean and std
2025-12-10 11:33:55,681:INFO:Creating metrics dataframe
2025-12-10 11:33:55,684:INFO:Finalizing model
2025-12-10 11:33:55,715:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:33:55,715:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:33:55,715:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:33:55,717:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:55,717:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:33:55,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:33:55,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:33:55,717:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:33:55,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.
2025-12-10 11:33:55,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:55,719:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:55,719:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:33:55,719:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:33:55,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:55,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:33:55,986:INFO:Uploading results into container
2025-12-10 11:33:55,987:INFO:Uploading model into container now
2025-12-10 11:33:55,987:INFO:_master_model_container: 52
2025-12-10 11:33:55,987:INFO:_display_container: 33
2025-12-10 11:33:55,988:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:33:55,988:INFO:create_model() successfully completed......................................
2025-12-10 11:33:56,173:INFO:SubProcess create_model() end ==================================
2025-12-10 11:33:56,173:INFO:choose_better activated
2025-12-10 11:33:56,175:INFO:SubProcess create_model() called ==================================
2025-12-10 11:33:56,175:INFO:Initializing create_model()
2025-12-10 11:33:56,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:33:56,175:INFO:Checking exceptions
2025-12-10 11:33:56,176:INFO:Importing libraries
2025-12-10 11:33:56,176:INFO:Copying training dataset
2025-12-10 11:33:56,178:INFO:Defining folds
2025-12-10 11:33:56,178:INFO:Declaring metric variables
2025-12-10 11:33:56,178:INFO:Importing untrained model
2025-12-10 11:33:56,178:INFO:Declaring custom model
2025-12-10 11:33:56,179:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:33:56,179:INFO:Starting cross validation
2025-12-10 11:33:56,179:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:33:57,747:INFO:Calculating mean and std
2025-12-10 11:33:57,748:INFO:Creating metrics dataframe
2025-12-10 11:33:57,762:INFO:Finalizing model
2025-12-10 11:33:57,796:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:33:57,796:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:33:57,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.
2025-12-10 11:33:57,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:33:57,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:33:57,797:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:33:57,797:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:33:57,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:33:58,176:INFO:Uploading results into container
2025-12-10 11:33:58,176:INFO:Uploading model into container now
2025-12-10 11:33:58,176:INFO:_master_model_container: 53
2025-12-10 11:33:58,176:INFO:_display_container: 34
2025-12-10 11:33:58,177:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:33:58,177:INFO:create_model() successfully completed......................................
2025-12-10 11:33:58,369:INFO:SubProcess create_model() end ==================================
2025-12-10 11:33:58,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-10 11:33:58,370:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-10 11:33:58,370:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-10 11:33:58,370:INFO:choose_better completed
2025-12-10 11:33:58,374:INFO:_master_model_container: 53
2025-12-10 11:33:58,374:INFO:_display_container: 33
2025-12-10 11:33:58,374:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:33:58,374:INFO:tune_model() successfully completed......................................
2025-12-10 11:34:03,754:INFO:Initializing plot_model()
2025-12-10 11:34:03,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:34:03,755:INFO:Checking exceptions
2025-12-10 11:34:03,764:INFO:Preloading libraries
2025-12-10 11:34:03,767:INFO:Copying training dataset
2025-12-10 11:34:03,768:INFO:Plot type: confusion_matrix
2025-12-10 11:34:03,813:INFO:Fitting Model
2025-12-10 11:34:03,813:INFO:Scoring test/hold-out set
2025-12-10 11:34:03,814:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:34:03,814:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:34:03,814:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:34:03,817:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:34:03,817:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:34:03,817:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:34:03,879:INFO:Visual Rendered Successfully
2025-12-10 11:34:04,081:INFO:plot_model() successfully completed......................................
2025-12-10 11:34:06,227:INFO:Initializing plot_model()
2025-12-10 11:34:06,227:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:34:06,227:INFO:Checking exceptions
2025-12-10 11:34:06,245:INFO:Preloading libraries
2025-12-10 11:34:06,253:INFO:Copying training dataset
2025-12-10 11:34:06,253:INFO:Plot type: pr
2025-12-10 11:34:06,285:INFO:Fitting Model
2025-12-10 11:34:06,286:INFO:Scoring test/hold-out set
2025-12-10 11:34:06,287:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:34:06,287:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:34:06,287:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:34:06,289:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:34:06,289:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:34:06,289:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:34:06,347:INFO:Visual Rendered Successfully
2025-12-10 11:34:06,546:INFO:plot_model() successfully completed......................................
2025-12-10 11:34:42,164:INFO:Initializing create_model()
2025-12-10 11:34:42,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:34:42,166:INFO:Checking exceptions
2025-12-10 11:34:42,193:INFO:Importing libraries
2025-12-10 11:34:42,193:INFO:Copying training dataset
2025-12-10 11:34:42,199:INFO:Defining folds
2025-12-10 11:34:42,199:INFO:Declaring metric variables
2025-12-10 11:34:42,202:INFO:Importing untrained model
2025-12-10 11:34:42,205:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:34:42,207:INFO:Starting cross validation
2025-12-10 11:34:42,220:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:34:44,012:INFO:Calculating mean and std
2025-12-10 11:34:44,016:INFO:Creating metrics dataframe
2025-12-10 11:34:44,024:INFO:Finalizing model
2025-12-10 11:34:44,081:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:34:44,081:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:34:44,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.
2025-12-10 11:34:44,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:34:44,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:34:44,083:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:34:44,083:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:34:44,083:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:34:44,349:INFO:Uploading results into container
2025-12-10 11:34:44,349:INFO:Uploading model into container now
2025-12-10 11:34:44,353:INFO:_master_model_container: 54
2025-12-10 11:34:44,353:INFO:_display_container: 34
2025-12-10 11:34:44,354:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:34:44,355:INFO:create_model() successfully completed......................................
2025-12-10 11:34:44,763:INFO:Initializing tune_model()
2025-12-10 11:34:44,764:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=40, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-10 11:34:44,764:INFO:Checking exceptions
2025-12-10 11:34:44,773:INFO:Copying training dataset
2025-12-10 11:34:44,779:INFO:Checking base model
2025-12-10 11:34:44,779:INFO:Base model : Light Gradient Boosting Machine
2025-12-10 11:34:44,781:INFO:Declaring metric variables
2025-12-10 11:34:44,782:INFO:Defining Hyperparameters
2025-12-10 11:34:44,917:INFO:Tuning with n_jobs=-1
2025-12-10 11:34:44,917:INFO:Initializing RandomizedSearchCV
2025-12-10 11:35:20,247:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-10 11:35:20,255:INFO:Hyperparameter search completed
2025-12-10 11:35:20,255:INFO:SubProcess create_model() called ==================================
2025-12-10 11:35:20,258:INFO:Initializing create_model()
2025-12-10 11:35:20,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x319cf3210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-10 11:35:20,258:INFO:Checking exceptions
2025-12-10 11:35:20,258:INFO:Importing libraries
2025-12-10 11:35:20,259:INFO:Copying training dataset
2025-12-10 11:35:20,281:INFO:Defining folds
2025-12-10 11:35:20,281:INFO:Declaring metric variables
2025-12-10 11:35:20,297:INFO:Importing untrained model
2025-12-10 11:35:20,297:INFO:Declaring custom model
2025-12-10 11:35:20,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:35:20,306:INFO:Starting cross validation
2025-12-10 11:35:20,312:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:35:21,360:INFO:Calculating mean and std
2025-12-10 11:35:21,365:INFO:Creating metrics dataframe
2025-12-10 11:35:21,374:INFO:Finalizing model
2025-12-10 11:35:21,403:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:35:21,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:35:21,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:35:21,405:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:35:21,405:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:35:21,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:35:21,405:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:35:21,405:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:35:21,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.
2025-12-10 11:35:21,406:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:35:21,406:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:35:21,407:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:35:21,407:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:35:21,407:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:35:21,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:35:21,730:INFO:Uploading results into container
2025-12-10 11:35:21,731:INFO:Uploading model into container now
2025-12-10 11:35:21,731:INFO:_master_model_container: 55
2025-12-10 11:35:21,731:INFO:_display_container: 35
2025-12-10 11:35:21,732:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:35:21,732:INFO:create_model() successfully completed......................................
2025-12-10 11:35:22,072:INFO:SubProcess create_model() end ==================================
2025-12-10 11:35:22,072:INFO:choose_better activated
2025-12-10 11:35:22,073:INFO:SubProcess create_model() called ==================================
2025-12-10 11:35:22,074:INFO:Initializing create_model()
2025-12-10 11:35:22,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:35:22,074:INFO:Checking exceptions
2025-12-10 11:35:22,074:INFO:Importing libraries
2025-12-10 11:35:22,075:INFO:Copying training dataset
2025-12-10 11:35:22,077:INFO:Defining folds
2025-12-10 11:35:22,077:INFO:Declaring metric variables
2025-12-10 11:35:22,077:INFO:Importing untrained model
2025-12-10 11:35:22,077:INFO:Declaring custom model
2025-12-10 11:35:22,078:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:35:22,078:INFO:Starting cross validation
2025-12-10 11:35:22,078:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:35:23,582:INFO:Calculating mean and std
2025-12-10 11:35:23,584:INFO:Creating metrics dataframe
2025-12-10 11:35:23,587:INFO:Finalizing model
2025-12-10 11:35:23,615:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:35:23,616:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:35:23,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.
2025-12-10 11:35:23,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:35:23,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:35:23,618:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:35:23,618:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:35:23,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:35:24,016:INFO:Uploading results into container
2025-12-10 11:35:24,016:INFO:Uploading model into container now
2025-12-10 11:35:24,017:INFO:_master_model_container: 56
2025-12-10 11:35:24,017:INFO:_display_container: 36
2025-12-10 11:35:24,017:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:35:24,017:INFO:create_model() successfully completed......................................
2025-12-10 11:35:24,207:INFO:SubProcess create_model() end ==================================
2025-12-10 11:35:24,208:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-10 11:35:24,208:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-10 11:35:24,208:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-10 11:35:24,208:INFO:choose_better completed
2025-12-10 11:35:24,214:INFO:_master_model_container: 56
2025-12-10 11:35:24,214:INFO:_display_container: 35
2025-12-10 11:35:24,214:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:35:24,215:INFO:tune_model() successfully completed......................................
2025-12-10 11:40:08,216:INFO:Initializing plot_model()
2025-12-10 11:40:08,218:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:40:08,218:INFO:Checking exceptions
2025-12-10 11:40:08,269:INFO:Preloading libraries
2025-12-10 11:40:08,284:INFO:Copying training dataset
2025-12-10 11:40:08,284:INFO:Plot type: confusion_matrix
2025-12-10 11:40:08,351:INFO:Fitting Model
2025-12-10 11:40:08,353:INFO:Scoring test/hold-out set
2025-12-10 11:40:08,355:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:40:08,355:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:40:08,355:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:40:08,359:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:40:08,359:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:40:08,359:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:40:08,440:INFO:Visual Rendered Successfully
2025-12-10 11:40:09,036:INFO:plot_model() successfully completed......................................
2025-12-10 11:40:10,141:INFO:Initializing plot_model()
2025-12-10 11:40:10,141:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:40:10,141:INFO:Checking exceptions
2025-12-10 11:40:10,153:INFO:Preloading libraries
2025-12-10 11:40:10,157:INFO:Copying training dataset
2025-12-10 11:40:10,157:INFO:Plot type: pr
2025-12-10 11:40:10,195:INFO:Fitting Model
2025-12-10 11:40:10,196:INFO:Scoring test/hold-out set
2025-12-10 11:40:10,196:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:40:10,196:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:40:10,196:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:40:10,199:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:40:10,199:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:40:10,199:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:40:10,259:INFO:Visual Rendered Successfully
2025-12-10 11:40:10,409:INFO:plot_model() successfully completed......................................
2025-12-10 11:40:20,960:INFO:Initializing create_model()
2025-12-10 11:40:20,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:40:20,960:INFO:Checking exceptions
2025-12-10 11:40:20,974:INFO:Importing libraries
2025-12-10 11:40:20,975:INFO:Copying training dataset
2025-12-10 11:40:20,980:INFO:Defining folds
2025-12-10 11:40:20,980:INFO:Declaring metric variables
2025-12-10 11:40:20,981:INFO:Importing untrained model
2025-12-10 11:40:20,983:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:40:20,985:INFO:Starting cross validation
2025-12-10 11:40:20,989:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:40:22,758:INFO:Calculating mean and std
2025-12-10 11:40:22,761:INFO:Creating metrics dataframe
2025-12-10 11:40:22,769:INFO:Finalizing model
2025-12-10 11:40:22,858:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:40:22,858:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:40:22,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.
2025-12-10 11:40:22,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:40:22,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:40:22,863:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:40:22,863:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:40:22,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:40:23,452:INFO:Uploading results into container
2025-12-10 11:40:23,462:INFO:Uploading model into container now
2025-12-10 11:40:23,475:INFO:_master_model_container: 57
2025-12-10 11:40:23,475:INFO:_display_container: 36
2025-12-10 11:40:23,477:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:40:23,477:INFO:create_model() successfully completed......................................
2025-12-10 11:40:24,242:INFO:Initializing tune_model()
2025-12-10 11:40:24,242:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-10 11:40:24,242:INFO:Checking exceptions
2025-12-10 11:40:24,255:INFO:Copying training dataset
2025-12-10 11:40:24,264:INFO:Checking base model
2025-12-10 11:40:24,264:INFO:Base model : Light Gradient Boosting Machine
2025-12-10 11:40:24,268:INFO:Declaring metric variables
2025-12-10 11:40:24,272:INFO:Defining Hyperparameters
2025-12-10 11:40:24,512:INFO:Tuning with n_jobs=-1
2025-12-10 11:40:24,512:INFO:Initializing RandomizedSearchCV
2025-12-10 11:40:29,945:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:40:30,754:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:40:31,328:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-10 11:41:12,091:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-12-10 11:41:12,104:INFO:Hyperparameter search completed
2025-12-10 11:41:12,104:INFO:SubProcess create_model() called ==================================
2025-12-10 11:41:12,110:INFO:Initializing create_model()
2025-12-10 11:41:12,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e464710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 2, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.3, 'min_child_samples': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-12-10 11:41:12,110:INFO:Checking exceptions
2025-12-10 11:41:12,110:INFO:Importing libraries
2025-12-10 11:41:12,111:INFO:Copying training dataset
2025-12-10 11:41:12,139:INFO:Defining folds
2025-12-10 11:41:12,139:INFO:Declaring metric variables
2025-12-10 11:41:12,156:INFO:Importing untrained model
2025-12-10 11:41:12,156:INFO:Declaring custom model
2025-12-10 11:41:12,162:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:41:12,165:INFO:Starting cross validation
2025-12-10 11:41:12,169:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:41:13,155:INFO:Calculating mean and std
2025-12-10 11:41:13,156:INFO:Creating metrics dataframe
2025-12-10 11:41:13,158:INFO:Finalizing model
2025-12-10 11:41:13,197:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:41:13,197:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:41:13,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:41:13,201:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:41:13,201:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:41:13,201:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:41:13,201:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:41:13,201:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:41:13,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000952 seconds.
2025-12-10 11:41:13,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:41:13,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:41:13,202:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:41:13,203:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:41:13,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:41:13,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-10 11:41:13,490:INFO:Uploading results into container
2025-12-10 11:41:13,491:INFO:Uploading model into container now
2025-12-10 11:41:13,492:INFO:_master_model_container: 58
2025-12-10 11:41:13,493:INFO:_display_container: 37
2025-12-10 11:41:13,493:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:41:13,493:INFO:create_model() successfully completed......................................
2025-12-10 11:41:13,809:INFO:SubProcess create_model() end ==================================
2025-12-10 11:41:13,809:INFO:choose_better activated
2025-12-10 11:41:13,810:INFO:SubProcess create_model() called ==================================
2025-12-10 11:41:13,811:INFO:Initializing create_model()
2025-12-10 11:41:13,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-10 11:41:13,811:INFO:Checking exceptions
2025-12-10 11:41:13,812:INFO:Importing libraries
2025-12-10 11:41:13,812:INFO:Copying training dataset
2025-12-10 11:41:13,816:INFO:Defining folds
2025-12-10 11:41:13,816:INFO:Declaring metric variables
2025-12-10 11:41:13,816:INFO:Importing untrained model
2025-12-10 11:41:13,816:INFO:Declaring custom model
2025-12-10 11:41:13,817:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-10 11:41:13,817:INFO:Starting cross validation
2025-12-10 11:41:13,817:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-10 11:41:15,444:INFO:Calculating mean and std
2025-12-10 11:41:15,444:INFO:Creating metrics dataframe
2025-12-10 11:41:15,445:INFO:Finalizing model
2025-12-10 11:41:15,474:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-10 11:41:15,474:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-10 11:41:15,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.
2025-12-10 11:41:15,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-10 11:41:15,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-10 11:41:15,475:INFO:[LightGBM] [Info] Total Bins 85
2025-12-10 11:41:15,475:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-10 11:41:15,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-10 11:41:15,834:INFO:Uploading results into container
2025-12-10 11:41:15,834:INFO:Uploading model into container now
2025-12-10 11:41:15,835:INFO:_master_model_container: 59
2025-12-10 11:41:15,835:INFO:_display_container: 38
2025-12-10 11:41:15,835:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:41:15,835:INFO:create_model() successfully completed......................................
2025-12-10 11:41:16,050:INFO:SubProcess create_model() end ==================================
2025-12-10 11:41:16,050:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-10 11:41:16,051:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8849
2025-12-10 11:41:16,051:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-10 11:41:16,051:INFO:choose_better completed
2025-12-10 11:41:16,055:INFO:_master_model_container: 59
2025-12-10 11:41:16,055:INFO:_display_container: 37
2025-12-10 11:41:16,055:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-10 11:41:16,055:INFO:tune_model() successfully completed......................................
2025-12-10 11:45:16,232:INFO:Initializing plot_model()
2025-12-10 11:45:16,234:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:45:16,234:INFO:Checking exceptions
2025-12-10 11:45:16,277:INFO:Preloading libraries
2025-12-10 11:45:16,291:INFO:Copying training dataset
2025-12-10 11:45:16,291:INFO:Plot type: confusion_matrix
2025-12-10 11:45:16,395:INFO:Fitting Model
2025-12-10 11:45:16,413:INFO:Scoring test/hold-out set
2025-12-10 11:45:16,418:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:45:16,418:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:45:16,418:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:45:16,437:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:45:16,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:45:16,437:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:45:16,594:INFO:Visual Rendered Successfully
2025-12-10 11:45:16,954:INFO:plot_model() successfully completed......................................
2025-12-10 11:45:18,449:INFO:Initializing plot_model()
2025-12-10 11:45:18,449:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 11:45:18,450:INFO:Checking exceptions
2025-12-10 11:45:18,465:INFO:Preloading libraries
2025-12-10 11:45:18,474:INFO:Copying training dataset
2025-12-10 11:45:18,474:INFO:Plot type: pr
2025-12-10 11:45:18,513:INFO:Fitting Model
2025-12-10 11:45:18,513:INFO:Scoring test/hold-out set
2025-12-10 11:45:18,514:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:45:18,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:45:18,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:45:18,517:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-10 11:45:18,517:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-12-10 11:45:18,517:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-12-10 11:45:18,580:INFO:Visual Rendered Successfully
2025-12-10 11:45:18,736:INFO:plot_model() successfully completed......................................
2025-12-10 12:01:27,795:INFO:Initializing predict_model()
2025-12-10 12:01:27,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.7, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3256f8d60>)
2025-12-10 12:01:27,802:INFO:Checking exceptions
2025-12-10 12:01:27,804:INFO:Preloading libraries
2025-12-10 12:01:28,306:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 12:01:29,709:INFO:Initializing predict_model()
2025-12-10 12:01:29,710:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.75, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c351080>)
2025-12-10 12:01:29,710:INFO:Checking exceptions
2025-12-10 12:01:29,710:INFO:Preloading libraries
2025-12-10 12:01:29,740:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 12:01:29,884:INFO:Initializing predict_model()
2025-12-10 12:01:29,884:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.8, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3256f8d60>)
2025-12-10 12:01:29,884:INFO:Checking exceptions
2025-12-10 12:01:29,884:INFO:Preloading libraries
2025-12-10 12:01:29,911:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-10 12:01:46,945:INFO:Initializing predict_model()
2025-12-10 12:01:46,946:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.7, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x319e6dc60>)
2025-12-10 12:01:46,946:INFO:Checking exceptions
2025-12-10 12:01:46,946:INFO:Preloading libraries
2025-12-10 12:01:47,200:INFO:Initializing predict_model()
2025-12-10 12:01:47,200:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.75, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16bc0fec0>)
2025-12-10 12:01:47,201:INFO:Checking exceptions
2025-12-10 12:01:47,201:INFO:Preloading libraries
2025-12-10 12:01:47,334:INFO:Initializing predict_model()
2025-12-10 12:01:47,334:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.8, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x319e6dc60>)
2025-12-10 12:01:47,334:INFO:Checking exceptions
2025-12-10 12:01:47,334:INFO:Preloading libraries
2025-12-10 12:02:01,399:INFO:Initializing predict_model()
2025-12-10 12:02:01,400:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x326a219e0>)
2025-12-10 12:02:01,400:INFO:Checking exceptions
2025-12-10 12:02:01,400:INFO:Preloading libraries
2025-12-10 12:02:01,662:INFO:Initializing predict_model()
2025-12-10 12:02:01,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.75, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3256f8d60>)
2025-12-10 12:02:01,662:INFO:Checking exceptions
2025-12-10 12:02:01,662:INFO:Preloading libraries
2025-12-10 12:02:01,802:INFO:Initializing predict_model()
2025-12-10 12:02:01,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.8, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x326a20c20>)
2025-12-10 12:02:01,803:INFO:Checking exceptions
2025-12-10 12:02:01,803:INFO:Preloading libraries
2025-12-10 12:02:07,134:INFO:Initializing predict_model()
2025-12-10 12:02:07,135:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.7, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fd6c0>)
2025-12-10 12:02:07,135:INFO:Checking exceptions
2025-12-10 12:02:07,135:INFO:Preloading libraries
2025-12-10 12:02:07,376:INFO:Initializing predict_model()
2025-12-10 12:02:07,376:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.75, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f18a8e0>)
2025-12-10 12:02:07,376:INFO:Checking exceptions
2025-12-10 12:02:07,376:INFO:Preloading libraries
2025-12-10 12:02:07,516:INFO:Initializing predict_model()
2025-12-10 12:02:07,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.8, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16bc0fec0>)
2025-12-10 12:02:07,517:INFO:Checking exceptions
2025-12-10 12:02:07,517:INFO:Preloading libraries
2025-12-10 12:02:12,801:INFO:Initializing predict_model()
2025-12-10 12:02:12,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.7, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fd6c0>)
2025-12-10 12:02:12,802:INFO:Checking exceptions
2025-12-10 12:02:12,803:INFO:Preloading libraries
2025-12-10 12:38:29,319:INFO:Initializing plot_model()
2025-12-10 12:38:29,320:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=0.005, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 12:38:29,320:INFO:Checking exceptions
2025-12-10 12:38:29,399:INFO:Preloading libraries
2025-12-10 12:38:29,406:INFO:Copying training dataset
2025-12-10 12:38:29,406:INFO:Plot type: pr
2025-12-10 12:38:29,587:INFO:Fitting Model
2025-12-10 12:38:29,596:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-12-10 12:38:29,602:INFO:Scoring test/hold-out set
2025-12-10 12:38:29,883:INFO:Visual Rendered Successfully
2025-12-10 12:38:31,405:INFO:plot_model() successfully completed......................................
2025-12-10 12:38:51,725:INFO:Initializing plot_model()
2025-12-10 12:38:51,726:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-10 12:38:51,726:INFO:Checking exceptions
2025-12-10 12:38:51,739:INFO:Preloading libraries
2025-12-10 12:38:51,740:INFO:Copying training dataset
2025-12-10 12:38:51,740:INFO:Plot type: pr
2025-12-10 12:38:51,790:INFO:Fitting Model
2025-12-10 12:38:51,790:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but QuadraticDiscriminantAnalysis was fitted with feature names
  warnings.warn(

2025-12-10 12:38:51,790:INFO:Scoring test/hold-out set
2025-12-10 12:38:51,853:INFO:Visual Rendered Successfully
2025-12-10 12:38:52,037:INFO:plot_model() successfully completed......................................
2025-12-12 14:58:43,610:INFO:Initializing create_model()
2025-12-12 14:58:43,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 14:58:43,617:INFO:Checking exceptions
2025-12-12 14:58:43,946:INFO:Importing libraries
2025-12-12 14:58:43,949:INFO:Copying training dataset
2025-12-12 14:58:43,979:INFO:Defining folds
2025-12-12 14:58:43,979:INFO:Declaring metric variables
2025-12-12 14:58:43,981:INFO:Importing untrained model
2025-12-12 14:58:43,993:INFO:Logistic Regression Imported successfully
2025-12-12 14:58:44,002:INFO:Starting cross validation
2025-12-12 14:58:44,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 14:58:53,845:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:53,845:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:53,845:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:53,845:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:53,845:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:54,211:INFO:Calculating mean and std
2025-12-12 14:58:54,227:INFO:Creating metrics dataframe
2025-12-12 14:58:54,341:INFO:Finalizing model
2025-12-12 14:58:54,500:INFO:Uploading results into container
2025-12-12 14:58:54,501:INFO:Uploading model into container now
2025-12-12 14:58:54,552:INFO:_master_model_container: 60
2025-12-12 14:58:54,552:INFO:_display_container: 51
2025-12-12 14:58:54,556:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 14:58:54,556:INFO:create_model() successfully completed......................................
2025-12-12 14:58:57,307:INFO:Initializing create_model()
2025-12-12 14:58:57,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 14:58:57,308:INFO:Checking exceptions
2025-12-12 14:58:57,314:INFO:Importing libraries
2025-12-12 14:58:57,314:INFO:Copying training dataset
2025-12-12 14:58:57,319:INFO:Defining folds
2025-12-12 14:58:57,319:INFO:Declaring metric variables
2025-12-12 14:58:57,320:INFO:Importing untrained model
2025-12-12 14:58:57,322:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 14:58:57,324:INFO:Starting cross validation
2025-12-12 14:58:57,325:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 14:58:59,891:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:58:59,892:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:59:00,005:INFO:Calculating mean and std
2025-12-12 14:59:00,017:INFO:Creating metrics dataframe
2025-12-12 14:59:00,033:INFO:Finalizing model
2025-12-12 14:59:00,134:INFO:Uploading results into container
2025-12-12 14:59:00,145:INFO:Uploading model into container now
2025-12-12 14:59:00,159:INFO:_master_model_container: 61
2025-12-12 14:59:00,159:INFO:_display_container: 52
2025-12-12 14:59:00,160:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 14:59:00,160:INFO:create_model() successfully completed......................................
2025-12-12 14:59:00,427:INFO:Initializing create_model()
2025-12-12 14:59:00,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 14:59:00,427:INFO:Checking exceptions
2025-12-12 14:59:00,474:INFO:Importing libraries
2025-12-12 14:59:00,474:INFO:Copying training dataset
2025-12-12 14:59:00,481:INFO:Defining folds
2025-12-12 14:59:00,481:INFO:Declaring metric variables
2025-12-12 14:59:00,485:INFO:Importing untrained model
2025-12-12 14:59:00,487:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 14:59:00,489:INFO:Starting cross validation
2025-12-12 14:59:00,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 14:59:02,234:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 14:59:02,745:INFO:Calculating mean and std
2025-12-12 14:59:02,750:INFO:Creating metrics dataframe
2025-12-12 14:59:02,768:INFO:Finalizing model
2025-12-12 14:59:02,818:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 14:59:02,819:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 14:59:02,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.
2025-12-12 14:59:02,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 14:59:02,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 14:59:02,821:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 14:59:02,822:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 14:59:02,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 14:59:03,123:INFO:Uploading results into container
2025-12-12 14:59:03,123:INFO:Uploading model into container now
2025-12-12 14:59:03,130:INFO:_master_model_container: 62
2025-12-12 14:59:03,130:INFO:_display_container: 53
2025-12-12 14:59:03,132:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 14:59:03,133:INFO:create_model() successfully completed......................................
2025-12-12 15:00:42,554:INFO:Initializing create_model()
2025-12-12 15:00:42,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:00:42,561:INFO:Checking exceptions
2025-12-12 15:00:42,630:INFO:Importing libraries
2025-12-12 15:00:42,634:INFO:Copying training dataset
2025-12-12 15:00:42,651:INFO:Defining folds
2025-12-12 15:00:42,651:INFO:Declaring metric variables
2025-12-12 15:00:42,654:INFO:Importing untrained model
2025-12-12 15:00:42,661:INFO:Logistic Regression Imported successfully
2025-12-12 15:00:42,665:INFO:Starting cross validation
2025-12-12 15:00:42,673:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:00:42,977:INFO:Calculating mean and std
2025-12-12 15:00:42,977:INFO:Creating metrics dataframe
2025-12-12 15:00:42,979:INFO:Finalizing model
2025-12-12 15:00:43,059:INFO:Uploading results into container
2025-12-12 15:00:43,060:INFO:Uploading model into container now
2025-12-12 15:00:43,069:INFO:_master_model_container: 63
2025-12-12 15:00:43,069:INFO:_display_container: 54
2025-12-12 15:00:43,069:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:00:43,069:INFO:create_model() successfully completed......................................
2025-12-12 15:00:43,550:INFO:Initializing create_model()
2025-12-12 15:00:43,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:00:43,550:INFO:Checking exceptions
2025-12-12 15:00:43,603:INFO:Importing libraries
2025-12-12 15:00:43,607:INFO:Copying training dataset
2025-12-12 15:00:43,633:INFO:Defining folds
2025-12-12 15:00:43,633:INFO:Declaring metric variables
2025-12-12 15:00:43,639:INFO:Importing untrained model
2025-12-12 15:00:43,643:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:00:43,647:INFO:Starting cross validation
2025-12-12 15:00:43,648:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:00:43,866:INFO:Calculating mean and std
2025-12-12 15:00:43,866:INFO:Creating metrics dataframe
2025-12-12 15:00:43,869:INFO:Finalizing model
2025-12-12 15:00:43,938:INFO:Uploading results into container
2025-12-12 15:00:43,939:INFO:Uploading model into container now
2025-12-12 15:00:43,945:INFO:_master_model_container: 64
2025-12-12 15:00:43,946:INFO:_display_container: 55
2025-12-12 15:00:43,946:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:00:43,946:INFO:create_model() successfully completed......................................
2025-12-12 15:00:44,247:INFO:Initializing create_model()
2025-12-12 15:00:44,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:00:44,247:INFO:Checking exceptions
2025-12-12 15:00:44,253:INFO:Importing libraries
2025-12-12 15:00:44,253:INFO:Copying training dataset
2025-12-12 15:00:44,259:INFO:Defining folds
2025-12-12 15:00:44,259:INFO:Declaring metric variables
2025-12-12 15:00:44,261:INFO:Importing untrained model
2025-12-12 15:00:44,262:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:00:44,264:INFO:Starting cross validation
2025-12-12 15:00:44,265:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:00:46,471:INFO:Calculating mean and std
2025-12-12 15:00:46,474:INFO:Creating metrics dataframe
2025-12-12 15:00:46,481:INFO:Finalizing model
2025-12-12 15:00:46,535:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:00:46,535:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:00:46,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.
2025-12-12 15:00:46,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:00:46,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:00:46,537:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:00:46,537:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:00:46,537:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:00:46,975:INFO:Uploading results into container
2025-12-12 15:00:46,976:INFO:Uploading model into container now
2025-12-12 15:00:46,984:INFO:_master_model_container: 65
2025-12-12 15:00:46,984:INFO:_display_container: 56
2025-12-12 15:00:46,984:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:00:46,984:INFO:create_model() successfully completed......................................
2025-12-12 15:00:47,157:INFO:Initializing create_model()
2025-12-12 15:00:47,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:00:47,157:INFO:Checking exceptions
2025-12-12 15:00:47,162:INFO:Importing libraries
2025-12-12 15:00:47,162:INFO:Copying training dataset
2025-12-12 15:00:47,170:INFO:Defining folds
2025-12-12 15:00:47,170:INFO:Declaring metric variables
2025-12-12 15:00:47,171:INFO:Importing untrained model
2025-12-12 15:00:47,172:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:00:47,174:INFO:Starting cross validation
2025-12-12 15:00:47,175:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:00:47,240:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,250:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,252:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,268:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,323:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,442:INFO:Calculating mean and std
2025-12-12 15:00:47,442:INFO:Creating metrics dataframe
2025-12-12 15:00:47,445:INFO:Finalizing model
2025-12-12 15:00:47,467:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:00:47,555:INFO:Uploading results into container
2025-12-12 15:00:47,555:INFO:Uploading model into container now
2025-12-12 15:00:47,558:INFO:_master_model_container: 66
2025-12-12 15:00:47,558:INFO:_display_container: 57
2025-12-12 15:00:47,558:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:00:47,558:INFO:create_model() successfully completed......................................
2025-12-12 15:01:18,059:INFO:Initializing tune_model()
2025-12-12 15:01:18,059:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=40, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:01:18,059:INFO:Checking exceptions
2025-12-12 15:01:18,081:INFO:Copying training dataset
2025-12-12 15:01:18,087:INFO:Checking base model
2025-12-12 15:01:18,087:INFO:Base model : Logistic Regression
2025-12-12 15:01:18,090:INFO:Declaring metric variables
2025-12-12 15:01:18,091:INFO:Defining Hyperparameters
2025-12-12 15:01:18,304:INFO:Tuning with n_jobs=-1
2025-12-12 15:01:18,304:INFO:Initializing RandomizedSearchCV
2025-12-12 15:01:20,337:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 4.162000000000001}
2025-12-12 15:01:20,339:INFO:Hyperparameter search completed
2025-12-12 15:01:20,339:INFO:SubProcess create_model() called ==================================
2025-12-12 15:01:20,340:INFO:Initializing create_model()
2025-12-12 15:01:20,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31dd48310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 4.162000000000001})
2025-12-12 15:01:20,341:INFO:Checking exceptions
2025-12-12 15:01:20,341:INFO:Importing libraries
2025-12-12 15:01:20,341:INFO:Copying training dataset
2025-12-12 15:01:20,350:INFO:Defining folds
2025-12-12 15:01:20,350:INFO:Declaring metric variables
2025-12-12 15:01:20,355:INFO:Importing untrained model
2025-12-12 15:01:20,355:INFO:Declaring custom model
2025-12-12 15:01:20,357:INFO:Logistic Regression Imported successfully
2025-12-12 15:01:20,359:INFO:Starting cross validation
2025-12-12 15:01:20,363:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:01:20,429:INFO:Calculating mean and std
2025-12-12 15:01:20,429:INFO:Creating metrics dataframe
2025-12-12 15:01:20,432:INFO:Finalizing model
2025-12-12 15:01:20,490:INFO:Uploading results into container
2025-12-12 15:01:20,490:INFO:Uploading model into container now
2025-12-12 15:01:20,491:INFO:_master_model_container: 67
2025-12-12 15:01:20,491:INFO:_display_container: 58
2025-12-12 15:01:20,491:INFO:LogisticRegression(C=4.162000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:01:20,491:INFO:create_model() successfully completed......................................
2025-12-12 15:01:20,745:INFO:SubProcess create_model() end ==================================
2025-12-12 15:01:20,746:INFO:choose_better activated
2025-12-12 15:01:20,747:INFO:SubProcess create_model() called ==================================
2025-12-12 15:01:20,748:INFO:Initializing create_model()
2025-12-12 15:01:20,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:01:20,748:INFO:Checking exceptions
2025-12-12 15:01:20,749:INFO:Importing libraries
2025-12-12 15:01:20,749:INFO:Copying training dataset
2025-12-12 15:01:20,751:INFO:Defining folds
2025-12-12 15:01:20,751:INFO:Declaring metric variables
2025-12-12 15:01:20,752:INFO:Importing untrained model
2025-12-12 15:01:20,752:INFO:Declaring custom model
2025-12-12 15:01:20,752:INFO:Logistic Regression Imported successfully
2025-12-12 15:01:20,752:INFO:Starting cross validation
2025-12-12 15:01:20,752:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:01:20,819:INFO:Calculating mean and std
2025-12-12 15:01:20,819:INFO:Creating metrics dataframe
2025-12-12 15:01:20,820:INFO:Finalizing model
2025-12-12 15:01:20,871:INFO:Uploading results into container
2025-12-12 15:01:20,871:INFO:Uploading model into container now
2025-12-12 15:01:20,872:INFO:_master_model_container: 68
2025-12-12 15:01:20,872:INFO:_display_container: 59
2025-12-12 15:01:20,872:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:01:20,872:INFO:create_model() successfully completed......................................
2025-12-12 15:01:21,050:INFO:SubProcess create_model() end ==================================
2025-12-12 15:01:21,051:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-12 15:01:21,051:INFO:LogisticRegression(C=4.162000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Recall is 0.8763
2025-12-12 15:01:21,052:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-12 15:01:21,052:INFO:choose_better completed
2025-12-12 15:01:21,052:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-12 15:01:21,065:INFO:_master_model_container: 68
2025-12-12 15:01:21,066:INFO:_display_container: 58
2025-12-12 15:01:21,066:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:01:21,066:INFO:tune_model() successfully completed......................................
2025-12-12 15:01:21,197:INFO:Initializing tune_model()
2025-12-12 15:01:21,197:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:01:21,197:INFO:Checking exceptions
2025-12-12 15:01:21,204:INFO:Copying training dataset
2025-12-12 15:01:21,208:INFO:Checking base model
2025-12-12 15:01:21,208:INFO:Base model : Quadratic Discriminant Analysis
2025-12-12 15:01:21,209:INFO:Declaring metric variables
2025-12-12 15:01:21,210:INFO:Defining Hyperparameters
2025-12-12 15:01:21,336:INFO:Tuning with n_jobs=-1
2025-12-12 15:01:21,336:INFO:Initializing RandomizedSearchCV
2025-12-12 15:01:22,097:INFO:best_params: {'actual_estimator__reg_param': 0.29}
2025-12-12 15:01:22,098:INFO:Hyperparameter search completed
2025-12-12 15:01:22,098:INFO:SubProcess create_model() called ==================================
2025-12-12 15:01:22,099:INFO:Initializing create_model()
2025-12-12 15:01:22,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f6e5b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.29})
2025-12-12 15:01:22,099:INFO:Checking exceptions
2025-12-12 15:01:22,099:INFO:Importing libraries
2025-12-12 15:01:22,099:INFO:Copying training dataset
2025-12-12 15:01:22,103:INFO:Defining folds
2025-12-12 15:01:22,103:INFO:Declaring metric variables
2025-12-12 15:01:22,110:INFO:Importing untrained model
2025-12-12 15:01:22,110:INFO:Declaring custom model
2025-12-12 15:01:22,112:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:01:22,123:INFO:Starting cross validation
2025-12-12 15:01:22,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:01:22,220:INFO:Calculating mean and std
2025-12-12 15:01:22,221:INFO:Creating metrics dataframe
2025-12-12 15:01:22,224:INFO:Finalizing model
2025-12-12 15:01:22,293:INFO:Uploading results into container
2025-12-12 15:01:22,294:INFO:Uploading model into container now
2025-12-12 15:01:22,295:INFO:_master_model_container: 69
2025-12-12 15:01:22,295:INFO:_display_container: 59
2025-12-12 15:01:22,295:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:01:22,295:INFO:create_model() successfully completed......................................
2025-12-12 15:01:22,945:INFO:SubProcess create_model() end ==================================
2025-12-12 15:01:22,946:INFO:choose_better activated
2025-12-12 15:01:22,948:INFO:SubProcess create_model() called ==================================
2025-12-12 15:01:22,948:INFO:Initializing create_model()
2025-12-12 15:01:22,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:01:22,948:INFO:Checking exceptions
2025-12-12 15:01:22,949:INFO:Importing libraries
2025-12-12 15:01:22,949:INFO:Copying training dataset
2025-12-12 15:01:22,955:INFO:Defining folds
2025-12-12 15:01:22,956:INFO:Declaring metric variables
2025-12-12 15:01:22,956:INFO:Importing untrained model
2025-12-12 15:01:22,956:INFO:Declaring custom model
2025-12-12 15:01:22,956:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:01:22,956:INFO:Starting cross validation
2025-12-12 15:01:22,957:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:01:23,358:INFO:Calculating mean and std
2025-12-12 15:01:23,362:INFO:Creating metrics dataframe
2025-12-12 15:01:23,370:INFO:Finalizing model
2025-12-12 15:01:23,443:INFO:Uploading results into container
2025-12-12 15:01:23,443:INFO:Uploading model into container now
2025-12-12 15:01:23,443:INFO:_master_model_container: 70
2025-12-12 15:01:23,443:INFO:_display_container: 60
2025-12-12 15:01:23,444:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:01:23,444:INFO:create_model() successfully completed......................................
2025-12-12 15:01:23,960:INFO:SubProcess create_model() end ==================================
2025-12-12 15:01:23,960:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8508
2025-12-12 15:01:23,961:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) result for Recall is 0.9538
2025-12-12 15:01:23,961:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) is best model
2025-12-12 15:01:23,961:INFO:choose_better completed
2025-12-12 15:01:23,964:INFO:_master_model_container: 70
2025-12-12 15:01:23,965:INFO:_display_container: 59
2025-12-12 15:01:23,965:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:01:23,965:INFO:tune_model() successfully completed......................................
2025-12-12 15:01:24,224:INFO:Initializing tune_model()
2025-12-12 15:01:24,224:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:01:24,224:INFO:Checking exceptions
2025-12-12 15:01:24,231:INFO:Copying training dataset
2025-12-12 15:01:24,234:INFO:Checking base model
2025-12-12 15:01:24,234:INFO:Base model : Light Gradient Boosting Machine
2025-12-12 15:01:24,235:INFO:Declaring metric variables
2025-12-12 15:01:24,237:INFO:Defining Hyperparameters
2025-12-12 15:01:24,361:INFO:Tuning with n_jobs=-1
2025-12-12 15:01:24,361:INFO:Initializing RandomizedSearchCV
2025-12-12 15:02:09,542:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2025-12-12 15:02:09,550:INFO:Hyperparameter search completed
2025-12-12 15:02:09,551:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:09,551:INFO:Initializing create_model()
2025-12-12 15:02:09,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f48a4d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.7, 'num_leaves': 2, 'n_estimators': 220, 'min_split_gain': 0.8, 'min_child_samples': 36, 'learning_rate': 0.0001, 'feature_fraction': 0.6, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2025-12-12 15:02:09,552:INFO:Checking exceptions
2025-12-12 15:02:09,552:INFO:Importing libraries
2025-12-12 15:02:09,552:INFO:Copying training dataset
2025-12-12 15:02:09,567:INFO:Defining folds
2025-12-12 15:02:09,567:INFO:Declaring metric variables
2025-12-12 15:02:09,571:INFO:Importing untrained model
2025-12-12 15:02:09,571:INFO:Declaring custom model
2025-12-12 15:02:09,577:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:02:09,583:INFO:Starting cross validation
2025-12-12 15:02:09,585:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:09,916:INFO:Calculating mean and std
2025-12-12 15:02:09,917:INFO:Creating metrics dataframe
2025-12-12 15:02:09,919:INFO:Finalizing model
2025-12-12 15:02:09,949:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-12 15:02:09,949:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-12 15:02:09,949:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-12 15:02:09,951:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:02:09,951:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2025-12-12 15:02:09,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2025-12-12 15:02:09,951:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-12 15:02:09,951:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:02:09,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.
2025-12-12 15:02:09,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:02:09,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:02:09,952:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:02:09,953:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:02:09,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:02:10,024:INFO:Uploading results into container
2025-12-12 15:02:10,025:INFO:Uploading model into container now
2025-12-12 15:02:10,025:INFO:_master_model_container: 71
2025-12-12 15:02:10,026:INFO:_display_container: 60
2025-12-12 15:02:10,026:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:10,026:INFO:create_model() successfully completed......................................
2025-12-12 15:02:10,285:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:10,286:INFO:choose_better activated
2025-12-12 15:02:10,287:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:10,288:INFO:Initializing create_model()
2025-12-12 15:02:10,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:10,288:INFO:Checking exceptions
2025-12-12 15:02:10,289:INFO:Importing libraries
2025-12-12 15:02:10,289:INFO:Copying training dataset
2025-12-12 15:02:10,292:INFO:Defining folds
2025-12-12 15:02:10,292:INFO:Declaring metric variables
2025-12-12 15:02:10,292:INFO:Importing untrained model
2025-12-12 15:02:10,292:INFO:Declaring custom model
2025-12-12 15:02:10,292:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:02:10,292:INFO:Starting cross validation
2025-12-12 15:02:10,293:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:11,688:INFO:Calculating mean and std
2025-12-12 15:02:11,689:INFO:Creating metrics dataframe
2025-12-12 15:02:11,692:INFO:Finalizing model
2025-12-12 15:02:11,719:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:02:11,719:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:02:11,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.
2025-12-12 15:02:11,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:02:11,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:02:11,720:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:02:11,720:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:02:11,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:02:12,113:INFO:Uploading results into container
2025-12-12 15:02:12,113:INFO:Uploading model into container now
2025-12-12 15:02:12,113:INFO:_master_model_container: 72
2025-12-12 15:02:12,113:INFO:_display_container: 61
2025-12-12 15:02:12,114:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:12,114:INFO:create_model() successfully completed......................................
2025-12-12 15:02:12,325:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:12,326:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8803
2025-12-12 15:02:12,326:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9666
2025-12-12 15:02:12,326:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-12 15:02:12,326:INFO:choose_better completed
2025-12-12 15:02:12,330:INFO:_master_model_container: 72
2025-12-12 15:02:12,330:INFO:_display_container: 60
2025-12-12 15:02:12,330:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:12,330:INFO:tune_model() successfully completed......................................
2025-12-12 15:02:12,451:INFO:Initializing tune_model()
2025-12-12 15:02:12,451:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:02:12,451:INFO:Checking exceptions
2025-12-12 15:02:12,458:INFO:Copying training dataset
2025-12-12 15:02:12,461:INFO:Checking base model
2025-12-12 15:02:12,461:INFO:Base model : Ada Boost Classifier
2025-12-12 15:02:12,462:INFO:Declaring metric variables
2025-12-12 15:02:12,463:INFO:Defining Hyperparameters
2025-12-12 15:02:12,598:INFO:Tuning with n_jobs=-1
2025-12-12 15:02:12,598:INFO:Initializing RandomizedSearchCV
2025-12-12 15:02:25,160:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:02:25,162:INFO:Hyperparameter search completed
2025-12-12 15:02:25,162:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:25,163:INFO:Initializing create_model()
2025-12-12 15:02:25,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e4db2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'learning_rate': 0.01, 'algorithm': 'SAMME'})
2025-12-12 15:02:25,163:INFO:Checking exceptions
2025-12-12 15:02:25,163:INFO:Importing libraries
2025-12-12 15:02:25,164:INFO:Copying training dataset
2025-12-12 15:02:25,173:INFO:Defining folds
2025-12-12 15:02:25,174:INFO:Declaring metric variables
2025-12-12 15:02:25,176:INFO:Importing untrained model
2025-12-12 15:02:25,176:INFO:Declaring custom model
2025-12-12 15:02:25,178:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:02:25,180:INFO:Starting cross validation
2025-12-12 15:02:25,181:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:25,411:INFO:Calculating mean and std
2025-12-12 15:02:25,411:INFO:Creating metrics dataframe
2025-12-12 15:02:25,413:INFO:Finalizing model
2025-12-12 15:02:25,584:INFO:Uploading results into container
2025-12-12 15:02:25,585:INFO:Uploading model into container now
2025-12-12 15:02:25,586:INFO:_master_model_container: 73
2025-12-12 15:02:25,586:INFO:_display_container: 61
2025-12-12 15:02:25,586:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:02:25,586:INFO:create_model() successfully completed......................................
2025-12-12 15:02:25,783:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:25,783:INFO:choose_better activated
2025-12-12 15:02:25,786:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:25,786:INFO:Initializing create_model()
2025-12-12 15:02:25,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:25,787:INFO:Checking exceptions
2025-12-12 15:02:25,790:INFO:Importing libraries
2025-12-12 15:02:25,790:INFO:Copying training dataset
2025-12-12 15:02:25,792:INFO:Defining folds
2025-12-12 15:02:25,792:INFO:Declaring metric variables
2025-12-12 15:02:25,792:INFO:Importing untrained model
2025-12-12 15:02:25,792:INFO:Declaring custom model
2025-12-12 15:02:25,792:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:02:25,792:INFO:Starting cross validation
2025-12-12 15:02:25,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:25,822:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:25,833:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:25,838:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:25,856:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:25,861:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:25,974:INFO:Calculating mean and std
2025-12-12 15:02:25,974:INFO:Creating metrics dataframe
2025-12-12 15:02:25,975:INFO:Finalizing model
2025-12-12 15:02:25,993:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:26,104:INFO:Uploading results into container
2025-12-12 15:02:26,105:INFO:Uploading model into container now
2025-12-12 15:02:26,106:INFO:_master_model_container: 74
2025-12-12 15:02:26,106:INFO:_display_container: 62
2025-12-12 15:02:26,108:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:02:26,108:INFO:create_model() successfully completed......................................
2025-12-12 15:02:26,286:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:26,286:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Recall is 0.8776
2025-12-12 15:02:26,286:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) result for Recall is 0.9739
2025-12-12 15:02:26,286:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) is best model
2025-12-12 15:02:26,286:INFO:choose_better completed
2025-12-12 15:02:26,290:INFO:_master_model_container: 74
2025-12-12 15:02:26,290:INFO:_display_container: 61
2025-12-12 15:02:26,290:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:02:26,290:INFO:tune_model() successfully completed......................................
2025-12-12 15:02:36,777:INFO:Initializing compare_models()
2025-12-12 15:02:36,779:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, include=['lr', 'qda', 'lightgbm', 'ada'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, 'include': ['lr', 'qda', 'lightgbm', 'ada'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-12 15:02:36,779:INFO:Checking exceptions
2025-12-12 15:02:36,789:INFO:Preparing display monitor
2025-12-12 15:02:36,807:INFO:Initializing Logistic Regression
2025-12-12 15:02:36,807:INFO:Total runtime is 2.0702679951985678e-06 minutes
2025-12-12 15:02:36,808:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:36,809:INFO:Initializing create_model()
2025-12-12 15:02:36,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6746d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:36,809:INFO:Checking exceptions
2025-12-12 15:02:36,809:INFO:Importing libraries
2025-12-12 15:02:36,809:INFO:Copying training dataset
2025-12-12 15:02:36,812:INFO:Defining folds
2025-12-12 15:02:36,812:INFO:Declaring metric variables
2025-12-12 15:02:36,813:INFO:Importing untrained model
2025-12-12 15:02:36,817:INFO:Logistic Regression Imported successfully
2025-12-12 15:02:36,819:INFO:Starting cross validation
2025-12-12 15:02:36,823:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:36,956:INFO:Calculating mean and std
2025-12-12 15:02:36,956:INFO:Creating metrics dataframe
2025-12-12 15:02:36,958:INFO:Uploading results into container
2025-12-12 15:02:36,958:INFO:Uploading model into container now
2025-12-12 15:02:36,958:INFO:_master_model_container: 75
2025-12-12 15:02:36,958:INFO:_display_container: 62
2025-12-12 15:02:36,958:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:02:36,958:INFO:create_model() successfully completed......................................
2025-12-12 15:02:37,129:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:37,129:INFO:Creating metrics dataframe
2025-12-12 15:02:37,134:INFO:Initializing Quadratic Discriminant Analysis
2025-12-12 15:02:37,134:INFO:Total runtime is 0.005446084340413411 minutes
2025-12-12 15:02:37,135:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:37,136:INFO:Initializing create_model()
2025-12-12 15:02:37,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6746d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:37,136:INFO:Checking exceptions
2025-12-12 15:02:37,136:INFO:Importing libraries
2025-12-12 15:02:37,136:INFO:Copying training dataset
2025-12-12 15:02:37,139:INFO:Defining folds
2025-12-12 15:02:37,139:INFO:Declaring metric variables
2025-12-12 15:02:37,140:INFO:Importing untrained model
2025-12-12 15:02:37,141:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:02:37,143:INFO:Starting cross validation
2025-12-12 15:02:37,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:37,235:INFO:Calculating mean and std
2025-12-12 15:02:37,235:INFO:Creating metrics dataframe
2025-12-12 15:02:37,236:INFO:Uploading results into container
2025-12-12 15:02:37,236:INFO:Uploading model into container now
2025-12-12 15:02:37,236:INFO:_master_model_container: 76
2025-12-12 15:02:37,236:INFO:_display_container: 62
2025-12-12 15:02:37,236:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:02:37,236:INFO:create_model() successfully completed......................................
2025-12-12 15:02:37,337:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:37,337:INFO:Creating metrics dataframe
2025-12-12 15:02:37,341:INFO:Initializing Light Gradient Boosting Machine
2025-12-12 15:02:37,341:INFO:Total runtime is 0.008889504273732503 minutes
2025-12-12 15:02:37,342:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:37,342:INFO:Initializing create_model()
2025-12-12 15:02:37,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6746d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:37,342:INFO:Checking exceptions
2025-12-12 15:02:37,342:INFO:Importing libraries
2025-12-12 15:02:37,342:INFO:Copying training dataset
2025-12-12 15:02:37,345:INFO:Defining folds
2025-12-12 15:02:37,345:INFO:Declaring metric variables
2025-12-12 15:02:37,346:INFO:Importing untrained model
2025-12-12 15:02:37,347:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:02:37,349:INFO:Starting cross validation
2025-12-12 15:02:37,350:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:38,982:INFO:Calculating mean and std
2025-12-12 15:02:38,989:INFO:Creating metrics dataframe
2025-12-12 15:02:38,992:INFO:Uploading results into container
2025-12-12 15:02:38,993:INFO:Uploading model into container now
2025-12-12 15:02:38,994:INFO:_master_model_container: 77
2025-12-12 15:02:38,994:INFO:_display_container: 62
2025-12-12 15:02:38,997:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:38,998:INFO:create_model() successfully completed......................................
2025-12-12 15:02:39,192:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:39,192:INFO:Creating metrics dataframe
2025-12-12 15:02:39,195:INFO:Initializing Ada Boost Classifier
2025-12-12 15:02:39,195:INFO:Total runtime is 0.03979313770929972 minutes
2025-12-12 15:02:39,196:INFO:SubProcess create_model() called ==================================
2025-12-12 15:02:39,196:INFO:Initializing create_model()
2025-12-12 15:02:39,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6746d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:39,196:INFO:Checking exceptions
2025-12-12 15:02:39,197:INFO:Importing libraries
2025-12-12 15:02:39,197:INFO:Copying training dataset
2025-12-12 15:02:39,200:INFO:Defining folds
2025-12-12 15:02:39,200:INFO:Declaring metric variables
2025-12-12 15:02:39,201:INFO:Importing untrained model
2025-12-12 15:02:39,203:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:02:39,205:INFO:Starting cross validation
2025-12-12 15:02:39,206:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:02:39,284:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:39,285:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:39,291:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:39,295:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:39,294:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:02:39,404:INFO:Calculating mean and std
2025-12-12 15:02:39,404:INFO:Creating metrics dataframe
2025-12-12 15:02:39,405:INFO:Uploading results into container
2025-12-12 15:02:39,405:INFO:Uploading model into container now
2025-12-12 15:02:39,405:INFO:_master_model_container: 78
2025-12-12 15:02:39,405:INFO:_display_container: 62
2025-12-12 15:02:39,406:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:02:39,406:INFO:create_model() successfully completed......................................
2025-12-12 15:02:39,508:INFO:SubProcess create_model() end ==================================
2025-12-12 15:02:39,508:INFO:Creating metrics dataframe
2025-12-12 15:02:39,511:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-12 15:02:39,515:INFO:Initializing create_model()
2025-12-12 15:02:39,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:02:39,515:INFO:Checking exceptions
2025-12-12 15:02:39,516:INFO:Importing libraries
2025-12-12 15:02:39,516:INFO:Copying training dataset
2025-12-12 15:02:39,518:INFO:Defining folds
2025-12-12 15:02:39,519:INFO:Declaring metric variables
2025-12-12 15:02:39,519:INFO:Importing untrained model
2025-12-12 15:02:39,519:INFO:Declaring custom model
2025-12-12 15:02:39,519:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:02:39,519:INFO:Cross validation set to False
2025-12-12 15:02:39,519:INFO:Fitting Model
2025-12-12 15:02:39,545:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:02:39,546:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:02:39,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.
2025-12-12 15:02:39,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:02:39,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:02:39,547:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:02:39,547:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:02:39,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:02:39,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:39,863:INFO:create_model() successfully completed......................................
2025-12-12 15:02:39,982:INFO:_master_model_container: 78
2025-12-12 15:02:39,983:INFO:_display_container: 62
2025-12-12 15:02:39,983:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:02:39,983:INFO:compare_models() successfully completed......................................
2025-12-12 15:02:59,821:INFO:Initializing tune_model()
2025-12-12 15:02:59,822:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=40, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:02:59,823:INFO:Checking exceptions
2025-12-12 15:02:59,849:INFO:Copying training dataset
2025-12-12 15:02:59,853:INFO:Checking base model
2025-12-12 15:02:59,854:INFO:Base model : Ada Boost Classifier
2025-12-12 15:02:59,855:INFO:Declaring metric variables
2025-12-12 15:02:59,856:INFO:Defining Hyperparameters
2025-12-12 15:03:00,067:INFO:Tuning with n_jobs=-1
2025-12-12 15:03:00,068:INFO:Initializing RandomizedSearchCV
2025-12-12 15:03:10,009:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:03:10,015:INFO:Hyperparameter search completed
2025-12-12 15:03:10,017:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:10,018:INFO:Initializing create_model()
2025-12-12 15:03:10,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e074c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'learning_rate': 0.01, 'algorithm': 'SAMME'})
2025-12-12 15:03:10,018:INFO:Checking exceptions
2025-12-12 15:03:10,018:INFO:Importing libraries
2025-12-12 15:03:10,018:INFO:Copying training dataset
2025-12-12 15:03:10,033:INFO:Defining folds
2025-12-12 15:03:10,033:INFO:Declaring metric variables
2025-12-12 15:03:10,037:INFO:Importing untrained model
2025-12-12 15:03:10,038:INFO:Declaring custom model
2025-12-12 15:03:10,039:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:10,041:INFO:Starting cross validation
2025-12-12 15:03:10,042:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:10,268:INFO:Calculating mean and std
2025-12-12 15:03:10,268:INFO:Creating metrics dataframe
2025-12-12 15:03:10,271:INFO:Finalizing model
2025-12-12 15:03:10,452:INFO:Uploading results into container
2025-12-12 15:03:10,453:INFO:Uploading model into container now
2025-12-12 15:03:10,453:INFO:_master_model_container: 79
2025-12-12 15:03:10,453:INFO:_display_container: 63
2025-12-12 15:03:10,454:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:10,454:INFO:create_model() successfully completed......................................
2025-12-12 15:03:10,806:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:10,807:INFO:choose_better activated
2025-12-12 15:03:10,808:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:10,808:INFO:Initializing create_model()
2025-12-12 15:03:10,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:03:10,808:INFO:Checking exceptions
2025-12-12 15:03:10,809:INFO:Importing libraries
2025-12-12 15:03:10,809:INFO:Copying training dataset
2025-12-12 15:03:10,812:INFO:Defining folds
2025-12-12 15:03:10,812:INFO:Declaring metric variables
2025-12-12 15:03:10,812:INFO:Importing untrained model
2025-12-12 15:03:10,812:INFO:Declaring custom model
2025-12-12 15:03:10,812:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:10,812:INFO:Starting cross validation
2025-12-12 15:03:10,812:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:10,860:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:10,871:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:10,880:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:10,899:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:10,913:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:11,015:INFO:Calculating mean and std
2025-12-12 15:03:11,015:INFO:Creating metrics dataframe
2025-12-12 15:03:11,016:INFO:Finalizing model
2025-12-12 15:03:11,040:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:11,116:INFO:Uploading results into container
2025-12-12 15:03:11,117:INFO:Uploading model into container now
2025-12-12 15:03:11,117:INFO:_master_model_container: 80
2025-12-12 15:03:11,117:INFO:_display_container: 64
2025-12-12 15:03:11,117:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:03:11,117:INFO:create_model() successfully completed......................................
2025-12-12 15:03:11,240:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:11,240:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Recall is 0.8776
2025-12-12 15:03:11,240:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) result for Recall is 0.9739
2025-12-12 15:03:11,240:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) is best model
2025-12-12 15:03:11,240:INFO:choose_better completed
2025-12-12 15:03:11,244:INFO:_master_model_container: 80
2025-12-12 15:03:11,244:INFO:_display_container: 63
2025-12-12 15:03:11,244:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:11,244:INFO:tune_model() successfully completed......................................
2025-12-12 15:03:24,803:INFO:Initializing tune_model()
2025-12-12 15:03:24,803:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:03:24,803:INFO:Checking exceptions
2025-12-12 15:03:24,834:INFO:Copying training dataset
2025-12-12 15:03:24,843:INFO:Checking base model
2025-12-12 15:03:24,845:INFO:Base model : Ada Boost Classifier
2025-12-12 15:03:24,886:INFO:Declaring metric variables
2025-12-12 15:03:24,890:INFO:Defining Hyperparameters
2025-12-12 15:03:25,121:INFO:Tuning with n_jobs=-1
2025-12-12 15:03:25,121:INFO:Initializing RandomizedSearchCV
2025-12-12 15:03:29,402:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:03:29,406:INFO:Hyperparameter search completed
2025-12-12 15:03:29,407:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:29,407:INFO:Initializing create_model()
2025-12-12 15:03:29,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c24e0d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'learning_rate': 0.01, 'algorithm': 'SAMME'})
2025-12-12 15:03:29,408:INFO:Checking exceptions
2025-12-12 15:03:29,408:INFO:Importing libraries
2025-12-12 15:03:29,408:INFO:Copying training dataset
2025-12-12 15:03:29,415:INFO:Defining folds
2025-12-12 15:03:29,415:INFO:Declaring metric variables
2025-12-12 15:03:29,418:INFO:Importing untrained model
2025-12-12 15:03:29,418:INFO:Declaring custom model
2025-12-12 15:03:29,423:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:29,425:INFO:Starting cross validation
2025-12-12 15:03:29,426:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:29,910:INFO:Calculating mean and std
2025-12-12 15:03:29,911:INFO:Creating metrics dataframe
2025-12-12 15:03:29,913:INFO:Finalizing model
2025-12-12 15:03:30,110:INFO:Uploading results into container
2025-12-12 15:03:30,111:INFO:Uploading model into container now
2025-12-12 15:03:30,112:INFO:_master_model_container: 81
2025-12-12 15:03:30,112:INFO:_display_container: 64
2025-12-12 15:03:30,112:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:30,112:INFO:create_model() successfully completed......................................
2025-12-12 15:03:30,329:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:30,330:INFO:choose_better activated
2025-12-12 15:03:30,331:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:30,331:INFO:Initializing create_model()
2025-12-12 15:03:30,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:03:30,331:INFO:Checking exceptions
2025-12-12 15:03:30,332:INFO:Importing libraries
2025-12-12 15:03:30,332:INFO:Copying training dataset
2025-12-12 15:03:30,335:INFO:Defining folds
2025-12-12 15:03:30,335:INFO:Declaring metric variables
2025-12-12 15:03:30,335:INFO:Importing untrained model
2025-12-12 15:03:30,335:INFO:Declaring custom model
2025-12-12 15:03:30,335:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:30,335:INFO:Starting cross validation
2025-12-12 15:03:30,336:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:30,400:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,416:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,425:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,428:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,428:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,553:INFO:Calculating mean and std
2025-12-12 15:03:30,563:INFO:Creating metrics dataframe
2025-12-12 15:03:30,567:INFO:Finalizing model
2025-12-12 15:03:30,599:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:30,678:INFO:Uploading results into container
2025-12-12 15:03:30,678:INFO:Uploading model into container now
2025-12-12 15:03:30,678:INFO:_master_model_container: 82
2025-12-12 15:03:30,678:INFO:_display_container: 65
2025-12-12 15:03:30,678:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:03:30,678:INFO:create_model() successfully completed......................................
2025-12-12 15:03:30,779:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:30,780:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Recall is 0.8776
2025-12-12 15:03:30,780:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) result for Recall is 0.9739
2025-12-12 15:03:30,780:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) is best model
2025-12-12 15:03:30,780:INFO:choose_better completed
2025-12-12 15:03:30,783:INFO:_master_model_container: 82
2025-12-12 15:03:30,784:INFO:_display_container: 64
2025-12-12 15:03:30,784:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:30,784:INFO:tune_model() successfully completed......................................
2025-12-12 15:03:35,295:INFO:Initializing tune_model()
2025-12-12 15:03:35,296:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:03:35,297:INFO:Checking exceptions
2025-12-12 15:03:35,336:INFO:Copying training dataset
2025-12-12 15:03:35,342:INFO:Checking base model
2025-12-12 15:03:35,343:INFO:Base model : Ada Boost Classifier
2025-12-12 15:03:35,344:INFO:Declaring metric variables
2025-12-12 15:03:35,345:INFO:Defining Hyperparameters
2025-12-12 15:03:35,539:INFO:Tuning with n_jobs=-1
2025-12-12 15:03:35,539:INFO:Initializing RandomizedSearchCV
2025-12-12 15:03:50,760:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:03:50,769:INFO:Hyperparameter search completed
2025-12-12 15:03:50,769:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:50,770:INFO:Initializing create_model()
2025-12-12 15:03:50,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f47f590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'learning_rate': 0.01, 'algorithm': 'SAMME'})
2025-12-12 15:03:50,770:INFO:Checking exceptions
2025-12-12 15:03:50,770:INFO:Importing libraries
2025-12-12 15:03:50,770:INFO:Copying training dataset
2025-12-12 15:03:50,777:INFO:Defining folds
2025-12-12 15:03:50,778:INFO:Declaring metric variables
2025-12-12 15:03:50,784:INFO:Importing untrained model
2025-12-12 15:03:50,784:INFO:Declaring custom model
2025-12-12 15:03:50,788:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:50,792:INFO:Starting cross validation
2025-12-12 15:03:50,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:51,015:INFO:Calculating mean and std
2025-12-12 15:03:51,015:INFO:Creating metrics dataframe
2025-12-12 15:03:51,017:INFO:Finalizing model
2025-12-12 15:03:51,189:INFO:Uploading results into container
2025-12-12 15:03:51,190:INFO:Uploading model into container now
2025-12-12 15:03:51,190:INFO:_master_model_container: 83
2025-12-12 15:03:51,190:INFO:_display_container: 65
2025-12-12 15:03:51,191:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:51,191:INFO:create_model() successfully completed......................................
2025-12-12 15:03:51,391:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:51,391:INFO:choose_better activated
2025-12-12 15:03:51,392:INFO:SubProcess create_model() called ==================================
2025-12-12 15:03:51,393:INFO:Initializing create_model()
2025-12-12 15:03:51,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:03:51,393:INFO:Checking exceptions
2025-12-12 15:03:51,393:INFO:Importing libraries
2025-12-12 15:03:51,393:INFO:Copying training dataset
2025-12-12 15:03:51,396:INFO:Defining folds
2025-12-12 15:03:51,396:INFO:Declaring metric variables
2025-12-12 15:03:51,396:INFO:Importing untrained model
2025-12-12 15:03:51,396:INFO:Declaring custom model
2025-12-12 15:03:51,396:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:03:51,396:INFO:Starting cross validation
2025-12-12 15:03:51,397:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:03:51,422:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,429:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,428:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,437:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,439:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,533:INFO:Calculating mean and std
2025-12-12 15:03:51,534:INFO:Creating metrics dataframe
2025-12-12 15:03:51,534:INFO:Finalizing model
2025-12-12 15:03:51,553:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:03:51,632:INFO:Uploading results into container
2025-12-12 15:03:51,632:INFO:Uploading model into container now
2025-12-12 15:03:51,633:INFO:_master_model_container: 84
2025-12-12 15:03:51,633:INFO:_display_container: 66
2025-12-12 15:03:51,633:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:03:51,633:INFO:create_model() successfully completed......................................
2025-12-12 15:03:51,735:INFO:SubProcess create_model() end ==================================
2025-12-12 15:03:51,735:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Recall is 0.8776
2025-12-12 15:03:51,736:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) result for Recall is 0.9739
2025-12-12 15:03:51,736:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) is best model
2025-12-12 15:03:51,736:INFO:choose_better completed
2025-12-12 15:03:51,739:INFO:_master_model_container: 84
2025-12-12 15:03:51,739:INFO:_display_container: 65
2025-12-12 15:03:51,740:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:03:51,740:INFO:tune_model() successfully completed......................................
2025-12-12 15:04:14,236:INFO:Initializing tune_model()
2025-12-12 15:04:14,237:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:04:14,237:INFO:Checking exceptions
2025-12-12 15:04:14,279:INFO:Copying training dataset
2025-12-12 15:04:14,282:INFO:Checking base model
2025-12-12 15:04:14,282:INFO:Base model : Ada Boost Classifier
2025-12-12 15:04:14,284:INFO:Declaring metric variables
2025-12-12 15:04:14,286:INFO:Defining Hyperparameters
2025-12-12 15:04:14,639:INFO:Tuning with n_jobs=-1
2025-12-12 15:04:14,639:INFO:Initializing RandomizedSearchCV
2025-12-12 15:04:25,914:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:04:25,918:INFO:Hyperparameter search completed
2025-12-12 15:04:25,920:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:25,922:INFO:Initializing create_model()
2025-12-12 15:04:25,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f190f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'learning_rate': 0.01, 'algorithm': 'SAMME'})
2025-12-12 15:04:25,922:INFO:Checking exceptions
2025-12-12 15:04:25,922:INFO:Importing libraries
2025-12-12 15:04:25,922:INFO:Copying training dataset
2025-12-12 15:04:25,933:INFO:Defining folds
2025-12-12 15:04:25,933:INFO:Declaring metric variables
2025-12-12 15:04:25,941:INFO:Importing untrained model
2025-12-12 15:04:25,941:INFO:Declaring custom model
2025-12-12 15:04:25,946:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:04:25,950:INFO:Starting cross validation
2025-12-12 15:04:25,951:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:26,228:INFO:Calculating mean and std
2025-12-12 15:04:26,229:INFO:Creating metrics dataframe
2025-12-12 15:04:26,231:INFO:Finalizing model
2025-12-12 15:04:26,406:INFO:Uploading results into container
2025-12-12 15:04:26,407:INFO:Uploading model into container now
2025-12-12 15:04:26,409:INFO:_master_model_container: 85
2025-12-12 15:04:26,409:INFO:_display_container: 66
2025-12-12 15:04:26,410:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:04:26,410:INFO:create_model() successfully completed......................................
2025-12-12 15:04:26,609:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:26,609:INFO:choose_better activated
2025-12-12 15:04:26,610:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:26,611:INFO:Initializing create_model()
2025-12-12 15:04:26,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:26,611:INFO:Checking exceptions
2025-12-12 15:04:26,612:INFO:Importing libraries
2025-12-12 15:04:26,612:INFO:Copying training dataset
2025-12-12 15:04:26,614:INFO:Defining folds
2025-12-12 15:04:26,614:INFO:Declaring metric variables
2025-12-12 15:04:26,614:INFO:Importing untrained model
2025-12-12 15:04:26,614:INFO:Declaring custom model
2025-12-12 15:04:26,614:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:04:26,614:INFO:Starting cross validation
2025-12-12 15:04:26,615:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:26,660:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,666:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,672:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,673:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,674:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,791:INFO:Calculating mean and std
2025-12-12 15:04:26,792:INFO:Creating metrics dataframe
2025-12-12 15:04:26,793:INFO:Finalizing model
2025-12-12 15:04:26,813:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:26,896:INFO:Uploading results into container
2025-12-12 15:04:26,896:INFO:Uploading model into container now
2025-12-12 15:04:26,896:INFO:_master_model_container: 86
2025-12-12 15:04:26,896:INFO:_display_container: 67
2025-12-12 15:04:26,896:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:04:26,896:INFO:create_model() successfully completed......................................
2025-12-12 15:04:27,000:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:27,001:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Recall is 0.8776
2025-12-12 15:04:27,001:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) result for Recall is 0.9739
2025-12-12 15:04:27,001:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42) is best model
2025-12-12 15:04:27,001:INFO:choose_better completed
2025-12-12 15:04:27,005:INFO:_master_model_container: 86
2025-12-12 15:04:27,005:INFO:_display_container: 66
2025-12-12 15:04:27,005:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42)
2025-12-12 15:04:27,005:INFO:tune_model() successfully completed......................................
2025-12-12 15:04:54,548:INFO:Initializing compare_models()
2025-12-12 15:04:54,548:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, include=['lr', 'qda', 'lightgbm', 'ada'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, 'include': ['lr', 'qda', 'lightgbm', 'ada'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-12 15:04:54,549:INFO:Checking exceptions
2025-12-12 15:04:54,566:INFO:Preparing display monitor
2025-12-12 15:04:54,601:INFO:Initializing Logistic Regression
2025-12-12 15:04:54,601:INFO:Total runtime is 3.866354624430338e-06 minutes
2025-12-12 15:04:54,611:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:54,611:INFO:Initializing create_model()
2025-12-12 15:04:54,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e5c4210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:54,611:INFO:Checking exceptions
2025-12-12 15:04:54,611:INFO:Importing libraries
2025-12-12 15:04:54,612:INFO:Copying training dataset
2025-12-12 15:04:54,616:INFO:Defining folds
2025-12-12 15:04:54,616:INFO:Declaring metric variables
2025-12-12 15:04:54,617:INFO:Importing untrained model
2025-12-12 15:04:54,619:INFO:Logistic Regression Imported successfully
2025-12-12 15:04:54,621:INFO:Starting cross validation
2025-12-12 15:04:54,624:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:54,780:INFO:Calculating mean and std
2025-12-12 15:04:54,781:INFO:Creating metrics dataframe
2025-12-12 15:04:54,783:INFO:Uploading results into container
2025-12-12 15:04:54,783:INFO:Uploading model into container now
2025-12-12 15:04:54,783:INFO:_master_model_container: 87
2025-12-12 15:04:54,783:INFO:_display_container: 67
2025-12-12 15:04:54,784:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:04:54,784:INFO:create_model() successfully completed......................................
2025-12-12 15:04:54,984:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:54,984:INFO:Creating metrics dataframe
2025-12-12 15:04:54,988:INFO:Initializing Quadratic Discriminant Analysis
2025-12-12 15:04:54,988:INFO:Total runtime is 0.006450764338175456 minutes
2025-12-12 15:04:54,989:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:54,989:INFO:Initializing create_model()
2025-12-12 15:04:54,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e5c4210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:54,990:INFO:Checking exceptions
2025-12-12 15:04:54,990:INFO:Importing libraries
2025-12-12 15:04:54,990:INFO:Copying training dataset
2025-12-12 15:04:54,992:INFO:Defining folds
2025-12-12 15:04:54,992:INFO:Declaring metric variables
2025-12-12 15:04:54,993:INFO:Importing untrained model
2025-12-12 15:04:54,994:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:04:54,996:INFO:Starting cross validation
2025-12-12 15:04:54,997:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:55,069:INFO:Calculating mean and std
2025-12-12 15:04:55,070:INFO:Creating metrics dataframe
2025-12-12 15:04:55,071:INFO:Uploading results into container
2025-12-12 15:04:55,071:INFO:Uploading model into container now
2025-12-12 15:04:55,071:INFO:_master_model_container: 88
2025-12-12 15:04:55,072:INFO:_display_container: 67
2025-12-12 15:04:55,072:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:04:55,072:INFO:create_model() successfully completed......................................
2025-12-12 15:04:55,179:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:55,179:INFO:Creating metrics dataframe
2025-12-12 15:04:55,184:INFO:Initializing Light Gradient Boosting Machine
2025-12-12 15:04:55,184:INFO:Total runtime is 0.009712966283162434 minutes
2025-12-12 15:04:55,185:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:55,185:INFO:Initializing create_model()
2025-12-12 15:04:55,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e5c4210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:55,185:INFO:Checking exceptions
2025-12-12 15:04:55,185:INFO:Importing libraries
2025-12-12 15:04:55,185:INFO:Copying training dataset
2025-12-12 15:04:55,188:INFO:Defining folds
2025-12-12 15:04:55,188:INFO:Declaring metric variables
2025-12-12 15:04:55,189:INFO:Importing untrained model
2025-12-12 15:04:55,190:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:04:55,192:INFO:Starting cross validation
2025-12-12 15:04:55,193:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:56,813:INFO:Calculating mean and std
2025-12-12 15:04:56,814:INFO:Creating metrics dataframe
2025-12-12 15:04:56,815:INFO:Uploading results into container
2025-12-12 15:04:56,815:INFO:Uploading model into container now
2025-12-12 15:04:56,815:INFO:_master_model_container: 89
2025-12-12 15:04:56,815:INFO:_display_container: 67
2025-12-12 15:04:56,816:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:04:56,816:INFO:create_model() successfully completed......................................
2025-12-12 15:04:57,012:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:57,012:INFO:Creating metrics dataframe
2025-12-12 15:04:57,015:INFO:Initializing Ada Boost Classifier
2025-12-12 15:04:57,015:INFO:Total runtime is 0.040228899319966635 minutes
2025-12-12 15:04:57,016:INFO:SubProcess create_model() called ==================================
2025-12-12 15:04:57,016:INFO:Initializing create_model()
2025-12-12 15:04:57,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e5c4210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:57,016:INFO:Checking exceptions
2025-12-12 15:04:57,016:INFO:Importing libraries
2025-12-12 15:04:57,016:INFO:Copying training dataset
2025-12-12 15:04:57,020:INFO:Defining folds
2025-12-12 15:04:57,020:INFO:Declaring metric variables
2025-12-12 15:04:57,021:INFO:Importing untrained model
2025-12-12 15:04:57,023:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:04:57,025:INFO:Starting cross validation
2025-12-12 15:04:57,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:04:57,090:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:57,094:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:57,108:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:57,109:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:57,120:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:04:57,220:INFO:Calculating mean and std
2025-12-12 15:04:57,220:INFO:Creating metrics dataframe
2025-12-12 15:04:57,221:INFO:Uploading results into container
2025-12-12 15:04:57,221:INFO:Uploading model into container now
2025-12-12 15:04:57,221:INFO:_master_model_container: 90
2025-12-12 15:04:57,221:INFO:_display_container: 67
2025-12-12 15:04:57,221:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:04:57,222:INFO:create_model() successfully completed......................................
2025-12-12 15:04:57,327:INFO:SubProcess create_model() end ==================================
2025-12-12 15:04:57,327:INFO:Creating metrics dataframe
2025-12-12 15:04:57,331:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-12 15:04:57,334:INFO:Initializing create_model()
2025-12-12 15:04:57,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:04:57,334:INFO:Checking exceptions
2025-12-12 15:04:57,335:INFO:Importing libraries
2025-12-12 15:04:57,335:INFO:Copying training dataset
2025-12-12 15:04:57,339:INFO:Defining folds
2025-12-12 15:04:57,339:INFO:Declaring metric variables
2025-12-12 15:04:57,339:INFO:Importing untrained model
2025-12-12 15:04:57,339:INFO:Declaring custom model
2025-12-12 15:04:57,339:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:04:57,339:INFO:Cross validation set to False
2025-12-12 15:04:57,339:INFO:Fitting Model
2025-12-12 15:04:57,366:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:04:57,367:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:04:57,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.
2025-12-12 15:04:57,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:04:57,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:04:57,368:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:04:57,368:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:04:57,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:04:57,749:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:04:57,750:INFO:create_model() successfully completed......................................
2025-12-12 15:04:57,861:INFO:_master_model_container: 90
2025-12-12 15:04:57,861:INFO:_display_container: 67
2025-12-12 15:04:57,862:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:04:57,862:INFO:compare_models() successfully completed......................................
2025-12-12 15:05:49,055:INFO:Initializing predict_model()
2025-12-12 15:05:49,058:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd0ea0>)
2025-12-12 15:05:49,058:INFO:Checking exceptions
2025-12-12 15:05:49,058:INFO:Preloading libraries
2025-12-12 15:05:49,134:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:05:49,391:INFO:Initializing predict_model()
2025-12-12 15:05:49,391:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fd120>)
2025-12-12 15:05:49,391:INFO:Checking exceptions
2025-12-12 15:05:49,391:INFO:Preloading libraries
2025-12-12 15:06:02,648:INFO:Initializing predict_model()
2025-12-12 15:06:02,648:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd19e0>)
2025-12-12 15:06:02,648:INFO:Checking exceptions
2025-12-12 15:06:02,648:INFO:Preloading libraries
2025-12-12 15:06:02,886:INFO:Initializing predict_model()
2025-12-12 15:06:02,886:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ff2e0>)
2025-12-12 15:06:02,887:INFO:Checking exceptions
2025-12-12 15:06:02,887:INFO:Preloading libraries
2025-12-12 15:06:17,038:INFO:Initializing predict_model()
2025-12-12 15:06:17,040:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.75, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd1d00>)
2025-12-12 15:06:17,040:INFO:Checking exceptions
2025-12-12 15:06:17,040:INFO:Preloading libraries
2025-12-12 15:06:17,099:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:06:17,304:INFO:Initializing predict_model()
2025-12-12 15:06:17,305:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fe2a0>)
2025-12-12 15:06:17,305:INFO:Checking exceptions
2025-12-12 15:06:17,305:INFO:Preloading libraries
2025-12-12 15:06:20,639:INFO:Initializing predict_model()
2025-12-12 15:06:20,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.1, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd36a0>)
2025-12-12 15:06:20,640:INFO:Checking exceptions
2025-12-12 15:06:20,640:INFO:Preloading libraries
2025-12-12 15:06:20,910:INFO:Initializing predict_model()
2025-12-12 15:06:20,911:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fd120>)
2025-12-12 15:06:20,911:INFO:Checking exceptions
2025-12-12 15:06:20,911:INFO:Preloading libraries
2025-12-12 15:06:25,036:INFO:Initializing predict_model()
2025-12-12 15:06:25,036:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.2, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd39c0>)
2025-12-12 15:06:25,036:INFO:Checking exceptions
2025-12-12 15:06:25,037:INFO:Preloading libraries
2025-12-12 15:06:25,283:INFO:Initializing predict_model()
2025-12-12 15:06:25,283:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ffc40>)
2025-12-12 15:06:25,283:INFO:Checking exceptions
2025-12-12 15:06:25,283:INFO:Preloading libraries
2025-12-12 15:06:28,291:INFO:Initializing predict_model()
2025-12-12 15:06:28,292:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.3, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3e20>)
2025-12-12 15:06:28,292:INFO:Checking exceptions
2025-12-12 15:06:28,292:INFO:Preloading libraries
2025-12-12 15:06:28,554:INFO:Initializing predict_model()
2025-12-12 15:06:28,555:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ff2e0>)
2025-12-12 15:06:28,555:INFO:Checking exceptions
2025-12-12 15:06:28,555:INFO:Preloading libraries
2025-12-12 15:06:30,559:INFO:Initializing predict_model()
2025-12-12 15:06:30,560:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.4, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd1d00>)
2025-12-12 15:06:30,560:INFO:Checking exceptions
2025-12-12 15:06:30,560:INFO:Preloading libraries
2025-12-12 15:06:30,920:INFO:Initializing predict_model()
2025-12-12 15:06:30,921:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ffc40>)
2025-12-12 15:06:30,921:INFO:Checking exceptions
2025-12-12 15:06:30,921:INFO:Preloading libraries
2025-12-12 15:06:38,841:INFO:Initializing predict_model()
2025-12-12 15:06:38,842:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.45, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd2d40>)
2025-12-12 15:06:38,842:INFO:Checking exceptions
2025-12-12 15:06:38,842:INFO:Preloading libraries
2025-12-12 15:06:39,174:INFO:Initializing predict_model()
2025-12-12 15:06:39,175:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ff2e0>)
2025-12-12 15:06:39,175:INFO:Checking exceptions
2025-12-12 15:06:39,175:INFO:Preloading libraries
2025-12-12 15:06:43,058:INFO:Initializing predict_model()
2025-12-12 15:06:43,058:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.46, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3e20>)
2025-12-12 15:06:43,058:INFO:Checking exceptions
2025-12-12 15:06:43,058:INFO:Preloading libraries
2025-12-12 15:06:43,319:INFO:Initializing predict_model()
2025-12-12 15:06:43,319:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fefc0>)
2025-12-12 15:06:43,319:INFO:Checking exceptions
2025-12-12 15:06:43,319:INFO:Preloading libraries
2025-12-12 15:06:48,022:INFO:Initializing predict_model()
2025-12-12 15:06:48,023:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.47, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd2ca0>)
2025-12-12 15:06:48,023:INFO:Checking exceptions
2025-12-12 15:06:48,024:INFO:Preloading libraries
2025-12-12 15:06:48,264:INFO:Initializing predict_model()
2025-12-12 15:06:48,264:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ffa60>)
2025-12-12 15:06:48,264:INFO:Checking exceptions
2025-12-12 15:06:48,265:INFO:Preloading libraries
2025-12-12 15:06:56,975:INFO:Initializing predict_model()
2025-12-12 15:06:56,976:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.46, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd1da0>)
2025-12-12 15:06:56,977:INFO:Checking exceptions
2025-12-12 15:06:56,977:INFO:Preloading libraries
2025-12-12 15:06:57,219:INFO:Initializing predict_model()
2025-12-12 15:06:57,219:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fe7a0>)
2025-12-12 15:06:57,219:INFO:Checking exceptions
2025-12-12 15:06:57,219:INFO:Preloading libraries
2025-12-12 15:07:00,081:INFO:Initializing predict_model()
2025-12-12 15:07:00,081:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.45, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd1ee0>)
2025-12-12 15:07:00,081:INFO:Checking exceptions
2025-12-12 15:07:00,081:INFO:Preloading libraries
2025-12-12 15:07:00,240:INFO:Initializing predict_model()
2025-12-12 15:07:00,240:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x319e6dc60>)
2025-12-12 15:07:00,240:INFO:Checking exceptions
2025-12-12 15:07:00,240:INFO:Preloading libraries
2025-12-12 15:07:01,677:INFO:Initializing predict_model()
2025-12-12 15:07:01,678:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.44, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd0e00>)
2025-12-12 15:07:01,678:INFO:Checking exceptions
2025-12-12 15:07:01,678:INFO:Preloading libraries
2025-12-12 15:07:01,948:INFO:Initializing predict_model()
2025-12-12 15:07:01,948:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fef20>)
2025-12-12 15:07:01,948:INFO:Checking exceptions
2025-12-12 15:07:01,948:INFO:Preloading libraries
2025-12-12 15:07:03,326:INFO:Initializing predict_model()
2025-12-12 15:07:03,327:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.43, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3600>)
2025-12-12 15:07:03,327:INFO:Checking exceptions
2025-12-12 15:07:03,327:INFO:Preloading libraries
2025-12-12 15:07:03,492:INFO:Initializing predict_model()
2025-12-12 15:07:03,492:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3600>)
2025-12-12 15:07:03,492:INFO:Checking exceptions
2025-12-12 15:07:03,492:INFO:Preloading libraries
2025-12-12 15:07:05,918:INFO:Initializing predict_model()
2025-12-12 15:07:05,919:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.42, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd2d40>)
2025-12-12 15:07:05,919:INFO:Checking exceptions
2025-12-12 15:07:05,920:INFO:Preloading libraries
2025-12-12 15:07:06,136:INFO:Initializing predict_model()
2025-12-12 15:07:06,137:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3600>)
2025-12-12 15:07:06,137:INFO:Checking exceptions
2025-12-12 15:07:06,137:INFO:Preloading libraries
2025-12-12 15:07:09,526:INFO:Initializing predict_model()
2025-12-12 15:07:09,527:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.43, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd2d40>)
2025-12-12 15:07:09,527:INFO:Checking exceptions
2025-12-12 15:07:09,527:INFO:Preloading libraries
2025-12-12 15:07:09,808:INFO:Initializing predict_model()
2025-12-12 15:07:09,808:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd3600>)
2025-12-12 15:07:09,808:INFO:Checking exceptions
2025-12-12 15:07:09,808:INFO:Preloading libraries
2025-12-12 15:07:11,095:INFO:Initializing predict_model()
2025-12-12 15:07:11,096:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.44, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e04a0>)
2025-12-12 15:07:11,096:INFO:Checking exceptions
2025-12-12 15:07:11,096:INFO:Preloading libraries
2025-12-12 15:07:11,248:INFO:Initializing predict_model()
2025-12-12 15:07:11,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c352980>)
2025-12-12 15:07:11,249:INFO:Checking exceptions
2025-12-12 15:07:11,249:INFO:Preloading libraries
2025-12-12 15:07:12,291:INFO:Initializing predict_model()
2025-12-12 15:07:12,292:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.45, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e00e0>)
2025-12-12 15:07:12,292:INFO:Checking exceptions
2025-12-12 15:07:12,292:INFO:Preloading libraries
2025-12-12 15:07:12,584:INFO:Initializing predict_model()
2025-12-12 15:07:12,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ff2e0>)
2025-12-12 15:07:12,584:INFO:Checking exceptions
2025-12-12 15:07:12,584:INFO:Preloading libraries
2025-12-12 15:07:15,539:INFO:Initializing predict_model()
2025-12-12 15:07:15,540:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.46, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0540>)
2025-12-12 15:07:15,540:INFO:Checking exceptions
2025-12-12 15:07:15,540:INFO:Preloading libraries
2025-12-12 15:07:15,813:INFO:Initializing predict_model()
2025-12-12 15:07:15,813:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2fd120>)
2025-12-12 15:07:15,813:INFO:Checking exceptions
2025-12-12 15:07:15,813:INFO:Preloading libraries
2025-12-12 15:07:17,371:INFO:Initializing predict_model()
2025-12-12 15:07:17,371:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.46, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0f40>)
2025-12-12 15:07:17,372:INFO:Checking exceptions
2025-12-12 15:07:17,372:INFO:Preloading libraries
2025-12-12 15:07:17,525:INFO:Initializing predict_model()
2025-12-12 15:07:17,525:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31dfd1580>)
2025-12-12 15:07:17,525:INFO:Checking exceptions
2025-12-12 15:07:17,526:INFO:Preloading libraries
2025-12-12 15:07:18,511:INFO:Initializing predict_model()
2025-12-12 15:07:18,512:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.47, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0040>)
2025-12-12 15:07:18,512:INFO:Checking exceptions
2025-12-12 15:07:18,512:INFO:Preloading libraries
2025-12-12 15:07:18,693:INFO:Initializing predict_model()
2025-12-12 15:07:18,693:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31f2ffa60>)
2025-12-12 15:07:18,693:INFO:Checking exceptions
2025-12-12 15:07:18,694:INFO:Preloading libraries
2025-12-12 15:07:20,395:INFO:Initializing predict_model()
2025-12-12 15:07:20,395:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.6, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0540>)
2025-12-12 15:07:20,395:INFO:Checking exceptions
2025-12-12 15:07:20,395:INFO:Preloading libraries
2025-12-12 15:07:20,430:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:07:20,545:INFO:Initializing predict_model()
2025-12-12 15:07:20,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0540>)
2025-12-12 15:07:20,545:INFO:Checking exceptions
2025-12-12 15:07:20,545:INFO:Preloading libraries
2025-12-12 15:07:22,405:INFO:Initializing predict_model()
2025-12-12 15:07:22,406:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1120>)
2025-12-12 15:07:22,406:INFO:Checking exceptions
2025-12-12 15:07:22,406:INFO:Preloading libraries
2025-12-12 15:07:22,674:INFO:Initializing predict_model()
2025-12-12 15:07:22,674:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1120>)
2025-12-12 15:07:22,674:INFO:Checking exceptions
2025-12-12 15:07:22,674:INFO:Preloading libraries
2025-12-12 15:07:28,512:INFO:Initializing predict_model()
2025-12-12 15:07:28,514:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.49, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1300>)
2025-12-12 15:07:28,514:INFO:Checking exceptions
2025-12-12 15:07:28,514:INFO:Preloading libraries
2025-12-12 15:07:28,811:INFO:Initializing predict_model()
2025-12-12 15:07:28,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1300>)
2025-12-12 15:07:28,811:INFO:Checking exceptions
2025-12-12 15:07:28,811:INFO:Preloading libraries
2025-12-12 15:07:32,866:INFO:Initializing predict_model()
2025-12-12 15:07:32,867:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.495, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1c60>)
2025-12-12 15:07:32,867:INFO:Checking exceptions
2025-12-12 15:07:32,867:INFO:Preloading libraries
2025-12-12 15:07:33,117:INFO:Initializing predict_model()
2025-12-12 15:07:33,117:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1c60>)
2025-12-12 15:07:33,117:INFO:Checking exceptions
2025-12-12 15:07:33,117:INFO:Preloading libraries
2025-12-12 15:07:36,198:INFO:Initializing predict_model()
2025-12-12 15:07:36,199:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0f40>)
2025-12-12 15:07:36,199:INFO:Checking exceptions
2025-12-12 15:07:36,199:INFO:Preloading libraries
2025-12-12 15:07:36,471:INFO:Initializing predict_model()
2025-12-12 15:07:36,471:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e0f40>)
2025-12-12 15:07:36,471:INFO:Checking exceptions
2025-12-12 15:07:36,471:INFO:Preloading libraries
2025-12-12 15:07:38,901:INFO:Initializing predict_model()
2025-12-12 15:07:38,901:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.51, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1ee0>)
2025-12-12 15:07:38,902:INFO:Checking exceptions
2025-12-12 15:07:38,902:INFO:Preloading libraries
2025-12-12 15:07:38,942:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:07:39,163:INFO:Initializing predict_model()
2025-12-12 15:07:39,163:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1ee0>)
2025-12-12 15:07:39,163:INFO:Checking exceptions
2025-12-12 15:07:39,163:INFO:Preloading libraries
2025-12-12 15:07:43,297:INFO:Initializing predict_model()
2025-12-12 15:07:43,297:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.505, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1c60>)
2025-12-12 15:07:43,298:INFO:Checking exceptions
2025-12-12 15:07:43,298:INFO:Preloading libraries
2025-12-12 15:07:43,346:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:07:43,522:INFO:Initializing predict_model()
2025-12-12 15:07:43,522:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1c60>)
2025-12-12 15:07:43,522:INFO:Checking exceptions
2025-12-12 15:07:43,522:INFO:Preloading libraries
2025-12-12 15:07:44,928:INFO:Initializing predict_model()
2025-12-12 15:07:44,928:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e04a0>)
2025-12-12 15:07:44,929:INFO:Checking exceptions
2025-12-12 15:07:44,929:INFO:Preloading libraries
2025-12-12 15:07:45,173:INFO:Initializing predict_model()
2025-12-12 15:07:45,173:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e04a0>)
2025-12-12 15:07:45,173:INFO:Checking exceptions
2025-12-12 15:07:45,173:INFO:Preloading libraries
2025-12-12 15:07:53,073:INFO:Initializing predict_model()
2025-12-12 15:07:53,074:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.4955, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1f80>)
2025-12-12 15:07:53,075:INFO:Checking exceptions
2025-12-12 15:07:53,075:INFO:Preloading libraries
2025-12-12 15:07:53,314:INFO:Initializing predict_model()
2025-12-12 15:07:53,315:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1f80>)
2025-12-12 15:07:53,315:INFO:Checking exceptions
2025-12-12 15:07:53,315:INFO:Preloading libraries
2025-12-12 15:07:55,892:INFO:Initializing predict_model()
2025-12-12 15:07:55,893:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.49, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1b20>)
2025-12-12 15:07:55,893:INFO:Checking exceptions
2025-12-12 15:07:55,893:INFO:Preloading libraries
2025-12-12 15:07:56,142:INFO:Initializing predict_model()
2025-12-12 15:07:56,142:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e1b20>)
2025-12-12 15:07:56,142:INFO:Checking exceptions
2025-12-12 15:07:56,142:INFO:Preloading libraries
2025-12-12 15:07:58,198:INFO:Initializing predict_model()
2025-12-12 15:07:58,199:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.48, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e2f20>)
2025-12-12 15:07:58,199:INFO:Checking exceptions
2025-12-12 15:07:58,199:INFO:Preloading libraries
2025-12-12 15:07:58,355:INFO:Initializing predict_model()
2025-12-12 15:07:58,355:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e2f20>)
2025-12-12 15:07:58,355:INFO:Checking exceptions
2025-12-12 15:07:58,355:INFO:Preloading libraries
2025-12-12 15:08:00,836:INFO:Initializing predict_model()
2025-12-12 15:08:00,837:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.47, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e31a0>)
2025-12-12 15:08:00,837:INFO:Checking exceptions
2025-12-12 15:08:00,837:INFO:Preloading libraries
2025-12-12 15:08:01,094:INFO:Initializing predict_model()
2025-12-12 15:08:01,094:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e31a0>)
2025-12-12 15:08:01,094:INFO:Checking exceptions
2025-12-12 15:08:01,094:INFO:Preloading libraries
2025-12-12 15:08:04,193:INFO:Initializing predict_model()
2025-12-12 15:08:04,193:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.6, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e2ca0>)
2025-12-12 15:08:04,194:INFO:Checking exceptions
2025-12-12 15:08:04,194:INFO:Preloading libraries
2025-12-12 15:08:04,266:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:08:04,501:INFO:Initializing predict_model()
2025-12-12 15:08:04,501:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e2ca0>)
2025-12-12 15:08:04,501:INFO:Checking exceptions
2025-12-12 15:08:04,501:INFO:Preloading libraries
2025-12-12 15:08:06,087:INFO:Initializing predict_model()
2025-12-12 15:08:06,087:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.7, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e32e0>)
2025-12-12 15:08:06,088:INFO:Checking exceptions
2025-12-12 15:08:06,088:INFO:Preloading libraries
2025-12-12 15:08:06,252:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-12 15:08:06,451:INFO:Initializing predict_model()
2025-12-12 15:08:06,451:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e32e0>)
2025-12-12 15:08:06,452:INFO:Checking exceptions
2025-12-12 15:08:06,452:INFO:Preloading libraries
2025-12-12 15:08:09,871:INFO:Initializing predict_model()
2025-12-12 15:08:09,872:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e3600>)
2025-12-12 15:08:09,872:INFO:Checking exceptions
2025-12-12 15:08:09,872:INFO:Preloading libraries
2025-12-12 15:08:10,134:INFO:Initializing predict_model()
2025-12-12 15:08:10,134:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e3600>)
2025-12-12 15:08:10,134:INFO:Checking exceptions
2025-12-12 15:08:10,134:INFO:Preloading libraries
2025-12-12 15:08:12,530:INFO:Initializing predict_model()
2025-12-12 15:08:12,530:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0001, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=220, n_jobs=-1, num_leaves=2, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=0.01, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=0.5, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e3a60>)
2025-12-12 15:08:12,530:INFO:Checking exceptions
2025-12-12 15:08:12,530:INFO:Preloading libraries
2025-12-12 15:08:13,023:INFO:Initializing predict_model()
2025-12-12 15:08:13,023:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.01,
                   n_estimators=110, random_state=42), probability_threshold=0.65, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31c4e3a60>)
2025-12-12 15:08:13,023:INFO:Checking exceptions
2025-12-12 15:08:13,023:INFO:Preloading libraries
2025-12-12 15:08:57,135:INFO:Initializing compare_models()
2025-12-12 15:08:57,139:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, include=['lr', 'qda', 'lightgbm', 'ada'], exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, 'include': ['lr', 'qda', 'lightgbm', 'ada'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-12-12 15:08:57,140:INFO:Checking exceptions
2025-12-12 15:08:57,183:INFO:Preparing display monitor
2025-12-12 15:08:57,214:INFO:Initializing Logistic Regression
2025-12-12 15:08:57,215:INFO:Total runtime is 5.563100179036458e-06 minutes
2025-12-12 15:08:57,217:INFO:SubProcess create_model() called ==================================
2025-12-12 15:08:57,219:INFO:Initializing create_model()
2025-12-12 15:08:57,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e1be9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:08:57,220:INFO:Checking exceptions
2025-12-12 15:08:57,220:INFO:Importing libraries
2025-12-12 15:08:57,220:INFO:Copying training dataset
2025-12-12 15:08:57,232:INFO:Defining folds
2025-12-12 15:08:57,232:INFO:Declaring metric variables
2025-12-12 15:08:57,233:INFO:Importing untrained model
2025-12-12 15:08:57,235:INFO:Logistic Regression Imported successfully
2025-12-12 15:08:57,240:INFO:Starting cross validation
2025-12-12 15:08:57,248:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:08:57,411:INFO:Calculating mean and std
2025-12-12 15:08:57,411:INFO:Creating metrics dataframe
2025-12-12 15:08:57,413:INFO:Uploading results into container
2025-12-12 15:08:57,414:INFO:Uploading model into container now
2025-12-12 15:08:57,414:INFO:_master_model_container: 91
2025-12-12 15:08:57,414:INFO:_display_container: 142
2025-12-12 15:08:57,414:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:08:57,414:INFO:create_model() successfully completed......................................
2025-12-12 15:08:57,673:INFO:SubProcess create_model() end ==================================
2025-12-12 15:08:57,673:INFO:Creating metrics dataframe
2025-12-12 15:08:57,676:INFO:Initializing Quadratic Discriminant Analysis
2025-12-12 15:08:57,676:INFO:Total runtime is 0.007688466707865397 minutes
2025-12-12 15:08:57,677:INFO:SubProcess create_model() called ==================================
2025-12-12 15:08:57,677:INFO:Initializing create_model()
2025-12-12 15:08:57,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e1be9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:08:57,677:INFO:Checking exceptions
2025-12-12 15:08:57,677:INFO:Importing libraries
2025-12-12 15:08:57,677:INFO:Copying training dataset
2025-12-12 15:08:57,680:INFO:Defining folds
2025-12-12 15:08:57,680:INFO:Declaring metric variables
2025-12-12 15:08:57,681:INFO:Importing untrained model
2025-12-12 15:08:57,682:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:08:57,684:INFO:Starting cross validation
2025-12-12 15:08:57,684:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:08:57,895:INFO:Calculating mean and std
2025-12-12 15:08:57,896:INFO:Creating metrics dataframe
2025-12-12 15:08:57,897:INFO:Uploading results into container
2025-12-12 15:08:57,897:INFO:Uploading model into container now
2025-12-12 15:08:57,897:INFO:_master_model_container: 92
2025-12-12 15:08:57,897:INFO:_display_container: 142
2025-12-12 15:08:57,898:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:08:57,898:INFO:create_model() successfully completed......................................
2025-12-12 15:08:58,001:INFO:SubProcess create_model() end ==================================
2025-12-12 15:08:58,001:INFO:Creating metrics dataframe
2025-12-12 15:08:58,004:INFO:Initializing Light Gradient Boosting Machine
2025-12-12 15:08:58,005:INFO:Total runtime is 0.013169248898824055 minutes
2025-12-12 15:08:58,006:INFO:SubProcess create_model() called ==================================
2025-12-12 15:08:58,006:INFO:Initializing create_model()
2025-12-12 15:08:58,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e1be9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:08:58,006:INFO:Checking exceptions
2025-12-12 15:08:58,006:INFO:Importing libraries
2025-12-12 15:08:58,006:INFO:Copying training dataset
2025-12-12 15:08:58,009:INFO:Defining folds
2025-12-12 15:08:58,009:INFO:Declaring metric variables
2025-12-12 15:08:58,010:INFO:Importing untrained model
2025-12-12 15:08:58,011:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:08:58,013:INFO:Starting cross validation
2025-12-12 15:08:58,013:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:08:59,491:INFO:Calculating mean and std
2025-12-12 15:08:59,491:INFO:Creating metrics dataframe
2025-12-12 15:08:59,492:INFO:Uploading results into container
2025-12-12 15:08:59,493:INFO:Uploading model into container now
2025-12-12 15:08:59,493:INFO:_master_model_container: 93
2025-12-12 15:08:59,493:INFO:_display_container: 142
2025-12-12 15:08:59,493:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:08:59,493:INFO:create_model() successfully completed......................................
2025-12-12 15:08:59,628:INFO:SubProcess create_model() end ==================================
2025-12-12 15:08:59,628:INFO:Creating metrics dataframe
2025-12-12 15:08:59,631:INFO:Initializing Ada Boost Classifier
2025-12-12 15:08:59,631:INFO:Total runtime is 0.04027576843897501 minutes
2025-12-12 15:08:59,632:INFO:SubProcess create_model() called ==================================
2025-12-12 15:08:59,632:INFO:Initializing create_model()
2025-12-12 15:08:59,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e1be9d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:08:59,633:INFO:Checking exceptions
2025-12-12 15:08:59,633:INFO:Importing libraries
2025-12-12 15:08:59,633:INFO:Copying training dataset
2025-12-12 15:08:59,635:INFO:Defining folds
2025-12-12 15:08:59,636:INFO:Declaring metric variables
2025-12-12 15:08:59,637:INFO:Importing untrained model
2025-12-12 15:08:59,638:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:08:59,640:INFO:Starting cross validation
2025-12-12 15:08:59,641:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:08:59,688:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:08:59,691:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:08:59,693:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:08:59,697:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:08:59,701:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:08:59,803:INFO:Calculating mean and std
2025-12-12 15:08:59,803:INFO:Creating metrics dataframe
2025-12-12 15:08:59,804:INFO:Uploading results into container
2025-12-12 15:08:59,804:INFO:Uploading model into container now
2025-12-12 15:08:59,804:INFO:_master_model_container: 94
2025-12-12 15:08:59,804:INFO:_display_container: 142
2025-12-12 15:08:59,804:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:08:59,804:INFO:create_model() successfully completed......................................
2025-12-12 15:08:59,909:INFO:SubProcess create_model() end ==================================
2025-12-12 15:08:59,909:INFO:Creating metrics dataframe
2025-12-12 15:08:59,911:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-12-12 15:08:59,916:INFO:Initializing create_model()
2025-12-12 15:08:59,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:08:59,916:INFO:Checking exceptions
2025-12-12 15:08:59,917:INFO:Importing libraries
2025-12-12 15:08:59,917:INFO:Copying training dataset
2025-12-12 15:08:59,919:INFO:Defining folds
2025-12-12 15:08:59,919:INFO:Declaring metric variables
2025-12-12 15:08:59,919:INFO:Importing untrained model
2025-12-12 15:08:59,919:INFO:Declaring custom model
2025-12-12 15:08:59,919:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:08:59,920:INFO:Cross validation set to False
2025-12-12 15:08:59,920:INFO:Fitting Model
2025-12-12 15:08:59,944:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:08:59,945:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:08:59,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.
2025-12-12 15:08:59,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:08:59,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:08:59,946:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:08:59,946:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:08:59,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:09:00,315:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:09:00,315:INFO:create_model() successfully completed......................................
2025-12-12 15:09:00,425:INFO:_master_model_container: 94
2025-12-12 15:09:00,425:INFO:_display_container: 142
2025-12-12 15:09:00,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:09:00,425:INFO:compare_models() successfully completed......................................
2025-12-12 15:10:25,273:INFO:Initializing plot_model()
2025-12-12 15:10:25,274:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-12-12 15:10:25,274:INFO:Checking exceptions
2025-12-12 15:10:25,285:INFO:Preloading libraries
2025-12-12 15:10:25,286:INFO:Copying training dataset
2025-12-12 15:10:25,286:INFO:Plot type: pr
2025-12-12 15:10:25,333:INFO:Fitting Model
2025-12-12 15:10:25,333:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but QuadraticDiscriminantAnalysis was fitted with feature names
  warnings.warn(

2025-12-12 15:10:25,334:INFO:Scoring test/hold-out set
2025-12-12 15:10:25,419:INFO:Visual Rendered Successfully
2025-12-12 15:10:25,629:INFO:plot_model() successfully completed......................................
2025-12-12 15:16:01,797:INFO:Initializing tune_model()
2025-12-12 15:16:01,799:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=40, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:16:01,799:INFO:Checking exceptions
2025-12-12 15:16:01,849:INFO:Copying training dataset
2025-12-12 15:16:01,854:INFO:Checking base model
2025-12-12 15:16:01,854:INFO:Base model : Logistic Regression
2025-12-12 15:16:01,856:INFO:Declaring metric variables
2025-12-12 15:16:01,860:INFO:Defining Hyperparameters
2025-12-12 15:16:02,118:INFO:Tuning with n_jobs=-1
2025-12-12 15:16:02,118:INFO:Initializing RandomizedSearchCV
2025-12-12 15:16:07,925:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,926:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,927:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,927:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,928:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,930:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,930:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:07,931:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-12 15:16:10,089:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.634}
2025-12-12 15:16:10,099:INFO:Hyperparameter search completed
2025-12-12 15:16:10,100:INFO:SubProcess create_model() called ==================================
2025-12-12 15:16:10,101:INFO:Initializing create_model()
2025-12-12 15:16:10,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c650a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 0.634})
2025-12-12 15:16:10,101:INFO:Checking exceptions
2025-12-12 15:16:10,101:INFO:Importing libraries
2025-12-12 15:16:10,101:INFO:Copying training dataset
2025-12-12 15:16:10,110:INFO:Defining folds
2025-12-12 15:16:10,110:INFO:Declaring metric variables
2025-12-12 15:16:10,117:INFO:Importing untrained model
2025-12-12 15:16:10,117:INFO:Declaring custom model
2025-12-12 15:16:10,122:INFO:Logistic Regression Imported successfully
2025-12-12 15:16:10,124:INFO:Starting cross validation
2025-12-12 15:16:10,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:16:10,341:INFO:Calculating mean and std
2025-12-12 15:16:10,343:INFO:Creating metrics dataframe
2025-12-12 15:16:10,349:INFO:Finalizing model
2025-12-12 15:16:10,477:INFO:Uploading results into container
2025-12-12 15:16:10,479:INFO:Uploading model into container now
2025-12-12 15:16:10,480:INFO:_master_model_container: 95
2025-12-12 15:16:10,480:INFO:_display_container: 143
2025-12-12 15:16:10,480:INFO:LogisticRegression(C=0.634, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:16:10,480:INFO:create_model() successfully completed......................................
2025-12-12 15:16:10,869:INFO:SubProcess create_model() end ==================================
2025-12-12 15:16:10,869:INFO:choose_better activated
2025-12-12 15:16:10,871:INFO:SubProcess create_model() called ==================================
2025-12-12 15:16:10,871:INFO:Initializing create_model()
2025-12-12 15:16:10,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:16:10,873:INFO:Checking exceptions
2025-12-12 15:16:10,875:INFO:Importing libraries
2025-12-12 15:16:10,875:INFO:Copying training dataset
2025-12-12 15:16:10,880:INFO:Defining folds
2025-12-12 15:16:10,881:INFO:Declaring metric variables
2025-12-12 15:16:10,881:INFO:Importing untrained model
2025-12-12 15:16:10,881:INFO:Declaring custom model
2025-12-12 15:16:10,881:INFO:Logistic Regression Imported successfully
2025-12-12 15:16:10,881:INFO:Starting cross validation
2025-12-12 15:16:10,882:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:16:11,025:INFO:Calculating mean and std
2025-12-12 15:16:11,025:INFO:Creating metrics dataframe
2025-12-12 15:16:11,026:INFO:Finalizing model
2025-12-12 15:16:11,533:INFO:Uploading results into container
2025-12-12 15:16:11,536:INFO:Uploading model into container now
2025-12-12 15:16:11,540:INFO:_master_model_container: 96
2025-12-12 15:16:11,540:INFO:_display_container: 144
2025-12-12 15:16:11,549:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:16:11,549:INFO:create_model() successfully completed......................................
2025-12-12 15:16:11,877:INFO:SubProcess create_model() end ==================================
2025-12-12 15:16:11,877:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Prec. is 0.5283
2025-12-12 15:16:11,877:INFO:LogisticRegression(C=0.634, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Prec. is 0.5285
2025-12-12 15:16:11,877:INFO:LogisticRegression(C=0.634, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-12-12 15:16:11,877:INFO:choose_better completed
2025-12-12 15:16:11,886:INFO:_master_model_container: 96
2025-12-12 15:16:11,886:INFO:_display_container: 143
2025-12-12 15:16:11,886:INFO:LogisticRegression(C=0.634, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-12 15:16:11,886:INFO:tune_model() successfully completed......................................
2025-12-12 15:16:12,018:INFO:Initializing tune_model()
2025-12-12 15:16:12,019:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:16:12,019:INFO:Checking exceptions
2025-12-12 15:16:12,027:INFO:Copying training dataset
2025-12-12 15:16:12,036:INFO:Checking base model
2025-12-12 15:16:12,036:INFO:Base model : Quadratic Discriminant Analysis
2025-12-12 15:16:12,041:INFO:Declaring metric variables
2025-12-12 15:16:12,044:INFO:Defining Hyperparameters
2025-12-12 15:16:12,172:INFO:Tuning with n_jobs=-1
2025-12-12 15:16:12,172:INFO:Initializing RandomizedSearchCV
2025-12-12 15:16:13,098:INFO:best_params: {'actual_estimator__reg_param': 0.02}
2025-12-12 15:16:13,099:INFO:Hyperparameter search completed
2025-12-12 15:16:13,100:INFO:SubProcess create_model() called ==================================
2025-12-12 15:16:13,100:INFO:Initializing create_model()
2025-12-12 15:16:13,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31c6e6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.02})
2025-12-12 15:16:13,100:INFO:Checking exceptions
2025-12-12 15:16:13,100:INFO:Importing libraries
2025-12-12 15:16:13,100:INFO:Copying training dataset
2025-12-12 15:16:13,106:INFO:Defining folds
2025-12-12 15:16:13,106:INFO:Declaring metric variables
2025-12-12 15:16:13,108:INFO:Importing untrained model
2025-12-12 15:16:13,108:INFO:Declaring custom model
2025-12-12 15:16:13,109:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:16:13,111:INFO:Starting cross validation
2025-12-12 15:16:13,113:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:16:13,178:INFO:Calculating mean and std
2025-12-12 15:16:13,178:INFO:Creating metrics dataframe
2025-12-12 15:16:13,180:INFO:Finalizing model
2025-12-12 15:16:13,267:INFO:Uploading results into container
2025-12-12 15:16:13,268:INFO:Uploading model into container now
2025-12-12 15:16:13,269:INFO:_master_model_container: 97
2025-12-12 15:16:13,269:INFO:_display_container: 144
2025-12-12 15:16:13,269:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.02,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:16:13,269:INFO:create_model() successfully completed......................................
2025-12-12 15:16:13,585:INFO:SubProcess create_model() end ==================================
2025-12-12 15:16:13,586:INFO:choose_better activated
2025-12-12 15:16:13,590:INFO:SubProcess create_model() called ==================================
2025-12-12 15:16:13,590:INFO:Initializing create_model()
2025-12-12 15:16:13,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:16:13,590:INFO:Checking exceptions
2025-12-12 15:16:13,592:INFO:Importing libraries
2025-12-12 15:16:13,593:INFO:Copying training dataset
2025-12-12 15:16:13,596:INFO:Defining folds
2025-12-12 15:16:13,596:INFO:Declaring metric variables
2025-12-12 15:16:13,596:INFO:Importing untrained model
2025-12-12 15:16:13,596:INFO:Declaring custom model
2025-12-12 15:16:13,597:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-12 15:16:13,597:INFO:Starting cross validation
2025-12-12 15:16:13,597:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:16:13,697:INFO:Calculating mean and std
2025-12-12 15:16:13,698:INFO:Creating metrics dataframe
2025-12-12 15:16:13,699:INFO:Finalizing model
2025-12-12 15:16:13,740:INFO:Uploading results into container
2025-12-12 15:16:13,740:INFO:Uploading model into container now
2025-12-12 15:16:13,740:INFO:_master_model_container: 98
2025-12-12 15:16:13,741:INFO:_display_container: 145
2025-12-12 15:16:13,741:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:16:13,741:INFO:create_model() successfully completed......................................
2025-12-12 15:16:13,935:INFO:SubProcess create_model() end ==================================
2025-12-12 15:16:13,935:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Prec. is 0.5302
2025-12-12 15:16:13,935:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.02,
                              store_covariance=False, tol=0.0001) result for Prec. is 0.5295
2025-12-12 15:16:13,935:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2025-12-12 15:16:13,935:INFO:choose_better completed
2025-12-12 15:16:13,936:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-12 15:16:13,980:INFO:_master_model_container: 98
2025-12-12 15:16:13,981:INFO:_display_container: 144
2025-12-12 15:16:13,981:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-12 15:16:13,981:INFO:tune_model() successfully completed......................................
2025-12-12 15:16:14,128:INFO:Initializing tune_model()
2025-12-12 15:16:14,128:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=60, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:16:14,128:INFO:Checking exceptions
2025-12-12 15:16:14,134:INFO:Copying training dataset
2025-12-12 15:16:14,140:INFO:Checking base model
2025-12-12 15:16:14,140:INFO:Base model : Light Gradient Boosting Machine
2025-12-12 15:16:14,142:INFO:Declaring metric variables
2025-12-12 15:16:14,143:INFO:Defining Hyperparameters
2025-12-12 15:16:14,280:INFO:Tuning with n_jobs=-1
2025-12-12 15:16:14,280:INFO:Initializing RandomizedSearchCV
2025-12-12 15:17:13,353:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 6, 'actual_estimator__n_estimators': 40, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 1.0}
2025-12-12 15:17:13,372:INFO:Hyperparameter search completed
2025-12-12 15:17:13,372:INFO:SubProcess create_model() called ==================================
2025-12-12 15:17:13,375:INFO:Initializing create_model()
2025-12-12 15:17:13,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f27e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 1, 'num_leaves': 6, 'n_estimators': 40, 'min_split_gain': 0.1, 'min_child_samples': 66, 'learning_rate': 0.001, 'feature_fraction': 0.7, 'bagging_freq': 0, 'bagging_fraction': 1.0})
2025-12-12 15:17:13,375:INFO:Checking exceptions
2025-12-12 15:17:13,376:INFO:Importing libraries
2025-12-12 15:17:13,376:INFO:Copying training dataset
2025-12-12 15:17:13,394:INFO:Defining folds
2025-12-12 15:17:13,394:INFO:Declaring metric variables
2025-12-12 15:17:13,400:INFO:Importing untrained model
2025-12-12 15:17:13,401:INFO:Declaring custom model
2025-12-12 15:17:13,409:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:17:13,416:INFO:Starting cross validation
2025-12-12 15:17:13,418:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:17:14,002:INFO:Calculating mean and std
2025-12-12 15:17:14,004:INFO:Creating metrics dataframe
2025-12-12 15:17:14,010:INFO:Finalizing model
2025-12-12 15:17:14,044:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-12 15:17:14,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-12 15:17:14,044:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-12 15:17:14,060:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:17:14,060:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-12-12 15:17:14,060:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2025-12-12 15:17:14,060:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2025-12-12 15:17:14,061:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:17:14,064:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.
2025-12-12 15:17:14,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:17:14,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:17:14,064:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:17:14,064:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:17:14,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:17:14,104:INFO:Uploading results into container
2025-12-12 15:17:14,105:INFO:Uploading model into container now
2025-12-12 15:17:14,106:INFO:_master_model_container: 99
2025-12-12 15:17:14,106:INFO:_display_container: 145
2025-12-12 15:17:14,107:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=40, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:17:14,107:INFO:create_model() successfully completed......................................
2025-12-12 15:17:14,360:INFO:SubProcess create_model() end ==================================
2025-12-12 15:17:14,360:INFO:choose_better activated
2025-12-12 15:17:14,362:INFO:SubProcess create_model() called ==================================
2025-12-12 15:17:14,362:INFO:Initializing create_model()
2025-12-12 15:17:14,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:17:14,362:INFO:Checking exceptions
2025-12-12 15:17:14,363:INFO:Importing libraries
2025-12-12 15:17:14,363:INFO:Copying training dataset
2025-12-12 15:17:14,366:INFO:Defining folds
2025-12-12 15:17:14,366:INFO:Declaring metric variables
2025-12-12 15:17:14,366:INFO:Importing untrained model
2025-12-12 15:17:14,366:INFO:Declaring custom model
2025-12-12 15:17:14,366:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-12 15:17:14,366:INFO:Starting cross validation
2025-12-12 15:17:14,367:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:17:17,128:INFO:Calculating mean and std
2025-12-12 15:17:17,137:INFO:Creating metrics dataframe
2025-12-12 15:17:17,155:INFO:Finalizing model
2025-12-12 15:17:17,210:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-12-12 15:17:17,211:INFO:[LightGBM] [Info] Number of positive: 4139, number of negative: 4139
2025-12-12 15:17:17,212:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-12-12 15:17:17,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-12 15:17:17,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-12 15:17:17,212:INFO:[LightGBM] [Info] Total Bins 85
2025-12-12 15:17:17,212:INFO:[LightGBM] [Info] Number of data points in the train set: 8278, number of used features: 11
2025-12-12 15:17:17,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-12 15:17:17,589:INFO:Uploading results into container
2025-12-12 15:17:17,589:INFO:Uploading model into container now
2025-12-12 15:17:17,590:INFO:_master_model_container: 100
2025-12-12 15:17:17,590:INFO:_display_container: 146
2025-12-12 15:17:17,590:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:17:17,590:INFO:create_model() successfully completed......................................
2025-12-12 15:17:18,120:INFO:SubProcess create_model() end ==================================
2025-12-12 15:17:18,124:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.5302
2025-12-12 15:17:18,125:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=40, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Prec. is 0.5531
2025-12-12 15:17:18,125:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=40, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-12-12 15:17:18,125:INFO:choose_better completed
2025-12-12 15:17:18,182:INFO:_master_model_container: 100
2025-12-12 15:17:18,182:INFO:_display_container: 145
2025-12-12 15:17:18,183:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=40, n_jobs=-1, num_leaves=6, objective=None,
               random_state=42, reg_alpha=1, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-12 15:17:18,183:INFO:tune_model() successfully completed......................................
2025-12-12 15:17:18,499:INFO:Initializing tune_model()
2025-12-12 15:17:18,499:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Precision, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-12-12 15:17:18,499:INFO:Checking exceptions
2025-12-12 15:17:18,507:INFO:Copying training dataset
2025-12-12 15:17:18,511:INFO:Checking base model
2025-12-12 15:17:18,511:INFO:Base model : Ada Boost Classifier
2025-12-12 15:17:18,514:INFO:Declaring metric variables
2025-12-12 15:17:18,516:INFO:Defining Hyperparameters
2025-12-12 15:17:18,720:INFO:Tuning with n_jobs=-1
2025-12-12 15:17:18,720:INFO:Initializing RandomizedSearchCV
2025-12-12 15:17:34,602:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-12-12 15:17:34,605:INFO:Hyperparameter search completed
2025-12-12 15:17:34,605:INFO:SubProcess create_model() called ==================================
2025-12-12 15:17:34,606:INFO:Initializing create_model()
2025-12-12 15:17:34,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f2e2d50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-12-12 15:17:34,606:INFO:Checking exceptions
2025-12-12 15:17:34,606:INFO:Importing libraries
2025-12-12 15:17:34,607:INFO:Copying training dataset
2025-12-12 15:17:34,619:INFO:Defining folds
2025-12-12 15:17:34,619:INFO:Declaring metric variables
2025-12-12 15:17:34,623:INFO:Importing untrained model
2025-12-12 15:17:34,623:INFO:Declaring custom model
2025-12-12 15:17:34,629:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:17:34,631:INFO:Starting cross validation
2025-12-12 15:17:34,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:17:35,048:INFO:Calculating mean and std
2025-12-12 15:17:35,048:INFO:Creating metrics dataframe
2025-12-12 15:17:35,051:INFO:Finalizing model
2025-12-12 15:17:35,342:INFO:Uploading results into container
2025-12-12 15:17:35,342:INFO:Uploading model into container now
2025-12-12 15:17:35,342:INFO:_master_model_container: 101
2025-12-12 15:17:35,342:INFO:_display_container: 146
2025-12-12 15:17:35,343:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=200, random_state=42)
2025-12-12 15:17:35,343:INFO:create_model() successfully completed......................................
2025-12-12 15:17:35,557:INFO:SubProcess create_model() end ==================================
2025-12-12 15:17:35,557:INFO:choose_better activated
2025-12-12 15:17:35,558:INFO:SubProcess create_model() called ==================================
2025-12-12 15:17:35,559:INFO:Initializing create_model()
2025-12-12 15:17:35,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-12 15:17:35,559:INFO:Checking exceptions
2025-12-12 15:17:35,560:INFO:Importing libraries
2025-12-12 15:17:35,560:INFO:Copying training dataset
2025-12-12 15:17:35,562:INFO:Defining folds
2025-12-12 15:17:35,562:INFO:Declaring metric variables
2025-12-12 15:17:35,562:INFO:Importing untrained model
2025-12-12 15:17:35,562:INFO:Declaring custom model
2025-12-12 15:17:35,562:INFO:Ada Boost Classifier Imported successfully
2025-12-12 15:17:35,562:INFO:Starting cross validation
2025-12-12 15:17:35,563:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-12-12 15:17:35,638:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,640:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,644:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,647:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,652:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,763:INFO:Calculating mean and std
2025-12-12 15:17:35,763:INFO:Creating metrics dataframe
2025-12-12 15:17:35,765:INFO:Finalizing model
2025-12-12 15:17:35,784:WARNING:/opt/miniconda3/envs/churn_prediction/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-12-12 15:17:35,874:INFO:Uploading results into container
2025-12-12 15:17:35,874:INFO:Uploading model into container now
2025-12-12 15:17:35,875:INFO:_master_model_container: 102
2025-12-12 15:17:35,875:INFO:_display_container: 147
2025-12-12 15:17:35,875:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-12-12 15:17:35,875:INFO:create_model() successfully completed......................................
2025-12-12 15:17:35,981:INFO:SubProcess create_model() end ==================================
2025-12-12 15:17:35,981:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Prec. is 0.5301
2025-12-12 15:17:35,981:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=200, random_state=42) result for Prec. is 0.5364
2025-12-12 15:17:35,981:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=200, random_state=42) is best model
2025-12-12 15:17:35,981:INFO:choose_better completed
2025-12-12 15:17:35,987:INFO:_master_model_container: 102
2025-12-12 15:17:35,987:INFO:_display_container: 146
2025-12-12 15:17:35,987:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=200, random_state=42)
2025-12-12 15:17:35,987:INFO:tune_model() successfully completed......................................
2025-12-18 09:31:13,855:INFO:Initializing finalize_model()
2025-12-18 09:31:13,864:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-18 09:31:13,876:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-18 09:31:14,013:INFO:Initializing create_model()
2025-12-18 09:31:14,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x319cbc590>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-18 09:31:14,013:INFO:Checking exceptions
2025-12-18 09:31:14,127:INFO:Importing libraries
2025-12-18 09:31:14,127:INFO:Copying training dataset
2025-12-18 09:31:14,135:INFO:Defining folds
2025-12-18 09:31:14,137:INFO:Declaring metric variables
2025-12-18 09:31:14,137:INFO:Importing untrained model
2025-12-18 09:31:14,137:INFO:Declaring custom model
2025-12-18 09:31:14,143:INFO:Logistic Regression Imported successfully
2025-12-18 09:31:14,190:INFO:Cross validation set to False
2025-12-18 09:31:14,190:INFO:Fitting Model
2025-12-18 09:31:14,491:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-12-18 09:31:14,494:INFO:create_model() successfully completed......................................
2025-12-18 09:31:16,422:INFO:_master_model_container: 102
2025-12-18 09:31:16,422:INFO:_display_container: 146
2025-12-18 09:31:16,425:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-12-18 09:31:16,425:INFO:finalize_model() successfully completed......................................
2025-12-18 09:31:16,603:INFO:Initializing save_model()
2025-12-18 09:31:16,603:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=churn_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/6y/27y43kts0_v5lwz5yk6b0n4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-18 09:31:16,603:INFO:Adding model into prep_pipe
2025-12-18 09:31:16,603:WARNING:Only Model saved as it was a pipeline.
2025-12-18 09:31:16,607:INFO:churn_model.pkl saved in current working directory
2025-12-18 09:31:16,610:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['referred_a_friend', 'dependents',
                                             'senior_citizen',
                                             'number_of_referrals',
                                             'phone_service_x',
                                             'premium_tech_support', 'married',
                                             'married_senior'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              miss...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-12-18 09:31:16,610:INFO:save_model() successfully completed......................................
2025-12-18 09:32:17,838:INFO:Initializing load_model()
2025-12-18 09:32:17,839:INFO:load_model(model_name=churn_model, platform=None, authentication=None, verbose=True)
